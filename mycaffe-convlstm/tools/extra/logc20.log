I1223 00:14:22.023669 25375 caffe.cpp:218] Using GPUs 0
I1223 00:14:22.045802 25375 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I1223 00:14:22.268712 25375 solver.cpp:44] Initializing solver from parameters: 
test_iter: 86
test_interval: 650
base_lr: 1e-08
display: 50
max_iter: 30000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 650
snapshot_prefix: "/home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20"
solver_mode: GPU
device_id: 0
random_seed: 1701
net: "/home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/c20.prototxt"
train_state {
  level: 0
  stage: ""
}
test_state {
  stage: "test-on-test"
}
average_loss: 1000
type: "SGD"
I1223 00:14:22.268889 25375 solver.cpp:87] Creating training net from net file: /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/c20.prototxt
I1223 00:14:22.269474 25375 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1223 00:14:22.269899 25375 net.cpp:51] Initializing net from parameters: 
name: "May_lstm"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  top: "clip_markers"
  include {
    phase: TRAIN
  }
  python_param {
    module: "sequence_input_layer"
    layer: "videoReadTrain_RGB"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    name: "conv1_1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv1_1_bn"
  type: "BN"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    name: "conv1_2_w"
    lr_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv1_2_bn"
  type: "BN"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    name: "conv2_1_w"
    lr_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv2_1_bn"
  type: "BN"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    name: "conv2_2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv2_2_bn"
  type: "BN"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    name: "conv3_1_w"
    lr_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv3_1_bn"
  type: "BN"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    name: "conv3_2_w"
    lr_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv3_2_bn"
  type: "BN"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    name: "conv3_3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv3_3_bn"
  type: "BN"
  bottom: "conv3_3"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    name: "conv4_1_w"
    lr_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv4_1_bn"
  type: "BN"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    name: "conv4_2_w"
    lr_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv4_2_bn"
  type: "BN"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    name: "conv4_3_w"
    lr_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv4_3_bn"
  type: "BN"
  bottom: "conv4_3"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "relu4_3"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "relu4_3"
  top: "conv5_1"
  param {
    name: "conv5_1_w"
    lr_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "conv5_1_bn"
  type: "BN"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    name: "conv5_2_w"
    lr_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 4
    kernel_size: 3
    dilation: 4
  }
}
layer {
  name: "conv5_2_bn"
  type: "BN"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    name: "conv5_3_w"
    lr_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 8
    kernel_size: 3
    dilation: 8
  }
}
layer {
  name: "conv5_3_bn"
  type: "BN"
  bottom: "conv5_3"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "conv5"
  type: "Eltwise"
  bottom: "conv4_3"
  bottom: "conv5_3"
  top: "conv5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "fc6_1"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_1"
  param {
    name: "fc6_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_1_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "fc6_1"
  top: "fc6_1"
}
layer {
  name: "fc6_2"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_2"
  param {
    name: "fc6_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_2_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 4
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 4
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "fc6_2"
  top: "fc6_2"
}
layer {
  name: "fc6_3"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_3"
  param {
    name: "fc6_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_3_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 8
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 8
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "fc6_3"
  top: "fc6_3"
}
layer {
  name: "fc6_4"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_4"
  param {
    name: "fc6_4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_4_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 16
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 16
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "fc6_4"
  top: "fc6_4"
}
layer {
  name: "concat4"
  type: "Concat"
  bottom: "fc6_1"
  bottom: "fc6_2"
  bottom: "fc6_3"
  bottom: "fc6_4"
  top: "concat4"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "concat4_512"
  type: "Convolution"
  bottom: "concat4"
  top: "concat4_512"
  param {
    name: "concat4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "concat4_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "sum_5_concat4"
  type: "Eltwise"
  bottom: "concat4_512"
  bottom: "conv5"
  top: "sum_5_concat4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum"
  type: "ReLU"
  bottom: "sum_5_concat4"
  top: "sum_5_concat4"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "sum_5_concat4"
  top: "conv5_4"
  param {
    name: "conv5_4_w"
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/bn"
  type: "BN"
  bottom: "conv5_4"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "conv5_4/relu"
  type: "ReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "conv5_4/dropout"
  type: "Dropout"
  bottom: "conv5_4"
  top: "conv5_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5_4"
  top: "conv6"
  param {
    name: "conv6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv6_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BN"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "relu6"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "reshape-cm"
  type: "Reshape"
  bottom: "clip_markers"
  top: "reshape-cm"
  reshape_param {
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "reshape-data"
  type: "Reshape"
  bottom: "relu6"
  top: "conv6-reshape"
  reshape_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "dummy"
  type: "DummyData"
  top: "dummy"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode1"
  top: "encode1_h"
  top: "encode1_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "encode2"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode2"
  top: "encode2_h"
  top: "encode2_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "encode3"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode3"
  top: "encode3_h"
  top: "encode3_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 4
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "encode4"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode4"
  top: "encode4_h"
  top: "encode4_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 8
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 8
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "reshape_encode1"
  type: "Reshape"
  bottom: "encode1"
  top: "reshape_encode1"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "reshape_encode2"
  type: "Reshape"
  bottom: "encode2"
  top: "reshape_encode2"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "reshape_encode3"
  type: "Reshape"
  bottom: "encode3"
  top: "reshape_encode3"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "reshape_encode4"
  type: "Reshape"
  bottom: "encode4"
  top: "reshape_encode4"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "concat_encode1234"
  type: "Concat"
  bottom: "reshape_encode1"
  bottom: "reshape_encode2"
  bottom: "reshape_encode3"
  bottom: "reshape_encode4"
  top: "concat_encode1234"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv7_"
  type: "Convolution"
  bottom: "concat_encode1234"
  top: "conv7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1
    pad: 0
    kernel_size: 1
  }
}
layer {
  name: "conv7_interp"
  type: "Interp"
  bottom: "conv7"
  top: "conv7_interp"
  interp_param {
    height: 256
    width: 256
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "conv7_interp"
  bottom: "label"
  top: "loss"
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "encode1_h"
  bottom: "encode2_h"
  bottom: "encode3_h"
  bottom: "encode4_h"
  bottom: "encode1_c"
  bottom: "encode2_c"
  bottom: "encode3_c"
  bottom: "encode4_c"
}
I1223 00:14:22.270190 25375 layer_factory.hpp:77] Creating layer data
/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:68: UserWarning: h5py is running against HDF5 1.8.16 when it was built against 1.8.18, this may cause problems
  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)
I1223 00:14:22.813880 25375 net.cpp:84] Creating Layer data
I1223 00:14:22.813897 25375 net.cpp:380] data -> data
I1223 00:14:22.813913 25375 net.cpp:380] data -> label
I1223 00:14:22.813920 25375 net.cpp:380] data -> clip_markers
I1223 00:14:23.481727 25375 net.cpp:122] Setting up data
I1223 00:14:23.481765 25375 net.cpp:129] Top shape: 16 3 256 256 (3145728)
I1223 00:14:23.481771 25375 net.cpp:129] Top shape: 16 1 256 256 (1048576)
I1223 00:14:23.481776 25375 net.cpp:129] Top shape: 16 (16)
I1223 00:14:23.481778 25375 net.cpp:137] Memory required for data: 16777280
I1223 00:14:23.481797 25375 layer_factory.hpp:77] Creating layer conv1_1
I1223 00:14:23.481825 25375 net.cpp:84] Creating Layer conv1_1
I1223 00:14:23.481832 25375 net.cpp:406] conv1_1 <- data
I1223 00:14:23.481854 25375 net.cpp:380] conv1_1 -> conv1_1
I1223 00:14:23.483520 25375 net.cpp:122] Setting up conv1_1
I1223 00:14:23.483534 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:23.483538 25375 net.cpp:137] Memory required for data: 285212736
I1223 00:14:23.483557 25375 layer_factory.hpp:77] Creating layer conv1_1_bn
I1223 00:14:23.483570 25375 net.cpp:84] Creating Layer conv1_1_bn
I1223 00:14:23.483577 25375 net.cpp:406] conv1_1_bn <- conv1_1
I1223 00:14:23.483585 25375 net.cpp:367] conv1_1_bn -> conv1_1 (in-place)
I1223 00:14:23.483840 25375 net.cpp:122] Setting up conv1_1_bn
I1223 00:14:23.483850 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:23.483852 25375 net.cpp:137] Memory required for data: 553648192
I1223 00:14:23.483876 25375 layer_factory.hpp:77] Creating layer relu1_1
I1223 00:14:23.483886 25375 net.cpp:84] Creating Layer relu1_1
I1223 00:14:23.483888 25375 net.cpp:406] relu1_1 <- conv1_1
I1223 00:14:23.483894 25375 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I1223 00:14:23.483901 25375 net.cpp:122] Setting up relu1_1
I1223 00:14:23.483906 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:23.483909 25375 net.cpp:137] Memory required for data: 822083648
I1223 00:14:23.483914 25375 layer_factory.hpp:77] Creating layer conv1_2
I1223 00:14:23.483922 25375 net.cpp:84] Creating Layer conv1_2
I1223 00:14:23.483927 25375 net.cpp:406] conv1_2 <- conv1_1
I1223 00:14:23.483932 25375 net.cpp:380] conv1_2 -> conv1_2
I1223 00:14:23.484182 25375 net.cpp:122] Setting up conv1_2
I1223 00:14:23.484192 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:23.484196 25375 net.cpp:137] Memory required for data: 1090519104
I1223 00:14:23.484201 25375 layer_factory.hpp:77] Creating layer conv1_2_bn
I1223 00:14:23.484208 25375 net.cpp:84] Creating Layer conv1_2_bn
I1223 00:14:23.484213 25375 net.cpp:406] conv1_2_bn <- conv1_2
I1223 00:14:23.484223 25375 net.cpp:367] conv1_2_bn -> conv1_2 (in-place)
I1223 00:14:23.484442 25375 net.cpp:122] Setting up conv1_2_bn
I1223 00:14:23.484452 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:23.484454 25375 net.cpp:137] Memory required for data: 1358954560
I1223 00:14:23.484463 25375 layer_factory.hpp:77] Creating layer relu1_2
I1223 00:14:23.484472 25375 net.cpp:84] Creating Layer relu1_2
I1223 00:14:23.484474 25375 net.cpp:406] relu1_2 <- conv1_2
I1223 00:14:23.484479 25375 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I1223 00:14:23.484485 25375 net.cpp:122] Setting up relu1_2
I1223 00:14:23.484489 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:23.484493 25375 net.cpp:137] Memory required for data: 1627390016
I1223 00:14:23.484498 25375 layer_factory.hpp:77] Creating layer pool1
I1223 00:14:23.484503 25375 net.cpp:84] Creating Layer pool1
I1223 00:14:23.484505 25375 net.cpp:406] pool1 <- conv1_2
I1223 00:14:23.484511 25375 net.cpp:380] pool1 -> pool1
I1223 00:14:23.484551 25375 net.cpp:122] Setting up pool1
I1223 00:14:23.484560 25375 net.cpp:129] Top shape: 16 64 128 128 (16777216)
I1223 00:14:23.484563 25375 net.cpp:137] Memory required for data: 1694498880
I1223 00:14:23.484566 25375 layer_factory.hpp:77] Creating layer conv2_1
I1223 00:14:23.484578 25375 net.cpp:84] Creating Layer conv2_1
I1223 00:14:23.484585 25375 net.cpp:406] conv2_1 <- pool1
I1223 00:14:23.484591 25375 net.cpp:380] conv2_1 -> conv2_1
I1223 00:14:23.486153 25375 net.cpp:122] Setting up conv2_1
I1223 00:14:23.486168 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:23.486172 25375 net.cpp:137] Memory required for data: 1828716608
I1223 00:14:23.486179 25375 layer_factory.hpp:77] Creating layer conv2_1_bn
I1223 00:14:23.486188 25375 net.cpp:84] Creating Layer conv2_1_bn
I1223 00:14:23.486193 25375 net.cpp:406] conv2_1_bn <- conv2_1
I1223 00:14:23.486202 25375 net.cpp:367] conv2_1_bn -> conv2_1 (in-place)
I1223 00:14:23.486404 25375 net.cpp:122] Setting up conv2_1_bn
I1223 00:14:23.486413 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:23.486415 25375 net.cpp:137] Memory required for data: 1962934336
I1223 00:14:23.486428 25375 layer_factory.hpp:77] Creating layer relu2_1
I1223 00:14:23.486435 25375 net.cpp:84] Creating Layer relu2_1
I1223 00:14:23.486438 25375 net.cpp:406] relu2_1 <- conv2_1
I1223 00:14:23.486444 25375 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1223 00:14:23.486450 25375 net.cpp:122] Setting up relu2_1
I1223 00:14:23.486456 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:23.486459 25375 net.cpp:137] Memory required for data: 2097152064
I1223 00:14:23.486462 25375 layer_factory.hpp:77] Creating layer conv2_2
I1223 00:14:23.486469 25375 net.cpp:84] Creating Layer conv2_2
I1223 00:14:23.486472 25375 net.cpp:406] conv2_2 <- conv2_1
I1223 00:14:23.486481 25375 net.cpp:380] conv2_2 -> conv2_2
I1223 00:14:23.486776 25375 net.cpp:122] Setting up conv2_2
I1223 00:14:23.486785 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:23.486788 25375 net.cpp:137] Memory required for data: 2231369792
I1223 00:14:23.486793 25375 layer_factory.hpp:77] Creating layer conv2_2_bn
I1223 00:14:23.486804 25375 net.cpp:84] Creating Layer conv2_2_bn
I1223 00:14:23.486809 25375 net.cpp:406] conv2_2_bn <- conv2_2
I1223 00:14:23.486814 25375 net.cpp:367] conv2_2_bn -> conv2_2 (in-place)
I1223 00:14:23.486999 25375 net.cpp:122] Setting up conv2_2_bn
I1223 00:14:23.487007 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:23.487010 25375 net.cpp:137] Memory required for data: 2365587520
I1223 00:14:23.487020 25375 layer_factory.hpp:77] Creating layer relu2_2
I1223 00:14:23.487026 25375 net.cpp:84] Creating Layer relu2_2
I1223 00:14:23.487030 25375 net.cpp:406] relu2_2 <- conv2_2
I1223 00:14:23.487035 25375 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1223 00:14:23.487067 25375 net.cpp:122] Setting up relu2_2
I1223 00:14:23.487089 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:23.487107 25375 net.cpp:137] Memory required for data: 2499805248
I1223 00:14:23.487123 25375 layer_factory.hpp:77] Creating layer pool2
I1223 00:14:23.487150 25375 net.cpp:84] Creating Layer pool2
I1223 00:14:23.487170 25375 net.cpp:406] pool2 <- conv2_2
I1223 00:14:23.487190 25375 net.cpp:380] pool2 -> pool2
I1223 00:14:23.487246 25375 net.cpp:122] Setting up pool2
I1223 00:14:23.487267 25375 net.cpp:129] Top shape: 16 128 64 64 (8388608)
I1223 00:14:23.487283 25375 net.cpp:137] Memory required for data: 2533359680
I1223 00:14:23.487299 25375 layer_factory.hpp:77] Creating layer conv3_1
I1223 00:14:23.487326 25375 net.cpp:84] Creating Layer conv3_1
I1223 00:14:23.487345 25375 net.cpp:406] conv3_1 <- pool2
I1223 00:14:23.487367 25375 net.cpp:380] conv3_1 -> conv3_1
I1223 00:14:23.487782 25375 net.cpp:122] Setting up conv3_1
I1223 00:14:23.487813 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.487831 25375 net.cpp:137] Memory required for data: 2600468544
I1223 00:14:23.487851 25375 layer_factory.hpp:77] Creating layer conv3_1_bn
I1223 00:14:23.487876 25375 net.cpp:84] Creating Layer conv3_1_bn
I1223 00:14:23.487895 25375 net.cpp:406] conv3_1_bn <- conv3_1
I1223 00:14:23.487915 25375 net.cpp:367] conv3_1_bn -> conv3_1 (in-place)
I1223 00:14:23.488119 25375 net.cpp:122] Setting up conv3_1_bn
I1223 00:14:23.488142 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.488159 25375 net.cpp:137] Memory required for data: 2667577408
I1223 00:14:23.488183 25375 layer_factory.hpp:77] Creating layer relu3_1
I1223 00:14:23.488203 25375 net.cpp:84] Creating Layer relu3_1
I1223 00:14:23.488220 25375 net.cpp:406] relu3_1 <- conv3_1
I1223 00:14:23.488240 25375 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1223 00:14:23.488260 25375 net.cpp:122] Setting up relu3_1
I1223 00:14:23.488281 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.488297 25375 net.cpp:137] Memory required for data: 2734686272
I1223 00:14:23.488315 25375 layer_factory.hpp:77] Creating layer conv3_2
I1223 00:14:23.488334 25375 net.cpp:84] Creating Layer conv3_2
I1223 00:14:23.488353 25375 net.cpp:406] conv3_2 <- conv3_1
I1223 00:14:23.488375 25375 net.cpp:380] conv3_2 -> conv3_2
I1223 00:14:23.489778 25375 net.cpp:122] Setting up conv3_2
I1223 00:14:23.489794 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.489796 25375 net.cpp:137] Memory required for data: 2801795136
I1223 00:14:23.489804 25375 layer_factory.hpp:77] Creating layer conv3_2_bn
I1223 00:14:23.489814 25375 net.cpp:84] Creating Layer conv3_2_bn
I1223 00:14:23.489820 25375 net.cpp:406] conv3_2_bn <- conv3_2
I1223 00:14:23.489825 25375 net.cpp:367] conv3_2_bn -> conv3_2 (in-place)
I1223 00:14:23.490013 25375 net.cpp:122] Setting up conv3_2_bn
I1223 00:14:23.490022 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.490025 25375 net.cpp:137] Memory required for data: 2868904000
I1223 00:14:23.490041 25375 layer_factory.hpp:77] Creating layer relu3_2
I1223 00:14:23.490048 25375 net.cpp:84] Creating Layer relu3_2
I1223 00:14:23.490052 25375 net.cpp:406] relu3_2 <- conv3_2
I1223 00:14:23.490058 25375 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I1223 00:14:23.490064 25375 net.cpp:122] Setting up relu3_2
I1223 00:14:23.490069 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.490072 25375 net.cpp:137] Memory required for data: 2936012864
I1223 00:14:23.490074 25375 layer_factory.hpp:77] Creating layer conv3_3
I1223 00:14:23.490080 25375 net.cpp:84] Creating Layer conv3_3
I1223 00:14:23.490084 25375 net.cpp:406] conv3_3 <- conv3_2
I1223 00:14:23.490090 25375 net.cpp:380] conv3_3 -> conv3_3
I1223 00:14:23.491478 25375 net.cpp:122] Setting up conv3_3
I1223 00:14:23.491493 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.491497 25375 net.cpp:137] Memory required for data: 3003121728
I1223 00:14:23.491504 25375 layer_factory.hpp:77] Creating layer conv3_3_bn
I1223 00:14:23.491528 25375 net.cpp:84] Creating Layer conv3_3_bn
I1223 00:14:23.491533 25375 net.cpp:406] conv3_3_bn <- conv3_3
I1223 00:14:23.491538 25375 net.cpp:367] conv3_3_bn -> conv3_3 (in-place)
I1223 00:14:23.491758 25375 net.cpp:122] Setting up conv3_3_bn
I1223 00:14:23.491766 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.491770 25375 net.cpp:137] Memory required for data: 3070230592
I1223 00:14:23.491780 25375 layer_factory.hpp:77] Creating layer relu3_3
I1223 00:14:23.491786 25375 net.cpp:84] Creating Layer relu3_3
I1223 00:14:23.491791 25375 net.cpp:406] relu3_3 <- conv3_3
I1223 00:14:23.491794 25375 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I1223 00:14:23.491801 25375 net.cpp:122] Setting up relu3_3
I1223 00:14:23.491804 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:23.491807 25375 net.cpp:137] Memory required for data: 3137339456
I1223 00:14:23.491811 25375 layer_factory.hpp:77] Creating layer pool3
I1223 00:14:23.491816 25375 net.cpp:84] Creating Layer pool3
I1223 00:14:23.491819 25375 net.cpp:406] pool3 <- conv3_3
I1223 00:14:23.491824 25375 net.cpp:380] pool3 -> pool3
I1223 00:14:23.491863 25375 net.cpp:122] Setting up pool3
I1223 00:14:23.491870 25375 net.cpp:129] Top shape: 16 256 32 32 (4194304)
I1223 00:14:23.491873 25375 net.cpp:137] Memory required for data: 3154116672
I1223 00:14:23.491876 25375 layer_factory.hpp:77] Creating layer conv4_1
I1223 00:14:23.491885 25375 net.cpp:84] Creating Layer conv4_1
I1223 00:14:23.491888 25375 net.cpp:406] conv4_1 <- pool3
I1223 00:14:23.491894 25375 net.cpp:380] conv4_1 -> conv4_1
I1223 00:14:23.495203 25375 net.cpp:122] Setting up conv4_1
I1223 00:14:23.495225 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.495230 25375 net.cpp:137] Memory required for data: 3187671104
I1223 00:14:23.495268 25375 layer_factory.hpp:77] Creating layer conv4_1_bn
I1223 00:14:23.495280 25375 net.cpp:84] Creating Layer conv4_1_bn
I1223 00:14:23.495285 25375 net.cpp:406] conv4_1_bn <- conv4_1
I1223 00:14:23.495293 25375 net.cpp:367] conv4_1_bn -> conv4_1 (in-place)
I1223 00:14:23.495506 25375 net.cpp:122] Setting up conv4_1_bn
I1223 00:14:23.495513 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.495517 25375 net.cpp:137] Memory required for data: 3221225536
I1223 00:14:23.495539 25375 layer_factory.hpp:77] Creating layer relu4_1
I1223 00:14:23.495548 25375 net.cpp:84] Creating Layer relu4_1
I1223 00:14:23.495551 25375 net.cpp:406] relu4_1 <- conv4_1
I1223 00:14:23.495555 25375 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1223 00:14:23.495561 25375 net.cpp:122] Setting up relu4_1
I1223 00:14:23.495565 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.495568 25375 net.cpp:137] Memory required for data: 3254779968
I1223 00:14:23.495584 25375 layer_factory.hpp:77] Creating layer conv4_2
I1223 00:14:23.495591 25375 net.cpp:84] Creating Layer conv4_2
I1223 00:14:23.495595 25375 net.cpp:406] conv4_2 <- conv4_1
I1223 00:14:23.495601 25375 net.cpp:380] conv4_2 -> conv4_2
I1223 00:14:23.499740 25375 net.cpp:122] Setting up conv4_2
I1223 00:14:23.499763 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.499768 25375 net.cpp:137] Memory required for data: 3288334400
I1223 00:14:23.499794 25375 layer_factory.hpp:77] Creating layer conv4_2_bn
I1223 00:14:23.499819 25375 net.cpp:84] Creating Layer conv4_2_bn
I1223 00:14:23.499825 25375 net.cpp:406] conv4_2_bn <- conv4_2
I1223 00:14:23.499833 25375 net.cpp:367] conv4_2_bn -> conv4_2 (in-place)
I1223 00:14:23.500043 25375 net.cpp:122] Setting up conv4_2_bn
I1223 00:14:23.500051 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.500054 25375 net.cpp:137] Memory required for data: 3321888832
I1223 00:14:23.500077 25375 layer_factory.hpp:77] Creating layer relu4_2
I1223 00:14:23.500082 25375 net.cpp:84] Creating Layer relu4_2
I1223 00:14:23.500087 25375 net.cpp:406] relu4_2 <- conv4_2
I1223 00:14:23.500090 25375 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1223 00:14:23.500097 25375 net.cpp:122] Setting up relu4_2
I1223 00:14:23.500100 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.500103 25375 net.cpp:137] Memory required for data: 3355443264
I1223 00:14:23.500107 25375 layer_factory.hpp:77] Creating layer conv4_3
I1223 00:14:23.500128 25375 net.cpp:84] Creating Layer conv4_3
I1223 00:14:23.500136 25375 net.cpp:406] conv4_3 <- conv4_2
I1223 00:14:23.500144 25375 net.cpp:380] conv4_3 -> conv4_3
I1223 00:14:23.504400 25375 net.cpp:122] Setting up conv4_3
I1223 00:14:23.504426 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.504431 25375 net.cpp:137] Memory required for data: 3388997696
I1223 00:14:23.504441 25375 layer_factory.hpp:77] Creating layer conv4_3_bn
I1223 00:14:23.504458 25375 net.cpp:84] Creating Layer conv4_3_bn
I1223 00:14:23.504464 25375 net.cpp:406] conv4_3_bn <- conv4_3
I1223 00:14:23.504472 25375 net.cpp:367] conv4_3_bn -> conv4_3 (in-place)
I1223 00:14:23.504683 25375 net.cpp:122] Setting up conv4_3_bn
I1223 00:14:23.504690 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.504693 25375 net.cpp:137] Memory required for data: 3422552128
I1223 00:14:23.504703 25375 layer_factory.hpp:77] Creating layer conv4_3_conv4_3_bn_0_split
I1223 00:14:23.504709 25375 net.cpp:84] Creating Layer conv4_3_conv4_3_bn_0_split
I1223 00:14:23.504712 25375 net.cpp:406] conv4_3_conv4_3_bn_0_split <- conv4_3
I1223 00:14:23.504717 25375 net.cpp:380] conv4_3_conv4_3_bn_0_split -> conv4_3_conv4_3_bn_0_split_0
I1223 00:14:23.504726 25375 net.cpp:380] conv4_3_conv4_3_bn_0_split -> conv4_3_conv4_3_bn_0_split_1
I1223 00:14:23.504765 25375 net.cpp:122] Setting up conv4_3_conv4_3_bn_0_split
I1223 00:14:23.504771 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.504776 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.504778 25375 net.cpp:137] Memory required for data: 3489660992
I1223 00:14:23.504781 25375 layer_factory.hpp:77] Creating layer relu4_3
I1223 00:14:23.504786 25375 net.cpp:84] Creating Layer relu4_3
I1223 00:14:23.504791 25375 net.cpp:406] relu4_3 <- conv4_3_conv4_3_bn_0_split_0
I1223 00:14:23.504796 25375 net.cpp:380] relu4_3 -> relu4_3
I1223 00:14:23.504817 25375 net.cpp:122] Setting up relu4_3
I1223 00:14:23.504825 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.504828 25375 net.cpp:137] Memory required for data: 3523215424
I1223 00:14:23.504832 25375 layer_factory.hpp:77] Creating layer conv5_1
I1223 00:14:23.504839 25375 net.cpp:84] Creating Layer conv5_1
I1223 00:14:23.504845 25375 net.cpp:406] conv5_1 <- relu4_3
I1223 00:14:23.504853 25375 net.cpp:380] conv5_1 -> conv5_1
I1223 00:14:23.509152 25375 net.cpp:122] Setting up conv5_1
I1223 00:14:23.509174 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.509178 25375 net.cpp:137] Memory required for data: 3556769856
I1223 00:14:23.509204 25375 layer_factory.hpp:77] Creating layer conv5_1_bn
I1223 00:14:23.509217 25375 net.cpp:84] Creating Layer conv5_1_bn
I1223 00:14:23.509220 25375 net.cpp:406] conv5_1_bn <- conv5_1
I1223 00:14:23.509227 25375 net.cpp:367] conv5_1_bn -> conv5_1 (in-place)
I1223 00:14:23.509449 25375 net.cpp:122] Setting up conv5_1_bn
I1223 00:14:23.509456 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.509459 25375 net.cpp:137] Memory required for data: 3590324288
I1223 00:14:23.509485 25375 layer_factory.hpp:77] Creating layer relu5_1
I1223 00:14:23.509492 25375 net.cpp:84] Creating Layer relu5_1
I1223 00:14:23.509496 25375 net.cpp:406] relu5_1 <- conv5_1
I1223 00:14:23.509501 25375 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I1223 00:14:23.509506 25375 net.cpp:122] Setting up relu5_1
I1223 00:14:23.509510 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.509513 25375 net.cpp:137] Memory required for data: 3623878720
I1223 00:14:23.509529 25375 layer_factory.hpp:77] Creating layer conv5_2
I1223 00:14:23.509536 25375 net.cpp:84] Creating Layer conv5_2
I1223 00:14:23.509541 25375 net.cpp:406] conv5_2 <- conv5_1
I1223 00:14:23.509546 25375 net.cpp:380] conv5_2 -> conv5_2
I1223 00:14:23.513685 25375 net.cpp:122] Setting up conv5_2
I1223 00:14:23.513708 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.513712 25375 net.cpp:137] Memory required for data: 3657433152
I1223 00:14:23.513736 25375 layer_factory.hpp:77] Creating layer conv5_2_bn
I1223 00:14:23.513748 25375 net.cpp:84] Creating Layer conv5_2_bn
I1223 00:14:23.513767 25375 net.cpp:406] conv5_2_bn <- conv5_2
I1223 00:14:23.513772 25375 net.cpp:367] conv5_2_bn -> conv5_2 (in-place)
I1223 00:14:23.513993 25375 net.cpp:122] Setting up conv5_2_bn
I1223 00:14:23.514000 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.514003 25375 net.cpp:137] Memory required for data: 3690987584
I1223 00:14:23.514011 25375 layer_factory.hpp:77] Creating layer relu5_2
I1223 00:14:23.514031 25375 net.cpp:84] Creating Layer relu5_2
I1223 00:14:23.514034 25375 net.cpp:406] relu5_2 <- conv5_2
I1223 00:14:23.514039 25375 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I1223 00:14:23.514045 25375 net.cpp:122] Setting up relu5_2
I1223 00:14:23.514050 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.514051 25375 net.cpp:137] Memory required for data: 3724542016
I1223 00:14:23.514055 25375 layer_factory.hpp:77] Creating layer conv5_3
I1223 00:14:23.514076 25375 net.cpp:84] Creating Layer conv5_3
I1223 00:14:23.514080 25375 net.cpp:406] conv5_3 <- conv5_2
I1223 00:14:23.514086 25375 net.cpp:380] conv5_3 -> conv5_3
I1223 00:14:23.518216 25375 net.cpp:122] Setting up conv5_3
I1223 00:14:23.518240 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518244 25375 net.cpp:137] Memory required for data: 3758096448
I1223 00:14:23.518268 25375 layer_factory.hpp:77] Creating layer conv5_3_bn
I1223 00:14:23.518280 25375 net.cpp:84] Creating Layer conv5_3_bn
I1223 00:14:23.518283 25375 net.cpp:406] conv5_3_bn <- conv5_3
I1223 00:14:23.518306 25375 net.cpp:367] conv5_3_bn -> conv5_3 (in-place)
I1223 00:14:23.518512 25375 net.cpp:122] Setting up conv5_3_bn
I1223 00:14:23.518520 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518523 25375 net.cpp:137] Memory required for data: 3791650880
I1223 00:14:23.518545 25375 layer_factory.hpp:77] Creating layer conv5
I1223 00:14:23.518553 25375 net.cpp:84] Creating Layer conv5
I1223 00:14:23.518569 25375 net.cpp:406] conv5 <- conv4_3_conv4_3_bn_0_split_1
I1223 00:14:23.518574 25375 net.cpp:406] conv5 <- conv5_3
I1223 00:14:23.518579 25375 net.cpp:380] conv5 -> conv5
I1223 00:14:23.518605 25375 net.cpp:122] Setting up conv5
I1223 00:14:23.518611 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518615 25375 net.cpp:137] Memory required for data: 3825205312
I1223 00:14:23.518617 25375 layer_factory.hpp:77] Creating layer conv5_conv5_0_split
I1223 00:14:23.518622 25375 net.cpp:84] Creating Layer conv5_conv5_0_split
I1223 00:14:23.518625 25375 net.cpp:406] conv5_conv5_0_split <- conv5
I1223 00:14:23.518631 25375 net.cpp:380] conv5_conv5_0_split -> conv5_conv5_0_split_0
I1223 00:14:23.518638 25375 net.cpp:380] conv5_conv5_0_split -> conv5_conv5_0_split_1
I1223 00:14:23.518671 25375 net.cpp:122] Setting up conv5_conv5_0_split
I1223 00:14:23.518678 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518682 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518684 25375 net.cpp:137] Memory required for data: 3892314176
I1223 00:14:23.518689 25375 layer_factory.hpp:77] Creating layer relu5
I1223 00:14:23.518694 25375 net.cpp:84] Creating Layer relu5
I1223 00:14:23.518697 25375 net.cpp:406] relu5 <- conv5_conv5_0_split_0
I1223 00:14:23.518703 25375 net.cpp:380] relu5 -> relu5
I1223 00:14:23.518723 25375 net.cpp:122] Setting up relu5
I1223 00:14:23.518728 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518731 25375 net.cpp:137] Memory required for data: 3925868608
I1223 00:14:23.518734 25375 layer_factory.hpp:77] Creating layer relu5_relu5_0_split
I1223 00:14:23.518740 25375 net.cpp:84] Creating Layer relu5_relu5_0_split
I1223 00:14:23.518743 25375 net.cpp:406] relu5_relu5_0_split <- relu5
I1223 00:14:23.518750 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_0
I1223 00:14:23.518759 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_1
I1223 00:14:23.518765 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_2
I1223 00:14:23.518770 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_3
I1223 00:14:23.518824 25375 net.cpp:122] Setting up relu5_relu5_0_split
I1223 00:14:23.518844 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518847 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518851 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518854 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.518872 25375 net.cpp:137] Memory required for data: 4060086336
I1223 00:14:23.518875 25375 layer_factory.hpp:77] Creating layer fc6_1
I1223 00:14:23.518884 25375 net.cpp:84] Creating Layer fc6_1
I1223 00:14:23.518887 25375 net.cpp:406] fc6_1 <- relu5_relu5_0_split_0
I1223 00:14:23.518893 25375 net.cpp:380] fc6_1 -> fc6_1
I1223 00:14:23.528362 25375 net.cpp:122] Setting up fc6_1
I1223 00:14:23.528398 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.528414 25375 net.cpp:137] Memory required for data: 4068474944
I1223 00:14:23.528426 25375 layer_factory.hpp:77] Creating layer relu6_1
I1223 00:14:23.528435 25375 net.cpp:84] Creating Layer relu6_1
I1223 00:14:23.528439 25375 net.cpp:406] relu6_1 <- fc6_1
I1223 00:14:23.528445 25375 net.cpp:367] relu6_1 -> fc6_1 (in-place)
I1223 00:14:23.528452 25375 net.cpp:122] Setting up relu6_1
I1223 00:14:23.528456 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.528460 25375 net.cpp:137] Memory required for data: 4076863552
I1223 00:14:23.528461 25375 layer_factory.hpp:77] Creating layer fc6_2
I1223 00:14:23.528471 25375 net.cpp:84] Creating Layer fc6_2
I1223 00:14:23.528475 25375 net.cpp:406] fc6_2 <- relu5_relu5_0_split_1
I1223 00:14:23.528482 25375 net.cpp:380] fc6_2 -> fc6_2
I1223 00:14:23.536177 25375 net.cpp:122] Setting up fc6_2
I1223 00:14:23.536193 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.536197 25375 net.cpp:137] Memory required for data: 4085252160
I1223 00:14:23.536218 25375 layer_factory.hpp:77] Creating layer relu6_2
I1223 00:14:23.536227 25375 net.cpp:84] Creating Layer relu6_2
I1223 00:14:23.536232 25375 net.cpp:406] relu6_2 <- fc6_2
I1223 00:14:23.536237 25375 net.cpp:367] relu6_2 -> fc6_2 (in-place)
I1223 00:14:23.536243 25375 net.cpp:122] Setting up relu6_2
I1223 00:14:23.536248 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.536252 25375 net.cpp:137] Memory required for data: 4093640768
I1223 00:14:23.536269 25375 layer_factory.hpp:77] Creating layer fc6_3
I1223 00:14:23.536279 25375 net.cpp:84] Creating Layer fc6_3
I1223 00:14:23.536283 25375 net.cpp:406] fc6_3 <- relu5_relu5_0_split_2
I1223 00:14:23.536289 25375 net.cpp:380] fc6_3 -> fc6_3
I1223 00:14:23.544327 25375 net.cpp:122] Setting up fc6_3
I1223 00:14:23.544349 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.544353 25375 net.cpp:137] Memory required for data: 4102029376
I1223 00:14:23.544361 25375 layer_factory.hpp:77] Creating layer relu6_3
I1223 00:14:23.544369 25375 net.cpp:84] Creating Layer relu6_3
I1223 00:14:23.544374 25375 net.cpp:406] relu6_3 <- fc6_3
I1223 00:14:23.544380 25375 net.cpp:367] relu6_3 -> fc6_3 (in-place)
I1223 00:14:23.544389 25375 net.cpp:122] Setting up relu6_3
I1223 00:14:23.544392 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.544395 25375 net.cpp:137] Memory required for data: 4110417984
I1223 00:14:23.544397 25375 layer_factory.hpp:77] Creating layer fc6_4
I1223 00:14:23.544407 25375 net.cpp:84] Creating Layer fc6_4
I1223 00:14:23.544421 25375 net.cpp:406] fc6_4 <- relu5_relu5_0_split_3
I1223 00:14:23.544428 25375 net.cpp:380] fc6_4 -> fc6_4
I1223 00:14:23.552031 25375 net.cpp:122] Setting up fc6_4
I1223 00:14:23.552043 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.552047 25375 net.cpp:137] Memory required for data: 4118806592
I1223 00:14:23.552052 25375 layer_factory.hpp:77] Creating layer relu6_4
I1223 00:14:23.552057 25375 net.cpp:84] Creating Layer relu6_4
I1223 00:14:23.552062 25375 net.cpp:406] relu6_4 <- fc6_4
I1223 00:14:23.552067 25375 net.cpp:367] relu6_4 -> fc6_4 (in-place)
I1223 00:14:23.552073 25375 net.cpp:122] Setting up relu6_4
I1223 00:14:23.552076 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.552079 25375 net.cpp:137] Memory required for data: 4127195200
I1223 00:14:23.552084 25375 layer_factory.hpp:77] Creating layer concat4
I1223 00:14:23.552091 25375 net.cpp:84] Creating Layer concat4
I1223 00:14:23.552109 25375 net.cpp:406] concat4 <- fc6_1
I1223 00:14:23.552114 25375 net.cpp:406] concat4 <- fc6_2
I1223 00:14:23.552131 25375 net.cpp:406] concat4 <- fc6_3
I1223 00:14:23.552134 25375 net.cpp:406] concat4 <- fc6_4
I1223 00:14:23.552153 25375 net.cpp:380] concat4 -> concat4
I1223 00:14:23.552191 25375 net.cpp:122] Setting up concat4
I1223 00:14:23.552197 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.552201 25375 net.cpp:137] Memory required for data: 4160749632
I1223 00:14:23.552203 25375 layer_factory.hpp:77] Creating layer concat4_512
I1223 00:14:23.552212 25375 net.cpp:84] Creating Layer concat4_512
I1223 00:14:23.552230 25375 net.cpp:406] concat4_512 <- concat4
I1223 00:14:23.552235 25375 net.cpp:380] concat4_512 -> concat4_512
I1223 00:14:23.556167 25375 net.cpp:122] Setting up concat4_512
I1223 00:14:23.556187 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.556191 25375 net.cpp:137] Memory required for data: 4194304064
I1223 00:14:23.556212 25375 layer_factory.hpp:77] Creating layer sum_5_concat4
I1223 00:14:23.556221 25375 net.cpp:84] Creating Layer sum_5_concat4
I1223 00:14:23.556226 25375 net.cpp:406] sum_5_concat4 <- concat4_512
I1223 00:14:23.556231 25375 net.cpp:406] sum_5_concat4 <- conv5_conv5_0_split_1
I1223 00:14:23.556236 25375 net.cpp:380] sum_5_concat4 -> sum_5_concat4
I1223 00:14:23.556262 25375 net.cpp:122] Setting up sum_5_concat4
I1223 00:14:23.556282 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.556284 25375 net.cpp:137] Memory required for data: 4227858496
I1223 00:14:23.556289 25375 layer_factory.hpp:77] Creating layer relu_sum
I1223 00:14:23.556294 25375 net.cpp:84] Creating Layer relu_sum
I1223 00:14:23.556298 25375 net.cpp:406] relu_sum <- sum_5_concat4
I1223 00:14:23.556301 25375 net.cpp:367] relu_sum -> sum_5_concat4 (in-place)
I1223 00:14:23.556306 25375 net.cpp:122] Setting up relu_sum
I1223 00:14:23.556311 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:23.556313 25375 net.cpp:137] Memory required for data: 4261412928
I1223 00:14:23.556316 25375 layer_factory.hpp:77] Creating layer conv5_4
I1223 00:14:23.556326 25375 net.cpp:84] Creating Layer conv5_4
I1223 00:14:23.556330 25375 net.cpp:406] conv5_4 <- sum_5_concat4
I1223 00:14:23.556339 25375 net.cpp:380] conv5_4 -> conv5_4
I1223 00:14:23.560530 25375 net.cpp:122] Setting up conv5_4
I1223 00:14:23.560550 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:23.560554 25375 net.cpp:137] Memory required for data: 4265607232
I1223 00:14:23.560575 25375 layer_factory.hpp:77] Creating layer conv5_4/bn
I1223 00:14:23.560585 25375 net.cpp:84] Creating Layer conv5_4/bn
I1223 00:14:23.560588 25375 net.cpp:406] conv5_4/bn <- conv5_4
I1223 00:14:23.560607 25375 net.cpp:367] conv5_4/bn -> conv5_4 (in-place)
I1223 00:14:23.560878 25375 net.cpp:122] Setting up conv5_4/bn
I1223 00:14:23.560885 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:23.560889 25375 net.cpp:137] Memory required for data: 4269801536
I1223 00:14:23.560914 25375 layer_factory.hpp:77] Creating layer conv5_4/relu
I1223 00:14:23.560919 25375 net.cpp:84] Creating Layer conv5_4/relu
I1223 00:14:23.560935 25375 net.cpp:406] conv5_4/relu <- conv5_4
I1223 00:14:23.560940 25375 net.cpp:367] conv5_4/relu -> conv5_4 (in-place)
I1223 00:14:23.560945 25375 net.cpp:122] Setting up conv5_4/relu
I1223 00:14:23.560950 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:23.560966 25375 net.cpp:137] Memory required for data: 4273995840
I1223 00:14:23.560969 25375 layer_factory.hpp:77] Creating layer conv5_4/dropout
I1223 00:14:23.560973 25375 net.cpp:84] Creating Layer conv5_4/dropout
I1223 00:14:23.560989 25375 net.cpp:406] conv5_4/dropout <- conv5_4
I1223 00:14:23.560994 25375 net.cpp:367] conv5_4/dropout -> conv5_4 (in-place)
I1223 00:14:23.561022 25375 net.cpp:122] Setting up conv5_4/dropout
I1223 00:14:23.561028 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:23.561030 25375 net.cpp:137] Memory required for data: 4278190144
I1223 00:14:23.561034 25375 layer_factory.hpp:77] Creating layer conv6
I1223 00:14:23.561043 25375 net.cpp:84] Creating Layer conv6
I1223 00:14:23.561054 25375 net.cpp:406] conv6 <- conv5_4
I1223 00:14:23.561061 25375 net.cpp:380] conv6 -> conv6
I1223 00:14:23.561296 25375 net.cpp:122] Setting up conv6
I1223 00:14:23.561305 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:23.561307 25375 net.cpp:137] Memory required for data: 4278255680
I1223 00:14:23.561312 25375 layer_factory.hpp:77] Creating layer conv6/bn
I1223 00:14:23.561338 25375 net.cpp:84] Creating Layer conv6/bn
I1223 00:14:23.561342 25375 net.cpp:406] conv6/bn <- conv6
I1223 00:14:23.561360 25375 net.cpp:367] conv6/bn -> conv6 (in-place)
I1223 00:14:23.561566 25375 net.cpp:122] Setting up conv6/bn
I1223 00:14:23.561574 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:23.561576 25375 net.cpp:137] Memory required for data: 4278321216
I1223 00:14:23.561601 25375 layer_factory.hpp:77] Creating layer relu6
I1223 00:14:23.561606 25375 net.cpp:84] Creating Layer relu6
I1223 00:14:23.561624 25375 net.cpp:406] relu6 <- conv6
I1223 00:14:23.561627 25375 net.cpp:380] relu6 -> relu6
I1223 00:14:23.561651 25375 net.cpp:122] Setting up relu6
I1223 00:14:23.561657 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:23.561661 25375 net.cpp:137] Memory required for data: 4278386752
I1223 00:14:23.561664 25375 layer_factory.hpp:77] Creating layer reshape-cm
I1223 00:14:23.561669 25375 net.cpp:84] Creating Layer reshape-cm
I1223 00:14:23.561672 25375 net.cpp:406] reshape-cm <- clip_markers
I1223 00:14:23.561678 25375 net.cpp:380] reshape-cm -> reshape-cm
I1223 00:14:23.561704 25375 net.cpp:122] Setting up reshape-cm
I1223 00:14:23.561710 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.561713 25375 net.cpp:137] Memory required for data: 4278386816
I1223 00:14:23.561717 25375 layer_factory.hpp:77] Creating layer reshape-cm_reshape-cm_0_split
I1223 00:14:23.561723 25375 net.cpp:84] Creating Layer reshape-cm_reshape-cm_0_split
I1223 00:14:23.561727 25375 net.cpp:406] reshape-cm_reshape-cm_0_split <- reshape-cm
I1223 00:14:23.561733 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_0
I1223 00:14:23.561738 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_1
I1223 00:14:23.561744 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_2
I1223 00:14:23.561749 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_3
I1223 00:14:23.561810 25375 net.cpp:122] Setting up reshape-cm_reshape-cm_0_split
I1223 00:14:23.561816 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.561820 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.561823 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.561826 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.561828 25375 net.cpp:137] Memory required for data: 4278387072
I1223 00:14:23.561833 25375 layer_factory.hpp:77] Creating layer reshape-data
I1223 00:14:23.561837 25375 net.cpp:84] Creating Layer reshape-data
I1223 00:14:23.561841 25375 net.cpp:406] reshape-data <- relu6
I1223 00:14:23.561847 25375 net.cpp:380] reshape-data -> conv6-reshape
I1223 00:14:23.561869 25375 net.cpp:122] Setting up reshape-data
I1223 00:14:23.561875 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.561878 25375 net.cpp:137] Memory required for data: 4278452608
I1223 00:14:23.561894 25375 layer_factory.hpp:77] Creating layer conv6-reshape_reshape-data_0_split
I1223 00:14:23.561898 25375 net.cpp:84] Creating Layer conv6-reshape_reshape-data_0_split
I1223 00:14:23.561902 25375 net.cpp:406] conv6-reshape_reshape-data_0_split <- conv6-reshape
I1223 00:14:23.561908 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_0
I1223 00:14:23.561914 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_1
I1223 00:14:23.561920 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_2
I1223 00:14:23.561939 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_3
I1223 00:14:23.562010 25375 net.cpp:122] Setting up conv6-reshape_reshape-data_0_split
I1223 00:14:23.562016 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.562021 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.562024 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.562028 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.562031 25375 net.cpp:137] Memory required for data: 4278714752
I1223 00:14:23.562036 25375 layer_factory.hpp:77] Creating layer dummy
I1223 00:14:23.562041 25375 net.cpp:84] Creating Layer dummy
I1223 00:14:23.562045 25375 net.cpp:380] dummy -> dummy
I1223 00:14:23.562101 25375 net.cpp:122] Setting up dummy
I1223 00:14:23.562109 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562111 25375 net.cpp:137] Memory required for data: 4278845824
I1223 00:14:23.562114 25375 layer_factory.hpp:77] Creating layer dummy_dummy_0_split
I1223 00:14:23.562134 25375 net.cpp:84] Creating Layer dummy_dummy_0_split
I1223 00:14:23.562136 25375 net.cpp:406] dummy_dummy_0_split <- dummy
I1223 00:14:23.562142 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_0
I1223 00:14:23.562150 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_1
I1223 00:14:23.562155 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_2
I1223 00:14:23.562161 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_3
I1223 00:14:23.562168 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_4
I1223 00:14:23.562175 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_5
I1223 00:14:23.562180 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_6
I1223 00:14:23.562186 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_7
I1223 00:14:23.562295 25375 net.cpp:122] Setting up dummy_dummy_0_split
I1223 00:14:23.562302 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562306 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562309 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562312 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562315 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562319 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562322 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562326 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.562342 25375 net.cpp:137] Memory required for data: 4279894400
I1223 00:14:23.562345 25375 layer_factory.hpp:77] Creating layer encode1
I1223 00:14:23.562355 25375 net.cpp:84] Creating Layer encode1
I1223 00:14:23.562358 25375 net.cpp:406] encode1 <- conv6-reshape_reshape-data_0_split_0
I1223 00:14:23.562362 25375 net.cpp:406] encode1 <- reshape-cm_reshape-cm_0_split_0
I1223 00:14:23.562366 25375 net.cpp:406] encode1 <- dummy_dummy_0_split_0
I1223 00:14:23.562371 25375 net.cpp:406] encode1 <- dummy_dummy_0_split_1
I1223 00:14:23.562377 25375 net.cpp:380] encode1 -> encode1
I1223 00:14:23.562391 25375 net.cpp:380] encode1 -> encode1_h
I1223 00:14:23.562398 25375 net.cpp:380] encode1 -> encode1_c
I1223 00:14:23.562410 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:23.563980 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode1_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode1_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode1_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode1_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode1_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode1_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode1_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode1_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode1_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode1_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode1_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode1_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode1_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode1_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode1_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode1_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode1_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->13"
  type: "Convolution"
  bottom: "h_conted_t=13"
  top: "hidden->transform->13"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_ou
I1223 00:14:23.564966 25375 layer_factory.hpp:77] Creating layer encode1_
I1223 00:14:23.564977 25375 net.cpp:84] Creating Layer encode1_
I1223 00:14:23.564982 25375 net.cpp:380] encode1_ -> x
I1223 00:14:23.564992 25375 net.cpp:380] encode1_ -> cont
I1223 00:14:23.565035 25375 net.cpp:122] Setting up encode1_
I1223 00:14:23.565043 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.565047 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.565050 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:23.565053 25375 layer_factory.hpp:77] Creating layer encode1_x->transform
I1223 00:14:23.565065 25375 net.cpp:84] Creating Layer encode1_x->transform
I1223 00:14:23.565073 25375 net.cpp:406] encode1_x->transform <- x
I1223 00:14:23.565079 25375 net.cpp:380] encode1_x->transform -> x->transform
I1223 00:14:23.565273 25375 net.cpp:122] Setting up encode1_x->transform
I1223 00:14:23.565281 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:23.565284 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:23.565289 25375 layer_factory.hpp:77] Creating layer encode1_input->cell_hidden
I1223 00:14:23.565294 25375 net.cpp:84] Creating Layer encode1_input->cell_hidden
I1223 00:14:23.565299 25375 net.cpp:380] encode1_input->cell_hidden -> c_t=0
I1223 00:14:23.565305 25375 net.cpp:380] encode1_input->cell_hidden -> h_t=0
I1223 00:14:23.565340 25375 net.cpp:122] Setting up encode1_input->cell_hidden
I1223 00:14:23.565347 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.565351 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.565354 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:23.565357 25375 layer_factory.hpp:77] Creating layer encode1_W_xc_x_slice
I1223 00:14:23.565363 25375 net.cpp:84] Creating Layer encode1_W_xc_x_slice
I1223 00:14:23.565366 25375 net.cpp:406] encode1_W_xc_x_slice <- x->transform
I1223 00:14:23.565374 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=1
I1223 00:14:23.565385 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=2
I1223 00:14:23.565393 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=3
I1223 00:14:23.565402 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=4
I1223 00:14:23.565410 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=5
I1223 00:14:23.565418 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=6
I1223 00:14:23.565426 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=7
I1223 00:14:23.565433 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=8
I1223 00:14:23.565440 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=9
I1223 00:14:23.565448 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=10
I1223 00:14:23.565455 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=11
I1223 00:14:23.565464 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=12
I1223 00:14:23.565474 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=13
I1223 00:14:23.565480 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=14
I1223 00:14:23.565488 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=15
I1223 00:14:23.565496 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=16
I1223 00:14:23.565681 25375 net.cpp:122] Setting up encode1_W_xc_x_slice
I1223 00:14:23.565688 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565692 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565696 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565701 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565704 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565708 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565711 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565716 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565719 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565722 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565726 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565731 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565733 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565737 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565740 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565745 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.565747 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:23.565750 25375 layer_factory.hpp:77] Creating layer encode1_cont_slice
I1223 00:14:23.565757 25375 net.cpp:84] Creating Layer encode1_cont_slice
I1223 00:14:23.565759 25375 net.cpp:406] encode1_cont_slice <- cont
I1223 00:14:23.565767 25375 net.cpp:380] encode1_cont_slice -> cont_t=1
I1223 00:14:23.565773 25375 net.cpp:380] encode1_cont_slice -> cont_t=2
I1223 00:14:23.565780 25375 net.cpp:380] encode1_cont_slice -> cont_t=3
I1223 00:14:23.565788 25375 net.cpp:380] encode1_cont_slice -> cont_t=4
I1223 00:14:23.565795 25375 net.cpp:380] encode1_cont_slice -> cont_t=5
I1223 00:14:23.565804 25375 net.cpp:380] encode1_cont_slice -> cont_t=6
I1223 00:14:23.565809 25375 net.cpp:380] encode1_cont_slice -> cont_t=7
I1223 00:14:23.565815 25375 net.cpp:380] encode1_cont_slice -> cont_t=8
I1223 00:14:23.565821 25375 net.cpp:380] encode1_cont_slice -> cont_t=9
I1223 00:14:23.565827 25375 net.cpp:380] encode1_cont_slice -> cont_t=10
I1223 00:14:23.565834 25375 net.cpp:380] encode1_cont_slice -> cont_t=11
I1223 00:14:23.565840 25375 net.cpp:380] encode1_cont_slice -> cont_t=12
I1223 00:14:23.565850 25375 net.cpp:380] encode1_cont_slice -> cont_t=13
I1223 00:14:23.565855 25375 net.cpp:380] encode1_cont_slice -> cont_t=14
I1223 00:14:23.565861 25375 net.cpp:380] encode1_cont_slice -> cont_t=15
I1223 00:14:23.565867 25375 net.cpp:380] encode1_cont_slice -> cont_t=16
I1223 00:14:23.566048 25375 net.cpp:122] Setting up encode1_cont_slice
I1223 00:14:23.566056 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566058 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566062 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566066 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566068 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566072 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566076 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566078 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566082 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566085 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566088 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566092 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566095 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566098 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566102 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566107 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566108 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:23.566112 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode1_cont_slice_0_split
I1223 00:14:23.566117 25375 net.cpp:84] Creating Layer cont_t=1_encode1_cont_slice_0_split
I1223 00:14:23.566119 25375 net.cpp:406] cont_t=1_encode1_cont_slice_0_split <- cont_t=1
I1223 00:14:23.566125 25375 net.cpp:380] cont_t=1_encode1_cont_slice_0_split -> cont_t=1_encode1_cont_slice_0_split_0
I1223 00:14:23.566131 25375 net.cpp:380] cont_t=1_encode1_cont_slice_0_split -> cont_t=1_encode1_cont_slice_0_split_1
I1223 00:14:23.566164 25375 net.cpp:122] Setting up cont_t=1_encode1_cont_slice_0_split
I1223 00:14:23.566170 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566174 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566176 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:23.566179 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode1_cont_slice_1_split
I1223 00:14:23.566184 25375 net.cpp:84] Creating Layer cont_t=2_encode1_cont_slice_1_split
I1223 00:14:23.566186 25375 net.cpp:406] cont_t=2_encode1_cont_slice_1_split <- cont_t=2
I1223 00:14:23.566192 25375 net.cpp:380] cont_t=2_encode1_cont_slice_1_split -> cont_t=2_encode1_cont_slice_1_split_0
I1223 00:14:23.566198 25375 net.cpp:380] cont_t=2_encode1_cont_slice_1_split -> cont_t=2_encode1_cont_slice_1_split_1
I1223 00:14:23.566231 25375 net.cpp:122] Setting up cont_t=2_encode1_cont_slice_1_split
I1223 00:14:23.566236 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566241 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566243 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:23.566246 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode1_cont_slice_2_split
I1223 00:14:23.566249 25375 net.cpp:84] Creating Layer cont_t=3_encode1_cont_slice_2_split
I1223 00:14:23.566253 25375 net.cpp:406] cont_t=3_encode1_cont_slice_2_split <- cont_t=3
I1223 00:14:23.566259 25375 net.cpp:380] cont_t=3_encode1_cont_slice_2_split -> cont_t=3_encode1_cont_slice_2_split_0
I1223 00:14:23.566265 25375 net.cpp:380] cont_t=3_encode1_cont_slice_2_split -> cont_t=3_encode1_cont_slice_2_split_1
I1223 00:14:23.566296 25375 net.cpp:122] Setting up cont_t=3_encode1_cont_slice_2_split
I1223 00:14:23.566303 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566306 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566308 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:23.566311 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode1_cont_slice_3_split
I1223 00:14:23.566318 25375 net.cpp:84] Creating Layer cont_t=4_encode1_cont_slice_3_split
I1223 00:14:23.566321 25375 net.cpp:406] cont_t=4_encode1_cont_slice_3_split <- cont_t=4
I1223 00:14:23.566328 25375 net.cpp:380] cont_t=4_encode1_cont_slice_3_split -> cont_t=4_encode1_cont_slice_3_split_0
I1223 00:14:23.566332 25375 net.cpp:380] cont_t=4_encode1_cont_slice_3_split -> cont_t=4_encode1_cont_slice_3_split_1
I1223 00:14:23.566364 25375 net.cpp:122] Setting up cont_t=4_encode1_cont_slice_3_split
I1223 00:14:23.566370 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566373 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566376 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:23.566378 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode1_cont_slice_4_split
I1223 00:14:23.566383 25375 net.cpp:84] Creating Layer cont_t=5_encode1_cont_slice_4_split
I1223 00:14:23.566386 25375 net.cpp:406] cont_t=5_encode1_cont_slice_4_split <- cont_t=5
I1223 00:14:23.566391 25375 net.cpp:380] cont_t=5_encode1_cont_slice_4_split -> cont_t=5_encode1_cont_slice_4_split_0
I1223 00:14:23.566397 25375 net.cpp:380] cont_t=5_encode1_cont_slice_4_split -> cont_t=5_encode1_cont_slice_4_split_1
I1223 00:14:23.566429 25375 net.cpp:122] Setting up cont_t=5_encode1_cont_slice_4_split
I1223 00:14:23.566435 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566439 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566442 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:23.566444 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode1_cont_slice_5_split
I1223 00:14:23.566448 25375 net.cpp:84] Creating Layer cont_t=6_encode1_cont_slice_5_split
I1223 00:14:23.566452 25375 net.cpp:406] cont_t=6_encode1_cont_slice_5_split <- cont_t=6
I1223 00:14:23.566455 25375 net.cpp:380] cont_t=6_encode1_cont_slice_5_split -> cont_t=6_encode1_cont_slice_5_split_0
I1223 00:14:23.566462 25375 net.cpp:380] cont_t=6_encode1_cont_slice_5_split -> cont_t=6_encode1_cont_slice_5_split_1
I1223 00:14:23.566490 25375 net.cpp:122] Setting up cont_t=6_encode1_cont_slice_5_split
I1223 00:14:23.566496 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566500 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566503 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:23.566505 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode1_cont_slice_6_split
I1223 00:14:23.566509 25375 net.cpp:84] Creating Layer cont_t=7_encode1_cont_slice_6_split
I1223 00:14:23.566512 25375 net.cpp:406] cont_t=7_encode1_cont_slice_6_split <- cont_t=7
I1223 00:14:23.566519 25375 net.cpp:380] cont_t=7_encode1_cont_slice_6_split -> cont_t=7_encode1_cont_slice_6_split_0
I1223 00:14:23.566524 25375 net.cpp:380] cont_t=7_encode1_cont_slice_6_split -> cont_t=7_encode1_cont_slice_6_split_1
I1223 00:14:23.566552 25375 net.cpp:122] Setting up cont_t=7_encode1_cont_slice_6_split
I1223 00:14:23.566558 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566562 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566565 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:23.566567 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode1_cont_slice_7_split
I1223 00:14:23.566572 25375 net.cpp:84] Creating Layer cont_t=8_encode1_cont_slice_7_split
I1223 00:14:23.566576 25375 net.cpp:406] cont_t=8_encode1_cont_slice_7_split <- cont_t=8
I1223 00:14:23.566581 25375 net.cpp:380] cont_t=8_encode1_cont_slice_7_split -> cont_t=8_encode1_cont_slice_7_split_0
I1223 00:14:23.566586 25375 net.cpp:380] cont_t=8_encode1_cont_slice_7_split -> cont_t=8_encode1_cont_slice_7_split_1
I1223 00:14:23.566615 25375 net.cpp:122] Setting up cont_t=8_encode1_cont_slice_7_split
I1223 00:14:23.566622 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566625 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566627 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:23.566630 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode1_cont_slice_8_split
I1223 00:14:23.566634 25375 net.cpp:84] Creating Layer cont_t=9_encode1_cont_slice_8_split
I1223 00:14:23.566637 25375 net.cpp:406] cont_t=9_encode1_cont_slice_8_split <- cont_t=9
I1223 00:14:23.566642 25375 net.cpp:380] cont_t=9_encode1_cont_slice_8_split -> cont_t=9_encode1_cont_slice_8_split_0
I1223 00:14:23.566648 25375 net.cpp:380] cont_t=9_encode1_cont_slice_8_split -> cont_t=9_encode1_cont_slice_8_split_1
I1223 00:14:23.566679 25375 net.cpp:122] Setting up cont_t=9_encode1_cont_slice_8_split
I1223 00:14:23.566685 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566689 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566691 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:23.566694 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode1_cont_slice_9_split
I1223 00:14:23.566704 25375 net.cpp:84] Creating Layer cont_t=10_encode1_cont_slice_9_split
I1223 00:14:23.566707 25375 net.cpp:406] cont_t=10_encode1_cont_slice_9_split <- cont_t=10
I1223 00:14:23.566712 25375 net.cpp:380] cont_t=10_encode1_cont_slice_9_split -> cont_t=10_encode1_cont_slice_9_split_0
I1223 00:14:23.566718 25375 net.cpp:380] cont_t=10_encode1_cont_slice_9_split -> cont_t=10_encode1_cont_slice_9_split_1
I1223 00:14:23.566750 25375 net.cpp:122] Setting up cont_t=10_encode1_cont_slice_9_split
I1223 00:14:23.566756 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566758 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566761 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:23.566764 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode1_cont_slice_10_split
I1223 00:14:23.566768 25375 net.cpp:84] Creating Layer cont_t=11_encode1_cont_slice_10_split
I1223 00:14:23.566771 25375 net.cpp:406] cont_t=11_encode1_cont_slice_10_split <- cont_t=11
I1223 00:14:23.566776 25375 net.cpp:380] cont_t=11_encode1_cont_slice_10_split -> cont_t=11_encode1_cont_slice_10_split_0
I1223 00:14:23.566782 25375 net.cpp:380] cont_t=11_encode1_cont_slice_10_split -> cont_t=11_encode1_cont_slice_10_split_1
I1223 00:14:23.566812 25375 net.cpp:122] Setting up cont_t=11_encode1_cont_slice_10_split
I1223 00:14:23.566817 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566821 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566823 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:23.566826 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode1_cont_slice_11_split
I1223 00:14:23.566833 25375 net.cpp:84] Creating Layer cont_t=12_encode1_cont_slice_11_split
I1223 00:14:23.566836 25375 net.cpp:406] cont_t=12_encode1_cont_slice_11_split <- cont_t=12
I1223 00:14:23.566841 25375 net.cpp:380] cont_t=12_encode1_cont_slice_11_split -> cont_t=12_encode1_cont_slice_11_split_0
I1223 00:14:23.566846 25375 net.cpp:380] cont_t=12_encode1_cont_slice_11_split -> cont_t=12_encode1_cont_slice_11_split_1
I1223 00:14:23.566877 25375 net.cpp:122] Setting up cont_t=12_encode1_cont_slice_11_split
I1223 00:14:23.566882 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566886 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566889 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:23.566891 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode1_cont_slice_12_split
I1223 00:14:23.566895 25375 net.cpp:84] Creating Layer cont_t=13_encode1_cont_slice_12_split
I1223 00:14:23.566900 25375 net.cpp:406] cont_t=13_encode1_cont_slice_12_split <- cont_t=13
I1223 00:14:23.566905 25375 net.cpp:380] cont_t=13_encode1_cont_slice_12_split -> cont_t=13_encode1_cont_slice_12_split_0
I1223 00:14:23.566910 25375 net.cpp:380] cont_t=13_encode1_cont_slice_12_split -> cont_t=13_encode1_cont_slice_12_split_1
I1223 00:14:23.566941 25375 net.cpp:122] Setting up cont_t=13_encode1_cont_slice_12_split
I1223 00:14:23.566946 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566949 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.566952 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:23.566956 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode1_cont_slice_13_split
I1223 00:14:23.566961 25375 net.cpp:84] Creating Layer cont_t=14_encode1_cont_slice_13_split
I1223 00:14:23.566963 25375 net.cpp:406] cont_t=14_encode1_cont_slice_13_split <- cont_t=14
I1223 00:14:23.566967 25375 net.cpp:380] cont_t=14_encode1_cont_slice_13_split -> cont_t=14_encode1_cont_slice_13_split_0
I1223 00:14:23.566973 25375 net.cpp:380] cont_t=14_encode1_cont_slice_13_split -> cont_t=14_encode1_cont_slice_13_split_1
I1223 00:14:23.567006 25375 net.cpp:122] Setting up cont_t=14_encode1_cont_slice_13_split
I1223 00:14:23.567013 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.567016 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.567019 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:23.567021 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode1_cont_slice_14_split
I1223 00:14:23.567025 25375 net.cpp:84] Creating Layer cont_t=15_encode1_cont_slice_14_split
I1223 00:14:23.567028 25375 net.cpp:406] cont_t=15_encode1_cont_slice_14_split <- cont_t=15
I1223 00:14:23.567034 25375 net.cpp:380] cont_t=15_encode1_cont_slice_14_split -> cont_t=15_encode1_cont_slice_14_split_0
I1223 00:14:23.567039 25375 net.cpp:380] cont_t=15_encode1_cont_slice_14_split -> cont_t=15_encode1_cont_slice_14_split_1
I1223 00:14:23.567068 25375 net.cpp:122] Setting up cont_t=15_encode1_cont_slice_14_split
I1223 00:14:23.567075 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.567078 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.567081 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:23.567083 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode1_cont_slice_15_split
I1223 00:14:23.567087 25375 net.cpp:84] Creating Layer cont_t=16_encode1_cont_slice_15_split
I1223 00:14:23.567091 25375 net.cpp:406] cont_t=16_encode1_cont_slice_15_split <- cont_t=16
I1223 00:14:23.567096 25375 net.cpp:380] cont_t=16_encode1_cont_slice_15_split -> cont_t=16_encode1_cont_slice_15_split_0
I1223 00:14:23.567102 25375 net.cpp:380] cont_t=16_encode1_cont_slice_15_split -> cont_t=16_encode1_cont_slice_15_split_1
I1223 00:14:23.567132 25375 net.cpp:122] Setting up cont_t=16_encode1_cont_slice_15_split
I1223 00:14:23.567139 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.567142 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.567145 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:23.567147 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_c0
I1223 00:14:23.567152 25375 net.cpp:84] Creating Layer encode1_dummy_forward_c0
I1223 00:14:23.567155 25375 net.cpp:406] encode1_dummy_forward_c0 <- c_t=0
I1223 00:14:23.567160 25375 net.cpp:367] encode1_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:23.567181 25375 net.cpp:122] Setting up encode1_dummy_forward_c0
I1223 00:14:23.567188 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.567191 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:23.567198 25375 layer_factory.hpp:77] Creating layer c_t=0_encode1_dummy_forward_c0_0_split
I1223 00:14:23.567203 25375 net.cpp:84] Creating Layer c_t=0_encode1_dummy_forward_c0_0_split
I1223 00:14:23.567206 25375 net.cpp:406] c_t=0_encode1_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:23.567211 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_0
I1223 00:14:23.567217 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_1
I1223 00:14:23.567224 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_2
I1223 00:14:23.567230 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_3
I1223 00:14:23.567287 25375 net.cpp:122] Setting up c_t=0_encode1_dummy_forward_c0_0_split
I1223 00:14:23.567294 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.567298 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.567302 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.567306 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.567308 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:23.567312 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_h0
I1223 00:14:23.567317 25375 net.cpp:84] Creating Layer encode1_dummy_forward_h0
I1223 00:14:23.567319 25375 net.cpp:406] encode1_dummy_forward_h0 <- h_t=0
I1223 00:14:23.567325 25375 net.cpp:367] encode1_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:23.567345 25375 net.cpp:122] Setting up encode1_dummy_forward_h0
I1223 00:14:23.567351 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.567353 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:23.567359 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=0
I1223 00:14:23.567364 25375 net.cpp:84] Creating Layer encode1_h_conted_t=0
I1223 00:14:23.567368 25375 net.cpp:406] encode1_h_conted_t=0 <- h_t=0
I1223 00:14:23.567373 25375 net.cpp:406] encode1_h_conted_t=0 <- cont_t=1_encode1_cont_slice_0_split_0
I1223 00:14:23.567379 25375 net.cpp:380] encode1_h_conted_t=0 -> h_conted_t=0
I1223 00:14:23.567471 25375 net.cpp:122] Setting up encode1_h_conted_t=0
I1223 00:14:23.567477 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.567481 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:23.567483 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->0
I1223 00:14:23.567492 25375 net.cpp:84] Creating Layer encode1_hidden->transform->0
I1223 00:14:23.567495 25375 net.cpp:406] encode1_hidden->transform->0 <- h_conted_t=0
I1223 00:14:23.567502 25375 net.cpp:380] encode1_hidden->transform->0 -> hidden->transform->0
I1223 00:14:23.567992 25375 net.cpp:122] Setting up encode1_hidden->transform->0
I1223 00:14:23.568001 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.568003 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:23.568011 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=0
I1223 00:14:23.568017 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=0
I1223 00:14:23.568022 25375 net.cpp:406] encode1_hadamard->input_t=0 <- c_t=0_encode1_dummy_forward_c0_0_split_0
I1223 00:14:23.568027 25375 net.cpp:380] encode1_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:23.568130 25375 net.cpp:122] Setting up encode1_hadamard->input_t=0
I1223 00:14:23.568137 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568140 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:23.568145 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=0
I1223 00:14:23.568150 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=0
I1223 00:14:23.568155 25375 net.cpp:406] encode1_hadamard->forget_t=0 <- c_t=0_encode1_dummy_forward_c0_0_split_1
I1223 00:14:23.568159 25375 net.cpp:380] encode1_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:23.568255 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=0
I1223 00:14:23.568262 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568264 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:23.568282 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=0
I1223 00:14:23.568287 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=0
I1223 00:14:23.568290 25375 net.cpp:406] encode1_hadamard->output_t=0 <- c_t=0_encode1_dummy_forward_c0_0_split_2
I1223 00:14:23.568295 25375 net.cpp:380] encode1_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:23.568389 25375 net.cpp:122] Setting up encode1_hadamard->output_t=0
I1223 00:14:23.568397 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568400 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:23.568403 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=1
I1223 00:14:23.568409 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=1
I1223 00:14:23.568413 25375 net.cpp:380] encode1_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:23.568490 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=1
I1223 00:14:23.568497 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568500 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:23.568503 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=1
I1223 00:14:23.568509 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=1
I1223 00:14:23.568512 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:23.568516 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:23.568521 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:23.568524 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:23.568543 25375 net.cpp:380] encode1_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:23.568567 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=1
I1223 00:14:23.568574 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.568576 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:23.568579 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_1
I1223 00:14:23.568584 25375 net.cpp:84] Creating Layer encode1_gate_input_1
I1223 00:14:23.568588 25375 net.cpp:406] encode1_gate_input_1 <- hidden->transform->0
I1223 00:14:23.568593 25375 net.cpp:406] encode1_gate_input_1 <- x->transform->t=1
I1223 00:14:23.568596 25375 net.cpp:406] encode1_gate_input_1 <- hadamard_t=1
I1223 00:14:23.568603 25375 net.cpp:380] encode1_gate_input_1 -> gate_input_1
I1223 00:14:23.568624 25375 net.cpp:122] Setting up encode1_gate_input_1
I1223 00:14:23.568632 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.568636 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:23.568639 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=1
I1223 00:14:23.568646 25375 net.cpp:84] Creating Layer encode1_unit_t=1
I1223 00:14:23.568650 25375 net.cpp:406] encode1_unit_t=1 <- c_t=0_encode1_dummy_forward_c0_0_split_3
I1223 00:14:23.568655 25375 net.cpp:406] encode1_unit_t=1 <- gate_input_1
I1223 00:14:23.568657 25375 net.cpp:406] encode1_unit_t=1 <- cont_t=1_encode1_cont_slice_0_split_1
I1223 00:14:23.568663 25375 net.cpp:380] encode1_unit_t=1 -> c_t=1
I1223 00:14:23.568670 25375 net.cpp:380] encode1_unit_t=1 -> h_t=1
I1223 00:14:23.568714 25375 net.cpp:122] Setting up encode1_unit_t=1
I1223 00:14:23.568722 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568725 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568728 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:23.568732 25375 layer_factory.hpp:77] Creating layer c_t=1_encode1_unit_t=1_0_split
I1223 00:14:23.568735 25375 net.cpp:84] Creating Layer c_t=1_encode1_unit_t=1_0_split
I1223 00:14:23.568739 25375 net.cpp:406] c_t=1_encode1_unit_t=1_0_split <- c_t=1
I1223 00:14:23.568745 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_0
I1223 00:14:23.568753 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_1
I1223 00:14:23.568758 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_2
I1223 00:14:23.568764 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_3
I1223 00:14:23.568819 25375 net.cpp:122] Setting up c_t=1_encode1_unit_t=1_0_split
I1223 00:14:23.568825 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568830 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568833 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568837 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568840 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:23.568842 25375 layer_factory.hpp:77] Creating layer h_t=1_encode1_unit_t=1_1_split
I1223 00:14:23.568847 25375 net.cpp:84] Creating Layer h_t=1_encode1_unit_t=1_1_split
I1223 00:14:23.568850 25375 net.cpp:406] h_t=1_encode1_unit_t=1_1_split <- h_t=1
I1223 00:14:23.568855 25375 net.cpp:380] h_t=1_encode1_unit_t=1_1_split -> h_t=1_encode1_unit_t=1_1_split_0
I1223 00:14:23.568861 25375 net.cpp:380] h_t=1_encode1_unit_t=1_1_split -> h_t=1_encode1_unit_t=1_1_split_1
I1223 00:14:23.568892 25375 net.cpp:122] Setting up h_t=1_encode1_unit_t=1_1_split
I1223 00:14:23.568898 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568902 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.568904 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:23.568907 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=1
I1223 00:14:23.568913 25375 net.cpp:84] Creating Layer encode1_h_conted_t=1
I1223 00:14:23.568917 25375 net.cpp:406] encode1_h_conted_t=1 <- h_t=1_encode1_unit_t=1_1_split_0
I1223 00:14:23.568922 25375 net.cpp:406] encode1_h_conted_t=1 <- cont_t=2_encode1_cont_slice_1_split_0
I1223 00:14:23.568927 25375 net.cpp:380] encode1_h_conted_t=1 -> h_conted_t=1
I1223 00:14:23.568997 25375 net.cpp:122] Setting up encode1_h_conted_t=1
I1223 00:14:23.569005 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.569007 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:23.569010 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->1
I1223 00:14:23.569018 25375 net.cpp:84] Creating Layer encode1_hidden->transform->1
I1223 00:14:23.569022 25375 net.cpp:406] encode1_hidden->transform->1 <- h_conted_t=1
I1223 00:14:23.569028 25375 net.cpp:380] encode1_hidden->transform->1 -> hidden->transform->1
I1223 00:14:23.569514 25375 net.cpp:122] Setting up encode1_hidden->transform->1
I1223 00:14:23.569522 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.569526 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:23.569531 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.569536 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.569540 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=1
I1223 00:14:23.569546 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=1
I1223 00:14:23.569550 25375 net.cpp:406] encode1_hadamard->input_t=1 <- c_t=1_encode1_unit_t=1_0_split_0
I1223 00:14:23.569555 25375 net.cpp:380] encode1_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:23.569640 25375 net.cpp:122] Setting up encode1_hadamard->input_t=1
I1223 00:14:23.569648 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.569651 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:23.569654 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.569658 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=1
I1223 00:14:23.569664 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=1
I1223 00:14:23.569667 25375 net.cpp:406] encode1_hadamard->forget_t=1 <- c_t=1_encode1_unit_t=1_0_split_1
I1223 00:14:23.569672 25375 net.cpp:380] encode1_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:23.569767 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=1
I1223 00:14:23.569774 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.569777 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:23.569782 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.569784 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=1
I1223 00:14:23.569802 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=1
I1223 00:14:23.569805 25375 net.cpp:406] encode1_hadamard->output_t=1 <- c_t=1_encode1_unit_t=1_0_split_2
I1223 00:14:23.569810 25375 net.cpp:380] encode1_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:23.569905 25375 net.cpp:122] Setting up encode1_hadamard->output_t=1
I1223 00:14:23.569912 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.569916 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:23.569918 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.569921 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=2
I1223 00:14:23.569926 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=2
I1223 00:14:23.569931 25375 net.cpp:380] encode1_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:23.570736 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=2
I1223 00:14:23.570746 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.570749 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:23.570752 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=2
I1223 00:14:23.570760 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=2
I1223 00:14:23.570765 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:23.570770 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:23.570773 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:23.570777 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:23.570782 25375 net.cpp:380] encode1_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:23.570824 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=2
I1223 00:14:23.570830 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.570833 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:23.570837 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_2
I1223 00:14:23.570842 25375 net.cpp:84] Creating Layer encode1_gate_input_2
I1223 00:14:23.570844 25375 net.cpp:406] encode1_gate_input_2 <- hidden->transform->1
I1223 00:14:23.570849 25375 net.cpp:406] encode1_gate_input_2 <- x->transform->t=2
I1223 00:14:23.570852 25375 net.cpp:406] encode1_gate_input_2 <- hadamard_t=2
I1223 00:14:23.570858 25375 net.cpp:380] encode1_gate_input_2 -> gate_input_2
I1223 00:14:23.570883 25375 net.cpp:122] Setting up encode1_gate_input_2
I1223 00:14:23.570888 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.570891 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:23.570894 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=2
I1223 00:14:23.570902 25375 net.cpp:84] Creating Layer encode1_unit_t=2
I1223 00:14:23.570906 25375 net.cpp:406] encode1_unit_t=2 <- c_t=1_encode1_unit_t=1_0_split_3
I1223 00:14:23.570910 25375 net.cpp:406] encode1_unit_t=2 <- gate_input_2
I1223 00:14:23.570914 25375 net.cpp:406] encode1_unit_t=2 <- cont_t=2_encode1_cont_slice_1_split_1
I1223 00:14:23.570919 25375 net.cpp:380] encode1_unit_t=2 -> c_t=2
I1223 00:14:23.570925 25375 net.cpp:380] encode1_unit_t=2 -> h_t=2
I1223 00:14:23.570991 25375 net.cpp:122] Setting up encode1_unit_t=2
I1223 00:14:23.570998 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571002 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571005 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:23.571008 25375 layer_factory.hpp:77] Creating layer c_t=2_encode1_unit_t=2_0_split
I1223 00:14:23.571013 25375 net.cpp:84] Creating Layer c_t=2_encode1_unit_t=2_0_split
I1223 00:14:23.571017 25375 net.cpp:406] c_t=2_encode1_unit_t=2_0_split <- c_t=2
I1223 00:14:23.571022 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_0
I1223 00:14:23.571029 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_1
I1223 00:14:23.571049 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_2
I1223 00:14:23.571055 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_3
I1223 00:14:23.571111 25375 net.cpp:122] Setting up c_t=2_encode1_unit_t=2_0_split
I1223 00:14:23.571118 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571122 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571125 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571130 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571132 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:23.571135 25375 layer_factory.hpp:77] Creating layer h_t=2_encode1_unit_t=2_1_split
I1223 00:14:23.571139 25375 net.cpp:84] Creating Layer h_t=2_encode1_unit_t=2_1_split
I1223 00:14:23.571143 25375 net.cpp:406] h_t=2_encode1_unit_t=2_1_split <- h_t=2
I1223 00:14:23.571147 25375 net.cpp:380] h_t=2_encode1_unit_t=2_1_split -> h_t=2_encode1_unit_t=2_1_split_0
I1223 00:14:23.571156 25375 net.cpp:380] h_t=2_encode1_unit_t=2_1_split -> h_t=2_encode1_unit_t=2_1_split_1
I1223 00:14:23.571185 25375 net.cpp:122] Setting up h_t=2_encode1_unit_t=2_1_split
I1223 00:14:23.571192 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571197 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571198 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:23.571202 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=2
I1223 00:14:23.571208 25375 net.cpp:84] Creating Layer encode1_h_conted_t=2
I1223 00:14:23.571211 25375 net.cpp:406] encode1_h_conted_t=2 <- h_t=2_encode1_unit_t=2_1_split_0
I1223 00:14:23.571215 25375 net.cpp:406] encode1_h_conted_t=2 <- cont_t=3_encode1_cont_slice_2_split_0
I1223 00:14:23.571220 25375 net.cpp:380] encode1_h_conted_t=2 -> h_conted_t=2
I1223 00:14:23.571307 25375 net.cpp:122] Setting up encode1_h_conted_t=2
I1223 00:14:23.571315 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571317 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:23.571321 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->2
I1223 00:14:23.571329 25375 net.cpp:84] Creating Layer encode1_hidden->transform->2
I1223 00:14:23.571333 25375 net.cpp:406] encode1_hidden->transform->2 <- h_conted_t=2
I1223 00:14:23.571341 25375 net.cpp:380] encode1_hidden->transform->2 -> hidden->transform->2
I1223 00:14:23.571837 25375 net.cpp:122] Setting up encode1_hidden->transform->2
I1223 00:14:23.571846 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.571848 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:23.571852 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.571856 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.571859 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=2
I1223 00:14:23.571864 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=2
I1223 00:14:23.571868 25375 net.cpp:406] encode1_hadamard->input_t=2 <- c_t=2_encode1_unit_t=2_0_split_0
I1223 00:14:23.571873 25375 net.cpp:380] encode1_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:23.571972 25375 net.cpp:122] Setting up encode1_hadamard->input_t=2
I1223 00:14:23.571979 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.571982 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:23.571986 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.571990 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=2
I1223 00:14:23.571995 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=2
I1223 00:14:23.572000 25375 net.cpp:406] encode1_hadamard->forget_t=2 <- c_t=2_encode1_unit_t=2_0_split_1
I1223 00:14:23.572005 25375 net.cpp:380] encode1_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:23.572099 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=2
I1223 00:14:23.572108 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572109 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:23.572115 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.572119 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=2
I1223 00:14:23.572124 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=2
I1223 00:14:23.572127 25375 net.cpp:406] encode1_hadamard->output_t=2 <- c_t=2_encode1_unit_t=2_0_split_2
I1223 00:14:23.572134 25375 net.cpp:380] encode1_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:23.572232 25375 net.cpp:122] Setting up encode1_hadamard->output_t=2
I1223 00:14:23.572239 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572242 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:23.572245 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.572249 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=3
I1223 00:14:23.572268 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=3
I1223 00:14:23.572273 25375 net.cpp:380] encode1_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:23.572335 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=3
I1223 00:14:23.572342 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572345 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:23.572348 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=3
I1223 00:14:23.572355 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=3
I1223 00:14:23.572360 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:23.572376 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:23.572379 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:23.572381 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:23.572386 25375 net.cpp:380] encode1_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:23.572405 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=3
I1223 00:14:23.572412 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.572414 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:23.572417 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_3
I1223 00:14:23.572422 25375 net.cpp:84] Creating Layer encode1_gate_input_3
I1223 00:14:23.572425 25375 net.cpp:406] encode1_gate_input_3 <- hidden->transform->2
I1223 00:14:23.572432 25375 net.cpp:406] encode1_gate_input_3 <- x->transform->t=3
I1223 00:14:23.572435 25375 net.cpp:406] encode1_gate_input_3 <- hadamard_t=3
I1223 00:14:23.572440 25375 net.cpp:380] encode1_gate_input_3 -> gate_input_3
I1223 00:14:23.572463 25375 net.cpp:122] Setting up encode1_gate_input_3
I1223 00:14:23.572469 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.572473 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:23.572474 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=3
I1223 00:14:23.572479 25375 net.cpp:84] Creating Layer encode1_unit_t=3
I1223 00:14:23.572481 25375 net.cpp:406] encode1_unit_t=3 <- c_t=2_encode1_unit_t=2_0_split_3
I1223 00:14:23.572485 25375 net.cpp:406] encode1_unit_t=3 <- gate_input_3
I1223 00:14:23.572489 25375 net.cpp:406] encode1_unit_t=3 <- cont_t=3_encode1_cont_slice_2_split_1
I1223 00:14:23.572494 25375 net.cpp:380] encode1_unit_t=3 -> c_t=3
I1223 00:14:23.572500 25375 net.cpp:380] encode1_unit_t=3 -> h_t=3
I1223 00:14:23.572546 25375 net.cpp:122] Setting up encode1_unit_t=3
I1223 00:14:23.572552 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572556 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572559 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:23.572561 25375 layer_factory.hpp:77] Creating layer c_t=3_encode1_unit_t=3_0_split
I1223 00:14:23.572566 25375 net.cpp:84] Creating Layer c_t=3_encode1_unit_t=3_0_split
I1223 00:14:23.572569 25375 net.cpp:406] c_t=3_encode1_unit_t=3_0_split <- c_t=3
I1223 00:14:23.572576 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_0
I1223 00:14:23.572584 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_1
I1223 00:14:23.572592 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_2
I1223 00:14:23.572598 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_3
I1223 00:14:23.572661 25375 net.cpp:122] Setting up c_t=3_encode1_unit_t=3_0_split
I1223 00:14:23.572670 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572674 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572679 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572681 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572685 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:23.572687 25375 layer_factory.hpp:77] Creating layer h_t=3_encode1_unit_t=3_1_split
I1223 00:14:23.572691 25375 net.cpp:84] Creating Layer h_t=3_encode1_unit_t=3_1_split
I1223 00:14:23.572695 25375 net.cpp:406] h_t=3_encode1_unit_t=3_1_split <- h_t=3
I1223 00:14:23.572700 25375 net.cpp:380] h_t=3_encode1_unit_t=3_1_split -> h_t=3_encode1_unit_t=3_1_split_0
I1223 00:14:23.572706 25375 net.cpp:380] h_t=3_encode1_unit_t=3_1_split -> h_t=3_encode1_unit_t=3_1_split_1
I1223 00:14:23.572741 25375 net.cpp:122] Setting up h_t=3_encode1_unit_t=3_1_split
I1223 00:14:23.572748 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572752 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572755 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:23.572758 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=3
I1223 00:14:23.572763 25375 net.cpp:84] Creating Layer encode1_h_conted_t=3
I1223 00:14:23.572767 25375 net.cpp:406] encode1_h_conted_t=3 <- h_t=3_encode1_unit_t=3_1_split_0
I1223 00:14:23.572772 25375 net.cpp:406] encode1_h_conted_t=3 <- cont_t=4_encode1_cont_slice_3_split_0
I1223 00:14:23.572777 25375 net.cpp:380] encode1_h_conted_t=3 -> h_conted_t=3
I1223 00:14:23.572851 25375 net.cpp:122] Setting up encode1_h_conted_t=3
I1223 00:14:23.572860 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.572863 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:23.572866 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->3
I1223 00:14:23.572875 25375 net.cpp:84] Creating Layer encode1_hidden->transform->3
I1223 00:14:23.572880 25375 net.cpp:406] encode1_hidden->transform->3 <- h_conted_t=3
I1223 00:14:23.572887 25375 net.cpp:380] encode1_hidden->transform->3 -> hidden->transform->3
I1223 00:14:23.573381 25375 net.cpp:122] Setting up encode1_hidden->transform->3
I1223 00:14:23.573390 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.573395 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:23.573398 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.573401 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.573405 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=3
I1223 00:14:23.573412 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=3
I1223 00:14:23.573415 25375 net.cpp:406] encode1_hadamard->input_t=3 <- c_t=3_encode1_unit_t=3_0_split_0
I1223 00:14:23.573422 25375 net.cpp:380] encode1_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:23.573521 25375 net.cpp:122] Setting up encode1_hadamard->input_t=3
I1223 00:14:23.573529 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.573545 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:23.573549 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.573551 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=3
I1223 00:14:23.573559 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=3
I1223 00:14:23.573561 25375 net.cpp:406] encode1_hadamard->forget_t=3 <- c_t=3_encode1_unit_t=3_0_split_1
I1223 00:14:23.573567 25375 net.cpp:380] encode1_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:23.573650 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=3
I1223 00:14:23.573658 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.573662 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:23.573664 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.573668 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=3
I1223 00:14:23.573673 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=3
I1223 00:14:23.573676 25375 net.cpp:406] encode1_hadamard->output_t=3 <- c_t=3_encode1_unit_t=3_0_split_2
I1223 00:14:23.573683 25375 net.cpp:380] encode1_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:23.573776 25375 net.cpp:122] Setting up encode1_hadamard->output_t=3
I1223 00:14:23.573782 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.573786 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:23.573801 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.573806 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=4
I1223 00:14:23.573812 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=4
I1223 00:14:23.573815 25375 net.cpp:380] encode1_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:23.573880 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=4
I1223 00:14:23.573900 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.573904 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:23.573906 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=4
I1223 00:14:23.573911 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=4
I1223 00:14:23.573915 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:23.573932 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:23.573936 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:23.573940 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:23.573945 25375 net.cpp:380] encode1_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:23.573982 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=4
I1223 00:14:23.573987 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.573990 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:23.573993 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_4
I1223 00:14:23.574003 25375 net.cpp:84] Creating Layer encode1_gate_input_4
I1223 00:14:23.574007 25375 net.cpp:406] encode1_gate_input_4 <- hidden->transform->3
I1223 00:14:23.574012 25375 net.cpp:406] encode1_gate_input_4 <- x->transform->t=4
I1223 00:14:23.574015 25375 net.cpp:406] encode1_gate_input_4 <- hadamard_t=4
I1223 00:14:23.574020 25375 net.cpp:380] encode1_gate_input_4 -> gate_input_4
I1223 00:14:23.574048 25375 net.cpp:122] Setting up encode1_gate_input_4
I1223 00:14:23.574054 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.574057 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:23.574060 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=4
I1223 00:14:23.574065 25375 net.cpp:84] Creating Layer encode1_unit_t=4
I1223 00:14:23.574069 25375 net.cpp:406] encode1_unit_t=4 <- c_t=3_encode1_unit_t=3_0_split_3
I1223 00:14:23.574072 25375 net.cpp:406] encode1_unit_t=4 <- gate_input_4
I1223 00:14:23.574076 25375 net.cpp:406] encode1_unit_t=4 <- cont_t=4_encode1_cont_slice_3_split_1
I1223 00:14:23.574081 25375 net.cpp:380] encode1_unit_t=4 -> c_t=4
I1223 00:14:23.574087 25375 net.cpp:380] encode1_unit_t=4 -> h_t=4
I1223 00:14:23.574136 25375 net.cpp:122] Setting up encode1_unit_t=4
I1223 00:14:23.574142 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574146 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574148 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:23.574151 25375 layer_factory.hpp:77] Creating layer c_t=4_encode1_unit_t=4_0_split
I1223 00:14:23.574156 25375 net.cpp:84] Creating Layer c_t=4_encode1_unit_t=4_0_split
I1223 00:14:23.574159 25375 net.cpp:406] c_t=4_encode1_unit_t=4_0_split <- c_t=4
I1223 00:14:23.574164 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_0
I1223 00:14:23.574172 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_1
I1223 00:14:23.574179 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_2
I1223 00:14:23.574187 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_3
I1223 00:14:23.574239 25375 net.cpp:122] Setting up c_t=4_encode1_unit_t=4_0_split
I1223 00:14:23.574246 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574250 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574254 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574257 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574260 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:23.574264 25375 layer_factory.hpp:77] Creating layer h_t=4_encode1_unit_t=4_1_split
I1223 00:14:23.574270 25375 net.cpp:84] Creating Layer h_t=4_encode1_unit_t=4_1_split
I1223 00:14:23.574275 25375 net.cpp:406] h_t=4_encode1_unit_t=4_1_split <- h_t=4
I1223 00:14:23.574280 25375 net.cpp:380] h_t=4_encode1_unit_t=4_1_split -> h_t=4_encode1_unit_t=4_1_split_0
I1223 00:14:23.574285 25375 net.cpp:380] h_t=4_encode1_unit_t=4_1_split -> h_t=4_encode1_unit_t=4_1_split_1
I1223 00:14:23.574318 25375 net.cpp:122] Setting up h_t=4_encode1_unit_t=4_1_split
I1223 00:14:23.574324 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574328 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574331 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:23.574334 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=4
I1223 00:14:23.574339 25375 net.cpp:84] Creating Layer encode1_h_conted_t=4
I1223 00:14:23.574344 25375 net.cpp:406] encode1_h_conted_t=4 <- h_t=4_encode1_unit_t=4_1_split_0
I1223 00:14:23.574348 25375 net.cpp:406] encode1_h_conted_t=4 <- cont_t=5_encode1_cont_slice_4_split_0
I1223 00:14:23.574353 25375 net.cpp:380] encode1_h_conted_t=4 -> h_conted_t=4
I1223 00:14:23.574430 25375 net.cpp:122] Setting up encode1_h_conted_t=4
I1223 00:14:23.574437 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.574440 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:23.574443 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->4
I1223 00:14:23.574452 25375 net.cpp:84] Creating Layer encode1_hidden->transform->4
I1223 00:14:23.574456 25375 net.cpp:406] encode1_hidden->transform->4 <- h_conted_t=4
I1223 00:14:23.574463 25375 net.cpp:380] encode1_hidden->transform->4 -> hidden->transform->4
I1223 00:14:23.574949 25375 net.cpp:122] Setting up encode1_hidden->transform->4
I1223 00:14:23.574957 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.574959 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:23.574964 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.574967 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.574970 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=4
I1223 00:14:23.574977 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=4
I1223 00:14:23.574981 25375 net.cpp:406] encode1_hadamard->input_t=4 <- c_t=4_encode1_unit_t=4_0_split_0
I1223 00:14:23.574987 25375 net.cpp:380] encode1_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:23.575073 25375 net.cpp:122] Setting up encode1_hadamard->input_t=4
I1223 00:14:23.575080 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575083 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:23.575088 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.575090 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=4
I1223 00:14:23.575096 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=4
I1223 00:14:23.575101 25375 net.cpp:406] encode1_hadamard->forget_t=4 <- c_t=4_encode1_unit_t=4_0_split_1
I1223 00:14:23.575106 25375 net.cpp:380] encode1_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:23.575230 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=4
I1223 00:14:23.575237 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575240 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:23.575244 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.575248 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=4
I1223 00:14:23.575253 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=4
I1223 00:14:23.575258 25375 net.cpp:406] encode1_hadamard->output_t=4 <- c_t=4_encode1_unit_t=4_0_split_2
I1223 00:14:23.575263 25375 net.cpp:380] encode1_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:23.575343 25375 net.cpp:122] Setting up encode1_hadamard->output_t=4
I1223 00:14:23.575350 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575353 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:23.575356 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.575359 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=5
I1223 00:14:23.575366 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=5
I1223 00:14:23.575372 25375 net.cpp:380] encode1_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:23.575436 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=5
I1223 00:14:23.575456 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575459 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:23.575462 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=5
I1223 00:14:23.575467 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=5
I1223 00:14:23.575470 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:23.575475 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:23.575479 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:23.575484 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:23.575501 25375 net.cpp:380] encode1_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:23.575522 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=5
I1223 00:14:23.575528 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.575531 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:23.575534 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_5
I1223 00:14:23.575541 25375 net.cpp:84] Creating Layer encode1_gate_input_5
I1223 00:14:23.575544 25375 net.cpp:406] encode1_gate_input_5 <- hidden->transform->4
I1223 00:14:23.575549 25375 net.cpp:406] encode1_gate_input_5 <- x->transform->t=5
I1223 00:14:23.575552 25375 net.cpp:406] encode1_gate_input_5 <- hadamard_t=5
I1223 00:14:23.575559 25375 net.cpp:380] encode1_gate_input_5 -> gate_input_5
I1223 00:14:23.575582 25375 net.cpp:122] Setting up encode1_gate_input_5
I1223 00:14:23.575587 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.575589 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:23.575592 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=5
I1223 00:14:23.575599 25375 net.cpp:84] Creating Layer encode1_unit_t=5
I1223 00:14:23.575603 25375 net.cpp:406] encode1_unit_t=5 <- c_t=4_encode1_unit_t=4_0_split_3
I1223 00:14:23.575608 25375 net.cpp:406] encode1_unit_t=5 <- gate_input_5
I1223 00:14:23.575611 25375 net.cpp:406] encode1_unit_t=5 <- cont_t=5_encode1_cont_slice_4_split_1
I1223 00:14:23.575616 25375 net.cpp:380] encode1_unit_t=5 -> c_t=5
I1223 00:14:23.575623 25375 net.cpp:380] encode1_unit_t=5 -> h_t=5
I1223 00:14:23.575667 25375 net.cpp:122] Setting up encode1_unit_t=5
I1223 00:14:23.575675 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575678 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575681 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:23.575685 25375 layer_factory.hpp:77] Creating layer c_t=5_encode1_unit_t=5_0_split
I1223 00:14:23.575688 25375 net.cpp:84] Creating Layer c_t=5_encode1_unit_t=5_0_split
I1223 00:14:23.575692 25375 net.cpp:406] c_t=5_encode1_unit_t=5_0_split <- c_t=5
I1223 00:14:23.575700 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_0
I1223 00:14:23.575706 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_1
I1223 00:14:23.575714 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_2
I1223 00:14:23.575721 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_3
I1223 00:14:23.575775 25375 net.cpp:122] Setting up c_t=5_encode1_unit_t=5_0_split
I1223 00:14:23.575783 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575786 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575790 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575793 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575796 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:23.575799 25375 layer_factory.hpp:77] Creating layer h_t=5_encode1_unit_t=5_1_split
I1223 00:14:23.575804 25375 net.cpp:84] Creating Layer h_t=5_encode1_unit_t=5_1_split
I1223 00:14:23.575808 25375 net.cpp:406] h_t=5_encode1_unit_t=5_1_split <- h_t=5
I1223 00:14:23.575812 25375 net.cpp:380] h_t=5_encode1_unit_t=5_1_split -> h_t=5_encode1_unit_t=5_1_split_0
I1223 00:14:23.575817 25375 net.cpp:380] h_t=5_encode1_unit_t=5_1_split -> h_t=5_encode1_unit_t=5_1_split_1
I1223 00:14:23.575851 25375 net.cpp:122] Setting up h_t=5_encode1_unit_t=5_1_split
I1223 00:14:23.575857 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575861 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575865 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:23.575867 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=5
I1223 00:14:23.575875 25375 net.cpp:84] Creating Layer encode1_h_conted_t=5
I1223 00:14:23.575881 25375 net.cpp:406] encode1_h_conted_t=5 <- h_t=5_encode1_unit_t=5_1_split_0
I1223 00:14:23.575884 25375 net.cpp:406] encode1_h_conted_t=5 <- cont_t=6_encode1_cont_slice_5_split_0
I1223 00:14:23.575889 25375 net.cpp:380] encode1_h_conted_t=5 -> h_conted_t=5
I1223 00:14:23.575963 25375 net.cpp:122] Setting up encode1_h_conted_t=5
I1223 00:14:23.575969 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.575973 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:23.575975 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->5
I1223 00:14:23.575984 25375 net.cpp:84] Creating Layer encode1_hidden->transform->5
I1223 00:14:23.575989 25375 net.cpp:406] encode1_hidden->transform->5 <- h_conted_t=5
I1223 00:14:23.575994 25375 net.cpp:380] encode1_hidden->transform->5 -> hidden->transform->5
I1223 00:14:23.576486 25375 net.cpp:122] Setting up encode1_hidden->transform->5
I1223 00:14:23.576494 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.576498 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:23.576501 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.576506 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.576509 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=5
I1223 00:14:23.576514 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=5
I1223 00:14:23.576519 25375 net.cpp:406] encode1_hadamard->input_t=5 <- c_t=5_encode1_unit_t=5_0_split_0
I1223 00:14:23.576525 25375 net.cpp:380] encode1_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:23.576611 25375 net.cpp:122] Setting up encode1_hadamard->input_t=5
I1223 00:14:23.576619 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.576622 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:23.576625 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.576628 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=5
I1223 00:14:23.576634 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=5
I1223 00:14:23.576638 25375 net.cpp:406] encode1_hadamard->forget_t=5 <- c_t=5_encode1_unit_t=5_0_split_1
I1223 00:14:23.576644 25375 net.cpp:380] encode1_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:23.576740 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=5
I1223 00:14:23.576747 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.576750 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:23.576753 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.576756 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=5
I1223 00:14:23.576774 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=5
I1223 00:14:23.576777 25375 net.cpp:406] encode1_hadamard->output_t=5 <- c_t=5_encode1_unit_t=5_0_split_2
I1223 00:14:23.576782 25375 net.cpp:380] encode1_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:23.576865 25375 net.cpp:122] Setting up encode1_hadamard->output_t=5
I1223 00:14:23.576872 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.576874 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:23.576880 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.576885 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=6
I1223 00:14:23.576892 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=6
I1223 00:14:23.576897 25375 net.cpp:380] encode1_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:23.576947 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=6
I1223 00:14:23.576953 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.576956 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:23.576959 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=6
I1223 00:14:23.576967 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=6
I1223 00:14:23.576972 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:23.576989 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:23.576993 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:23.576997 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:23.577003 25375 net.cpp:380] encode1_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:23.577025 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=6
I1223 00:14:23.577031 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.577034 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:23.577038 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_6
I1223 00:14:23.577044 25375 net.cpp:84] Creating Layer encode1_gate_input_6
I1223 00:14:23.577049 25375 net.cpp:406] encode1_gate_input_6 <- hidden->transform->5
I1223 00:14:23.577054 25375 net.cpp:406] encode1_gate_input_6 <- x->transform->t=6
I1223 00:14:23.577057 25375 net.cpp:406] encode1_gate_input_6 <- hadamard_t=6
I1223 00:14:23.577062 25375 net.cpp:380] encode1_gate_input_6 -> gate_input_6
I1223 00:14:23.577097 25375 net.cpp:122] Setting up encode1_gate_input_6
I1223 00:14:23.577105 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.577107 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:23.577111 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=6
I1223 00:14:23.577117 25375 net.cpp:84] Creating Layer encode1_unit_t=6
I1223 00:14:23.577121 25375 net.cpp:406] encode1_unit_t=6 <- c_t=5_encode1_unit_t=5_0_split_3
I1223 00:14:23.577126 25375 net.cpp:406] encode1_unit_t=6 <- gate_input_6
I1223 00:14:23.577131 25375 net.cpp:406] encode1_unit_t=6 <- cont_t=6_encode1_cont_slice_5_split_1
I1223 00:14:23.577134 25375 net.cpp:380] encode1_unit_t=6 -> c_t=6
I1223 00:14:23.577142 25375 net.cpp:380] encode1_unit_t=6 -> h_t=6
I1223 00:14:23.577188 25375 net.cpp:122] Setting up encode1_unit_t=6
I1223 00:14:23.577195 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577199 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577203 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:23.577205 25375 layer_factory.hpp:77] Creating layer c_t=6_encode1_unit_t=6_0_split
I1223 00:14:23.577210 25375 net.cpp:84] Creating Layer c_t=6_encode1_unit_t=6_0_split
I1223 00:14:23.577214 25375 net.cpp:406] c_t=6_encode1_unit_t=6_0_split <- c_t=6
I1223 00:14:23.577219 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_0
I1223 00:14:23.577226 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_1
I1223 00:14:23.577232 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_2
I1223 00:14:23.577239 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_3
I1223 00:14:23.577296 25375 net.cpp:122] Setting up c_t=6_encode1_unit_t=6_0_split
I1223 00:14:23.577301 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577306 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577309 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577313 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577316 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:23.577318 25375 layer_factory.hpp:77] Creating layer h_t=6_encode1_unit_t=6_1_split
I1223 00:14:23.577322 25375 net.cpp:84] Creating Layer h_t=6_encode1_unit_t=6_1_split
I1223 00:14:23.577327 25375 net.cpp:406] h_t=6_encode1_unit_t=6_1_split <- h_t=6
I1223 00:14:23.577332 25375 net.cpp:380] h_t=6_encode1_unit_t=6_1_split -> h_t=6_encode1_unit_t=6_1_split_0
I1223 00:14:23.577337 25375 net.cpp:380] h_t=6_encode1_unit_t=6_1_split -> h_t=6_encode1_unit_t=6_1_split_1
I1223 00:14:23.577370 25375 net.cpp:122] Setting up h_t=6_encode1_unit_t=6_1_split
I1223 00:14:23.577378 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577381 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577383 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:23.577386 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=6
I1223 00:14:23.577392 25375 net.cpp:84] Creating Layer encode1_h_conted_t=6
I1223 00:14:23.577396 25375 net.cpp:406] encode1_h_conted_t=6 <- h_t=6_encode1_unit_t=6_1_split_0
I1223 00:14:23.577400 25375 net.cpp:406] encode1_h_conted_t=6 <- cont_t=7_encode1_cont_slice_6_split_0
I1223 00:14:23.577405 25375 net.cpp:380] encode1_h_conted_t=6 -> h_conted_t=6
I1223 00:14:23.577478 25375 net.cpp:122] Setting up encode1_h_conted_t=6
I1223 00:14:23.577486 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.577487 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:23.577491 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->6
I1223 00:14:23.577502 25375 net.cpp:84] Creating Layer encode1_hidden->transform->6
I1223 00:14:23.577507 25375 net.cpp:406] encode1_hidden->transform->6 <- h_conted_t=6
I1223 00:14:23.577513 25375 net.cpp:380] encode1_hidden->transform->6 -> hidden->transform->6
I1223 00:14:23.578001 25375 net.cpp:122] Setting up encode1_hidden->transform->6
I1223 00:14:23.578011 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.578014 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:23.578017 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.578022 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.578025 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=6
I1223 00:14:23.578032 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=6
I1223 00:14:23.578035 25375 net.cpp:406] encode1_hadamard->input_t=6 <- c_t=6_encode1_unit_t=6_0_split_0
I1223 00:14:23.578042 25375 net.cpp:380] encode1_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:23.578142 25375 net.cpp:122] Setting up encode1_hadamard->input_t=6
I1223 00:14:23.578150 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.578152 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:23.578156 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.578161 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=6
I1223 00:14:23.578166 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=6
I1223 00:14:23.578169 25375 net.cpp:406] encode1_hadamard->forget_t=6 <- c_t=6_encode1_unit_t=6_0_split_1
I1223 00:14:23.578191 25375 net.cpp:380] encode1_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:23.578306 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=6
I1223 00:14:23.578313 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.578316 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:23.578320 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.578336 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=6
I1223 00:14:23.578341 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=6
I1223 00:14:23.578344 25375 net.cpp:406] encode1_hadamard->output_t=6 <- c_t=6_encode1_unit_t=6_0_split_2
I1223 00:14:23.578362 25375 net.cpp:380] encode1_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:23.578461 25375 net.cpp:122] Setting up encode1_hadamard->output_t=6
I1223 00:14:23.578469 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.578471 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:23.578474 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.578478 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=7
I1223 00:14:23.578483 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=7
I1223 00:14:23.578487 25375 net.cpp:380] encode1_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:23.579319 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=7
I1223 00:14:23.579334 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579337 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:23.579340 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=7
I1223 00:14:23.579347 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=7
I1223 00:14:23.579354 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:23.579358 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:23.579376 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:23.579380 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:23.579387 25375 net.cpp:380] encode1_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:23.579422 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=7
I1223 00:14:23.579440 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.579443 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:23.579447 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_7
I1223 00:14:23.579468 25375 net.cpp:84] Creating Layer encode1_gate_input_7
I1223 00:14:23.579471 25375 net.cpp:406] encode1_gate_input_7 <- hidden->transform->6
I1223 00:14:23.579488 25375 net.cpp:406] encode1_gate_input_7 <- x->transform->t=7
I1223 00:14:23.579493 25375 net.cpp:406] encode1_gate_input_7 <- hadamard_t=7
I1223 00:14:23.579497 25375 net.cpp:380] encode1_gate_input_7 -> gate_input_7
I1223 00:14:23.579520 25375 net.cpp:122] Setting up encode1_gate_input_7
I1223 00:14:23.579526 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.579530 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:23.579531 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=7
I1223 00:14:23.579551 25375 net.cpp:84] Creating Layer encode1_unit_t=7
I1223 00:14:23.579555 25375 net.cpp:406] encode1_unit_t=7 <- c_t=6_encode1_unit_t=6_0_split_3
I1223 00:14:23.579572 25375 net.cpp:406] encode1_unit_t=7 <- gate_input_7
I1223 00:14:23.579576 25375 net.cpp:406] encode1_unit_t=7 <- cont_t=7_encode1_cont_slice_6_split_1
I1223 00:14:23.579594 25375 net.cpp:380] encode1_unit_t=7 -> c_t=7
I1223 00:14:23.579601 25375 net.cpp:380] encode1_unit_t=7 -> h_t=7
I1223 00:14:23.579663 25375 net.cpp:122] Setting up encode1_unit_t=7
I1223 00:14:23.579669 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579672 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579675 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:23.579679 25375 layer_factory.hpp:77] Creating layer c_t=7_encode1_unit_t=7_0_split
I1223 00:14:23.579696 25375 net.cpp:84] Creating Layer c_t=7_encode1_unit_t=7_0_split
I1223 00:14:23.579699 25375 net.cpp:406] c_t=7_encode1_unit_t=7_0_split <- c_t=7
I1223 00:14:23.579718 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_0
I1223 00:14:23.579725 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_1
I1223 00:14:23.579735 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_2
I1223 00:14:23.579741 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_3
I1223 00:14:23.579795 25375 net.cpp:122] Setting up c_t=7_encode1_unit_t=7_0_split
I1223 00:14:23.579802 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579807 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579824 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579828 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579830 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:23.579833 25375 layer_factory.hpp:77] Creating layer h_t=7_encode1_unit_t=7_1_split
I1223 00:14:23.579838 25375 net.cpp:84] Creating Layer h_t=7_encode1_unit_t=7_1_split
I1223 00:14:23.579840 25375 net.cpp:406] h_t=7_encode1_unit_t=7_1_split <- h_t=7
I1223 00:14:23.579845 25375 net.cpp:380] h_t=7_encode1_unit_t=7_1_split -> h_t=7_encode1_unit_t=7_1_split_0
I1223 00:14:23.579864 25375 net.cpp:380] h_t=7_encode1_unit_t=7_1_split -> h_t=7_encode1_unit_t=7_1_split_1
I1223 00:14:23.579896 25375 net.cpp:122] Setting up h_t=7_encode1_unit_t=7_1_split
I1223 00:14:23.579903 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579907 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.579910 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:23.579913 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=7
I1223 00:14:23.579919 25375 net.cpp:84] Creating Layer encode1_h_conted_t=7
I1223 00:14:23.579923 25375 net.cpp:406] encode1_h_conted_t=7 <- h_t=7_encode1_unit_t=7_1_split_0
I1223 00:14:23.579927 25375 net.cpp:406] encode1_h_conted_t=7 <- cont_t=8_encode1_cont_slice_7_split_0
I1223 00:14:23.579932 25375 net.cpp:380] encode1_h_conted_t=7 -> h_conted_t=7
I1223 00:14:23.580008 25375 net.cpp:122] Setting up encode1_h_conted_t=7
I1223 00:14:23.580015 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.580018 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:23.580021 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->7
I1223 00:14:23.580031 25375 net.cpp:84] Creating Layer encode1_hidden->transform->7
I1223 00:14:23.580035 25375 net.cpp:406] encode1_hidden->transform->7 <- h_conted_t=7
I1223 00:14:23.580042 25375 net.cpp:380] encode1_hidden->transform->7 -> hidden->transform->7
I1223 00:14:23.580540 25375 net.cpp:122] Setting up encode1_hidden->transform->7
I1223 00:14:23.580549 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.580552 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:23.580555 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.580560 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.580564 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=7
I1223 00:14:23.580569 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=7
I1223 00:14:23.580572 25375 net.cpp:406] encode1_hadamard->input_t=7 <- c_t=7_encode1_unit_t=7_0_split_0
I1223 00:14:23.580579 25375 net.cpp:380] encode1_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:23.580667 25375 net.cpp:122] Setting up encode1_hadamard->input_t=7
I1223 00:14:23.580675 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.580678 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:23.580682 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.580685 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=7
I1223 00:14:23.580690 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=7
I1223 00:14:23.580694 25375 net.cpp:406] encode1_hadamard->forget_t=7 <- c_t=7_encode1_unit_t=7_0_split_1
I1223 00:14:23.580699 25375 net.cpp:380] encode1_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:23.580799 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=7
I1223 00:14:23.580806 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.580809 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:23.580812 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.580816 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=7
I1223 00:14:23.580833 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=7
I1223 00:14:23.580837 25375 net.cpp:406] encode1_hadamard->output_t=7 <- c_t=7_encode1_unit_t=7_0_split_2
I1223 00:14:23.580842 25375 net.cpp:380] encode1_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:23.580936 25375 net.cpp:122] Setting up encode1_hadamard->output_t=7
I1223 00:14:23.580943 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.580945 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:23.580950 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.580952 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=8
I1223 00:14:23.580971 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=8
I1223 00:14:23.580976 25375 net.cpp:380] encode1_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:23.581043 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=8
I1223 00:14:23.581050 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581053 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:23.581056 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=8
I1223 00:14:23.581061 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=8
I1223 00:14:23.581065 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:23.581079 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:23.581084 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:23.581086 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:23.581095 25375 net.cpp:380] encode1_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:23.581120 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=8
I1223 00:14:23.581142 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.581146 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:23.581148 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_8
I1223 00:14:23.581154 25375 net.cpp:84] Creating Layer encode1_gate_input_8
I1223 00:14:23.581157 25375 net.cpp:406] encode1_gate_input_8 <- hidden->transform->7
I1223 00:14:23.581161 25375 net.cpp:406] encode1_gate_input_8 <- x->transform->t=8
I1223 00:14:23.581166 25375 net.cpp:406] encode1_gate_input_8 <- hadamard_t=8
I1223 00:14:23.581183 25375 net.cpp:380] encode1_gate_input_8 -> gate_input_8
I1223 00:14:23.581205 25375 net.cpp:122] Setting up encode1_gate_input_8
I1223 00:14:23.581212 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.581214 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:23.581218 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=8
I1223 00:14:23.581223 25375 net.cpp:84] Creating Layer encode1_unit_t=8
I1223 00:14:23.581225 25375 net.cpp:406] encode1_unit_t=8 <- c_t=7_encode1_unit_t=7_0_split_3
I1223 00:14:23.581229 25375 net.cpp:406] encode1_unit_t=8 <- gate_input_8
I1223 00:14:23.581234 25375 net.cpp:406] encode1_unit_t=8 <- cont_t=8_encode1_cont_slice_7_split_1
I1223 00:14:23.581238 25375 net.cpp:380] encode1_unit_t=8 -> c_t=8
I1223 00:14:23.581244 25375 net.cpp:380] encode1_unit_t=8 -> h_t=8
I1223 00:14:23.581303 25375 net.cpp:122] Setting up encode1_unit_t=8
I1223 00:14:23.581310 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581315 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581317 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:23.581321 25375 layer_factory.hpp:77] Creating layer c_t=8_encode1_unit_t=8_0_split
I1223 00:14:23.581327 25375 net.cpp:84] Creating Layer c_t=8_encode1_unit_t=8_0_split
I1223 00:14:23.581343 25375 net.cpp:406] c_t=8_encode1_unit_t=8_0_split <- c_t=8
I1223 00:14:23.581349 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_0
I1223 00:14:23.581356 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_1
I1223 00:14:23.581362 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_2
I1223 00:14:23.581369 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_3
I1223 00:14:23.581425 25375 net.cpp:122] Setting up c_t=8_encode1_unit_t=8_0_split
I1223 00:14:23.581432 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581436 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581440 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581444 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581446 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:23.581449 25375 layer_factory.hpp:77] Creating layer h_t=8_encode1_unit_t=8_1_split
I1223 00:14:23.581454 25375 net.cpp:84] Creating Layer h_t=8_encode1_unit_t=8_1_split
I1223 00:14:23.581456 25375 net.cpp:406] h_t=8_encode1_unit_t=8_1_split <- h_t=8
I1223 00:14:23.581462 25375 net.cpp:380] h_t=8_encode1_unit_t=8_1_split -> h_t=8_encode1_unit_t=8_1_split_0
I1223 00:14:23.581470 25375 net.cpp:380] h_t=8_encode1_unit_t=8_1_split -> h_t=8_encode1_unit_t=8_1_split_1
I1223 00:14:23.581501 25375 net.cpp:122] Setting up h_t=8_encode1_unit_t=8_1_split
I1223 00:14:23.581508 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581511 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581514 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:23.581517 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=8
I1223 00:14:23.581522 25375 net.cpp:84] Creating Layer encode1_h_conted_t=8
I1223 00:14:23.581526 25375 net.cpp:406] encode1_h_conted_t=8 <- h_t=8_encode1_unit_t=8_1_split_0
I1223 00:14:23.581531 25375 net.cpp:406] encode1_h_conted_t=8 <- cont_t=9_encode1_cont_slice_8_split_0
I1223 00:14:23.581534 25375 net.cpp:380] encode1_h_conted_t=8 -> h_conted_t=8
I1223 00:14:23.581609 25375 net.cpp:122] Setting up encode1_h_conted_t=8
I1223 00:14:23.581615 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.581619 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:23.581621 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->8
I1223 00:14:23.581629 25375 net.cpp:84] Creating Layer encode1_hidden->transform->8
I1223 00:14:23.581631 25375 net.cpp:406] encode1_hidden->transform->8 <- h_conted_t=8
I1223 00:14:23.581640 25375 net.cpp:380] encode1_hidden->transform->8 -> hidden->transform->8
I1223 00:14:23.582132 25375 net.cpp:122] Setting up encode1_hidden->transform->8
I1223 00:14:23.582140 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.582142 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:23.582146 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.582151 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.582154 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=8
I1223 00:14:23.582159 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=8
I1223 00:14:23.582164 25375 net.cpp:406] encode1_hadamard->input_t=8 <- c_t=8_encode1_unit_t=8_0_split_0
I1223 00:14:23.582170 25375 net.cpp:380] encode1_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:23.582257 25375 net.cpp:122] Setting up encode1_hadamard->input_t=8
I1223 00:14:23.582265 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.582268 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:23.582273 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.582275 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=8
I1223 00:14:23.582280 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=8
I1223 00:14:23.582283 25375 net.cpp:406] encode1_hadamard->forget_t=8 <- c_t=8_encode1_unit_t=8_0_split_1
I1223 00:14:23.582290 25375 net.cpp:380] encode1_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:23.582403 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=8
I1223 00:14:23.582410 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.582413 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:23.582417 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.582432 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=8
I1223 00:14:23.582437 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=8
I1223 00:14:23.582442 25375 net.cpp:406] encode1_hadamard->output_t=8 <- c_t=8_encode1_unit_t=8_0_split_2
I1223 00:14:23.582463 25375 net.cpp:380] encode1_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:23.582558 25375 net.cpp:122] Setting up encode1_hadamard->output_t=8
I1223 00:14:23.582566 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.582569 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:23.582573 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.582576 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=9
I1223 00:14:23.582581 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=9
I1223 00:14:23.582588 25375 net.cpp:380] encode1_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:23.582641 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=9
I1223 00:14:23.582648 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.582651 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:23.582655 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=9
I1223 00:14:23.582675 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=9
I1223 00:14:23.582679 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:23.582684 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:23.582689 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:23.582692 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:23.582697 25375 net.cpp:380] encode1_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:23.582721 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=9
I1223 00:14:23.582727 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.582731 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:23.582733 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_9
I1223 00:14:23.582739 25375 net.cpp:84] Creating Layer encode1_gate_input_9
I1223 00:14:23.582744 25375 net.cpp:406] encode1_gate_input_9 <- hidden->transform->8
I1223 00:14:23.582748 25375 net.cpp:406] encode1_gate_input_9 <- x->transform->t=9
I1223 00:14:23.582753 25375 net.cpp:406] encode1_gate_input_9 <- hadamard_t=9
I1223 00:14:23.582758 25375 net.cpp:380] encode1_gate_input_9 -> gate_input_9
I1223 00:14:23.582785 25375 net.cpp:122] Setting up encode1_gate_input_9
I1223 00:14:23.582792 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.582794 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:23.582797 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=9
I1223 00:14:23.582803 25375 net.cpp:84] Creating Layer encode1_unit_t=9
I1223 00:14:23.582806 25375 net.cpp:406] encode1_unit_t=9 <- c_t=8_encode1_unit_t=8_0_split_3
I1223 00:14:23.582810 25375 net.cpp:406] encode1_unit_t=9 <- gate_input_9
I1223 00:14:23.582814 25375 net.cpp:406] encode1_unit_t=9 <- cont_t=9_encode1_cont_slice_8_split_1
I1223 00:14:23.582823 25375 net.cpp:380] encode1_unit_t=9 -> c_t=9
I1223 00:14:23.582830 25375 net.cpp:380] encode1_unit_t=9 -> h_t=9
I1223 00:14:23.582877 25375 net.cpp:122] Setting up encode1_unit_t=9
I1223 00:14:23.582883 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.582888 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.582891 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:23.582895 25375 layer_factory.hpp:77] Creating layer c_t=9_encode1_unit_t=9_0_split
I1223 00:14:23.582900 25375 net.cpp:84] Creating Layer c_t=9_encode1_unit_t=9_0_split
I1223 00:14:23.582903 25375 net.cpp:406] c_t=9_encode1_unit_t=9_0_split <- c_t=9
I1223 00:14:23.582912 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_0
I1223 00:14:23.582919 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_1
I1223 00:14:23.582926 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_2
I1223 00:14:23.582934 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_3
I1223 00:14:23.582991 25375 net.cpp:122] Setting up c_t=9_encode1_unit_t=9_0_split
I1223 00:14:23.582998 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583003 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583007 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583011 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583014 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:23.583017 25375 layer_factory.hpp:77] Creating layer h_t=9_encode1_unit_t=9_1_split
I1223 00:14:23.583021 25375 net.cpp:84] Creating Layer h_t=9_encode1_unit_t=9_1_split
I1223 00:14:23.583025 25375 net.cpp:406] h_t=9_encode1_unit_t=9_1_split <- h_t=9
I1223 00:14:23.583030 25375 net.cpp:380] h_t=9_encode1_unit_t=9_1_split -> h_t=9_encode1_unit_t=9_1_split_0
I1223 00:14:23.583036 25375 net.cpp:380] h_t=9_encode1_unit_t=9_1_split -> h_t=9_encode1_unit_t=9_1_split_1
I1223 00:14:23.583070 25375 net.cpp:122] Setting up h_t=9_encode1_unit_t=9_1_split
I1223 00:14:23.583076 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583081 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583083 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:23.583086 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=9
I1223 00:14:23.583091 25375 net.cpp:84] Creating Layer encode1_h_conted_t=9
I1223 00:14:23.583096 25375 net.cpp:406] encode1_h_conted_t=9 <- h_t=9_encode1_unit_t=9_1_split_0
I1223 00:14:23.583101 25375 net.cpp:406] encode1_h_conted_t=9 <- cont_t=10_encode1_cont_slice_9_split_0
I1223 00:14:23.583106 25375 net.cpp:380] encode1_h_conted_t=9 -> h_conted_t=9
I1223 00:14:23.583186 25375 net.cpp:122] Setting up encode1_h_conted_t=9
I1223 00:14:23.583194 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583197 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:23.583200 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->9
I1223 00:14:23.583209 25375 net.cpp:84] Creating Layer encode1_hidden->transform->9
I1223 00:14:23.583214 25375 net.cpp:406] encode1_hidden->transform->9 <- h_conted_t=9
I1223 00:14:23.583220 25375 net.cpp:380] encode1_hidden->transform->9 -> hidden->transform->9
I1223 00:14:23.583710 25375 net.cpp:122] Setting up encode1_hidden->transform->9
I1223 00:14:23.583719 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.583721 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:23.583725 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.583729 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.583734 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=9
I1223 00:14:23.583739 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=9
I1223 00:14:23.583744 25375 net.cpp:406] encode1_hadamard->input_t=9 <- c_t=9_encode1_unit_t=9_0_split_0
I1223 00:14:23.583750 25375 net.cpp:380] encode1_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:23.583837 25375 net.cpp:122] Setting up encode1_hadamard->input_t=9
I1223 00:14:23.583843 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583847 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:23.583850 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.583853 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=9
I1223 00:14:23.583859 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=9
I1223 00:14:23.583863 25375 net.cpp:406] encode1_hadamard->forget_t=9 <- c_t=9_encode1_unit_t=9_0_split_1
I1223 00:14:23.583869 25375 net.cpp:380] encode1_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:23.583966 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=9
I1223 00:14:23.583973 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.583976 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:23.583979 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.583982 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=9
I1223 00:14:23.584002 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=9
I1223 00:14:23.584005 25375 net.cpp:406] encode1_hadamard->output_t=9 <- c_t=9_encode1_unit_t=9_0_split_2
I1223 00:14:23.584010 25375 net.cpp:380] encode1_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:23.584120 25375 net.cpp:122] Setting up encode1_hadamard->output_t=9
I1223 00:14:23.584126 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584130 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:23.584132 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.584136 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=10
I1223 00:14:23.584161 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=10
I1223 00:14:23.584166 25375 net.cpp:380] encode1_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:23.584216 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=10
I1223 00:14:23.584223 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584226 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:23.584229 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=10
I1223 00:14:23.584234 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=10
I1223 00:14:23.584239 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:23.584242 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:23.584246 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:23.584250 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:23.584270 25375 net.cpp:380] encode1_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:23.584291 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=10
I1223 00:14:23.584297 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.584300 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:23.584303 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_10
I1223 00:14:23.584311 25375 net.cpp:84] Creating Layer encode1_gate_input_10
I1223 00:14:23.584314 25375 net.cpp:406] encode1_gate_input_10 <- hidden->transform->9
I1223 00:14:23.584318 25375 net.cpp:406] encode1_gate_input_10 <- x->transform->t=10
I1223 00:14:23.584322 25375 net.cpp:406] encode1_gate_input_10 <- hadamard_t=10
I1223 00:14:23.584327 25375 net.cpp:380] encode1_gate_input_10 -> gate_input_10
I1223 00:14:23.584348 25375 net.cpp:122] Setting up encode1_gate_input_10
I1223 00:14:23.584354 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.584357 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:23.584360 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=10
I1223 00:14:23.584364 25375 net.cpp:84] Creating Layer encode1_unit_t=10
I1223 00:14:23.584368 25375 net.cpp:406] encode1_unit_t=10 <- c_t=9_encode1_unit_t=9_0_split_3
I1223 00:14:23.584372 25375 net.cpp:406] encode1_unit_t=10 <- gate_input_10
I1223 00:14:23.584377 25375 net.cpp:406] encode1_unit_t=10 <- cont_t=10_encode1_cont_slice_9_split_1
I1223 00:14:23.584383 25375 net.cpp:380] encode1_unit_t=10 -> c_t=10
I1223 00:14:23.584390 25375 net.cpp:380] encode1_unit_t=10 -> h_t=10
I1223 00:14:23.584441 25375 net.cpp:122] Setting up encode1_unit_t=10
I1223 00:14:23.584448 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584451 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584455 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:23.584457 25375 layer_factory.hpp:77] Creating layer c_t=10_encode1_unit_t=10_0_split
I1223 00:14:23.584462 25375 net.cpp:84] Creating Layer c_t=10_encode1_unit_t=10_0_split
I1223 00:14:23.584465 25375 net.cpp:406] c_t=10_encode1_unit_t=10_0_split <- c_t=10
I1223 00:14:23.584471 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_0
I1223 00:14:23.584478 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_1
I1223 00:14:23.584483 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_2
I1223 00:14:23.584489 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_3
I1223 00:14:23.584547 25375 net.cpp:122] Setting up c_t=10_encode1_unit_t=10_0_split
I1223 00:14:23.584553 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584558 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584561 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584564 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584568 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:23.584570 25375 layer_factory.hpp:77] Creating layer h_t=10_encode1_unit_t=10_1_split
I1223 00:14:23.584574 25375 net.cpp:84] Creating Layer h_t=10_encode1_unit_t=10_1_split
I1223 00:14:23.584578 25375 net.cpp:406] h_t=10_encode1_unit_t=10_1_split <- h_t=10
I1223 00:14:23.584583 25375 net.cpp:380] h_t=10_encode1_unit_t=10_1_split -> h_t=10_encode1_unit_t=10_1_split_0
I1223 00:14:23.584589 25375 net.cpp:380] h_t=10_encode1_unit_t=10_1_split -> h_t=10_encode1_unit_t=10_1_split_1
I1223 00:14:23.584625 25375 net.cpp:122] Setting up h_t=10_encode1_unit_t=10_1_split
I1223 00:14:23.584631 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584635 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584637 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:23.584640 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=10
I1223 00:14:23.584645 25375 net.cpp:84] Creating Layer encode1_h_conted_t=10
I1223 00:14:23.584648 25375 net.cpp:406] encode1_h_conted_t=10 <- h_t=10_encode1_unit_t=10_1_split_0
I1223 00:14:23.584653 25375 net.cpp:406] encode1_h_conted_t=10 <- cont_t=11_encode1_cont_slice_10_split_0
I1223 00:14:23.584659 25375 net.cpp:380] encode1_h_conted_t=10 -> h_conted_t=10
I1223 00:14:23.584733 25375 net.cpp:122] Setting up encode1_h_conted_t=10
I1223 00:14:23.584740 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.584743 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:23.584746 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->10
I1223 00:14:23.584754 25375 net.cpp:84] Creating Layer encode1_hidden->transform->10
I1223 00:14:23.584759 25375 net.cpp:406] encode1_hidden->transform->10 <- h_conted_t=10
I1223 00:14:23.584765 25375 net.cpp:380] encode1_hidden->transform->10 -> hidden->transform->10
I1223 00:14:23.585258 25375 net.cpp:122] Setting up encode1_hidden->transform->10
I1223 00:14:23.585268 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.585270 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:23.585273 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.585278 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.585280 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=10
I1223 00:14:23.585289 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=10
I1223 00:14:23.585291 25375 net.cpp:406] encode1_hadamard->input_t=10 <- c_t=10_encode1_unit_t=10_0_split_0
I1223 00:14:23.585299 25375 net.cpp:380] encode1_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:23.585395 25375 net.cpp:122] Setting up encode1_hadamard->input_t=10
I1223 00:14:23.585402 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.585405 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:23.585408 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.585412 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=10
I1223 00:14:23.585431 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=10
I1223 00:14:23.585434 25375 net.cpp:406] encode1_hadamard->forget_t=10 <- c_t=10_encode1_unit_t=10_0_split_1
I1223 00:14:23.585440 25375 net.cpp:380] encode1_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:23.585536 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=10
I1223 00:14:23.585542 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.585546 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:23.585548 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.585551 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=10
I1223 00:14:23.585571 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=10
I1223 00:14:23.585573 25375 net.cpp:406] encode1_hadamard->output_t=10 <- c_t=10_encode1_unit_t=10_0_split_2
I1223 00:14:23.585578 25375 net.cpp:380] encode1_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:23.585686 25375 net.cpp:122] Setting up encode1_hadamard->output_t=10
I1223 00:14:23.585693 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.585695 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:23.585700 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.585714 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=11
I1223 00:14:23.585721 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=11
I1223 00:14:23.585724 25375 net.cpp:380] encode1_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:23.585777 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=11
I1223 00:14:23.585783 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.585786 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:23.585789 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=11
I1223 00:14:23.585794 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=11
I1223 00:14:23.585798 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:23.585816 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:23.585820 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:23.585824 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:23.585829 25375 net.cpp:380] encode1_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:23.585852 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=11
I1223 00:14:23.585858 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.585861 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:23.585865 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_11
I1223 00:14:23.585883 25375 net.cpp:84] Creating Layer encode1_gate_input_11
I1223 00:14:23.585887 25375 net.cpp:406] encode1_gate_input_11 <- hidden->transform->10
I1223 00:14:23.585904 25375 net.cpp:406] encode1_gate_input_11 <- x->transform->t=11
I1223 00:14:23.585908 25375 net.cpp:406] encode1_gate_input_11 <- hadamard_t=11
I1223 00:14:23.585913 25375 net.cpp:380] encode1_gate_input_11 -> gate_input_11
I1223 00:14:23.585937 25375 net.cpp:122] Setting up encode1_gate_input_11
I1223 00:14:23.585942 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.585944 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:23.585947 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=11
I1223 00:14:23.585952 25375 net.cpp:84] Creating Layer encode1_unit_t=11
I1223 00:14:23.585955 25375 net.cpp:406] encode1_unit_t=11 <- c_t=10_encode1_unit_t=10_0_split_3
I1223 00:14:23.585959 25375 net.cpp:406] encode1_unit_t=11 <- gate_input_11
I1223 00:14:23.585963 25375 net.cpp:406] encode1_unit_t=11 <- cont_t=11_encode1_cont_slice_10_split_1
I1223 00:14:23.585968 25375 net.cpp:380] encode1_unit_t=11 -> c_t=11
I1223 00:14:23.585974 25375 net.cpp:380] encode1_unit_t=11 -> h_t=11
I1223 00:14:23.586019 25375 net.cpp:122] Setting up encode1_unit_t=11
I1223 00:14:23.586026 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586030 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586033 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:23.586035 25375 layer_factory.hpp:77] Creating layer c_t=11_encode1_unit_t=11_0_split
I1223 00:14:23.586045 25375 net.cpp:84] Creating Layer c_t=11_encode1_unit_t=11_0_split
I1223 00:14:23.586048 25375 net.cpp:406] c_t=11_encode1_unit_t=11_0_split <- c_t=11
I1223 00:14:23.586055 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_0
I1223 00:14:23.586061 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_1
I1223 00:14:23.586068 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_2
I1223 00:14:23.586073 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_3
I1223 00:14:23.586140 25375 net.cpp:122] Setting up c_t=11_encode1_unit_t=11_0_split
I1223 00:14:23.586146 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586150 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586167 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586171 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586174 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:23.586177 25375 layer_factory.hpp:77] Creating layer h_t=11_encode1_unit_t=11_1_split
I1223 00:14:23.586181 25375 net.cpp:84] Creating Layer h_t=11_encode1_unit_t=11_1_split
I1223 00:14:23.586184 25375 net.cpp:406] h_t=11_encode1_unit_t=11_1_split <- h_t=11
I1223 00:14:23.586190 25375 net.cpp:380] h_t=11_encode1_unit_t=11_1_split -> h_t=11_encode1_unit_t=11_1_split_0
I1223 00:14:23.586196 25375 net.cpp:380] h_t=11_encode1_unit_t=11_1_split -> h_t=11_encode1_unit_t=11_1_split_1
I1223 00:14:23.586241 25375 net.cpp:122] Setting up h_t=11_encode1_unit_t=11_1_split
I1223 00:14:23.586246 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586249 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586252 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:23.586256 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=11
I1223 00:14:23.586275 25375 net.cpp:84] Creating Layer encode1_h_conted_t=11
I1223 00:14:23.586278 25375 net.cpp:406] encode1_h_conted_t=11 <- h_t=11_encode1_unit_t=11_1_split_0
I1223 00:14:23.586282 25375 net.cpp:406] encode1_h_conted_t=11 <- cont_t=12_encode1_cont_slice_11_split_0
I1223 00:14:23.586288 25375 net.cpp:380] encode1_h_conted_t=11 -> h_conted_t=11
I1223 00:14:23.586362 25375 net.cpp:122] Setting up encode1_h_conted_t=11
I1223 00:14:23.586369 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.586371 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:23.586375 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->11
I1223 00:14:23.586382 25375 net.cpp:84] Creating Layer encode1_hidden->transform->11
I1223 00:14:23.586386 25375 net.cpp:406] encode1_hidden->transform->11 <- h_conted_t=11
I1223 00:14:23.586393 25375 net.cpp:380] encode1_hidden->transform->11 -> hidden->transform->11
I1223 00:14:23.586886 25375 net.cpp:122] Setting up encode1_hidden->transform->11
I1223 00:14:23.586894 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.586897 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:23.586900 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.586905 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.586908 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=11
I1223 00:14:23.586913 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=11
I1223 00:14:23.586916 25375 net.cpp:406] encode1_hadamard->input_t=11 <- c_t=11_encode1_unit_t=11_0_split_0
I1223 00:14:23.586923 25375 net.cpp:380] encode1_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:23.587009 25375 net.cpp:122] Setting up encode1_hadamard->input_t=11
I1223 00:14:23.587018 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.587020 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:23.587024 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.587028 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=11
I1223 00:14:23.587033 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=11
I1223 00:14:23.587035 25375 net.cpp:406] encode1_hadamard->forget_t=11 <- c_t=11_encode1_unit_t=11_0_split_1
I1223 00:14:23.587043 25375 net.cpp:380] encode1_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:23.587139 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=11
I1223 00:14:23.587146 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.587149 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:23.587153 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.587157 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=11
I1223 00:14:23.587174 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=11
I1223 00:14:23.587177 25375 net.cpp:406] encode1_hadamard->output_t=11 <- c_t=11_encode1_unit_t=11_0_split_2
I1223 00:14:23.587196 25375 net.cpp:380] encode1_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:23.587292 25375 net.cpp:122] Setting up encode1_hadamard->output_t=11
I1223 00:14:23.587298 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.587301 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:23.587306 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.587307 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=12
I1223 00:14:23.587326 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=12
I1223 00:14:23.587332 25375 net.cpp:380] encode1_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:23.588165 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=12
I1223 00:14:23.588176 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588179 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:23.588182 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=12
I1223 00:14:23.588188 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=12
I1223 00:14:23.588192 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:23.588197 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:23.588201 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:23.588204 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:23.588224 25375 net.cpp:380] encode1_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:23.588253 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=12
I1223 00:14:23.588260 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.588263 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:23.588265 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_12
I1223 00:14:23.588270 25375 net.cpp:84] Creating Layer encode1_gate_input_12
I1223 00:14:23.588274 25375 net.cpp:406] encode1_gate_input_12 <- hidden->transform->11
I1223 00:14:23.588279 25375 net.cpp:406] encode1_gate_input_12 <- x->transform->t=12
I1223 00:14:23.588281 25375 net.cpp:406] encode1_gate_input_12 <- hadamard_t=12
I1223 00:14:23.588286 25375 net.cpp:380] encode1_gate_input_12 -> gate_input_12
I1223 00:14:23.588361 25375 net.cpp:122] Setting up encode1_gate_input_12
I1223 00:14:23.588369 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.588372 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:23.588374 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=12
I1223 00:14:23.588394 25375 net.cpp:84] Creating Layer encode1_unit_t=12
I1223 00:14:23.588398 25375 net.cpp:406] encode1_unit_t=12 <- c_t=11_encode1_unit_t=11_0_split_3
I1223 00:14:23.588402 25375 net.cpp:406] encode1_unit_t=12 <- gate_input_12
I1223 00:14:23.588407 25375 net.cpp:406] encode1_unit_t=12 <- cont_t=12_encode1_cont_slice_11_split_1
I1223 00:14:23.588412 25375 net.cpp:380] encode1_unit_t=12 -> c_t=12
I1223 00:14:23.588418 25375 net.cpp:380] encode1_unit_t=12 -> h_t=12
I1223 00:14:23.588477 25375 net.cpp:122] Setting up encode1_unit_t=12
I1223 00:14:23.588485 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588488 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588490 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:23.588493 25375 layer_factory.hpp:77] Creating layer c_t=12_encode1_unit_t=12_0_split
I1223 00:14:23.588512 25375 net.cpp:84] Creating Layer c_t=12_encode1_unit_t=12_0_split
I1223 00:14:23.588515 25375 net.cpp:406] c_t=12_encode1_unit_t=12_0_split <- c_t=12
I1223 00:14:23.588521 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_0
I1223 00:14:23.588529 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_1
I1223 00:14:23.588536 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_2
I1223 00:14:23.588541 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_3
I1223 00:14:23.588629 25375 net.cpp:122] Setting up c_t=12_encode1_unit_t=12_0_split
I1223 00:14:23.588636 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588640 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588644 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588649 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588650 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:23.588666 25375 layer_factory.hpp:77] Creating layer h_t=12_encode1_unit_t=12_1_split
I1223 00:14:23.588672 25375 net.cpp:84] Creating Layer h_t=12_encode1_unit_t=12_1_split
I1223 00:14:23.588676 25375 net.cpp:406] h_t=12_encode1_unit_t=12_1_split <- h_t=12
I1223 00:14:23.588682 25375 net.cpp:380] h_t=12_encode1_unit_t=12_1_split -> h_t=12_encode1_unit_t=12_1_split_0
I1223 00:14:23.588688 25375 net.cpp:380] h_t=12_encode1_unit_t=12_1_split -> h_t=12_encode1_unit_t=12_1_split_1
I1223 00:14:23.588737 25375 net.cpp:122] Setting up h_t=12_encode1_unit_t=12_1_split
I1223 00:14:23.588757 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588760 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588763 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:23.588765 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=12
I1223 00:14:23.588785 25375 net.cpp:84] Creating Layer encode1_h_conted_t=12
I1223 00:14:23.588789 25375 net.cpp:406] encode1_h_conted_t=12 <- h_t=12_encode1_unit_t=12_1_split_0
I1223 00:14:23.588793 25375 net.cpp:406] encode1_h_conted_t=12 <- cont_t=13_encode1_cont_slice_12_split_0
I1223 00:14:23.588798 25375 net.cpp:380] encode1_h_conted_t=12 -> h_conted_t=12
I1223 00:14:23.588886 25375 net.cpp:122] Setting up encode1_h_conted_t=12
I1223 00:14:23.588894 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.588896 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:23.588899 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->12
I1223 00:14:23.588923 25375 net.cpp:84] Creating Layer encode1_hidden->transform->12
I1223 00:14:23.588940 25375 net.cpp:406] encode1_hidden->transform->12 <- h_conted_t=12
I1223 00:14:23.588946 25375 net.cpp:380] encode1_hidden->transform->12 -> hidden->transform->12
I1223 00:14:23.589444 25375 net.cpp:122] Setting up encode1_hidden->transform->12
I1223 00:14:23.589453 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.589457 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:23.589459 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.589484 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.589503 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=12
I1223 00:14:23.589509 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=12
I1223 00:14:23.589512 25375 net.cpp:406] encode1_hadamard->input_t=12 <- c_t=12_encode1_unit_t=12_0_split_0
I1223 00:14:23.589519 25375 net.cpp:380] encode1_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:23.589622 25375 net.cpp:122] Setting up encode1_hadamard->input_t=12
I1223 00:14:23.589628 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.589632 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:23.589634 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.589637 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=12
I1223 00:14:23.589658 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=12
I1223 00:14:23.589661 25375 net.cpp:406] encode1_hadamard->forget_t=12 <- c_t=12_encode1_unit_t=12_0_split_1
I1223 00:14:23.589668 25375 net.cpp:380] encode1_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:23.589764 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=12
I1223 00:14:23.589771 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.589773 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:23.589776 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.589781 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=12
I1223 00:14:23.589800 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=12
I1223 00:14:23.589803 25375 net.cpp:406] encode1_hadamard->output_t=12 <- c_t=12_encode1_unit_t=12_0_split_2
I1223 00:14:23.589808 25375 net.cpp:380] encode1_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:23.589916 25375 net.cpp:122] Setting up encode1_hadamard->output_t=12
I1223 00:14:23.589923 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.589926 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:23.589929 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.589932 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=13
I1223 00:14:23.589938 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=13
I1223 00:14:23.589957 25375 net.cpp:380] encode1_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:23.590020 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=13
I1223 00:14:23.590029 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590030 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:23.590034 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=13
I1223 00:14:23.590039 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=13
I1223 00:14:23.590057 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:23.590061 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:23.590065 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:23.590068 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:23.590073 25375 net.cpp:380] encode1_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:23.590111 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=13
I1223 00:14:23.590118 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.590121 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:23.590124 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_13
I1223 00:14:23.590128 25375 net.cpp:84] Creating Layer encode1_gate_input_13
I1223 00:14:23.590132 25375 net.cpp:406] encode1_gate_input_13 <- hidden->transform->12
I1223 00:14:23.590137 25375 net.cpp:406] encode1_gate_input_13 <- x->transform->t=13
I1223 00:14:23.590140 25375 net.cpp:406] encode1_gate_input_13 <- hadamard_t=13
I1223 00:14:23.590147 25375 net.cpp:380] encode1_gate_input_13 -> gate_input_13
I1223 00:14:23.590181 25375 net.cpp:122] Setting up encode1_gate_input_13
I1223 00:14:23.590186 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.590189 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:23.590205 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=13
I1223 00:14:23.590212 25375 net.cpp:84] Creating Layer encode1_unit_t=13
I1223 00:14:23.590215 25375 net.cpp:406] encode1_unit_t=13 <- c_t=12_encode1_unit_t=12_0_split_3
I1223 00:14:23.590219 25375 net.cpp:406] encode1_unit_t=13 <- gate_input_13
I1223 00:14:23.590224 25375 net.cpp:406] encode1_unit_t=13 <- cont_t=13_encode1_cont_slice_12_split_1
I1223 00:14:23.590229 25375 net.cpp:380] encode1_unit_t=13 -> c_t=13
I1223 00:14:23.590234 25375 net.cpp:380] encode1_unit_t=13 -> h_t=13
I1223 00:14:23.590281 25375 net.cpp:122] Setting up encode1_unit_t=13
I1223 00:14:23.590288 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590292 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590296 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:23.590298 25375 layer_factory.hpp:77] Creating layer c_t=13_encode1_unit_t=13_0_split
I1223 00:14:23.590303 25375 net.cpp:84] Creating Layer c_t=13_encode1_unit_t=13_0_split
I1223 00:14:23.590307 25375 net.cpp:406] c_t=13_encode1_unit_t=13_0_split <- c_t=13
I1223 00:14:23.590312 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_0
I1223 00:14:23.590333 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_1
I1223 00:14:23.590339 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_2
I1223 00:14:23.590344 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_3
I1223 00:14:23.590412 25375 net.cpp:122] Setting up c_t=13_encode1_unit_t=13_0_split
I1223 00:14:23.590420 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590423 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590440 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590442 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590445 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:23.590463 25375 layer_factory.hpp:77] Creating layer h_t=13_encode1_unit_t=13_1_split
I1223 00:14:23.590467 25375 net.cpp:84] Creating Layer h_t=13_encode1_unit_t=13_1_split
I1223 00:14:23.590471 25375 net.cpp:406] h_t=13_encode1_unit_t=13_1_split <- h_t=13
I1223 00:14:23.590488 25375 net.cpp:380] h_t=13_encode1_unit_t=13_1_split -> h_t=13_encode1_unit_t=13_1_split_0
I1223 00:14:23.590495 25375 net.cpp:380] h_t=13_encode1_unit_t=13_1_split -> h_t=13_encode1_unit_t=13_1_split_1
I1223 00:14:23.590528 25375 net.cpp:122] Setting up h_t=13_encode1_unit_t=13_1_split
I1223 00:14:23.590533 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590538 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590540 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:23.590555 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=13
I1223 00:14:23.590561 25375 net.cpp:84] Creating Layer encode1_h_conted_t=13
I1223 00:14:23.590580 25375 net.cpp:406] encode1_h_conted_t=13 <- h_t=13_encode1_unit_t=13_1_split_0
I1223 00:14:23.590584 25375 net.cpp:406] encode1_h_conted_t=13 <- cont_t=14_encode1_cont_slice_13_split_0
I1223 00:14:23.590602 25375 net.cpp:380] encode1_h_conted_t=13 -> h_conted_t=13
I1223 00:14:23.590687 25375 net.cpp:122] Setting up encode1_h_conted_t=13
I1223 00:14:23.590693 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.590697 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:23.590699 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->13
I1223 00:14:23.590720 25375 net.cpp:84] Creating Layer encode1_hidden->transform->13
I1223 00:14:23.590724 25375 net.cpp:406] encode1_hidden->transform->13 <- h_conted_t=13
I1223 00:14:23.590731 25375 net.cpp:380] encode1_hidden->transform->13 -> hidden->transform->13
I1223 00:14:23.591264 25375 net.cpp:122] Setting up encode1_hidden->transform->13
I1223 00:14:23.591270 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.591274 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:23.591277 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.591281 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.591284 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=13
I1223 00:14:23.591289 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=13
I1223 00:14:23.591292 25375 net.cpp:406] encode1_hadamard->input_t=13 <- c_t=13_encode1_unit_t=13_0_split_0
I1223 00:14:23.591297 25375 net.cpp:380] encode1_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:23.591385 25375 net.cpp:122] Setting up encode1_hadamard->input_t=13
I1223 00:14:23.591392 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.591395 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:23.591398 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.591403 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=13
I1223 00:14:23.591408 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=13
I1223 00:14:23.591411 25375 net.cpp:406] encode1_hadamard->forget_t=13 <- c_t=13_encode1_unit_t=13_0_split_1
I1223 00:14:23.591416 25375 net.cpp:380] encode1_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:23.591518 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=13
I1223 00:14:23.591526 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.591528 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:23.591532 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.591536 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=13
I1223 00:14:23.591554 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=13
I1223 00:14:23.591557 25375 net.cpp:406] encode1_hadamard->output_t=13 <- c_t=13_encode1_unit_t=13_0_split_2
I1223 00:14:23.591563 25375 net.cpp:380] encode1_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:23.591670 25375 net.cpp:122] Setting up encode1_hadamard->output_t=13
I1223 00:14:23.591678 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.591681 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:23.591684 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.591687 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=14
I1223 00:14:23.591706 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=14
I1223 00:14:23.591711 25375 net.cpp:380] encode1_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:23.591773 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=14
I1223 00:14:23.591780 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.591784 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:23.591786 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=14
I1223 00:14:23.591791 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=14
I1223 00:14:23.591809 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:23.591812 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:23.591816 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:23.591820 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:23.591826 25375 net.cpp:380] encode1_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:23.591864 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=14
I1223 00:14:23.591871 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.591873 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:23.591876 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_14
I1223 00:14:23.591881 25375 net.cpp:84] Creating Layer encode1_gate_input_14
I1223 00:14:23.591898 25375 net.cpp:406] encode1_gate_input_14 <- hidden->transform->13
I1223 00:14:23.591902 25375 net.cpp:406] encode1_gate_input_14 <- x->transform->t=14
I1223 00:14:23.591907 25375 net.cpp:406] encode1_gate_input_14 <- hadamard_t=14
I1223 00:14:23.591928 25375 net.cpp:380] encode1_gate_input_14 -> gate_input_14
I1223 00:14:23.591948 25375 net.cpp:122] Setting up encode1_gate_input_14
I1223 00:14:23.591956 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.591959 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:23.591962 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=14
I1223 00:14:23.591966 25375 net.cpp:84] Creating Layer encode1_unit_t=14
I1223 00:14:23.591969 25375 net.cpp:406] encode1_unit_t=14 <- c_t=13_encode1_unit_t=13_0_split_3
I1223 00:14:23.591974 25375 net.cpp:406] encode1_unit_t=14 <- gate_input_14
I1223 00:14:23.591977 25375 net.cpp:406] encode1_unit_t=14 <- cont_t=14_encode1_cont_slice_13_split_1
I1223 00:14:23.591982 25375 net.cpp:380] encode1_unit_t=14 -> c_t=14
I1223 00:14:23.592001 25375 net.cpp:380] encode1_unit_t=14 -> h_t=14
I1223 00:14:23.592047 25375 net.cpp:122] Setting up encode1_unit_t=14
I1223 00:14:23.592056 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592058 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592061 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:23.592064 25375 layer_factory.hpp:77] Creating layer c_t=14_encode1_unit_t=14_0_split
I1223 00:14:23.592082 25375 net.cpp:84] Creating Layer c_t=14_encode1_unit_t=14_0_split
I1223 00:14:23.592085 25375 net.cpp:406] c_t=14_encode1_unit_t=14_0_split <- c_t=14
I1223 00:14:23.592089 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_0
I1223 00:14:23.592097 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_1
I1223 00:14:23.592104 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_2
I1223 00:14:23.592110 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_3
I1223 00:14:23.592182 25375 net.cpp:122] Setting up c_t=14_encode1_unit_t=14_0_split
I1223 00:14:23.592188 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592192 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592196 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592200 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592202 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:23.592206 25375 layer_factory.hpp:77] Creating layer h_t=14_encode1_unit_t=14_1_split
I1223 00:14:23.592211 25375 net.cpp:84] Creating Layer h_t=14_encode1_unit_t=14_1_split
I1223 00:14:23.592216 25375 net.cpp:406] h_t=14_encode1_unit_t=14_1_split <- h_t=14
I1223 00:14:23.592221 25375 net.cpp:380] h_t=14_encode1_unit_t=14_1_split -> h_t=14_encode1_unit_t=14_1_split_0
I1223 00:14:23.592239 25375 net.cpp:380] h_t=14_encode1_unit_t=14_1_split -> h_t=14_encode1_unit_t=14_1_split_1
I1223 00:14:23.592272 25375 net.cpp:122] Setting up h_t=14_encode1_unit_t=14_1_split
I1223 00:14:23.592279 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592283 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592285 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:23.592288 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=14
I1223 00:14:23.592293 25375 net.cpp:84] Creating Layer encode1_h_conted_t=14
I1223 00:14:23.592296 25375 net.cpp:406] encode1_h_conted_t=14 <- h_t=14_encode1_unit_t=14_1_split_0
I1223 00:14:23.592300 25375 net.cpp:406] encode1_h_conted_t=14 <- cont_t=15_encode1_cont_slice_14_split_0
I1223 00:14:23.592320 25375 net.cpp:380] encode1_h_conted_t=14 -> h_conted_t=14
I1223 00:14:23.592408 25375 net.cpp:122] Setting up encode1_h_conted_t=14
I1223 00:14:23.592417 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.592420 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:23.592423 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->14
I1223 00:14:23.592432 25375 net.cpp:84] Creating Layer encode1_hidden->transform->14
I1223 00:14:23.592435 25375 net.cpp:406] encode1_hidden->transform->14 <- h_conted_t=14
I1223 00:14:23.592442 25375 net.cpp:380] encode1_hidden->transform->14 -> hidden->transform->14
I1223 00:14:23.592932 25375 net.cpp:122] Setting up encode1_hidden->transform->14
I1223 00:14:23.592939 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.592942 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:23.592947 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.592950 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.592953 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=14
I1223 00:14:23.592958 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=14
I1223 00:14:23.592962 25375 net.cpp:406] encode1_hadamard->input_t=14 <- c_t=14_encode1_unit_t=14_0_split_0
I1223 00:14:23.592969 25375 net.cpp:380] encode1_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:23.593075 25375 net.cpp:122] Setting up encode1_hadamard->input_t=14
I1223 00:14:23.593083 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593086 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:23.593089 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.593092 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=14
I1223 00:14:23.593112 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=14
I1223 00:14:23.593116 25375 net.cpp:406] encode1_hadamard->forget_t=14 <- c_t=14_encode1_unit_t=14_0_split_1
I1223 00:14:23.593122 25375 net.cpp:380] encode1_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:23.593224 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=14
I1223 00:14:23.593230 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593232 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:23.593235 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.593238 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=14
I1223 00:14:23.593258 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=14
I1223 00:14:23.593262 25375 net.cpp:406] encode1_hadamard->output_t=14 <- c_t=14_encode1_unit_t=14_0_split_2
I1223 00:14:23.593281 25375 net.cpp:380] encode1_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:23.593374 25375 net.cpp:122] Setting up encode1_hadamard->output_t=14
I1223 00:14:23.593381 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593384 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:23.593389 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.593390 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=15
I1223 00:14:23.593410 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=15
I1223 00:14:23.593415 25375 net.cpp:380] encode1_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:23.593484 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=15
I1223 00:14:23.593492 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593508 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:23.593510 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=15
I1223 00:14:23.593528 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=15
I1223 00:14:23.593533 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:23.593536 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:23.593554 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:23.593557 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:23.593561 25375 net.cpp:380] encode1_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:23.593586 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=15
I1223 00:14:23.593592 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.593595 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:23.593598 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_15
I1223 00:14:23.593603 25375 net.cpp:84] Creating Layer encode1_gate_input_15
I1223 00:14:23.593606 25375 net.cpp:406] encode1_gate_input_15 <- hidden->transform->14
I1223 00:14:23.593611 25375 net.cpp:406] encode1_gate_input_15 <- x->transform->t=15
I1223 00:14:23.593614 25375 net.cpp:406] encode1_gate_input_15 <- hadamard_t=15
I1223 00:14:23.593636 25375 net.cpp:380] encode1_gate_input_15 -> gate_input_15
I1223 00:14:23.593657 25375 net.cpp:122] Setting up encode1_gate_input_15
I1223 00:14:23.593662 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.593665 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:23.593667 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=15
I1223 00:14:23.593674 25375 net.cpp:84] Creating Layer encode1_unit_t=15
I1223 00:14:23.593678 25375 net.cpp:406] encode1_unit_t=15 <- c_t=14_encode1_unit_t=14_0_split_3
I1223 00:14:23.593683 25375 net.cpp:406] encode1_unit_t=15 <- gate_input_15
I1223 00:14:23.593686 25375 net.cpp:406] encode1_unit_t=15 <- cont_t=15_encode1_cont_slice_14_split_1
I1223 00:14:23.593691 25375 net.cpp:380] encode1_unit_t=15 -> c_t=15
I1223 00:14:23.593698 25375 net.cpp:380] encode1_unit_t=15 -> h_t=15
I1223 00:14:23.593756 25375 net.cpp:122] Setting up encode1_unit_t=15
I1223 00:14:23.593763 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593767 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593783 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:23.593786 25375 layer_factory.hpp:77] Creating layer c_t=15_encode1_unit_t=15_0_split
I1223 00:14:23.593791 25375 net.cpp:84] Creating Layer c_t=15_encode1_unit_t=15_0_split
I1223 00:14:23.593808 25375 net.cpp:406] c_t=15_encode1_unit_t=15_0_split <- c_t=15
I1223 00:14:23.593814 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_0
I1223 00:14:23.593822 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_1
I1223 00:14:23.593829 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_2
I1223 00:14:23.593837 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_3
I1223 00:14:23.593892 25375 net.cpp:122] Setting up c_t=15_encode1_unit_t=15_0_split
I1223 00:14:23.593899 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593902 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593907 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593910 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593914 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:23.593915 25375 layer_factory.hpp:77] Creating layer h_t=15_encode1_unit_t=15_1_split
I1223 00:14:23.593920 25375 net.cpp:84] Creating Layer h_t=15_encode1_unit_t=15_1_split
I1223 00:14:23.593924 25375 net.cpp:406] h_t=15_encode1_unit_t=15_1_split <- h_t=15
I1223 00:14:23.593928 25375 net.cpp:380] h_t=15_encode1_unit_t=15_1_split -> h_t=15_encode1_unit_t=15_1_split_0
I1223 00:14:23.593935 25375 net.cpp:380] h_t=15_encode1_unit_t=15_1_split -> h_t=15_encode1_unit_t=15_1_split_1
I1223 00:14:23.593967 25375 net.cpp:122] Setting up h_t=15_encode1_unit_t=15_1_split
I1223 00:14:23.593974 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593978 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.593981 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:23.593983 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=15
I1223 00:14:23.593989 25375 net.cpp:84] Creating Layer encode1_h_conted_t=15
I1223 00:14:23.593992 25375 net.cpp:406] encode1_h_conted_t=15 <- h_t=15_encode1_unit_t=15_1_split_0
I1223 00:14:23.593997 25375 net.cpp:406] encode1_h_conted_t=15 <- cont_t=16_encode1_cont_slice_15_split_0
I1223 00:14:23.594002 25375 net.cpp:380] encode1_h_conted_t=15 -> h_conted_t=15
I1223 00:14:23.594075 25375 net.cpp:122] Setting up encode1_h_conted_t=15
I1223 00:14:23.594084 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.594085 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:23.594089 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->15
I1223 00:14:23.594097 25375 net.cpp:84] Creating Layer encode1_hidden->transform->15
I1223 00:14:23.594102 25375 net.cpp:406] encode1_hidden->transform->15 <- h_conted_t=15
I1223 00:14:23.594108 25375 net.cpp:380] encode1_hidden->transform->15 -> hidden->transform->15
I1223 00:14:23.594590 25375 net.cpp:122] Setting up encode1_hidden->transform->15
I1223 00:14:23.594600 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.594604 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:23.594607 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:23.594611 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:23.594614 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=15
I1223 00:14:23.594621 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=15
I1223 00:14:23.594625 25375 net.cpp:406] encode1_hadamard->input_t=15 <- c_t=15_encode1_unit_t=15_0_split_0
I1223 00:14:23.594631 25375 net.cpp:380] encode1_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:23.594728 25375 net.cpp:122] Setting up encode1_hadamard->input_t=15
I1223 00:14:23.594738 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.594740 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:23.594744 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:23.594748 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=15
I1223 00:14:23.594753 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=15
I1223 00:14:23.594758 25375 net.cpp:406] encode1_hadamard->forget_t=15 <- c_t=15_encode1_unit_t=15_0_split_1
I1223 00:14:23.594763 25375 net.cpp:380] encode1_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:23.594859 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=15
I1223 00:14:23.594867 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.594871 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:23.594874 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:23.594878 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=15
I1223 00:14:23.594882 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=15
I1223 00:14:23.594887 25375 net.cpp:406] encode1_hadamard->output_t=15 <- c_t=15_encode1_unit_t=15_0_split_2
I1223 00:14:23.594892 25375 net.cpp:380] encode1_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:23.594985 25375 net.cpp:122] Setting up encode1_hadamard->output_t=15
I1223 00:14:23.594995 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.594997 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:23.595001 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:23.595005 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=16
I1223 00:14:23.595010 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=16
I1223 00:14:23.595016 25375 net.cpp:380] encode1_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:23.595072 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=16
I1223 00:14:23.595078 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.595082 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:23.595084 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=16
I1223 00:14:23.595090 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=16
I1223 00:14:23.595093 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:23.595098 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:23.595101 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:23.595105 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:23.595113 25375 net.cpp:380] encode1_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:23.595137 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=16
I1223 00:14:23.595144 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.595147 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:23.595150 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_16
I1223 00:14:23.595155 25375 net.cpp:84] Creating Layer encode1_gate_input_16
I1223 00:14:23.595158 25375 net.cpp:406] encode1_gate_input_16 <- hidden->transform->15
I1223 00:14:23.595163 25375 net.cpp:406] encode1_gate_input_16 <- x->transform->t=16
I1223 00:14:23.595167 25375 net.cpp:406] encode1_gate_input_16 <- hadamard_t=16
I1223 00:14:23.595173 25375 net.cpp:380] encode1_gate_input_16 -> gate_input_16
I1223 00:14:23.595197 25375 net.cpp:122] Setting up encode1_gate_input_16
I1223 00:14:23.595203 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.595206 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:23.595209 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=16
I1223 00:14:23.595216 25375 net.cpp:84] Creating Layer encode1_unit_t=16
I1223 00:14:23.595219 25375 net.cpp:406] encode1_unit_t=16 <- c_t=15_encode1_unit_t=15_0_split_3
I1223 00:14:23.595224 25375 net.cpp:406] encode1_unit_t=16 <- gate_input_16
I1223 00:14:23.595228 25375 net.cpp:406] encode1_unit_t=16 <- cont_t=16_encode1_cont_slice_15_split_1
I1223 00:14:23.595232 25375 net.cpp:380] encode1_unit_t=16 -> c_t=16
I1223 00:14:23.595239 25375 net.cpp:380] encode1_unit_t=16 -> h_t=16
I1223 00:14:23.595288 25375 net.cpp:122] Setting up encode1_unit_t=16
I1223 00:14:23.595294 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.595299 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.595300 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:23.595304 25375 layer_factory.hpp:77] Creating layer h_t=16_encode1_unit_t=16_1_split
I1223 00:14:23.595309 25375 net.cpp:84] Creating Layer h_t=16_encode1_unit_t=16_1_split
I1223 00:14:23.595311 25375 net.cpp:406] h_t=16_encode1_unit_t=16_1_split <- h_t=16
I1223 00:14:23.595317 25375 net.cpp:380] h_t=16_encode1_unit_t=16_1_split -> h_t=16_encode1_unit_t=16_1_split_0
I1223 00:14:23.595324 25375 net.cpp:380] h_t=16_encode1_unit_t=16_1_split -> h_t=16_encode1_unit_t=16_1_split_1
I1223 00:14:23.595365 25375 net.cpp:122] Setting up h_t=16_encode1_unit_t=16_1_split
I1223 00:14:23.595371 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.595376 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.595378 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:23.595381 25375 layer_factory.hpp:77] Creating layer encode1_h_concat
I1223 00:14:23.595388 25375 net.cpp:84] Creating Layer encode1_h_concat
I1223 00:14:23.595391 25375 net.cpp:406] encode1_h_concat <- h_t=1_encode1_unit_t=1_1_split_1
I1223 00:14:23.595396 25375 net.cpp:406] encode1_h_concat <- h_t=2_encode1_unit_t=2_1_split_1
I1223 00:14:23.595401 25375 net.cpp:406] encode1_h_concat <- h_t=3_encode1_unit_t=3_1_split_1
I1223 00:14:23.595403 25375 net.cpp:406] encode1_h_concat <- h_t=4_encode1_unit_t=4_1_split_1
I1223 00:14:23.595407 25375 net.cpp:406] encode1_h_concat <- h_t=5_encode1_unit_t=5_1_split_1
I1223 00:14:23.595410 25375 net.cpp:406] encode1_h_concat <- h_t=6_encode1_unit_t=6_1_split_1
I1223 00:14:23.595414 25375 net.cpp:406] encode1_h_concat <- h_t=7_encode1_unit_t=7_1_split_1
I1223 00:14:23.595417 25375 net.cpp:406] encode1_h_concat <- h_t=8_encode1_unit_t=8_1_split_1
I1223 00:14:23.595420 25375 net.cpp:406] encode1_h_concat <- h_t=9_encode1_unit_t=9_1_split_1
I1223 00:14:23.595424 25375 net.cpp:406] encode1_h_concat <- h_t=10_encode1_unit_t=10_1_split_1
I1223 00:14:23.595427 25375 net.cpp:406] encode1_h_concat <- h_t=11_encode1_unit_t=11_1_split_1
I1223 00:14:23.595430 25375 net.cpp:406] encode1_h_concat <- h_t=12_encode1_unit_t=12_1_split_1
I1223 00:14:23.595434 25375 net.cpp:406] encode1_h_concat <- h_t=13_encode1_unit_t=13_1_split_1
I1223 00:14:23.595438 25375 net.cpp:406] encode1_h_concat <- h_t=14_encode1_unit_t=14_1_split_1
I1223 00:14:23.595440 25375 net.cpp:406] encode1_h_concat <- h_t=15_encode1_unit_t=15_1_split_1
I1223 00:14:23.595443 25375 net.cpp:406] encode1_h_concat <- h_t=16_encode1_unit_t=16_1_split_0
I1223 00:14:23.595450 25375 net.cpp:380] encode1_h_concat -> h
I1223 00:14:23.595475 25375 net.cpp:122] Setting up encode1_h_concat
I1223 00:14:23.595482 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.595485 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:23.595489 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_h
I1223 00:14:23.595494 25375 net.cpp:84] Creating Layer encode1_dummy_forward_h
I1223 00:14:23.595496 25375 net.cpp:406] encode1_dummy_forward_h <- h_t=16_encode1_unit_t=16_1_split_1
I1223 00:14:23.595504 25375 net.cpp:380] encode1_dummy_forward_h -> h_t=T
I1223 00:14:23.595540 25375 net.cpp:122] Setting up encode1_dummy_forward_h
I1223 00:14:23.595546 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.595549 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:23.595556 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_c
I1223 00:14:23.595562 25375 net.cpp:84] Creating Layer encode1_dummy_forward_c
I1223 00:14:23.595566 25375 net.cpp:406] encode1_dummy_forward_c <- c_t=16
I1223 00:14:23.595571 25375 net.cpp:380] encode1_dummy_forward_c -> c_t=T
I1223 00:14:23.595607 25375 net.cpp:122] Setting up encode1_dummy_forward_c
I1223 00:14:23.595613 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.595618 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:23.595621 25375 layer_factory.hpp:77] Creating layer encode1_h_t=T_pseudoloss
I1223 00:14:23.595626 25375 net.cpp:84] Creating Layer encode1_h_t=T_pseudoloss
I1223 00:14:23.595629 25375 net.cpp:406] encode1_h_t=T_pseudoloss <- h_t=T
I1223 00:14:23.595634 25375 net.cpp:380] encode1_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:23.595703 25375 net.cpp:122] Setting up encode1_h_t=T_pseudoloss
I1223 00:14:23.595710 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.595713 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.595736 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:23.595741 25375 layer_factory.hpp:77] Creating layer encode1_c_t=T_pseudoloss
I1223 00:14:23.595746 25375 net.cpp:84] Creating Layer encode1_c_t=T_pseudoloss
I1223 00:14:23.595749 25375 net.cpp:406] encode1_c_t=T_pseudoloss <- c_t=T
I1223 00:14:23.595754 25375 net.cpp:380] encode1_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:23.595824 25375 net.cpp:122] Setting up encode1_c_t=T_pseudoloss
I1223 00:14:23.595829 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.595832 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.595837 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:23.595839 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:23.595844 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:23.595847 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:23.595852 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:23.597007 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:23.597024 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.597028 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.597048 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:23.597052 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:23.597055 25375 net.cpp:198] encode1_c_t=T_pseudoloss needs backward computation.
I1223 00:14:23.597059 25375 net.cpp:198] encode1_h_t=T_pseudoloss needs backward computation.
I1223 00:14:23.597062 25375 net.cpp:198] encode1_dummy_forward_c needs backward computation.
I1223 00:14:23.597064 25375 net.cpp:198] encode1_dummy_forward_h needs backward computation.
I1223 00:14:23.597079 25375 net.cpp:198] encode1_h_concat needs backward computation.
I1223 00:14:23.597090 25375 net.cpp:198] h_t=16_encode1_unit_t=16_1_split needs backward computation.
I1223 00:14:23.597095 25375 net.cpp:198] encode1_unit_t=16 needs backward computation.
I1223 00:14:23.597100 25375 net.cpp:198] encode1_gate_input_16 needs backward computation.
I1223 00:14:23.597105 25375 net.cpp:198] encode1_concat_hadamard_t=16 needs backward computation.
I1223 00:14:23.597123 25375 net.cpp:200] encode1_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:23.597126 25375 net.cpp:198] encode1_hadamard->output_t=15 needs backward computation.
I1223 00:14:23.597129 25375 net.cpp:198] encode1_hadamard->forget_t=15 needs backward computation.
I1223 00:14:23.597133 25375 net.cpp:198] encode1_hadamard->input_t=15 needs backward computation.
I1223 00:14:23.597136 25375 net.cpp:198] encode1_hidden->transform->15 needs backward computation.
I1223 00:14:23.597141 25375 net.cpp:198] encode1_h_conted_t=15 needs backward computation.
I1223 00:14:23.597144 25375 net.cpp:198] h_t=15_encode1_unit_t=15_1_split needs backward computation.
I1223 00:14:23.597160 25375 net.cpp:198] c_t=15_encode1_unit_t=15_0_split needs backward computation.
I1223 00:14:23.597163 25375 net.cpp:198] encode1_unit_t=15 needs backward computation.
I1223 00:14:23.597168 25375 net.cpp:198] encode1_gate_input_15 needs backward computation.
I1223 00:14:23.597172 25375 net.cpp:198] encode1_concat_hadamard_t=15 needs backward computation.
I1223 00:14:23.597177 25375 net.cpp:200] encode1_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:23.597180 25375 net.cpp:198] encode1_hadamard->output_t=14 needs backward computation.
I1223 00:14:23.597183 25375 net.cpp:198] encode1_hadamard->forget_t=14 needs backward computation.
I1223 00:14:23.597187 25375 net.cpp:198] encode1_hadamard->input_t=14 needs backward computation.
I1223 00:14:23.597190 25375 net.cpp:198] encode1_hidden->transform->14 needs backward computation.
I1223 00:14:23.597194 25375 net.cpp:198] encode1_h_conted_t=14 needs backward computation.
I1223 00:14:23.597199 25375 net.cpp:198] h_t=14_encode1_unit_t=14_1_split needs backward computation.
I1223 00:14:23.597203 25375 net.cpp:198] c_t=14_encode1_unit_t=14_0_split needs backward computation.
I1223 00:14:23.597206 25375 net.cpp:198] encode1_unit_t=14 needs backward computation.
I1223 00:14:23.597211 25375 net.cpp:198] encode1_gate_input_14 needs backward computation.
I1223 00:14:23.597215 25375 net.cpp:198] encode1_concat_hadamard_t=14 needs backward computation.
I1223 00:14:23.597220 25375 net.cpp:200] encode1_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:23.597223 25375 net.cpp:198] encode1_hadamard->output_t=13 needs backward computation.
I1223 00:14:23.597226 25375 net.cpp:198] encode1_hadamard->forget_t=13 needs backward computation.
I1223 00:14:23.597230 25375 net.cpp:198] encode1_hadamard->input_t=13 needs backward computation.
I1223 00:14:23.597234 25375 net.cpp:198] encode1_hidden->transform->13 needs backward computation.
I1223 00:14:23.597237 25375 net.cpp:198] encode1_h_conted_t=13 needs backward computation.
I1223 00:14:23.597241 25375 net.cpp:198] h_t=13_encode1_unit_t=13_1_split needs backward computation.
I1223 00:14:23.597245 25375 net.cpp:198] c_t=13_encode1_unit_t=13_0_split needs backward computation.
I1223 00:14:23.597249 25375 net.cpp:198] encode1_unit_t=13 needs backward computation.
I1223 00:14:23.597252 25375 net.cpp:198] encode1_gate_input_13 needs backward computation.
I1223 00:14:23.597256 25375 net.cpp:198] encode1_concat_hadamard_t=13 needs backward computation.
I1223 00:14:23.597261 25375 net.cpp:200] encode1_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:23.597265 25375 net.cpp:198] encode1_hadamard->output_t=12 needs backward computation.
I1223 00:14:23.597270 25375 net.cpp:198] encode1_hadamard->forget_t=12 needs backward computation.
I1223 00:14:23.597272 25375 net.cpp:198] encode1_hadamard->input_t=12 needs backward computation.
I1223 00:14:23.597276 25375 net.cpp:198] encode1_hidden->transform->12 needs backward computation.
I1223 00:14:23.597280 25375 net.cpp:198] encode1_h_conted_t=12 needs backward computation.
I1223 00:14:23.597285 25375 net.cpp:198] h_t=12_encode1_unit_t=12_1_split needs backward computation.
I1223 00:14:23.597287 25375 net.cpp:198] c_t=12_encode1_unit_t=12_0_split needs backward computation.
I1223 00:14:23.597291 25375 net.cpp:198] encode1_unit_t=12 needs backward computation.
I1223 00:14:23.597295 25375 net.cpp:198] encode1_gate_input_12 needs backward computation.
I1223 00:14:23.597299 25375 net.cpp:198] encode1_concat_hadamard_t=12 needs backward computation.
I1223 00:14:23.597304 25375 net.cpp:200] encode1_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:23.597307 25375 net.cpp:198] encode1_hadamard->output_t=11 needs backward computation.
I1223 00:14:23.597311 25375 net.cpp:198] encode1_hadamard->forget_t=11 needs backward computation.
I1223 00:14:23.597314 25375 net.cpp:198] encode1_hadamard->input_t=11 needs backward computation.
I1223 00:14:23.597317 25375 net.cpp:198] encode1_hidden->transform->11 needs backward computation.
I1223 00:14:23.597321 25375 net.cpp:198] encode1_h_conted_t=11 needs backward computation.
I1223 00:14:23.597326 25375 net.cpp:198] h_t=11_encode1_unit_t=11_1_split needs backward computation.
I1223 00:14:23.597328 25375 net.cpp:198] c_t=11_encode1_unit_t=11_0_split needs backward computation.
I1223 00:14:23.597332 25375 net.cpp:198] encode1_unit_t=11 needs backward computation.
I1223 00:14:23.597337 25375 net.cpp:198] encode1_gate_input_11 needs backward computation.
I1223 00:14:23.597340 25375 net.cpp:198] encode1_concat_hadamard_t=11 needs backward computation.
I1223 00:14:23.597347 25375 net.cpp:200] encode1_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:23.597349 25375 net.cpp:198] encode1_hadamard->output_t=10 needs backward computation.
I1223 00:14:23.597353 25375 net.cpp:198] encode1_hadamard->forget_t=10 needs backward computation.
I1223 00:14:23.597357 25375 net.cpp:198] encode1_hadamard->input_t=10 needs backward computation.
I1223 00:14:23.597359 25375 net.cpp:198] encode1_hidden->transform->10 needs backward computation.
I1223 00:14:23.597363 25375 net.cpp:198] encode1_h_conted_t=10 needs backward computation.
I1223 00:14:23.597368 25375 net.cpp:198] h_t=10_encode1_unit_t=10_1_split needs backward computation.
I1223 00:14:23.597370 25375 net.cpp:198] c_t=10_encode1_unit_t=10_0_split needs backward computation.
I1223 00:14:23.597374 25375 net.cpp:198] encode1_unit_t=10 needs backward computation.
I1223 00:14:23.597378 25375 net.cpp:198] encode1_gate_input_10 needs backward computation.
I1223 00:14:23.597383 25375 net.cpp:198] encode1_concat_hadamard_t=10 needs backward computation.
I1223 00:14:23.597388 25375 net.cpp:200] encode1_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:23.597391 25375 net.cpp:198] encode1_hadamard->output_t=9 needs backward computation.
I1223 00:14:23.597394 25375 net.cpp:198] encode1_hadamard->forget_t=9 needs backward computation.
I1223 00:14:23.597398 25375 net.cpp:198] encode1_hadamard->input_t=9 needs backward computation.
I1223 00:14:23.597401 25375 net.cpp:198] encode1_hidden->transform->9 needs backward computation.
I1223 00:14:23.597405 25375 net.cpp:198] encode1_h_conted_t=9 needs backward computation.
I1223 00:14:23.597409 25375 net.cpp:198] h_t=9_encode1_unit_t=9_1_split needs backward computation.
I1223 00:14:23.597414 25375 net.cpp:198] c_t=9_encode1_unit_t=9_0_split needs backward computation.
I1223 00:14:23.597417 25375 net.cpp:198] encode1_unit_t=9 needs backward computation.
I1223 00:14:23.597424 25375 net.cpp:198] encode1_gate_input_9 needs backward computation.
I1223 00:14:23.597429 25375 net.cpp:198] encode1_concat_hadamard_t=9 needs backward computation.
I1223 00:14:23.597434 25375 net.cpp:200] encode1_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:23.597437 25375 net.cpp:198] encode1_hadamard->output_t=8 needs backward computation.
I1223 00:14:23.597440 25375 net.cpp:198] encode1_hadamard->forget_t=8 needs backward computation.
I1223 00:14:23.597445 25375 net.cpp:198] encode1_hadamard->input_t=8 needs backward computation.
I1223 00:14:23.597448 25375 net.cpp:198] encode1_hidden->transform->8 needs backward computation.
I1223 00:14:23.597452 25375 net.cpp:198] encode1_h_conted_t=8 needs backward computation.
I1223 00:14:23.597456 25375 net.cpp:198] h_t=8_encode1_unit_t=8_1_split needs backward computation.
I1223 00:14:23.597460 25375 net.cpp:198] c_t=8_encode1_unit_t=8_0_split needs backward computation.
I1223 00:14:23.597463 25375 net.cpp:198] encode1_unit_t=8 needs backward computation.
I1223 00:14:23.597468 25375 net.cpp:198] encode1_gate_input_8 needs backward computation.
I1223 00:14:23.597472 25375 net.cpp:198] encode1_concat_hadamard_t=8 needs backward computation.
I1223 00:14:23.597478 25375 net.cpp:200] encode1_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:23.597481 25375 net.cpp:198] encode1_hadamard->output_t=7 needs backward computation.
I1223 00:14:23.597486 25375 net.cpp:198] encode1_hadamard->forget_t=7 needs backward computation.
I1223 00:14:23.597488 25375 net.cpp:198] encode1_hadamard->input_t=7 needs backward computation.
I1223 00:14:23.597492 25375 net.cpp:198] encode1_hidden->transform->7 needs backward computation.
I1223 00:14:23.597496 25375 net.cpp:198] encode1_h_conted_t=7 needs backward computation.
I1223 00:14:23.597503 25375 net.cpp:198] h_t=7_encode1_unit_t=7_1_split needs backward computation.
I1223 00:14:23.597506 25375 net.cpp:198] c_t=7_encode1_unit_t=7_0_split needs backward computation.
I1223 00:14:23.597510 25375 net.cpp:198] encode1_unit_t=7 needs backward computation.
I1223 00:14:23.597515 25375 net.cpp:198] encode1_gate_input_7 needs backward computation.
I1223 00:14:23.597519 25375 net.cpp:198] encode1_concat_hadamard_t=7 needs backward computation.
I1223 00:14:23.597524 25375 net.cpp:200] encode1_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:23.597527 25375 net.cpp:198] encode1_hadamard->output_t=6 needs backward computation.
I1223 00:14:23.597532 25375 net.cpp:198] encode1_hadamard->forget_t=6 needs backward computation.
I1223 00:14:23.597534 25375 net.cpp:198] encode1_hadamard->input_t=6 needs backward computation.
I1223 00:14:23.597539 25375 net.cpp:198] encode1_hidden->transform->6 needs backward computation.
I1223 00:14:23.597543 25375 net.cpp:198] encode1_h_conted_t=6 needs backward computation.
I1223 00:14:23.597548 25375 net.cpp:198] h_t=6_encode1_unit_t=6_1_split needs backward computation.
I1223 00:14:23.597551 25375 net.cpp:198] c_t=6_encode1_unit_t=6_0_split needs backward computation.
I1223 00:14:23.597554 25375 net.cpp:198] encode1_unit_t=6 needs backward computation.
I1223 00:14:23.597559 25375 net.cpp:198] encode1_gate_input_6 needs backward computation.
I1223 00:14:23.597564 25375 net.cpp:198] encode1_concat_hadamard_t=6 needs backward computation.
I1223 00:14:23.597569 25375 net.cpp:200] encode1_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:23.597573 25375 net.cpp:198] encode1_hadamard->output_t=5 needs backward computation.
I1223 00:14:23.597576 25375 net.cpp:198] encode1_hadamard->forget_t=5 needs backward computation.
I1223 00:14:23.597581 25375 net.cpp:198] encode1_hadamard->input_t=5 needs backward computation.
I1223 00:14:23.597585 25375 net.cpp:198] encode1_hidden->transform->5 needs backward computation.
I1223 00:14:23.597589 25375 net.cpp:198] encode1_h_conted_t=5 needs backward computation.
I1223 00:14:23.597592 25375 net.cpp:198] h_t=5_encode1_unit_t=5_1_split needs backward computation.
I1223 00:14:23.597596 25375 net.cpp:198] c_t=5_encode1_unit_t=5_0_split needs backward computation.
I1223 00:14:23.597599 25375 net.cpp:198] encode1_unit_t=5 needs backward computation.
I1223 00:14:23.597604 25375 net.cpp:198] encode1_gate_input_5 needs backward computation.
I1223 00:14:23.597609 25375 net.cpp:198] encode1_concat_hadamard_t=5 needs backward computation.
I1223 00:14:23.597615 25375 net.cpp:200] encode1_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:23.597617 25375 net.cpp:198] encode1_hadamard->output_t=4 needs backward computation.
I1223 00:14:23.597620 25375 net.cpp:198] encode1_hadamard->forget_t=4 needs backward computation.
I1223 00:14:23.597625 25375 net.cpp:198] encode1_hadamard->input_t=4 needs backward computation.
I1223 00:14:23.597627 25375 net.cpp:198] encode1_hidden->transform->4 needs backward computation.
I1223 00:14:23.597631 25375 net.cpp:198] encode1_h_conted_t=4 needs backward computation.
I1223 00:14:23.597635 25375 net.cpp:198] h_t=4_encode1_unit_t=4_1_split needs backward computation.
I1223 00:14:23.597638 25375 net.cpp:198] c_t=4_encode1_unit_t=4_0_split needs backward computation.
I1223 00:14:23.597642 25375 net.cpp:198] encode1_unit_t=4 needs backward computation.
I1223 00:14:23.597646 25375 net.cpp:198] encode1_gate_input_4 needs backward computation.
I1223 00:14:23.597651 25375 net.cpp:198] encode1_concat_hadamard_t=4 needs backward computation.
I1223 00:14:23.597657 25375 net.cpp:200] encode1_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:23.597661 25375 net.cpp:198] encode1_hadamard->output_t=3 needs backward computation.
I1223 00:14:23.597666 25375 net.cpp:198] encode1_hadamard->forget_t=3 needs backward computation.
I1223 00:14:23.597668 25375 net.cpp:198] encode1_hadamard->input_t=3 needs backward computation.
I1223 00:14:23.597672 25375 net.cpp:198] encode1_hidden->transform->3 needs backward computation.
I1223 00:14:23.597676 25375 net.cpp:198] encode1_h_conted_t=3 needs backward computation.
I1223 00:14:23.597679 25375 net.cpp:198] h_t=3_encode1_unit_t=3_1_split needs backward computation.
I1223 00:14:23.597683 25375 net.cpp:198] c_t=3_encode1_unit_t=3_0_split needs backward computation.
I1223 00:14:23.597687 25375 net.cpp:198] encode1_unit_t=3 needs backward computation.
I1223 00:14:23.597692 25375 net.cpp:198] encode1_gate_input_3 needs backward computation.
I1223 00:14:23.597695 25375 net.cpp:198] encode1_concat_hadamard_t=3 needs backward computation.
I1223 00:14:23.597700 25375 net.cpp:200] encode1_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:23.597703 25375 net.cpp:198] encode1_hadamard->output_t=2 needs backward computation.
I1223 00:14:23.597707 25375 net.cpp:198] encode1_hadamard->forget_t=2 needs backward computation.
I1223 00:14:23.597710 25375 net.cpp:198] encode1_hadamard->input_t=2 needs backward computation.
I1223 00:14:23.597714 25375 net.cpp:198] encode1_hidden->transform->2 needs backward computation.
I1223 00:14:23.597718 25375 net.cpp:198] encode1_h_conted_t=2 needs backward computation.
I1223 00:14:23.597721 25375 net.cpp:198] h_t=2_encode1_unit_t=2_1_split needs backward computation.
I1223 00:14:23.597725 25375 net.cpp:198] c_t=2_encode1_unit_t=2_0_split needs backward computation.
I1223 00:14:23.597728 25375 net.cpp:198] encode1_unit_t=2 needs backward computation.
I1223 00:14:23.597733 25375 net.cpp:198] encode1_gate_input_2 needs backward computation.
I1223 00:14:23.597738 25375 net.cpp:198] encode1_concat_hadamard_t=2 needs backward computation.
I1223 00:14:23.597743 25375 net.cpp:200] encode1_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:23.597746 25375 net.cpp:198] encode1_hadamard->output_t=1 needs backward computation.
I1223 00:14:23.597750 25375 net.cpp:198] encode1_hadamard->forget_t=1 needs backward computation.
I1223 00:14:23.597754 25375 net.cpp:198] encode1_hadamard->input_t=1 needs backward computation.
I1223 00:14:23.597757 25375 net.cpp:198] encode1_hidden->transform->1 needs backward computation.
I1223 00:14:23.597760 25375 net.cpp:198] encode1_h_conted_t=1 needs backward computation.
I1223 00:14:23.597765 25375 net.cpp:198] h_t=1_encode1_unit_t=1_1_split needs backward computation.
I1223 00:14:23.597769 25375 net.cpp:198] c_t=1_encode1_unit_t=1_0_split needs backward computation.
I1223 00:14:23.597772 25375 net.cpp:198] encode1_unit_t=1 needs backward computation.
I1223 00:14:23.597777 25375 net.cpp:198] encode1_gate_input_1 needs backward computation.
I1223 00:14:23.597781 25375 net.cpp:198] encode1_concat_hadamard_t=1 needs backward computation.
I1223 00:14:23.597787 25375 net.cpp:200] encode1_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:23.597790 25375 net.cpp:198] encode1_hadamard->output_t=0 needs backward computation.
I1223 00:14:23.597795 25375 net.cpp:198] encode1_hadamard->forget_t=0 needs backward computation.
I1223 00:14:23.597797 25375 net.cpp:198] encode1_hadamard->input_t=0 needs backward computation.
I1223 00:14:23.597801 25375 net.cpp:198] encode1_hidden->transform->0 needs backward computation.
I1223 00:14:23.597805 25375 net.cpp:198] encode1_h_conted_t=0 needs backward computation.
I1223 00:14:23.597810 25375 net.cpp:198] encode1_dummy_forward_h0 needs backward computation.
I1223 00:14:23.597813 25375 net.cpp:198] c_t=0_encode1_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:23.597817 25375 net.cpp:198] encode1_dummy_forward_c0 needs backward computation.
I1223 00:14:23.597821 25375 net.cpp:200] cont_t=16_encode1_cont_slice_15_split does not need backward computation.
I1223 00:14:23.597826 25375 net.cpp:200] cont_t=15_encode1_cont_slice_14_split does not need backward computation.
I1223 00:14:23.597831 25375 net.cpp:200] cont_t=14_encode1_cont_slice_13_split does not need backward computation.
I1223 00:14:23.597834 25375 net.cpp:200] cont_t=13_encode1_cont_slice_12_split does not need backward computation.
I1223 00:14:23.597837 25375 net.cpp:200] cont_t=12_encode1_cont_slice_11_split does not need backward computation.
I1223 00:14:23.597841 25375 net.cpp:200] cont_t=11_encode1_cont_slice_10_split does not need backward computation.
I1223 00:14:23.597844 25375 net.cpp:200] cont_t=10_encode1_cont_slice_9_split does not need backward computation.
I1223 00:14:23.597849 25375 net.cpp:200] cont_t=9_encode1_cont_slice_8_split does not need backward computation.
I1223 00:14:23.597853 25375 net.cpp:200] cont_t=8_encode1_cont_slice_7_split does not need backward computation.
I1223 00:14:23.597856 25375 net.cpp:200] cont_t=7_encode1_cont_slice_6_split does not need backward computation.
I1223 00:14:23.597860 25375 net.cpp:200] cont_t=6_encode1_cont_slice_5_split does not need backward computation.
I1223 00:14:23.597864 25375 net.cpp:200] cont_t=5_encode1_cont_slice_4_split does not need backward computation.
I1223 00:14:23.597867 25375 net.cpp:200] cont_t=4_encode1_cont_slice_3_split does not need backward computation.
I1223 00:14:23.597872 25375 net.cpp:200] cont_t=3_encode1_cont_slice_2_split does not need backward computation.
I1223 00:14:23.597874 25375 net.cpp:200] cont_t=2_encode1_cont_slice_1_split does not need backward computation.
I1223 00:14:23.597879 25375 net.cpp:200] cont_t=1_encode1_cont_slice_0_split does not need backward computation.
I1223 00:14:23.597887 25375 net.cpp:200] encode1_cont_slice does not need backward computation.
I1223 00:14:23.597892 25375 net.cpp:198] encode1_W_xc_x_slice needs backward computation.
I1223 00:14:23.597895 25375 net.cpp:200] encode1_input->cell_hidden does not need backward computation.
I1223 00:14:23.597898 25375 net.cpp:198] encode1_x->transform needs backward computation.
I1223 00:14:23.597901 25375 net.cpp:200] encode1_ does not need backward computation.
I1223 00:14:23.597904 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:23.597908 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:23.597913 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:23.598846 25375 net.cpp:255] Network initialization done.
I1223 00:14:23.599251 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:23.599259 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:23.599263 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:23.599267 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:23.599282 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:23.599285 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:23.599287 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:23.599290 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:23.599293 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:23.599295 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:23.599967 25375 net.cpp:122] Setting up encode1
I1223 00:14:23.599975 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.599980 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.599984 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.599987 25375 net.cpp:137] Memory required for data: 4282253696
I1223 00:14:23.600018 25375 layer_factory.hpp:77] Creating layer encode2
I1223 00:14:23.600044 25375 net.cpp:84] Creating Layer encode2
I1223 00:14:23.600050 25375 net.cpp:406] encode2 <- conv6-reshape_reshape-data_0_split_1
I1223 00:14:23.600056 25375 net.cpp:406] encode2 <- reshape-cm_reshape-cm_0_split_1
I1223 00:14:23.600061 25375 net.cpp:406] encode2 <- dummy_dummy_0_split_2
I1223 00:14:23.600065 25375 net.cpp:406] encode2 <- dummy_dummy_0_split_3
I1223 00:14:23.600072 25375 net.cpp:380] encode2 -> encode2
I1223 00:14:23.600083 25375 net.cpp:380] encode2 -> encode2_h
I1223 00:14:23.600093 25375 net.cpp:380] encode2 -> encode2_c
I1223 00:14:23.600106 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:23.601498 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode2_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode2_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode2_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode2_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode2_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode2_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode2_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode2_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode2_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode2_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode2_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode2_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode2_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode2_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode2_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode2_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode2_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transfor
I1223 00:14:23.602430 25375 layer_factory.hpp:77] Creating layer encode2_
I1223 00:14:23.602442 25375 net.cpp:84] Creating Layer encode2_
I1223 00:14:23.602448 25375 net.cpp:380] encode2_ -> x
I1223 00:14:23.602455 25375 net.cpp:380] encode2_ -> cont
I1223 00:14:23.602510 25375 net.cpp:122] Setting up encode2_
I1223 00:14:23.602519 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.602524 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.602526 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:23.602530 25375 layer_factory.hpp:77] Creating layer encode2_x->transform
I1223 00:14:23.602538 25375 net.cpp:84] Creating Layer encode2_x->transform
I1223 00:14:23.602542 25375 net.cpp:406] encode2_x->transform <- x
I1223 00:14:23.602548 25375 net.cpp:380] encode2_x->transform -> x->transform
I1223 00:14:23.602800 25375 net.cpp:122] Setting up encode2_x->transform
I1223 00:14:23.602809 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:23.602813 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:23.602818 25375 layer_factory.hpp:77] Creating layer encode2_input->cell_hidden
I1223 00:14:23.602824 25375 net.cpp:84] Creating Layer encode2_input->cell_hidden
I1223 00:14:23.602828 25375 net.cpp:380] encode2_input->cell_hidden -> c_t=0
I1223 00:14:23.602835 25375 net.cpp:380] encode2_input->cell_hidden -> h_t=0
I1223 00:14:23.602874 25375 net.cpp:122] Setting up encode2_input->cell_hidden
I1223 00:14:23.602880 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.602885 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.602888 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:23.602891 25375 layer_factory.hpp:77] Creating layer encode2_W_xc_x_slice
I1223 00:14:23.602898 25375 net.cpp:84] Creating Layer encode2_W_xc_x_slice
I1223 00:14:23.602901 25375 net.cpp:406] encode2_W_xc_x_slice <- x->transform
I1223 00:14:23.602907 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=1
I1223 00:14:23.602916 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=2
I1223 00:14:23.602924 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=3
I1223 00:14:23.602931 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=4
I1223 00:14:23.602939 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=5
I1223 00:14:23.602948 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=6
I1223 00:14:23.602957 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=7
I1223 00:14:23.602964 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=8
I1223 00:14:23.602972 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=9
I1223 00:14:23.602979 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=10
I1223 00:14:23.602988 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=11
I1223 00:14:23.602995 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=12
I1223 00:14:23.603004 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=13
I1223 00:14:23.603013 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=14
I1223 00:14:23.603020 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=15
I1223 00:14:23.603029 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=16
I1223 00:14:23.603237 25375 net.cpp:122] Setting up encode2_W_xc_x_slice
I1223 00:14:23.603245 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603250 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603253 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603257 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603261 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603266 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603269 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603273 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603277 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603281 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603286 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603289 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603293 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603297 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603302 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603305 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.603307 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:23.603310 25375 layer_factory.hpp:77] Creating layer encode2_cont_slice
I1223 00:14:23.603317 25375 net.cpp:84] Creating Layer encode2_cont_slice
I1223 00:14:23.603320 25375 net.cpp:406] encode2_cont_slice <- cont
I1223 00:14:23.603327 25375 net.cpp:380] encode2_cont_slice -> cont_t=1
I1223 00:14:23.603333 25375 net.cpp:380] encode2_cont_slice -> cont_t=2
I1223 00:14:23.603341 25375 net.cpp:380] encode2_cont_slice -> cont_t=3
I1223 00:14:23.603348 25375 net.cpp:380] encode2_cont_slice -> cont_t=4
I1223 00:14:23.603354 25375 net.cpp:380] encode2_cont_slice -> cont_t=5
I1223 00:14:23.603363 25375 net.cpp:380] encode2_cont_slice -> cont_t=6
I1223 00:14:23.603368 25375 net.cpp:380] encode2_cont_slice -> cont_t=7
I1223 00:14:23.603374 25375 net.cpp:380] encode2_cont_slice -> cont_t=8
I1223 00:14:23.603381 25375 net.cpp:380] encode2_cont_slice -> cont_t=9
I1223 00:14:23.603389 25375 net.cpp:380] encode2_cont_slice -> cont_t=10
I1223 00:14:23.603395 25375 net.cpp:380] encode2_cont_slice -> cont_t=11
I1223 00:14:23.603402 25375 net.cpp:380] encode2_cont_slice -> cont_t=12
I1223 00:14:23.603410 25375 net.cpp:380] encode2_cont_slice -> cont_t=13
I1223 00:14:23.603417 25375 net.cpp:380] encode2_cont_slice -> cont_t=14
I1223 00:14:23.603423 25375 net.cpp:380] encode2_cont_slice -> cont_t=15
I1223 00:14:23.603430 25375 net.cpp:380] encode2_cont_slice -> cont_t=16
I1223 00:14:23.603652 25375 net.cpp:122] Setting up encode2_cont_slice
I1223 00:14:23.603660 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603664 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603667 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603670 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603674 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603677 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603682 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603684 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603688 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603691 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603694 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603698 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603703 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603705 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603708 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603713 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603714 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:23.603718 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode2_cont_slice_0_split
I1223 00:14:23.603724 25375 net.cpp:84] Creating Layer cont_t=1_encode2_cont_slice_0_split
I1223 00:14:23.603729 25375 net.cpp:406] cont_t=1_encode2_cont_slice_0_split <- cont_t=1
I1223 00:14:23.603735 25375 net.cpp:380] cont_t=1_encode2_cont_slice_0_split -> cont_t=1_encode2_cont_slice_0_split_0
I1223 00:14:23.603744 25375 net.cpp:380] cont_t=1_encode2_cont_slice_0_split -> cont_t=1_encode2_cont_slice_0_split_1
I1223 00:14:23.603780 25375 net.cpp:122] Setting up cont_t=1_encode2_cont_slice_0_split
I1223 00:14:23.603786 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603790 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603793 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:23.603796 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode2_cont_slice_1_split
I1223 00:14:23.603801 25375 net.cpp:84] Creating Layer cont_t=2_encode2_cont_slice_1_split
I1223 00:14:23.603804 25375 net.cpp:406] cont_t=2_encode2_cont_slice_1_split <- cont_t=2
I1223 00:14:23.603808 25375 net.cpp:380] cont_t=2_encode2_cont_slice_1_split -> cont_t=2_encode2_cont_slice_1_split_0
I1223 00:14:23.603816 25375 net.cpp:380] cont_t=2_encode2_cont_slice_1_split -> cont_t=2_encode2_cont_slice_1_split_1
I1223 00:14:23.603852 25375 net.cpp:122] Setting up cont_t=2_encode2_cont_slice_1_split
I1223 00:14:23.603858 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603862 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603864 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:23.603866 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode2_cont_slice_2_split
I1223 00:14:23.603873 25375 net.cpp:84] Creating Layer cont_t=3_encode2_cont_slice_2_split
I1223 00:14:23.603876 25375 net.cpp:406] cont_t=3_encode2_cont_slice_2_split <- cont_t=3
I1223 00:14:23.603881 25375 net.cpp:380] cont_t=3_encode2_cont_slice_2_split -> cont_t=3_encode2_cont_slice_2_split_0
I1223 00:14:23.603888 25375 net.cpp:380] cont_t=3_encode2_cont_slice_2_split -> cont_t=3_encode2_cont_slice_2_split_1
I1223 00:14:23.603924 25375 net.cpp:122] Setting up cont_t=3_encode2_cont_slice_2_split
I1223 00:14:23.603930 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603934 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.603936 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:23.603940 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode2_cont_slice_3_split
I1223 00:14:23.603945 25375 net.cpp:84] Creating Layer cont_t=4_encode2_cont_slice_3_split
I1223 00:14:23.603950 25375 net.cpp:406] cont_t=4_encode2_cont_slice_3_split <- cont_t=4
I1223 00:14:23.603955 25375 net.cpp:380] cont_t=4_encode2_cont_slice_3_split -> cont_t=4_encode2_cont_slice_3_split_0
I1223 00:14:23.603961 25375 net.cpp:380] cont_t=4_encode2_cont_slice_3_split -> cont_t=4_encode2_cont_slice_3_split_1
I1223 00:14:23.603997 25375 net.cpp:122] Setting up cont_t=4_encode2_cont_slice_3_split
I1223 00:14:23.604003 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604007 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604009 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:23.604012 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode2_cont_slice_4_split
I1223 00:14:23.604018 25375 net.cpp:84] Creating Layer cont_t=5_encode2_cont_slice_4_split
I1223 00:14:23.604022 25375 net.cpp:406] cont_t=5_encode2_cont_slice_4_split <- cont_t=5
I1223 00:14:23.604027 25375 net.cpp:380] cont_t=5_encode2_cont_slice_4_split -> cont_t=5_encode2_cont_slice_4_split_0
I1223 00:14:23.604032 25375 net.cpp:380] cont_t=5_encode2_cont_slice_4_split -> cont_t=5_encode2_cont_slice_4_split_1
I1223 00:14:23.604066 25375 net.cpp:122] Setting up cont_t=5_encode2_cont_slice_4_split
I1223 00:14:23.604073 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604076 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604079 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:23.604082 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode2_cont_slice_5_split
I1223 00:14:23.604086 25375 net.cpp:84] Creating Layer cont_t=6_encode2_cont_slice_5_split
I1223 00:14:23.604089 25375 net.cpp:406] cont_t=6_encode2_cont_slice_5_split <- cont_t=6
I1223 00:14:23.604094 25375 net.cpp:380] cont_t=6_encode2_cont_slice_5_split -> cont_t=6_encode2_cont_slice_5_split_0
I1223 00:14:23.604100 25375 net.cpp:380] cont_t=6_encode2_cont_slice_5_split -> cont_t=6_encode2_cont_slice_5_split_1
I1223 00:14:23.604135 25375 net.cpp:122] Setting up cont_t=6_encode2_cont_slice_5_split
I1223 00:14:23.604141 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604145 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604147 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:23.604149 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode2_cont_slice_6_split
I1223 00:14:23.604156 25375 net.cpp:84] Creating Layer cont_t=7_encode2_cont_slice_6_split
I1223 00:14:23.604158 25375 net.cpp:406] cont_t=7_encode2_cont_slice_6_split <- cont_t=7
I1223 00:14:23.604163 25375 net.cpp:380] cont_t=7_encode2_cont_slice_6_split -> cont_t=7_encode2_cont_slice_6_split_0
I1223 00:14:23.604169 25375 net.cpp:380] cont_t=7_encode2_cont_slice_6_split -> cont_t=7_encode2_cont_slice_6_split_1
I1223 00:14:23.604216 25375 net.cpp:122] Setting up cont_t=7_encode2_cont_slice_6_split
I1223 00:14:23.604223 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604226 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604228 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:23.604233 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode2_cont_slice_7_split
I1223 00:14:23.604236 25375 net.cpp:84] Creating Layer cont_t=8_encode2_cont_slice_7_split
I1223 00:14:23.604239 25375 net.cpp:406] cont_t=8_encode2_cont_slice_7_split <- cont_t=8
I1223 00:14:23.604256 25375 net.cpp:380] cont_t=8_encode2_cont_slice_7_split -> cont_t=8_encode2_cont_slice_7_split_0
I1223 00:14:23.604262 25375 net.cpp:380] cont_t=8_encode2_cont_slice_7_split -> cont_t=8_encode2_cont_slice_7_split_1
I1223 00:14:23.604298 25375 net.cpp:122] Setting up cont_t=8_encode2_cont_slice_7_split
I1223 00:14:23.604305 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604323 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604326 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:23.604329 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode2_cont_slice_8_split
I1223 00:14:23.604333 25375 net.cpp:84] Creating Layer cont_t=9_encode2_cont_slice_8_split
I1223 00:14:23.604336 25375 net.cpp:406] cont_t=9_encode2_cont_slice_8_split <- cont_t=9
I1223 00:14:23.604343 25375 net.cpp:380] cont_t=9_encode2_cont_slice_8_split -> cont_t=9_encode2_cont_slice_8_split_0
I1223 00:14:23.604364 25375 net.cpp:380] cont_t=9_encode2_cont_slice_8_split -> cont_t=9_encode2_cont_slice_8_split_1
I1223 00:14:23.604400 25375 net.cpp:122] Setting up cont_t=9_encode2_cont_slice_8_split
I1223 00:14:23.604408 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604411 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604413 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:23.604416 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode2_cont_slice_9_split
I1223 00:14:23.604420 25375 net.cpp:84] Creating Layer cont_t=10_encode2_cont_slice_9_split
I1223 00:14:23.604424 25375 net.cpp:406] cont_t=10_encode2_cont_slice_9_split <- cont_t=10
I1223 00:14:23.604429 25375 net.cpp:380] cont_t=10_encode2_cont_slice_9_split -> cont_t=10_encode2_cont_slice_9_split_0
I1223 00:14:23.604434 25375 net.cpp:380] cont_t=10_encode2_cont_slice_9_split -> cont_t=10_encode2_cont_slice_9_split_1
I1223 00:14:23.604470 25375 net.cpp:122] Setting up cont_t=10_encode2_cont_slice_9_split
I1223 00:14:23.604476 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604480 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604482 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:23.604485 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode2_cont_slice_10_split
I1223 00:14:23.604490 25375 net.cpp:84] Creating Layer cont_t=11_encode2_cont_slice_10_split
I1223 00:14:23.604492 25375 net.cpp:406] cont_t=11_encode2_cont_slice_10_split <- cont_t=11
I1223 00:14:23.604498 25375 net.cpp:380] cont_t=11_encode2_cont_slice_10_split -> cont_t=11_encode2_cont_slice_10_split_0
I1223 00:14:23.604506 25375 net.cpp:380] cont_t=11_encode2_cont_slice_10_split -> cont_t=11_encode2_cont_slice_10_split_1
I1223 00:14:23.604542 25375 net.cpp:122] Setting up cont_t=11_encode2_cont_slice_10_split
I1223 00:14:23.604548 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604552 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604553 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:23.604557 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode2_cont_slice_11_split
I1223 00:14:23.604562 25375 net.cpp:84] Creating Layer cont_t=12_encode2_cont_slice_11_split
I1223 00:14:23.604565 25375 net.cpp:406] cont_t=12_encode2_cont_slice_11_split <- cont_t=12
I1223 00:14:23.604569 25375 net.cpp:380] cont_t=12_encode2_cont_slice_11_split -> cont_t=12_encode2_cont_slice_11_split_0
I1223 00:14:23.604575 25375 net.cpp:380] cont_t=12_encode2_cont_slice_11_split -> cont_t=12_encode2_cont_slice_11_split_1
I1223 00:14:23.604610 25375 net.cpp:122] Setting up cont_t=12_encode2_cont_slice_11_split
I1223 00:14:23.604616 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604620 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604624 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:23.604626 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode2_cont_slice_12_split
I1223 00:14:23.604631 25375 net.cpp:84] Creating Layer cont_t=13_encode2_cont_slice_12_split
I1223 00:14:23.604635 25375 net.cpp:406] cont_t=13_encode2_cont_slice_12_split <- cont_t=13
I1223 00:14:23.604640 25375 net.cpp:380] cont_t=13_encode2_cont_slice_12_split -> cont_t=13_encode2_cont_slice_12_split_0
I1223 00:14:23.604645 25375 net.cpp:380] cont_t=13_encode2_cont_slice_12_split -> cont_t=13_encode2_cont_slice_12_split_1
I1223 00:14:23.604681 25375 net.cpp:122] Setting up cont_t=13_encode2_cont_slice_12_split
I1223 00:14:23.604686 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604691 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604693 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:23.604696 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode2_cont_slice_13_split
I1223 00:14:23.604699 25375 net.cpp:84] Creating Layer cont_t=14_encode2_cont_slice_13_split
I1223 00:14:23.604703 25375 net.cpp:406] cont_t=14_encode2_cont_slice_13_split <- cont_t=14
I1223 00:14:23.604707 25375 net.cpp:380] cont_t=14_encode2_cont_slice_13_split -> cont_t=14_encode2_cont_slice_13_split_0
I1223 00:14:23.604713 25375 net.cpp:380] cont_t=14_encode2_cont_slice_13_split -> cont_t=14_encode2_cont_slice_13_split_1
I1223 00:14:23.604751 25375 net.cpp:122] Setting up cont_t=14_encode2_cont_slice_13_split
I1223 00:14:23.604758 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604761 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604764 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:23.604766 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode2_cont_slice_14_split
I1223 00:14:23.604771 25375 net.cpp:84] Creating Layer cont_t=15_encode2_cont_slice_14_split
I1223 00:14:23.604774 25375 net.cpp:406] cont_t=15_encode2_cont_slice_14_split <- cont_t=15
I1223 00:14:23.604780 25375 net.cpp:380] cont_t=15_encode2_cont_slice_14_split -> cont_t=15_encode2_cont_slice_14_split_0
I1223 00:14:23.604787 25375 net.cpp:380] cont_t=15_encode2_cont_slice_14_split -> cont_t=15_encode2_cont_slice_14_split_1
I1223 00:14:23.604822 25375 net.cpp:122] Setting up cont_t=15_encode2_cont_slice_14_split
I1223 00:14:23.604828 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604832 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604835 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:23.604838 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode2_cont_slice_15_split
I1223 00:14:23.604843 25375 net.cpp:84] Creating Layer cont_t=16_encode2_cont_slice_15_split
I1223 00:14:23.604846 25375 net.cpp:406] cont_t=16_encode2_cont_slice_15_split <- cont_t=16
I1223 00:14:23.604851 25375 net.cpp:380] cont_t=16_encode2_cont_slice_15_split -> cont_t=16_encode2_cont_slice_15_split_0
I1223 00:14:23.604857 25375 net.cpp:380] cont_t=16_encode2_cont_slice_15_split -> cont_t=16_encode2_cont_slice_15_split_1
I1223 00:14:23.604894 25375 net.cpp:122] Setting up cont_t=16_encode2_cont_slice_15_split
I1223 00:14:23.604902 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604904 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.604907 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:23.604910 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_c0
I1223 00:14:23.604915 25375 net.cpp:84] Creating Layer encode2_dummy_forward_c0
I1223 00:14:23.604918 25375 net.cpp:406] encode2_dummy_forward_c0 <- c_t=0
I1223 00:14:23.604923 25375 net.cpp:367] encode2_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:23.604948 25375 net.cpp:122] Setting up encode2_dummy_forward_c0
I1223 00:14:23.604954 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.604956 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:23.604962 25375 layer_factory.hpp:77] Creating layer c_t=0_encode2_dummy_forward_c0_0_split
I1223 00:14:23.604967 25375 net.cpp:84] Creating Layer c_t=0_encode2_dummy_forward_c0_0_split
I1223 00:14:23.604970 25375 net.cpp:406] c_t=0_encode2_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:23.604976 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_0
I1223 00:14:23.604984 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_1
I1223 00:14:23.604991 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_2
I1223 00:14:23.604998 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_3
I1223 00:14:23.605072 25375 net.cpp:122] Setting up c_t=0_encode2_dummy_forward_c0_0_split
I1223 00:14:23.605080 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.605085 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.605089 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.605093 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.605096 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:23.605099 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_h0
I1223 00:14:23.605104 25375 net.cpp:84] Creating Layer encode2_dummy_forward_h0
I1223 00:14:23.605108 25375 net.cpp:406] encode2_dummy_forward_h0 <- h_t=0
I1223 00:14:23.605113 25375 net.cpp:367] encode2_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:23.605135 25375 net.cpp:122] Setting up encode2_dummy_forward_h0
I1223 00:14:23.605141 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.605144 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:23.605150 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=0
I1223 00:14:23.605159 25375 net.cpp:84] Creating Layer encode2_h_conted_t=0
I1223 00:14:23.605162 25375 net.cpp:406] encode2_h_conted_t=0 <- h_t=0
I1223 00:14:23.605166 25375 net.cpp:406] encode2_h_conted_t=0 <- cont_t=1_encode2_cont_slice_0_split_0
I1223 00:14:23.605172 25375 net.cpp:380] encode2_h_conted_t=0 -> h_conted_t=0
I1223 00:14:23.605253 25375 net.cpp:122] Setting up encode2_h_conted_t=0
I1223 00:14:23.605260 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.605263 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:23.605267 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->0
I1223 00:14:23.605275 25375 net.cpp:84] Creating Layer encode2_hidden->transform->0
I1223 00:14:23.605280 25375 net.cpp:406] encode2_hidden->transform->0 <- h_conted_t=0
I1223 00:14:23.605288 25375 net.cpp:380] encode2_hidden->transform->0 -> hidden->transform->0
I1223 00:14:23.605790 25375 net.cpp:122] Setting up encode2_hidden->transform->0
I1223 00:14:23.605799 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.605803 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:23.605809 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=0
I1223 00:14:23.605814 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=0
I1223 00:14:23.605818 25375 net.cpp:406] encode2_hadamard->input_t=0 <- c_t=0_encode2_dummy_forward_c0_0_split_0
I1223 00:14:23.605824 25375 net.cpp:380] encode2_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:23.605934 25375 net.cpp:122] Setting up encode2_hadamard->input_t=0
I1223 00:14:23.605942 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.605947 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:23.605950 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=0
I1223 00:14:23.605957 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=0
I1223 00:14:23.605973 25375 net.cpp:406] encode2_hadamard->forget_t=0 <- c_t=0_encode2_dummy_forward_c0_0_split_1
I1223 00:14:23.605980 25375 net.cpp:380] encode2_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:23.606071 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=0
I1223 00:14:23.606078 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606081 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:23.606086 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=0
I1223 00:14:23.606092 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=0
I1223 00:14:23.606096 25375 net.cpp:406] encode2_hadamard->output_t=0 <- c_t=0_encode2_dummy_forward_c0_0_split_2
I1223 00:14:23.606101 25375 net.cpp:380] encode2_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:23.606210 25375 net.cpp:122] Setting up encode2_hadamard->output_t=0
I1223 00:14:23.606218 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606221 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:23.606226 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=1
I1223 00:14:23.606233 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=1
I1223 00:14:23.606240 25375 net.cpp:380] encode2_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:23.606295 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=1
I1223 00:14:23.606302 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606307 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:23.606309 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=1
I1223 00:14:23.606328 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=1
I1223 00:14:23.606331 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:23.606336 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:23.606340 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:23.606343 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:23.606350 25375 net.cpp:380] encode2_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:23.606375 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=1
I1223 00:14:23.606381 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.606384 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:23.606387 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_1
I1223 00:14:23.606393 25375 net.cpp:84] Creating Layer encode2_gate_input_1
I1223 00:14:23.606396 25375 net.cpp:406] encode2_gate_input_1 <- hidden->transform->0
I1223 00:14:23.606400 25375 net.cpp:406] encode2_gate_input_1 <- x->transform->t=1
I1223 00:14:23.606405 25375 net.cpp:406] encode2_gate_input_1 <- hadamard_t=1
I1223 00:14:23.606411 25375 net.cpp:380] encode2_gate_input_1 -> gate_input_1
I1223 00:14:23.606434 25375 net.cpp:122] Setting up encode2_gate_input_1
I1223 00:14:23.606442 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.606446 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:23.606448 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=1
I1223 00:14:23.606456 25375 net.cpp:84] Creating Layer encode2_unit_t=1
I1223 00:14:23.606459 25375 net.cpp:406] encode2_unit_t=1 <- c_t=0_encode2_dummy_forward_c0_0_split_3
I1223 00:14:23.606464 25375 net.cpp:406] encode2_unit_t=1 <- gate_input_1
I1223 00:14:23.606468 25375 net.cpp:406] encode2_unit_t=1 <- cont_t=1_encode2_cont_slice_0_split_1
I1223 00:14:23.606473 25375 net.cpp:380] encode2_unit_t=1 -> c_t=1
I1223 00:14:23.606480 25375 net.cpp:380] encode2_unit_t=1 -> h_t=1
I1223 00:14:23.606544 25375 net.cpp:122] Setting up encode2_unit_t=1
I1223 00:14:23.606552 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606556 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606559 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:23.606561 25375 layer_factory.hpp:77] Creating layer c_t=1_encode2_unit_t=1_0_split
I1223 00:14:23.606566 25375 net.cpp:84] Creating Layer c_t=1_encode2_unit_t=1_0_split
I1223 00:14:23.606570 25375 net.cpp:406] c_t=1_encode2_unit_t=1_0_split <- c_t=1
I1223 00:14:23.606590 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_0
I1223 00:14:23.606597 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_1
I1223 00:14:23.606604 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_2
I1223 00:14:23.606616 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_3
I1223 00:14:23.606678 25375 net.cpp:122] Setting up c_t=1_encode2_unit_t=1_0_split
I1223 00:14:23.606684 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606688 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606693 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606696 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606699 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:23.606703 25375 layer_factory.hpp:77] Creating layer h_t=1_encode2_unit_t=1_1_split
I1223 00:14:23.606708 25375 net.cpp:84] Creating Layer h_t=1_encode2_unit_t=1_1_split
I1223 00:14:23.606710 25375 net.cpp:406] h_t=1_encode2_unit_t=1_1_split <- h_t=1
I1223 00:14:23.606715 25375 net.cpp:380] h_t=1_encode2_unit_t=1_1_split -> h_t=1_encode2_unit_t=1_1_split_0
I1223 00:14:23.606722 25375 net.cpp:380] h_t=1_encode2_unit_t=1_1_split -> h_t=1_encode2_unit_t=1_1_split_1
I1223 00:14:23.606760 25375 net.cpp:122] Setting up h_t=1_encode2_unit_t=1_1_split
I1223 00:14:23.606765 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606770 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606773 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:23.606776 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=1
I1223 00:14:23.606781 25375 net.cpp:84] Creating Layer encode2_h_conted_t=1
I1223 00:14:23.606784 25375 net.cpp:406] encode2_h_conted_t=1 <- h_t=1_encode2_unit_t=1_1_split_0
I1223 00:14:23.606788 25375 net.cpp:406] encode2_h_conted_t=1 <- cont_t=2_encode2_cont_slice_1_split_0
I1223 00:14:23.606796 25375 net.cpp:380] encode2_h_conted_t=1 -> h_conted_t=1
I1223 00:14:23.606875 25375 net.cpp:122] Setting up encode2_h_conted_t=1
I1223 00:14:23.606883 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.606886 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:23.606889 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->1
I1223 00:14:23.606897 25375 net.cpp:84] Creating Layer encode2_hidden->transform->1
I1223 00:14:23.606902 25375 net.cpp:406] encode2_hidden->transform->1 <- h_conted_t=1
I1223 00:14:23.606909 25375 net.cpp:380] encode2_hidden->transform->1 -> hidden->transform->1
I1223 00:14:23.607414 25375 net.cpp:122] Setting up encode2_hidden->transform->1
I1223 00:14:23.607422 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.607425 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:23.607430 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.607435 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.607439 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=1
I1223 00:14:23.607445 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=1
I1223 00:14:23.607450 25375 net.cpp:406] encode2_hadamard->input_t=1 <- c_t=1_encode2_unit_t=1_0_split_0
I1223 00:14:23.607457 25375 net.cpp:380] encode2_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:23.607544 25375 net.cpp:122] Setting up encode2_hadamard->input_t=1
I1223 00:14:23.607553 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.607555 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:23.607558 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.607561 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=1
I1223 00:14:23.607568 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=1
I1223 00:14:23.607573 25375 net.cpp:406] encode2_hadamard->forget_t=1 <- c_t=1_encode2_unit_t=1_0_split_1
I1223 00:14:23.607579 25375 net.cpp:380] encode2_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:23.607686 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=1
I1223 00:14:23.607694 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.607697 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:23.607700 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.607704 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=1
I1223 00:14:23.607710 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=1
I1223 00:14:23.607714 25375 net.cpp:406] encode2_hadamard->output_t=1 <- c_t=1_encode2_unit_t=1_0_split_2
I1223 00:14:23.607720 25375 net.cpp:380] encode2_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:23.607836 25375 net.cpp:122] Setting up encode2_hadamard->output_t=1
I1223 00:14:23.607844 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.607847 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:23.607851 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.607854 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=2
I1223 00:14:23.607861 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=2
I1223 00:14:23.607867 25375 net.cpp:380] encode2_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:23.607921 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=2
I1223 00:14:23.607929 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.607945 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:23.607949 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=2
I1223 00:14:23.607954 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=2
I1223 00:14:23.607957 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:23.607961 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:23.607966 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:23.607970 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:23.607975 25375 net.cpp:380] encode2_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:23.608001 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=2
I1223 00:14:23.608009 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.608012 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:23.608016 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_2
I1223 00:14:23.608021 25375 net.cpp:84] Creating Layer encode2_gate_input_2
I1223 00:14:23.608024 25375 net.cpp:406] encode2_gate_input_2 <- hidden->transform->1
I1223 00:14:23.608028 25375 net.cpp:406] encode2_gate_input_2 <- x->transform->t=2
I1223 00:14:23.608032 25375 net.cpp:406] encode2_gate_input_2 <- hadamard_t=2
I1223 00:14:23.608038 25375 net.cpp:380] encode2_gate_input_2 -> gate_input_2
I1223 00:14:23.608062 25375 net.cpp:122] Setting up encode2_gate_input_2
I1223 00:14:23.608069 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.608072 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:23.608075 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=2
I1223 00:14:23.608081 25375 net.cpp:84] Creating Layer encode2_unit_t=2
I1223 00:14:23.608085 25375 net.cpp:406] encode2_unit_t=2 <- c_t=1_encode2_unit_t=1_0_split_3
I1223 00:14:23.608089 25375 net.cpp:406] encode2_unit_t=2 <- gate_input_2
I1223 00:14:23.608093 25375 net.cpp:406] encode2_unit_t=2 <- cont_t=2_encode2_cont_slice_1_split_1
I1223 00:14:23.608098 25375 net.cpp:380] encode2_unit_t=2 -> c_t=2
I1223 00:14:23.608105 25375 net.cpp:380] encode2_unit_t=2 -> h_t=2
I1223 00:14:23.608155 25375 net.cpp:122] Setting up encode2_unit_t=2
I1223 00:14:23.608161 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608166 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608170 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:23.608171 25375 layer_factory.hpp:77] Creating layer c_t=2_encode2_unit_t=2_0_split
I1223 00:14:23.608177 25375 net.cpp:84] Creating Layer c_t=2_encode2_unit_t=2_0_split
I1223 00:14:23.608181 25375 net.cpp:406] c_t=2_encode2_unit_t=2_0_split <- c_t=2
I1223 00:14:23.608187 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_0
I1223 00:14:23.608196 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_1
I1223 00:14:23.608202 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_2
I1223 00:14:23.608209 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_3
I1223 00:14:23.608268 25375 net.cpp:122] Setting up c_t=2_encode2_unit_t=2_0_split
I1223 00:14:23.608275 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608280 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608284 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608289 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608290 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:23.608294 25375 layer_factory.hpp:77] Creating layer h_t=2_encode2_unit_t=2_1_split
I1223 00:14:23.608299 25375 net.cpp:84] Creating Layer h_t=2_encode2_unit_t=2_1_split
I1223 00:14:23.608301 25375 net.cpp:406] h_t=2_encode2_unit_t=2_1_split <- h_t=2
I1223 00:14:23.608306 25375 net.cpp:380] h_t=2_encode2_unit_t=2_1_split -> h_t=2_encode2_unit_t=2_1_split_0
I1223 00:14:23.608314 25375 net.cpp:380] h_t=2_encode2_unit_t=2_1_split -> h_t=2_encode2_unit_t=2_1_split_1
I1223 00:14:23.608361 25375 net.cpp:122] Setting up h_t=2_encode2_unit_t=2_1_split
I1223 00:14:23.608368 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608372 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608376 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:23.608378 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=2
I1223 00:14:23.608388 25375 net.cpp:84] Creating Layer encode2_h_conted_t=2
I1223 00:14:23.608407 25375 net.cpp:406] encode2_h_conted_t=2 <- h_t=2_encode2_unit_t=2_1_split_0
I1223 00:14:23.608425 25375 net.cpp:406] encode2_h_conted_t=2 <- cont_t=3_encode2_cont_slice_2_split_0
I1223 00:14:23.608431 25375 net.cpp:380] encode2_h_conted_t=2 -> h_conted_t=2
I1223 00:14:23.608511 25375 net.cpp:122] Setting up encode2_h_conted_t=2
I1223 00:14:23.608518 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.608521 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:23.608525 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->2
I1223 00:14:23.608534 25375 net.cpp:84] Creating Layer encode2_hidden->transform->2
I1223 00:14:23.608538 25375 net.cpp:406] encode2_hidden->transform->2 <- h_conted_t=2
I1223 00:14:23.608561 25375 net.cpp:380] encode2_hidden->transform->2 -> hidden->transform->2
I1223 00:14:23.609060 25375 net.cpp:122] Setting up encode2_hidden->transform->2
I1223 00:14:23.609072 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.609076 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:23.609081 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.609086 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.609088 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=2
I1223 00:14:23.609096 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=2
I1223 00:14:23.609099 25375 net.cpp:406] encode2_hadamard->input_t=2 <- c_t=2_encode2_unit_t=2_0_split_0
I1223 00:14:23.609105 25375 net.cpp:380] encode2_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:23.609202 25375 net.cpp:122] Setting up encode2_hadamard->input_t=2
I1223 00:14:23.609210 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609212 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:23.609216 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.609220 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=2
I1223 00:14:23.609226 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=2
I1223 00:14:23.609230 25375 net.cpp:406] encode2_hadamard->forget_t=2 <- c_t=2_encode2_unit_t=2_0_split_1
I1223 00:14:23.609238 25375 net.cpp:380] encode2_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:23.609350 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=2
I1223 00:14:23.609357 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609360 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:23.609367 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.609371 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=2
I1223 00:14:23.609376 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=2
I1223 00:14:23.609380 25375 net.cpp:406] encode2_hadamard->output_t=2 <- c_t=2_encode2_unit_t=2_0_split_2
I1223 00:14:23.609385 25375 net.cpp:380] encode2_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:23.609469 25375 net.cpp:122] Setting up encode2_hadamard->output_t=2
I1223 00:14:23.609477 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609480 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:23.609484 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.609488 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=3
I1223 00:14:23.609493 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=3
I1223 00:14:23.609498 25375 net.cpp:380] encode2_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:23.609581 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=3
I1223 00:14:23.609588 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609591 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:23.609594 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=3
I1223 00:14:23.609599 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=3
I1223 00:14:23.609603 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:23.609622 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:23.609627 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:23.609630 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:23.609635 25375 net.cpp:380] encode2_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:23.609661 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=3
I1223 00:14:23.609668 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.609671 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:23.609674 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_3
I1223 00:14:23.609681 25375 net.cpp:84] Creating Layer encode2_gate_input_3
I1223 00:14:23.609685 25375 net.cpp:406] encode2_gate_input_3 <- hidden->transform->2
I1223 00:14:23.609690 25375 net.cpp:406] encode2_gate_input_3 <- x->transform->t=3
I1223 00:14:23.609694 25375 net.cpp:406] encode2_gate_input_3 <- hadamard_t=3
I1223 00:14:23.609699 25375 net.cpp:380] encode2_gate_input_3 -> gate_input_3
I1223 00:14:23.609724 25375 net.cpp:122] Setting up encode2_gate_input_3
I1223 00:14:23.609731 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.609735 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:23.609737 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=3
I1223 00:14:23.609742 25375 net.cpp:84] Creating Layer encode2_unit_t=3
I1223 00:14:23.609745 25375 net.cpp:406] encode2_unit_t=3 <- c_t=2_encode2_unit_t=2_0_split_3
I1223 00:14:23.609750 25375 net.cpp:406] encode2_unit_t=3 <- gate_input_3
I1223 00:14:23.609755 25375 net.cpp:406] encode2_unit_t=3 <- cont_t=3_encode2_cont_slice_2_split_1
I1223 00:14:23.609758 25375 net.cpp:380] encode2_unit_t=3 -> c_t=3
I1223 00:14:23.609766 25375 net.cpp:380] encode2_unit_t=3 -> h_t=3
I1223 00:14:23.609815 25375 net.cpp:122] Setting up encode2_unit_t=3
I1223 00:14:23.609822 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609827 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609828 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:23.609832 25375 layer_factory.hpp:77] Creating layer c_t=3_encode2_unit_t=3_0_split
I1223 00:14:23.609838 25375 net.cpp:84] Creating Layer c_t=3_encode2_unit_t=3_0_split
I1223 00:14:23.609841 25375 net.cpp:406] c_t=3_encode2_unit_t=3_0_split <- c_t=3
I1223 00:14:23.609848 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_0
I1223 00:14:23.609855 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_1
I1223 00:14:23.609863 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_2
I1223 00:14:23.609870 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_3
I1223 00:14:23.609962 25375 net.cpp:122] Setting up c_t=3_encode2_unit_t=3_0_split
I1223 00:14:23.609969 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609973 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609977 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609982 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.609984 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:23.609987 25375 layer_factory.hpp:77] Creating layer h_t=3_encode2_unit_t=3_1_split
I1223 00:14:23.609992 25375 net.cpp:84] Creating Layer h_t=3_encode2_unit_t=3_1_split
I1223 00:14:23.609995 25375 net.cpp:406] h_t=3_encode2_unit_t=3_1_split <- h_t=3
I1223 00:14:23.610002 25375 net.cpp:380] h_t=3_encode2_unit_t=3_1_split -> h_t=3_encode2_unit_t=3_1_split_0
I1223 00:14:23.610009 25375 net.cpp:380] h_t=3_encode2_unit_t=3_1_split -> h_t=3_encode2_unit_t=3_1_split_1
I1223 00:14:23.610044 25375 net.cpp:122] Setting up h_t=3_encode2_unit_t=3_1_split
I1223 00:14:23.610051 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.610055 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.610059 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:23.610061 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=3
I1223 00:14:23.610069 25375 net.cpp:84] Creating Layer encode2_h_conted_t=3
I1223 00:14:23.610071 25375 net.cpp:406] encode2_h_conted_t=3 <- h_t=3_encode2_unit_t=3_1_split_0
I1223 00:14:23.610076 25375 net.cpp:406] encode2_h_conted_t=3 <- cont_t=4_encode2_cont_slice_3_split_0
I1223 00:14:23.610081 25375 net.cpp:380] encode2_h_conted_t=3 -> h_conted_t=3
I1223 00:14:23.610162 25375 net.cpp:122] Setting up encode2_h_conted_t=3
I1223 00:14:23.610168 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.610172 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:23.610175 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->3
I1223 00:14:23.610183 25375 net.cpp:84] Creating Layer encode2_hidden->transform->3
I1223 00:14:23.610188 25375 net.cpp:406] encode2_hidden->transform->3 <- h_conted_t=3
I1223 00:14:23.610196 25375 net.cpp:380] encode2_hidden->transform->3 -> hidden->transform->3
I1223 00:14:23.610707 25375 net.cpp:122] Setting up encode2_hidden->transform->3
I1223 00:14:23.610715 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.610718 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:23.610723 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.610726 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.610730 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=3
I1223 00:14:23.610735 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=3
I1223 00:14:23.610739 25375 net.cpp:406] encode2_hadamard->input_t=3 <- c_t=3_encode2_unit_t=3_0_split_0
I1223 00:14:23.610744 25375 net.cpp:380] encode2_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:23.610841 25375 net.cpp:122] Setting up encode2_hadamard->input_t=3
I1223 00:14:23.610849 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.610852 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:23.610855 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.610859 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=3
I1223 00:14:23.610867 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=3
I1223 00:14:23.610870 25375 net.cpp:406] encode2_hadamard->forget_t=3 <- c_t=3_encode2_unit_t=3_0_split_1
I1223 00:14:23.610875 25375 net.cpp:380] encode2_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:23.610965 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=3
I1223 00:14:23.610972 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.610975 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:23.610978 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.610982 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=3
I1223 00:14:23.610987 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=3
I1223 00:14:23.610991 25375 net.cpp:406] encode2_hadamard->output_t=3 <- c_t=3_encode2_unit_t=3_0_split_2
I1223 00:14:23.610997 25375 net.cpp:380] encode2_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:23.611090 25375 net.cpp:122] Setting up encode2_hadamard->output_t=3
I1223 00:14:23.611097 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611100 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:23.611104 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.611107 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=4
I1223 00:14:23.611114 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=4
I1223 00:14:23.611117 25375 net.cpp:380] encode2_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:23.611176 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=4
I1223 00:14:23.611184 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611187 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:23.611191 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=4
I1223 00:14:23.611196 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=4
I1223 00:14:23.611201 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:23.611204 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:23.611209 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:23.611213 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:23.611218 25375 net.cpp:380] encode2_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:23.611244 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=4
I1223 00:14:23.611251 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.611254 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:23.611258 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_4
I1223 00:14:23.611268 25375 net.cpp:84] Creating Layer encode2_gate_input_4
I1223 00:14:23.611273 25375 net.cpp:406] encode2_gate_input_4 <- hidden->transform->3
I1223 00:14:23.611277 25375 net.cpp:406] encode2_gate_input_4 <- x->transform->t=4
I1223 00:14:23.611281 25375 net.cpp:406] encode2_gate_input_4 <- hadamard_t=4
I1223 00:14:23.611286 25375 net.cpp:380] encode2_gate_input_4 -> gate_input_4
I1223 00:14:23.611316 25375 net.cpp:122] Setting up encode2_gate_input_4
I1223 00:14:23.611325 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.611327 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:23.611330 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=4
I1223 00:14:23.611336 25375 net.cpp:84] Creating Layer encode2_unit_t=4
I1223 00:14:23.611340 25375 net.cpp:406] encode2_unit_t=4 <- c_t=3_encode2_unit_t=3_0_split_3
I1223 00:14:23.611344 25375 net.cpp:406] encode2_unit_t=4 <- gate_input_4
I1223 00:14:23.611348 25375 net.cpp:406] encode2_unit_t=4 <- cont_t=4_encode2_cont_slice_3_split_1
I1223 00:14:23.611353 25375 net.cpp:380] encode2_unit_t=4 -> c_t=4
I1223 00:14:23.611359 25375 net.cpp:380] encode2_unit_t=4 -> h_t=4
I1223 00:14:23.611407 25375 net.cpp:122] Setting up encode2_unit_t=4
I1223 00:14:23.611414 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611418 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611421 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:23.611424 25375 layer_factory.hpp:77] Creating layer c_t=4_encode2_unit_t=4_0_split
I1223 00:14:23.611429 25375 net.cpp:84] Creating Layer c_t=4_encode2_unit_t=4_0_split
I1223 00:14:23.611433 25375 net.cpp:406] c_t=4_encode2_unit_t=4_0_split <- c_t=4
I1223 00:14:23.611439 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_0
I1223 00:14:23.611448 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_1
I1223 00:14:23.611454 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_2
I1223 00:14:23.611460 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_3
I1223 00:14:23.611521 25375 net.cpp:122] Setting up c_t=4_encode2_unit_t=4_0_split
I1223 00:14:23.611528 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611532 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611536 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611539 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611542 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:23.611546 25375 layer_factory.hpp:77] Creating layer h_t=4_encode2_unit_t=4_1_split
I1223 00:14:23.611552 25375 net.cpp:84] Creating Layer h_t=4_encode2_unit_t=4_1_split
I1223 00:14:23.611557 25375 net.cpp:406] h_t=4_encode2_unit_t=4_1_split <- h_t=4
I1223 00:14:23.611562 25375 net.cpp:380] h_t=4_encode2_unit_t=4_1_split -> h_t=4_encode2_unit_t=4_1_split_0
I1223 00:14:23.611567 25375 net.cpp:380] h_t=4_encode2_unit_t=4_1_split -> h_t=4_encode2_unit_t=4_1_split_1
I1223 00:14:23.611603 25375 net.cpp:122] Setting up h_t=4_encode2_unit_t=4_1_split
I1223 00:14:23.611611 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611615 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611618 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:23.611620 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=4
I1223 00:14:23.611624 25375 net.cpp:84] Creating Layer encode2_h_conted_t=4
I1223 00:14:23.611629 25375 net.cpp:406] encode2_h_conted_t=4 <- h_t=4_encode2_unit_t=4_1_split_0
I1223 00:14:23.611632 25375 net.cpp:406] encode2_h_conted_t=4 <- cont_t=5_encode2_cont_slice_4_split_0
I1223 00:14:23.611639 25375 net.cpp:380] encode2_h_conted_t=4 -> h_conted_t=4
I1223 00:14:23.611719 25375 net.cpp:122] Setting up encode2_h_conted_t=4
I1223 00:14:23.611728 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.611730 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:23.611733 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->4
I1223 00:14:23.611743 25375 net.cpp:84] Creating Layer encode2_hidden->transform->4
I1223 00:14:23.611747 25375 net.cpp:406] encode2_hidden->transform->4 <- h_conted_t=4
I1223 00:14:23.611753 25375 net.cpp:380] encode2_hidden->transform->4 -> hidden->transform->4
I1223 00:14:23.613049 25375 net.cpp:122] Setting up encode2_hidden->transform->4
I1223 00:14:23.613080 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.613085 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:23.613090 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.613095 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.613097 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=4
I1223 00:14:23.613106 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=4
I1223 00:14:23.613111 25375 net.cpp:406] encode2_hadamard->input_t=4 <- c_t=4_encode2_unit_t=4_0_split_0
I1223 00:14:23.613121 25375 net.cpp:380] encode2_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:23.613222 25375 net.cpp:122] Setting up encode2_hadamard->input_t=4
I1223 00:14:23.613230 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.613234 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:23.613237 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.613241 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=4
I1223 00:14:23.613250 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=4
I1223 00:14:23.613255 25375 net.cpp:406] encode2_hadamard->forget_t=4 <- c_t=4_encode2_unit_t=4_0_split_1
I1223 00:14:23.613261 25375 net.cpp:380] encode2_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:23.613363 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=4
I1223 00:14:23.613371 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.613374 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:23.613378 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.613381 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=4
I1223 00:14:23.613389 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=4
I1223 00:14:23.613391 25375 net.cpp:406] encode2_hadamard->output_t=4 <- c_t=4_encode2_unit_t=4_0_split_2
I1223 00:14:23.613399 25375 net.cpp:380] encode2_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:23.613502 25375 net.cpp:122] Setting up encode2_hadamard->output_t=4
I1223 00:14:23.613512 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.613514 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:23.613517 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.613520 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=5
I1223 00:14:23.613540 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=5
I1223 00:14:23.613546 25375 net.cpp:380] encode2_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:23.613615 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=5
I1223 00:14:23.613636 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.613638 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:23.613641 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=5
I1223 00:14:23.613647 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=5
I1223 00:14:23.613652 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:23.613657 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:23.613674 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:23.613678 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:23.613685 25375 net.cpp:380] encode2_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:23.613713 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=5
I1223 00:14:23.613718 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.613721 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:23.613724 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_5
I1223 00:14:23.613744 25375 net.cpp:84] Creating Layer encode2_gate_input_5
I1223 00:14:23.613747 25375 net.cpp:406] encode2_gate_input_5 <- hidden->transform->4
I1223 00:14:23.613751 25375 net.cpp:406] encode2_gate_input_5 <- x->transform->t=5
I1223 00:14:23.613770 25375 net.cpp:406] encode2_gate_input_5 <- hadamard_t=5
I1223 00:14:23.613795 25375 net.cpp:380] encode2_gate_input_5 -> gate_input_5
I1223 00:14:23.613819 25375 net.cpp:122] Setting up encode2_gate_input_5
I1223 00:14:23.613828 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.613831 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:23.613834 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=5
I1223 00:14:23.613840 25375 net.cpp:84] Creating Layer encode2_unit_t=5
I1223 00:14:23.613843 25375 net.cpp:406] encode2_unit_t=5 <- c_t=4_encode2_unit_t=4_0_split_3
I1223 00:14:23.613848 25375 net.cpp:406] encode2_unit_t=5 <- gate_input_5
I1223 00:14:23.613852 25375 net.cpp:406] encode2_unit_t=5 <- cont_t=5_encode2_cont_slice_4_split_1
I1223 00:14:23.613873 25375 net.cpp:380] encode2_unit_t=5 -> c_t=5
I1223 00:14:23.613880 25375 net.cpp:380] encode2_unit_t=5 -> h_t=5
I1223 00:14:23.613946 25375 net.cpp:122] Setting up encode2_unit_t=5
I1223 00:14:23.613953 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.613970 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.613973 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:23.613976 25375 layer_factory.hpp:77] Creating layer c_t=5_encode2_unit_t=5_0_split
I1223 00:14:23.613994 25375 net.cpp:84] Creating Layer c_t=5_encode2_unit_t=5_0_split
I1223 00:14:23.613998 25375 net.cpp:406] c_t=5_encode2_unit_t=5_0_split <- c_t=5
I1223 00:14:23.614003 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_0
I1223 00:14:23.614011 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_1
I1223 00:14:23.614020 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_2
I1223 00:14:23.614028 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_3
I1223 00:14:23.614106 25375 net.cpp:122] Setting up c_t=5_encode2_unit_t=5_0_split
I1223 00:14:23.614114 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.614117 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.614121 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.614125 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.614127 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:23.614131 25375 layer_factory.hpp:77] Creating layer h_t=5_encode2_unit_t=5_1_split
I1223 00:14:23.614137 25375 net.cpp:84] Creating Layer h_t=5_encode2_unit_t=5_1_split
I1223 00:14:23.614140 25375 net.cpp:406] h_t=5_encode2_unit_t=5_1_split <- h_t=5
I1223 00:14:23.614145 25375 net.cpp:380] h_t=5_encode2_unit_t=5_1_split -> h_t=5_encode2_unit_t=5_1_split_0
I1223 00:14:23.614152 25375 net.cpp:380] h_t=5_encode2_unit_t=5_1_split -> h_t=5_encode2_unit_t=5_1_split_1
I1223 00:14:23.614187 25375 net.cpp:122] Setting up h_t=5_encode2_unit_t=5_1_split
I1223 00:14:23.614194 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.614198 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.614202 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:23.614204 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=5
I1223 00:14:23.614209 25375 net.cpp:84] Creating Layer encode2_h_conted_t=5
I1223 00:14:23.614213 25375 net.cpp:406] encode2_h_conted_t=5 <- h_t=5_encode2_unit_t=5_1_split_0
I1223 00:14:23.614217 25375 net.cpp:406] encode2_h_conted_t=5 <- cont_t=6_encode2_cont_slice_5_split_0
I1223 00:14:23.614223 25375 net.cpp:380] encode2_h_conted_t=5 -> h_conted_t=5
I1223 00:14:23.614313 25375 net.cpp:122] Setting up encode2_h_conted_t=5
I1223 00:14:23.614321 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.614325 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:23.614327 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->5
I1223 00:14:23.614337 25375 net.cpp:84] Creating Layer encode2_hidden->transform->5
I1223 00:14:23.614342 25375 net.cpp:406] encode2_hidden->transform->5 <- h_conted_t=5
I1223 00:14:23.614362 25375 net.cpp:380] encode2_hidden->transform->5 -> hidden->transform->5
I1223 00:14:23.614886 25375 net.cpp:122] Setting up encode2_hidden->transform->5
I1223 00:14:23.614894 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.614897 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:23.614902 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.614920 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.614924 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=5
I1223 00:14:23.614929 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=5
I1223 00:14:23.614934 25375 net.cpp:406] encode2_hadamard->input_t=5 <- c_t=5_encode2_unit_t=5_0_split_0
I1223 00:14:23.614943 25375 net.cpp:380] encode2_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:23.615052 25375 net.cpp:122] Setting up encode2_hadamard->input_t=5
I1223 00:14:23.615059 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615062 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:23.615067 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.615069 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=5
I1223 00:14:23.615087 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=5
I1223 00:14:23.615092 25375 net.cpp:406] encode2_hadamard->forget_t=5 <- c_t=5_encode2_unit_t=5_0_split_1
I1223 00:14:23.615098 25375 net.cpp:380] encode2_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:23.615193 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=5
I1223 00:14:23.615200 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615205 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:23.615207 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.615211 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=5
I1223 00:14:23.615231 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=5
I1223 00:14:23.615234 25375 net.cpp:406] encode2_hadamard->output_t=5 <- c_t=5_encode2_unit_t=5_0_split_2
I1223 00:14:23.615242 25375 net.cpp:380] encode2_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:23.615341 25375 net.cpp:122] Setting up encode2_hadamard->output_t=5
I1223 00:14:23.615350 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615352 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:23.615358 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.615363 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=6
I1223 00:14:23.615370 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=6
I1223 00:14:23.615388 25375 net.cpp:380] encode2_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:23.615455 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=6
I1223 00:14:23.615463 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615465 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:23.615469 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=6
I1223 00:14:23.615474 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=6
I1223 00:14:23.615492 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:23.615497 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:23.615501 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:23.615505 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:23.615510 25375 net.cpp:380] encode2_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:23.615536 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=6
I1223 00:14:23.615556 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.615559 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:23.615562 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_6
I1223 00:14:23.615567 25375 net.cpp:84] Creating Layer encode2_gate_input_6
I1223 00:14:23.615571 25375 net.cpp:406] encode2_gate_input_6 <- hidden->transform->5
I1223 00:14:23.615576 25375 net.cpp:406] encode2_gate_input_6 <- x->transform->t=6
I1223 00:14:23.615581 25375 net.cpp:406] encode2_gate_input_6 <- hadamard_t=6
I1223 00:14:23.615602 25375 net.cpp:380] encode2_gate_input_6 -> gate_input_6
I1223 00:14:23.615627 25375 net.cpp:122] Setting up encode2_gate_input_6
I1223 00:14:23.615633 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.615635 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:23.615638 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=6
I1223 00:14:23.615644 25375 net.cpp:84] Creating Layer encode2_unit_t=6
I1223 00:14:23.615648 25375 net.cpp:406] encode2_unit_t=6 <- c_t=5_encode2_unit_t=5_0_split_3
I1223 00:14:23.615651 25375 net.cpp:406] encode2_unit_t=6 <- gate_input_6
I1223 00:14:23.615655 25375 net.cpp:406] encode2_unit_t=6 <- cont_t=6_encode2_cont_slice_5_split_1
I1223 00:14:23.615661 25375 net.cpp:380] encode2_unit_t=6 -> c_t=6
I1223 00:14:23.615669 25375 net.cpp:380] encode2_unit_t=6 -> h_t=6
I1223 00:14:23.615731 25375 net.cpp:122] Setting up encode2_unit_t=6
I1223 00:14:23.615738 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615756 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615759 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:23.615762 25375 layer_factory.hpp:77] Creating layer c_t=6_encode2_unit_t=6_0_split
I1223 00:14:23.615768 25375 net.cpp:84] Creating Layer c_t=6_encode2_unit_t=6_0_split
I1223 00:14:23.615773 25375 net.cpp:406] c_t=6_encode2_unit_t=6_0_split <- c_t=6
I1223 00:14:23.615780 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_0
I1223 00:14:23.615787 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_1
I1223 00:14:23.615794 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_2
I1223 00:14:23.615802 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_3
I1223 00:14:23.615864 25375 net.cpp:122] Setting up c_t=6_encode2_unit_t=6_0_split
I1223 00:14:23.615871 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615875 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615880 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615883 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615886 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:23.615890 25375 layer_factory.hpp:77] Creating layer h_t=6_encode2_unit_t=6_1_split
I1223 00:14:23.615895 25375 net.cpp:84] Creating Layer h_t=6_encode2_unit_t=6_1_split
I1223 00:14:23.615897 25375 net.cpp:406] h_t=6_encode2_unit_t=6_1_split <- h_t=6
I1223 00:14:23.615906 25375 net.cpp:380] h_t=6_encode2_unit_t=6_1_split -> h_t=6_encode2_unit_t=6_1_split_0
I1223 00:14:23.615914 25375 net.cpp:380] h_t=6_encode2_unit_t=6_1_split -> h_t=6_encode2_unit_t=6_1_split_1
I1223 00:14:23.615949 25375 net.cpp:122] Setting up h_t=6_encode2_unit_t=6_1_split
I1223 00:14:23.615955 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615959 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.615962 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:23.615965 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=6
I1223 00:14:23.615972 25375 net.cpp:84] Creating Layer encode2_h_conted_t=6
I1223 00:14:23.615978 25375 net.cpp:406] encode2_h_conted_t=6 <- h_t=6_encode2_unit_t=6_1_split_0
I1223 00:14:23.615981 25375 net.cpp:406] encode2_h_conted_t=6 <- cont_t=7_encode2_cont_slice_6_split_0
I1223 00:14:23.615988 25375 net.cpp:380] encode2_h_conted_t=6 -> h_conted_t=6
I1223 00:14:23.616066 25375 net.cpp:122] Setting up encode2_h_conted_t=6
I1223 00:14:23.616073 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.616076 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:23.616080 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->6
I1223 00:14:23.616089 25375 net.cpp:84] Creating Layer encode2_hidden->transform->6
I1223 00:14:23.616093 25375 net.cpp:406] encode2_hidden->transform->6 <- h_conted_t=6
I1223 00:14:23.616101 25375 net.cpp:380] encode2_hidden->transform->6 -> hidden->transform->6
I1223 00:14:23.616618 25375 net.cpp:122] Setting up encode2_hidden->transform->6
I1223 00:14:23.616627 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.616631 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:23.616634 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.616639 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.616642 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=6
I1223 00:14:23.616647 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=6
I1223 00:14:23.616652 25375 net.cpp:406] encode2_hadamard->input_t=6 <- c_t=6_encode2_unit_t=6_0_split_0
I1223 00:14:23.616657 25375 net.cpp:380] encode2_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:23.616753 25375 net.cpp:122] Setting up encode2_hadamard->input_t=6
I1223 00:14:23.616761 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.616765 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:23.616768 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.616771 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=6
I1223 00:14:23.616778 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=6
I1223 00:14:23.616783 25375 net.cpp:406] encode2_hadamard->forget_t=6 <- c_t=6_encode2_unit_t=6_0_split_1
I1223 00:14:23.616789 25375 net.cpp:380] encode2_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:23.616889 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=6
I1223 00:14:23.616896 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.616899 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:23.616904 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.616906 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=6
I1223 00:14:23.616926 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=6
I1223 00:14:23.616930 25375 net.cpp:406] encode2_hadamard->output_t=6 <- c_t=6_encode2_unit_t=6_0_split_2
I1223 00:14:23.616935 25375 net.cpp:380] encode2_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:23.617039 25375 net.cpp:122] Setting up encode2_hadamard->output_t=6
I1223 00:14:23.617046 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617048 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:23.617053 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.617055 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=7
I1223 00:14:23.617079 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=7
I1223 00:14:23.617085 25375 net.cpp:380] encode2_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:23.617141 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=7
I1223 00:14:23.617149 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617152 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:23.617156 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=7
I1223 00:14:23.617173 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=7
I1223 00:14:23.617177 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:23.617182 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:23.617187 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:23.617190 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:23.617197 25375 net.cpp:380] encode2_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:23.617221 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=7
I1223 00:14:23.617244 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.617249 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:23.617250 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_7
I1223 00:14:23.617255 25375 net.cpp:84] Creating Layer encode2_gate_input_7
I1223 00:14:23.617259 25375 net.cpp:406] encode2_gate_input_7 <- hidden->transform->6
I1223 00:14:23.617264 25375 net.cpp:406] encode2_gate_input_7 <- x->transform->t=7
I1223 00:14:23.617280 25375 net.cpp:406] encode2_gate_input_7 <- hadamard_t=7
I1223 00:14:23.617286 25375 net.cpp:380] encode2_gate_input_7 -> gate_input_7
I1223 00:14:23.617311 25375 net.cpp:122] Setting up encode2_gate_input_7
I1223 00:14:23.617317 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.617321 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:23.617323 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=7
I1223 00:14:23.617331 25375 net.cpp:84] Creating Layer encode2_unit_t=7
I1223 00:14:23.617334 25375 net.cpp:406] encode2_unit_t=7 <- c_t=6_encode2_unit_t=6_0_split_3
I1223 00:14:23.617339 25375 net.cpp:406] encode2_unit_t=7 <- gate_input_7
I1223 00:14:23.617343 25375 net.cpp:406] encode2_unit_t=7 <- cont_t=7_encode2_cont_slice_6_split_1
I1223 00:14:23.617348 25375 net.cpp:380] encode2_unit_t=7 -> c_t=7
I1223 00:14:23.617354 25375 net.cpp:380] encode2_unit_t=7 -> h_t=7
I1223 00:14:23.617408 25375 net.cpp:122] Setting up encode2_unit_t=7
I1223 00:14:23.617414 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617419 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617421 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:23.617424 25375 layer_factory.hpp:77] Creating layer c_t=7_encode2_unit_t=7_0_split
I1223 00:14:23.617429 25375 net.cpp:84] Creating Layer c_t=7_encode2_unit_t=7_0_split
I1223 00:14:23.617432 25375 net.cpp:406] c_t=7_encode2_unit_t=7_0_split <- c_t=7
I1223 00:14:23.617439 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_0
I1223 00:14:23.617446 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_1
I1223 00:14:23.617455 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_2
I1223 00:14:23.617462 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_3
I1223 00:14:23.617527 25375 net.cpp:122] Setting up c_t=7_encode2_unit_t=7_0_split
I1223 00:14:23.617534 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617538 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617542 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617547 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617548 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:23.617552 25375 layer_factory.hpp:77] Creating layer h_t=7_encode2_unit_t=7_1_split
I1223 00:14:23.617555 25375 net.cpp:84] Creating Layer h_t=7_encode2_unit_t=7_1_split
I1223 00:14:23.617559 25375 net.cpp:406] h_t=7_encode2_unit_t=7_1_split <- h_t=7
I1223 00:14:23.617566 25375 net.cpp:380] h_t=7_encode2_unit_t=7_1_split -> h_t=7_encode2_unit_t=7_1_split_0
I1223 00:14:23.617573 25375 net.cpp:380] h_t=7_encode2_unit_t=7_1_split -> h_t=7_encode2_unit_t=7_1_split_1
I1223 00:14:23.617609 25375 net.cpp:122] Setting up h_t=7_encode2_unit_t=7_1_split
I1223 00:14:23.617617 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617621 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617624 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:23.617627 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=7
I1223 00:14:23.617632 25375 net.cpp:84] Creating Layer encode2_h_conted_t=7
I1223 00:14:23.617635 25375 net.cpp:406] encode2_h_conted_t=7 <- h_t=7_encode2_unit_t=7_1_split_0
I1223 00:14:23.617640 25375 net.cpp:406] encode2_h_conted_t=7 <- cont_t=8_encode2_cont_slice_7_split_0
I1223 00:14:23.617645 25375 net.cpp:380] encode2_h_conted_t=7 -> h_conted_t=7
I1223 00:14:23.617727 25375 net.cpp:122] Setting up encode2_h_conted_t=7
I1223 00:14:23.617734 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.617738 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:23.617740 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->7
I1223 00:14:23.617748 25375 net.cpp:84] Creating Layer encode2_hidden->transform->7
I1223 00:14:23.617753 25375 net.cpp:406] encode2_hidden->transform->7 <- h_conted_t=7
I1223 00:14:23.617763 25375 net.cpp:380] encode2_hidden->transform->7 -> hidden->transform->7
I1223 00:14:23.618278 25375 net.cpp:122] Setting up encode2_hidden->transform->7
I1223 00:14:23.618288 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.618291 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:23.618294 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.618299 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.618302 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=7
I1223 00:14:23.618309 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=7
I1223 00:14:23.618312 25375 net.cpp:406] encode2_hadamard->input_t=7 <- c_t=7_encode2_unit_t=7_0_split_0
I1223 00:14:23.618319 25375 net.cpp:380] encode2_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:23.618422 25375 net.cpp:122] Setting up encode2_hadamard->input_t=7
I1223 00:14:23.618429 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.618432 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:23.618435 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.618439 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=7
I1223 00:14:23.618460 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=7
I1223 00:14:23.618464 25375 net.cpp:406] encode2_hadamard->forget_t=7 <- c_t=7_encode2_unit_t=7_0_split_1
I1223 00:14:23.618470 25375 net.cpp:380] encode2_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:23.618579 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=7
I1223 00:14:23.618588 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.618592 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:23.618594 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.618598 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=7
I1223 00:14:23.618604 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=7
I1223 00:14:23.618608 25375 net.cpp:406] encode2_hadamard->output_t=7 <- c_t=7_encode2_unit_t=7_0_split_2
I1223 00:14:23.618615 25375 net.cpp:380] encode2_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:23.618722 25375 net.cpp:122] Setting up encode2_hadamard->output_t=7
I1223 00:14:23.618729 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.618732 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:23.618736 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.618739 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=8
I1223 00:14:23.618758 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=8
I1223 00:14:23.618764 25375 net.cpp:380] encode2_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:23.618830 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=8
I1223 00:14:23.618839 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.618841 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:23.618844 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=8
I1223 00:14:23.618865 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=8
I1223 00:14:23.618870 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:23.618875 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:23.618878 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:23.618882 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:23.618888 25375 net.cpp:380] encode2_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:23.618912 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=8
I1223 00:14:23.618932 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.618935 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:23.618938 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_8
I1223 00:14:23.618943 25375 net.cpp:84] Creating Layer encode2_gate_input_8
I1223 00:14:23.618947 25375 net.cpp:406] encode2_gate_input_8 <- hidden->transform->7
I1223 00:14:23.618952 25375 net.cpp:406] encode2_gate_input_8 <- x->transform->t=8
I1223 00:14:23.618968 25375 net.cpp:406] encode2_gate_input_8 <- hadamard_t=8
I1223 00:14:23.618975 25375 net.cpp:380] encode2_gate_input_8 -> gate_input_8
I1223 00:14:23.619000 25375 net.cpp:122] Setting up encode2_gate_input_8
I1223 00:14:23.619006 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.619010 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:23.619014 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=8
I1223 00:14:23.619019 25375 net.cpp:84] Creating Layer encode2_unit_t=8
I1223 00:14:23.619021 25375 net.cpp:406] encode2_unit_t=8 <- c_t=7_encode2_unit_t=7_0_split_3
I1223 00:14:23.619025 25375 net.cpp:406] encode2_unit_t=8 <- gate_input_8
I1223 00:14:23.619029 25375 net.cpp:406] encode2_unit_t=8 <- cont_t=8_encode2_cont_slice_7_split_1
I1223 00:14:23.619037 25375 net.cpp:380] encode2_unit_t=8 -> c_t=8
I1223 00:14:23.619043 25375 net.cpp:380] encode2_unit_t=8 -> h_t=8
I1223 00:14:23.619096 25375 net.cpp:122] Setting up encode2_unit_t=8
I1223 00:14:23.619102 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619107 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619108 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:23.619112 25375 layer_factory.hpp:77] Creating layer c_t=8_encode2_unit_t=8_0_split
I1223 00:14:23.619117 25375 net.cpp:84] Creating Layer c_t=8_encode2_unit_t=8_0_split
I1223 00:14:23.619120 25375 net.cpp:406] c_t=8_encode2_unit_t=8_0_split <- c_t=8
I1223 00:14:23.619125 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_0
I1223 00:14:23.619134 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_1
I1223 00:14:23.619143 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_2
I1223 00:14:23.619149 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_3
I1223 00:14:23.619212 25375 net.cpp:122] Setting up c_t=8_encode2_unit_t=8_0_split
I1223 00:14:23.619220 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619225 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619228 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619231 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619235 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:23.619238 25375 layer_factory.hpp:77] Creating layer h_t=8_encode2_unit_t=8_1_split
I1223 00:14:23.619243 25375 net.cpp:84] Creating Layer h_t=8_encode2_unit_t=8_1_split
I1223 00:14:23.619247 25375 net.cpp:406] h_t=8_encode2_unit_t=8_1_split <- h_t=8
I1223 00:14:23.619252 25375 net.cpp:380] h_t=8_encode2_unit_t=8_1_split -> h_t=8_encode2_unit_t=8_1_split_0
I1223 00:14:23.619258 25375 net.cpp:380] h_t=8_encode2_unit_t=8_1_split -> h_t=8_encode2_unit_t=8_1_split_1
I1223 00:14:23.619293 25375 net.cpp:122] Setting up h_t=8_encode2_unit_t=8_1_split
I1223 00:14:23.619302 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619305 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619308 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:23.619312 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=8
I1223 00:14:23.619316 25375 net.cpp:84] Creating Layer encode2_h_conted_t=8
I1223 00:14:23.619320 25375 net.cpp:406] encode2_h_conted_t=8 <- h_t=8_encode2_unit_t=8_1_split_0
I1223 00:14:23.619324 25375 net.cpp:406] encode2_h_conted_t=8 <- cont_t=9_encode2_cont_slice_8_split_0
I1223 00:14:23.619331 25375 net.cpp:380] encode2_h_conted_t=8 -> h_conted_t=8
I1223 00:14:23.619410 25375 net.cpp:122] Setting up encode2_h_conted_t=8
I1223 00:14:23.619418 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.619421 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:23.619424 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->8
I1223 00:14:23.619433 25375 net.cpp:84] Creating Layer encode2_hidden->transform->8
I1223 00:14:23.619438 25375 net.cpp:406] encode2_hidden->transform->8 <- h_conted_t=8
I1223 00:14:23.619446 25375 net.cpp:380] encode2_hidden->transform->8 -> hidden->transform->8
I1223 00:14:23.619953 25375 net.cpp:122] Setting up encode2_hidden->transform->8
I1223 00:14:23.619962 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.619966 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:23.619969 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.619974 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.619977 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=8
I1223 00:14:23.619983 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=8
I1223 00:14:23.619987 25375 net.cpp:406] encode2_hadamard->input_t=8 <- c_t=8_encode2_unit_t=8_0_split_0
I1223 00:14:23.619994 25375 net.cpp:380] encode2_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:23.620095 25375 net.cpp:122] Setting up encode2_hadamard->input_t=8
I1223 00:14:23.620102 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620105 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:23.620110 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.620112 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=8
I1223 00:14:23.620118 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=8
I1223 00:14:23.620121 25375 net.cpp:406] encode2_hadamard->forget_t=8 <- c_t=8_encode2_unit_t=8_0_split_1
I1223 00:14:23.620128 25375 net.cpp:380] encode2_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:23.620240 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=8
I1223 00:14:23.620249 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620250 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:23.620254 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.620257 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=8
I1223 00:14:23.620277 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=8
I1223 00:14:23.620281 25375 net.cpp:406] encode2_hadamard->output_t=8 <- c_t=8_encode2_unit_t=8_0_split_2
I1223 00:14:23.620286 25375 net.cpp:380] encode2_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:23.620383 25375 net.cpp:122] Setting up encode2_hadamard->output_t=8
I1223 00:14:23.620391 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620394 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:23.620398 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.620400 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=9
I1223 00:14:23.620406 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=9
I1223 00:14:23.620412 25375 net.cpp:380] encode2_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:23.620478 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=9
I1223 00:14:23.620499 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620502 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:23.620506 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=9
I1223 00:14:23.620512 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=9
I1223 00:14:23.620517 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:23.620522 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:23.620539 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:23.620543 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:23.620548 25375 net.cpp:380] encode2_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:23.620573 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=9
I1223 00:14:23.620579 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.620582 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:23.620585 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_9
I1223 00:14:23.620604 25375 net.cpp:84] Creating Layer encode2_gate_input_9
I1223 00:14:23.620607 25375 net.cpp:406] encode2_gate_input_9 <- hidden->transform->8
I1223 00:14:23.620626 25375 net.cpp:406] encode2_gate_input_9 <- x->transform->t=9
I1223 00:14:23.620630 25375 net.cpp:406] encode2_gate_input_9 <- hadamard_t=9
I1223 00:14:23.620635 25375 net.cpp:380] encode2_gate_input_9 -> gate_input_9
I1223 00:14:23.620661 25375 net.cpp:122] Setting up encode2_gate_input_9
I1223 00:14:23.620666 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.620669 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:23.620673 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=9
I1223 00:14:23.620677 25375 net.cpp:84] Creating Layer encode2_unit_t=9
I1223 00:14:23.620682 25375 net.cpp:406] encode2_unit_t=9 <- c_t=8_encode2_unit_t=8_0_split_3
I1223 00:14:23.620685 25375 net.cpp:406] encode2_unit_t=9 <- gate_input_9
I1223 00:14:23.620690 25375 net.cpp:406] encode2_unit_t=9 <- cont_t=9_encode2_cont_slice_8_split_1
I1223 00:14:23.620697 25375 net.cpp:380] encode2_unit_t=9 -> c_t=9
I1223 00:14:23.620704 25375 net.cpp:380] encode2_unit_t=9 -> h_t=9
I1223 00:14:23.620756 25375 net.cpp:122] Setting up encode2_unit_t=9
I1223 00:14:23.620764 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620767 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620770 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:23.620774 25375 layer_factory.hpp:77] Creating layer c_t=9_encode2_unit_t=9_0_split
I1223 00:14:23.620779 25375 net.cpp:84] Creating Layer c_t=9_encode2_unit_t=9_0_split
I1223 00:14:23.620782 25375 net.cpp:406] c_t=9_encode2_unit_t=9_0_split <- c_t=9
I1223 00:14:23.620788 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_0
I1223 00:14:23.620795 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_1
I1223 00:14:23.620803 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_2
I1223 00:14:23.620810 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_3
I1223 00:14:23.620873 25375 net.cpp:122] Setting up c_t=9_encode2_unit_t=9_0_split
I1223 00:14:23.620880 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620885 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620889 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620893 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620895 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:23.620898 25375 layer_factory.hpp:77] Creating layer h_t=9_encode2_unit_t=9_1_split
I1223 00:14:23.620903 25375 net.cpp:84] Creating Layer h_t=9_encode2_unit_t=9_1_split
I1223 00:14:23.620906 25375 net.cpp:406] h_t=9_encode2_unit_t=9_1_split <- h_t=9
I1223 00:14:23.620911 25375 net.cpp:380] h_t=9_encode2_unit_t=9_1_split -> h_t=9_encode2_unit_t=9_1_split_0
I1223 00:14:23.620918 25375 net.cpp:380] h_t=9_encode2_unit_t=9_1_split -> h_t=9_encode2_unit_t=9_1_split_1
I1223 00:14:23.620954 25375 net.cpp:122] Setting up h_t=9_encode2_unit_t=9_1_split
I1223 00:14:23.620959 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620964 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.620966 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:23.620970 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=9
I1223 00:14:23.620975 25375 net.cpp:84] Creating Layer encode2_h_conted_t=9
I1223 00:14:23.620978 25375 net.cpp:406] encode2_h_conted_t=9 <- h_t=9_encode2_unit_t=9_1_split_0
I1223 00:14:23.620983 25375 net.cpp:406] encode2_h_conted_t=9 <- cont_t=10_encode2_cont_slice_9_split_0
I1223 00:14:23.620990 25375 net.cpp:380] encode2_h_conted_t=9 -> h_conted_t=9
I1223 00:14:23.621074 25375 net.cpp:122] Setting up encode2_h_conted_t=9
I1223 00:14:23.621083 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.621085 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:23.621088 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->9
I1223 00:14:23.621098 25375 net.cpp:84] Creating Layer encode2_hidden->transform->9
I1223 00:14:23.621103 25375 net.cpp:406] encode2_hidden->transform->9 <- h_conted_t=9
I1223 00:14:23.621110 25375 net.cpp:380] encode2_hidden->transform->9 -> hidden->transform->9
I1223 00:14:23.622370 25375 net.cpp:122] Setting up encode2_hidden->transform->9
I1223 00:14:23.622382 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.622385 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:23.622390 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.622393 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.622397 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=9
I1223 00:14:23.622403 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=9
I1223 00:14:23.622407 25375 net.cpp:406] encode2_hadamard->input_t=9 <- c_t=9_encode2_unit_t=9_0_split_0
I1223 00:14:23.622414 25375 net.cpp:380] encode2_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:23.622529 25375 net.cpp:122] Setting up encode2_hadamard->input_t=9
I1223 00:14:23.622535 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.622539 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:23.622542 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.622546 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=9
I1223 00:14:23.622565 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=9
I1223 00:14:23.622568 25375 net.cpp:406] encode2_hadamard->forget_t=9 <- c_t=9_encode2_unit_t=9_0_split_1
I1223 00:14:23.622577 25375 net.cpp:380] encode2_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:23.622680 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=9
I1223 00:14:23.622689 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.622692 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:23.622695 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.622714 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=9
I1223 00:14:23.622717 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=9
I1223 00:14:23.622735 25375 net.cpp:406] encode2_hadamard->output_t=9 <- c_t=9_encode2_unit_t=9_0_split_2
I1223 00:14:23.622742 25375 net.cpp:380] encode2_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:23.622848 25375 net.cpp:122] Setting up encode2_hadamard->output_t=9
I1223 00:14:23.622856 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.622859 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:23.622864 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.622879 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=10
I1223 00:14:23.622889 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=10
I1223 00:14:23.622895 25375 net.cpp:380] encode2_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:23.622961 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=10
I1223 00:14:23.622968 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.622972 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:23.622975 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=10
I1223 00:14:23.622993 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=10
I1223 00:14:23.622997 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:23.623001 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:23.623006 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:23.623010 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:23.623015 25375 net.cpp:380] encode2_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:23.623055 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=10
I1223 00:14:23.623062 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.623065 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:23.623069 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_10
I1223 00:14:23.623073 25375 net.cpp:84] Creating Layer encode2_gate_input_10
I1223 00:14:23.623077 25375 net.cpp:406] encode2_gate_input_10 <- hidden->transform->9
I1223 00:14:23.623081 25375 net.cpp:406] encode2_gate_input_10 <- x->transform->t=10
I1223 00:14:23.623085 25375 net.cpp:406] encode2_gate_input_10 <- hadamard_t=10
I1223 00:14:23.623090 25375 net.cpp:380] encode2_gate_input_10 -> gate_input_10
I1223 00:14:23.623117 25375 net.cpp:122] Setting up encode2_gate_input_10
I1223 00:14:23.623124 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.623127 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:23.623131 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=10
I1223 00:14:23.623136 25375 net.cpp:84] Creating Layer encode2_unit_t=10
I1223 00:14:23.623139 25375 net.cpp:406] encode2_unit_t=10 <- c_t=9_encode2_unit_t=9_0_split_3
I1223 00:14:23.623143 25375 net.cpp:406] encode2_unit_t=10 <- gate_input_10
I1223 00:14:23.623147 25375 net.cpp:406] encode2_unit_t=10 <- cont_t=10_encode2_cont_slice_9_split_1
I1223 00:14:23.623153 25375 net.cpp:380] encode2_unit_t=10 -> c_t=10
I1223 00:14:23.623159 25375 net.cpp:380] encode2_unit_t=10 -> h_t=10
I1223 00:14:23.623227 25375 net.cpp:122] Setting up encode2_unit_t=10
I1223 00:14:23.623234 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623239 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623241 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:23.623257 25375 layer_factory.hpp:77] Creating layer c_t=10_encode2_unit_t=10_0_split
I1223 00:14:23.623265 25375 net.cpp:84] Creating Layer c_t=10_encode2_unit_t=10_0_split
I1223 00:14:23.623267 25375 net.cpp:406] c_t=10_encode2_unit_t=10_0_split <- c_t=10
I1223 00:14:23.623273 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_0
I1223 00:14:23.623280 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_1
I1223 00:14:23.623286 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_2
I1223 00:14:23.623292 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_3
I1223 00:14:23.623373 25375 net.cpp:122] Setting up c_t=10_encode2_unit_t=10_0_split
I1223 00:14:23.623379 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623383 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623387 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623391 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623394 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:23.623397 25375 layer_factory.hpp:77] Creating layer h_t=10_encode2_unit_t=10_1_split
I1223 00:14:23.623415 25375 net.cpp:84] Creating Layer h_t=10_encode2_unit_t=10_1_split
I1223 00:14:23.623419 25375 net.cpp:406] h_t=10_encode2_unit_t=10_1_split <- h_t=10
I1223 00:14:23.623425 25375 net.cpp:380] h_t=10_encode2_unit_t=10_1_split -> h_t=10_encode2_unit_t=10_1_split_0
I1223 00:14:23.623431 25375 net.cpp:380] h_t=10_encode2_unit_t=10_1_split -> h_t=10_encode2_unit_t=10_1_split_1
I1223 00:14:23.623481 25375 net.cpp:122] Setting up h_t=10_encode2_unit_t=10_1_split
I1223 00:14:23.623487 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623492 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623494 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:23.623497 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=10
I1223 00:14:23.623504 25375 net.cpp:84] Creating Layer encode2_h_conted_t=10
I1223 00:14:23.623522 25375 net.cpp:406] encode2_h_conted_t=10 <- h_t=10_encode2_unit_t=10_1_split_0
I1223 00:14:23.623527 25375 net.cpp:406] encode2_h_conted_t=10 <- cont_t=11_encode2_cont_slice_10_split_0
I1223 00:14:23.623533 25375 net.cpp:380] encode2_h_conted_t=10 -> h_conted_t=10
I1223 00:14:23.623625 25375 net.cpp:122] Setting up encode2_h_conted_t=10
I1223 00:14:23.623632 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.623636 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:23.623638 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->10
I1223 00:14:23.623646 25375 net.cpp:84] Creating Layer encode2_hidden->transform->10
I1223 00:14:23.623651 25375 net.cpp:406] encode2_hidden->transform->10 <- h_conted_t=10
I1223 00:14:23.623659 25375 net.cpp:380] encode2_hidden->transform->10 -> hidden->transform->10
I1223 00:14:23.624192 25375 net.cpp:122] Setting up encode2_hidden->transform->10
I1223 00:14:23.624202 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.624204 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:23.624208 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.624212 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.624217 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=10
I1223 00:14:23.624222 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=10
I1223 00:14:23.624225 25375 net.cpp:406] encode2_hadamard->input_t=10 <- c_t=10_encode2_unit_t=10_0_split_0
I1223 00:14:23.624231 25375 net.cpp:380] encode2_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:23.624335 25375 net.cpp:122] Setting up encode2_hadamard->input_t=10
I1223 00:14:23.624341 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.624344 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:23.624348 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.624351 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=10
I1223 00:14:23.624372 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=10
I1223 00:14:23.624374 25375 net.cpp:406] encode2_hadamard->forget_t=10 <- c_t=10_encode2_unit_t=10_0_split_1
I1223 00:14:23.624394 25375 net.cpp:380] encode2_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:23.624490 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=10
I1223 00:14:23.624497 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.624500 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:23.624505 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.624507 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=10
I1223 00:14:23.624513 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=10
I1223 00:14:23.624516 25375 net.cpp:406] encode2_hadamard->output_t=10 <- c_t=10_encode2_unit_t=10_0_split_2
I1223 00:14:23.624522 25375 net.cpp:380] encode2_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:23.624615 25375 net.cpp:122] Setting up encode2_hadamard->output_t=10
I1223 00:14:23.624622 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.624625 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:23.624629 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.624632 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=11
I1223 00:14:23.624639 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=11
I1223 00:14:23.624642 25375 net.cpp:380] encode2_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:23.624696 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=11
I1223 00:14:23.624704 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.624707 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:23.624711 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=11
I1223 00:14:23.624716 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=11
I1223 00:14:23.624719 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:23.624723 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:23.624728 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:23.624732 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:23.624739 25375 net.cpp:380] encode2_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:23.624765 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=11
I1223 00:14:23.624773 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.624775 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:23.624778 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_11
I1223 00:14:23.624783 25375 net.cpp:84] Creating Layer encode2_gate_input_11
I1223 00:14:23.624788 25375 net.cpp:406] encode2_gate_input_11 <- hidden->transform->10
I1223 00:14:23.624791 25375 net.cpp:406] encode2_gate_input_11 <- x->transform->t=11
I1223 00:14:23.624796 25375 net.cpp:406] encode2_gate_input_11 <- hadamard_t=11
I1223 00:14:23.624802 25375 net.cpp:380] encode2_gate_input_11 -> gate_input_11
I1223 00:14:23.624827 25375 net.cpp:122] Setting up encode2_gate_input_11
I1223 00:14:23.624835 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.624838 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:23.624841 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=11
I1223 00:14:23.624861 25375 net.cpp:84] Creating Layer encode2_unit_t=11
I1223 00:14:23.624864 25375 net.cpp:406] encode2_unit_t=11 <- c_t=10_encode2_unit_t=10_0_split_3
I1223 00:14:23.624881 25375 net.cpp:406] encode2_unit_t=11 <- gate_input_11
I1223 00:14:23.624886 25375 net.cpp:406] encode2_unit_t=11 <- cont_t=11_encode2_cont_slice_10_split_1
I1223 00:14:23.624891 25375 net.cpp:380] encode2_unit_t=11 -> c_t=11
I1223 00:14:23.624897 25375 net.cpp:380] encode2_unit_t=11 -> h_t=11
I1223 00:14:23.624966 25375 net.cpp:122] Setting up encode2_unit_t=11
I1223 00:14:23.624974 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.624977 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.624980 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:23.624984 25375 layer_factory.hpp:77] Creating layer c_t=11_encode2_unit_t=11_0_split
I1223 00:14:23.624990 25375 net.cpp:84] Creating Layer c_t=11_encode2_unit_t=11_0_split
I1223 00:14:23.624995 25375 net.cpp:406] c_t=11_encode2_unit_t=11_0_split <- c_t=11
I1223 00:14:23.625000 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_0
I1223 00:14:23.625007 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_1
I1223 00:14:23.625015 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_2
I1223 00:14:23.625021 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_3
I1223 00:14:23.625102 25375 net.cpp:122] Setting up c_t=11_encode2_unit_t=11_0_split
I1223 00:14:23.625109 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625113 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625116 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625120 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625123 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:23.625126 25375 layer_factory.hpp:77] Creating layer h_t=11_encode2_unit_t=11_1_split
I1223 00:14:23.625131 25375 net.cpp:84] Creating Layer h_t=11_encode2_unit_t=11_1_split
I1223 00:14:23.625135 25375 net.cpp:406] h_t=11_encode2_unit_t=11_1_split <- h_t=11
I1223 00:14:23.625140 25375 net.cpp:380] h_t=11_encode2_unit_t=11_1_split -> h_t=11_encode2_unit_t=11_1_split_0
I1223 00:14:23.625146 25375 net.cpp:380] h_t=11_encode2_unit_t=11_1_split -> h_t=11_encode2_unit_t=11_1_split_1
I1223 00:14:23.625181 25375 net.cpp:122] Setting up h_t=11_encode2_unit_t=11_1_split
I1223 00:14:23.625188 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625192 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625195 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:23.625197 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=11
I1223 00:14:23.625203 25375 net.cpp:84] Creating Layer encode2_h_conted_t=11
I1223 00:14:23.625206 25375 net.cpp:406] encode2_h_conted_t=11 <- h_t=11_encode2_unit_t=11_1_split_0
I1223 00:14:23.625211 25375 net.cpp:406] encode2_h_conted_t=11 <- cont_t=12_encode2_cont_slice_11_split_0
I1223 00:14:23.625216 25375 net.cpp:380] encode2_h_conted_t=11 -> h_conted_t=11
I1223 00:14:23.625293 25375 net.cpp:122] Setting up encode2_h_conted_t=11
I1223 00:14:23.625300 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625303 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:23.625305 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->11
I1223 00:14:23.625315 25375 net.cpp:84] Creating Layer encode2_hidden->transform->11
I1223 00:14:23.625319 25375 net.cpp:406] encode2_hidden->transform->11 <- h_conted_t=11
I1223 00:14:23.625325 25375 net.cpp:380] encode2_hidden->transform->11 -> hidden->transform->11
I1223 00:14:23.625829 25375 net.cpp:122] Setting up encode2_hidden->transform->11
I1223 00:14:23.625838 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.625840 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:23.625844 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.625847 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.625851 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=11
I1223 00:14:23.625856 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=11
I1223 00:14:23.625859 25375 net.cpp:406] encode2_hadamard->input_t=11 <- c_t=11_encode2_unit_t=11_0_split_0
I1223 00:14:23.625866 25375 net.cpp:380] encode2_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:23.625970 25375 net.cpp:122] Setting up encode2_hadamard->input_t=11
I1223 00:14:23.625977 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.625980 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:23.625984 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.625988 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=11
I1223 00:14:23.626006 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=11
I1223 00:14:23.626010 25375 net.cpp:406] encode2_hadamard->forget_t=11 <- c_t=11_encode2_unit_t=11_0_split_1
I1223 00:14:23.626015 25375 net.cpp:380] encode2_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:23.626118 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=11
I1223 00:14:23.626125 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626128 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:23.626132 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.626135 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=11
I1223 00:14:23.626153 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=11
I1223 00:14:23.626157 25375 net.cpp:406] encode2_hadamard->output_t=11 <- c_t=11_encode2_unit_t=11_0_split_2
I1223 00:14:23.626161 25375 net.cpp:380] encode2_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:23.626276 25375 net.cpp:122] Setting up encode2_hadamard->output_t=11
I1223 00:14:23.626283 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626286 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:23.626291 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.626293 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=12
I1223 00:14:23.626299 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=12
I1223 00:14:23.626303 25375 net.cpp:380] encode2_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:23.626356 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=12
I1223 00:14:23.626364 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626368 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:23.626370 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=12
I1223 00:14:23.626375 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=12
I1223 00:14:23.626394 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:23.626399 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:23.626401 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:23.626405 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:23.626410 25375 net.cpp:380] encode2_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:23.626435 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=12
I1223 00:14:23.626456 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.626458 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:23.626461 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_12
I1223 00:14:23.626467 25375 net.cpp:84] Creating Layer encode2_gate_input_12
I1223 00:14:23.626472 25375 net.cpp:406] encode2_gate_input_12 <- hidden->transform->11
I1223 00:14:23.626477 25375 net.cpp:406] encode2_gate_input_12 <- x->transform->t=12
I1223 00:14:23.626480 25375 net.cpp:406] encode2_gate_input_12 <- hadamard_t=12
I1223 00:14:23.626500 25375 net.cpp:380] encode2_gate_input_12 -> gate_input_12
I1223 00:14:23.626533 25375 net.cpp:122] Setting up encode2_gate_input_12
I1223 00:14:23.626539 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.626543 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:23.626545 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=12
I1223 00:14:23.626564 25375 net.cpp:84] Creating Layer encode2_unit_t=12
I1223 00:14:23.626569 25375 net.cpp:406] encode2_unit_t=12 <- c_t=11_encode2_unit_t=11_0_split_3
I1223 00:14:23.626586 25375 net.cpp:406] encode2_unit_t=12 <- gate_input_12
I1223 00:14:23.626590 25375 net.cpp:406] encode2_unit_t=12 <- cont_t=12_encode2_cont_slice_11_split_1
I1223 00:14:23.626595 25375 net.cpp:380] encode2_unit_t=12 -> c_t=12
I1223 00:14:23.626601 25375 net.cpp:380] encode2_unit_t=12 -> h_t=12
I1223 00:14:23.626648 25375 net.cpp:122] Setting up encode2_unit_t=12
I1223 00:14:23.626655 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626659 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626662 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:23.626664 25375 layer_factory.hpp:77] Creating layer c_t=12_encode2_unit_t=12_0_split
I1223 00:14:23.626669 25375 net.cpp:84] Creating Layer c_t=12_encode2_unit_t=12_0_split
I1223 00:14:23.626672 25375 net.cpp:406] c_t=12_encode2_unit_t=12_0_split <- c_t=12
I1223 00:14:23.626678 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_0
I1223 00:14:23.626684 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_1
I1223 00:14:23.626691 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_2
I1223 00:14:23.626698 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_3
I1223 00:14:23.626761 25375 net.cpp:122] Setting up c_t=12_encode2_unit_t=12_0_split
I1223 00:14:23.626767 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626772 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626776 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626780 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626782 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:23.626785 25375 layer_factory.hpp:77] Creating layer h_t=12_encode2_unit_t=12_1_split
I1223 00:14:23.626790 25375 net.cpp:84] Creating Layer h_t=12_encode2_unit_t=12_1_split
I1223 00:14:23.626792 25375 net.cpp:406] h_t=12_encode2_unit_t=12_1_split <- h_t=12
I1223 00:14:23.626798 25375 net.cpp:380] h_t=12_encode2_unit_t=12_1_split -> h_t=12_encode2_unit_t=12_1_split_0
I1223 00:14:23.626806 25375 net.cpp:380] h_t=12_encode2_unit_t=12_1_split -> h_t=12_encode2_unit_t=12_1_split_1
I1223 00:14:23.626842 25375 net.cpp:122] Setting up h_t=12_encode2_unit_t=12_1_split
I1223 00:14:23.626847 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626852 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626854 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:23.626857 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=12
I1223 00:14:23.626864 25375 net.cpp:84] Creating Layer encode2_h_conted_t=12
I1223 00:14:23.626868 25375 net.cpp:406] encode2_h_conted_t=12 <- h_t=12_encode2_unit_t=12_1_split_0
I1223 00:14:23.626873 25375 net.cpp:406] encode2_h_conted_t=12 <- cont_t=13_encode2_cont_slice_12_split_0
I1223 00:14:23.626878 25375 net.cpp:380] encode2_h_conted_t=12 -> h_conted_t=12
I1223 00:14:23.626958 25375 net.cpp:122] Setting up encode2_h_conted_t=12
I1223 00:14:23.626965 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.626968 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:23.626971 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->12
I1223 00:14:23.626981 25375 net.cpp:84] Creating Layer encode2_hidden->transform->12
I1223 00:14:23.626986 25375 net.cpp:406] encode2_hidden->transform->12 <- h_conted_t=12
I1223 00:14:23.626992 25375 net.cpp:380] encode2_hidden->transform->12 -> hidden->transform->12
I1223 00:14:23.627501 25375 net.cpp:122] Setting up encode2_hidden->transform->12
I1223 00:14:23.627508 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.627511 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:23.627516 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.627522 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.627527 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=12
I1223 00:14:23.627533 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=12
I1223 00:14:23.627537 25375 net.cpp:406] encode2_hadamard->input_t=12 <- c_t=12_encode2_unit_t=12_0_split_0
I1223 00:14:23.627544 25375 net.cpp:380] encode2_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:23.627637 25375 net.cpp:122] Setting up encode2_hadamard->input_t=12
I1223 00:14:23.627646 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.627650 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:23.627653 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.627656 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=12
I1223 00:14:23.627661 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=12
I1223 00:14:23.627665 25375 net.cpp:406] encode2_hadamard->forget_t=12 <- c_t=12_encode2_unit_t=12_0_split_1
I1223 00:14:23.627671 25375 net.cpp:380] encode2_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:23.627764 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=12
I1223 00:14:23.627773 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.627775 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:23.627779 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.627782 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=12
I1223 00:14:23.627787 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=12
I1223 00:14:23.627790 25375 net.cpp:406] encode2_hadamard->output_t=12 <- c_t=12_encode2_unit_t=12_0_split_2
I1223 00:14:23.627797 25375 net.cpp:380] encode2_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:23.627887 25375 net.cpp:122] Setting up encode2_hadamard->output_t=12
I1223 00:14:23.627894 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.627897 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:23.627902 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.627904 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=13
I1223 00:14:23.627909 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=13
I1223 00:14:23.627915 25375 net.cpp:380] encode2_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:23.627967 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=13
I1223 00:14:23.627974 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.627976 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:23.627980 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=13
I1223 00:14:23.627987 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=13
I1223 00:14:23.627990 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:23.627995 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:23.628000 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:23.628003 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:23.628008 25375 net.cpp:380] encode2_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:23.628031 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=13
I1223 00:14:23.628038 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.628041 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:23.628044 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_13
I1223 00:14:23.628049 25375 net.cpp:84] Creating Layer encode2_gate_input_13
I1223 00:14:23.628053 25375 net.cpp:406] encode2_gate_input_13 <- hidden->transform->12
I1223 00:14:23.628057 25375 net.cpp:406] encode2_gate_input_13 <- x->transform->t=13
I1223 00:14:23.628060 25375 net.cpp:406] encode2_gate_input_13 <- hadamard_t=13
I1223 00:14:23.628067 25375 net.cpp:380] encode2_gate_input_13 -> gate_input_13
I1223 00:14:23.628093 25375 net.cpp:122] Setting up encode2_gate_input_13
I1223 00:14:23.628098 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.628101 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:23.628103 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=13
I1223 00:14:23.628108 25375 net.cpp:84] Creating Layer encode2_unit_t=13
I1223 00:14:23.628113 25375 net.cpp:406] encode2_unit_t=13 <- c_t=12_encode2_unit_t=12_0_split_3
I1223 00:14:23.628116 25375 net.cpp:406] encode2_unit_t=13 <- gate_input_13
I1223 00:14:23.628120 25375 net.cpp:406] encode2_unit_t=13 <- cont_t=13_encode2_cont_slice_12_split_1
I1223 00:14:23.628127 25375 net.cpp:380] encode2_unit_t=13 -> c_t=13
I1223 00:14:23.628134 25375 net.cpp:380] encode2_unit_t=13 -> h_t=13
I1223 00:14:23.628185 25375 net.cpp:122] Setting up encode2_unit_t=13
I1223 00:14:23.628192 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628196 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628199 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:23.628202 25375 layer_factory.hpp:77] Creating layer c_t=13_encode2_unit_t=13_0_split
I1223 00:14:23.628207 25375 net.cpp:84] Creating Layer c_t=13_encode2_unit_t=13_0_split
I1223 00:14:23.628211 25375 net.cpp:406] c_t=13_encode2_unit_t=13_0_split <- c_t=13
I1223 00:14:23.628217 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_0
I1223 00:14:23.628223 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_1
I1223 00:14:23.628229 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_2
I1223 00:14:23.628235 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_3
I1223 00:14:23.628294 25375 net.cpp:122] Setting up c_t=13_encode2_unit_t=13_0_split
I1223 00:14:23.628300 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628304 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628309 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628312 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628315 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:23.628317 25375 layer_factory.hpp:77] Creating layer h_t=13_encode2_unit_t=13_1_split
I1223 00:14:23.628324 25375 net.cpp:84] Creating Layer h_t=13_encode2_unit_t=13_1_split
I1223 00:14:23.628327 25375 net.cpp:406] h_t=13_encode2_unit_t=13_1_split <- h_t=13
I1223 00:14:23.628331 25375 net.cpp:380] h_t=13_encode2_unit_t=13_1_split -> h_t=13_encode2_unit_t=13_1_split_0
I1223 00:14:23.628337 25375 net.cpp:380] h_t=13_encode2_unit_t=13_1_split -> h_t=13_encode2_unit_t=13_1_split_1
I1223 00:14:23.628376 25375 net.cpp:122] Setting up h_t=13_encode2_unit_t=13_1_split
I1223 00:14:23.628382 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628386 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628389 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:23.628392 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=13
I1223 00:14:23.628397 25375 net.cpp:84] Creating Layer encode2_h_conted_t=13
I1223 00:14:23.628401 25375 net.cpp:406] encode2_h_conted_t=13 <- h_t=13_encode2_unit_t=13_1_split_0
I1223 00:14:23.628406 25375 net.cpp:406] encode2_h_conted_t=13 <- cont_t=14_encode2_cont_slice_13_split_0
I1223 00:14:23.628412 25375 net.cpp:380] encode2_h_conted_t=13 -> h_conted_t=13
I1223 00:14:23.628489 25375 net.cpp:122] Setting up encode2_h_conted_t=13
I1223 00:14:23.628496 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.628499 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:23.628502 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->13
I1223 00:14:23.628511 25375 net.cpp:84] Creating Layer encode2_hidden->transform->13
I1223 00:14:23.628515 25375 net.cpp:406] encode2_hidden->transform->13 <- h_conted_t=13
I1223 00:14:23.628522 25375 net.cpp:380] encode2_hidden->transform->13 -> hidden->transform->13
I1223 00:14:23.629029 25375 net.cpp:122] Setting up encode2_hidden->transform->13
I1223 00:14:23.629036 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.629040 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:23.629043 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.629047 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.629050 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=13
I1223 00:14:23.629057 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=13
I1223 00:14:23.629061 25375 net.cpp:406] encode2_hadamard->input_t=13 <- c_t=13_encode2_unit_t=13_0_split_0
I1223 00:14:23.629073 25375 net.cpp:380] encode2_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:23.629168 25375 net.cpp:122] Setting up encode2_hadamard->input_t=13
I1223 00:14:23.629176 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629179 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:23.629182 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.629186 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=13
I1223 00:14:23.629192 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=13
I1223 00:14:23.629195 25375 net.cpp:406] encode2_hadamard->forget_t=13 <- c_t=13_encode2_unit_t=13_0_split_1
I1223 00:14:23.629202 25375 net.cpp:380] encode2_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:23.629294 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=13
I1223 00:14:23.629302 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629304 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:23.629312 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.629314 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=13
I1223 00:14:23.629320 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=13
I1223 00:14:23.629324 25375 net.cpp:406] encode2_hadamard->output_t=13 <- c_t=13_encode2_unit_t=13_0_split_2
I1223 00:14:23.629329 25375 net.cpp:380] encode2_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:23.629418 25375 net.cpp:122] Setting up encode2_hadamard->output_t=13
I1223 00:14:23.629426 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629428 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:23.629432 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.629436 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=14
I1223 00:14:23.629441 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=14
I1223 00:14:23.629446 25375 net.cpp:380] encode2_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:23.629500 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=14
I1223 00:14:23.629508 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629510 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:23.629513 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=14
I1223 00:14:23.629518 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=14
I1223 00:14:23.629523 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:23.629526 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:23.629530 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:23.629534 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:23.629539 25375 net.cpp:380] encode2_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:23.629565 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=14
I1223 00:14:23.629570 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.629573 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:23.629576 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_14
I1223 00:14:23.629581 25375 net.cpp:84] Creating Layer encode2_gate_input_14
I1223 00:14:23.629586 25375 net.cpp:406] encode2_gate_input_14 <- hidden->transform->13
I1223 00:14:23.629590 25375 net.cpp:406] encode2_gate_input_14 <- x->transform->t=14
I1223 00:14:23.629595 25375 net.cpp:406] encode2_gate_input_14 <- hadamard_t=14
I1223 00:14:23.629600 25375 net.cpp:380] encode2_gate_input_14 -> gate_input_14
I1223 00:14:23.629623 25375 net.cpp:122] Setting up encode2_gate_input_14
I1223 00:14:23.629629 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.629632 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:23.629636 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=14
I1223 00:14:23.629640 25375 net.cpp:84] Creating Layer encode2_unit_t=14
I1223 00:14:23.629643 25375 net.cpp:406] encode2_unit_t=14 <- c_t=13_encode2_unit_t=13_0_split_3
I1223 00:14:23.629648 25375 net.cpp:406] encode2_unit_t=14 <- gate_input_14
I1223 00:14:23.629652 25375 net.cpp:406] encode2_unit_t=14 <- cont_t=14_encode2_cont_slice_13_split_1
I1223 00:14:23.629657 25375 net.cpp:380] encode2_unit_t=14 -> c_t=14
I1223 00:14:23.629662 25375 net.cpp:380] encode2_unit_t=14 -> h_t=14
I1223 00:14:23.629711 25375 net.cpp:122] Setting up encode2_unit_t=14
I1223 00:14:23.629719 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629722 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629725 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:23.629727 25375 layer_factory.hpp:77] Creating layer c_t=14_encode2_unit_t=14_0_split
I1223 00:14:23.629734 25375 net.cpp:84] Creating Layer c_t=14_encode2_unit_t=14_0_split
I1223 00:14:23.629737 25375 net.cpp:406] c_t=14_encode2_unit_t=14_0_split <- c_t=14
I1223 00:14:23.629743 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_0
I1223 00:14:23.629750 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_1
I1223 00:14:23.629756 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_2
I1223 00:14:23.629761 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_3
I1223 00:14:23.629823 25375 net.cpp:122] Setting up c_t=14_encode2_unit_t=14_0_split
I1223 00:14:23.629830 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629834 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629837 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629842 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629844 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:23.629848 25375 layer_factory.hpp:77] Creating layer h_t=14_encode2_unit_t=14_1_split
I1223 00:14:23.629851 25375 net.cpp:84] Creating Layer h_t=14_encode2_unit_t=14_1_split
I1223 00:14:23.629855 25375 net.cpp:406] h_t=14_encode2_unit_t=14_1_split <- h_t=14
I1223 00:14:23.629861 25375 net.cpp:380] h_t=14_encode2_unit_t=14_1_split -> h_t=14_encode2_unit_t=14_1_split_0
I1223 00:14:23.629868 25375 net.cpp:380] h_t=14_encode2_unit_t=14_1_split -> h_t=14_encode2_unit_t=14_1_split_1
I1223 00:14:23.629901 25375 net.cpp:122] Setting up h_t=14_encode2_unit_t=14_1_split
I1223 00:14:23.629920 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629925 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.629927 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:23.629930 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=14
I1223 00:14:23.629936 25375 net.cpp:84] Creating Layer encode2_h_conted_t=14
I1223 00:14:23.629940 25375 net.cpp:406] encode2_h_conted_t=14 <- h_t=14_encode2_unit_t=14_1_split_0
I1223 00:14:23.629945 25375 net.cpp:406] encode2_h_conted_t=14 <- cont_t=15_encode2_cont_slice_14_split_0
I1223 00:14:23.629962 25375 net.cpp:380] encode2_h_conted_t=14 -> h_conted_t=14
I1223 00:14:23.630041 25375 net.cpp:122] Setting up encode2_h_conted_t=14
I1223 00:14:23.630061 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.630064 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:23.630067 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->14
I1223 00:14:23.630075 25375 net.cpp:84] Creating Layer encode2_hidden->transform->14
I1223 00:14:23.630079 25375 net.cpp:406] encode2_hidden->transform->14 <- h_conted_t=14
I1223 00:14:23.630086 25375 net.cpp:380] encode2_hidden->transform->14 -> hidden->transform->14
I1223 00:14:23.631345 25375 net.cpp:122] Setting up encode2_hidden->transform->14
I1223 00:14:23.631357 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.631361 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:23.631364 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.631369 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.631373 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=14
I1223 00:14:23.631381 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=14
I1223 00:14:23.631386 25375 net.cpp:406] encode2_hadamard->input_t=14 <- c_t=14_encode2_unit_t=14_0_split_0
I1223 00:14:23.631393 25375 net.cpp:380] encode2_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:23.631496 25375 net.cpp:122] Setting up encode2_hadamard->input_t=14
I1223 00:14:23.631506 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.631508 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:23.631512 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.631516 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=14
I1223 00:14:23.631523 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=14
I1223 00:14:23.631528 25375 net.cpp:406] encode2_hadamard->forget_t=14 <- c_t=14_encode2_unit_t=14_0_split_1
I1223 00:14:23.631536 25375 net.cpp:380] encode2_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:23.631675 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=14
I1223 00:14:23.631682 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.631685 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:23.631701 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.631705 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=14
I1223 00:14:23.631711 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=14
I1223 00:14:23.631726 25375 net.cpp:406] encode2_hadamard->output_t=14 <- c_t=14_encode2_unit_t=14_0_split_2
I1223 00:14:23.631731 25375 net.cpp:380] encode2_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:23.631847 25375 net.cpp:122] Setting up encode2_hadamard->output_t=14
I1223 00:14:23.631855 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.631857 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:23.631860 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.631865 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=15
I1223 00:14:23.631882 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=15
I1223 00:14:23.631887 25375 net.cpp:380] encode2_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:23.631955 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=15
I1223 00:14:23.631963 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.631978 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:23.631980 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=15
I1223 00:14:23.631986 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=15
I1223 00:14:23.632002 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:23.632007 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:23.632010 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:23.632014 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:23.632019 25375 net.cpp:380] encode2_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:23.632057 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=15
I1223 00:14:23.632063 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.632066 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:23.632069 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_15
I1223 00:14:23.632089 25375 net.cpp:84] Creating Layer encode2_gate_input_15
I1223 00:14:23.632092 25375 net.cpp:406] encode2_gate_input_15 <- hidden->transform->14
I1223 00:14:23.632097 25375 net.cpp:406] encode2_gate_input_15 <- x->transform->t=15
I1223 00:14:23.632102 25375 net.cpp:406] encode2_gate_input_15 <- hadamard_t=15
I1223 00:14:23.632107 25375 net.cpp:380] encode2_gate_input_15 -> gate_input_15
I1223 00:14:23.632143 25375 net.cpp:122] Setting up encode2_gate_input_15
I1223 00:14:23.632148 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.632151 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:23.632154 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=15
I1223 00:14:23.632159 25375 net.cpp:84] Creating Layer encode2_unit_t=15
I1223 00:14:23.632163 25375 net.cpp:406] encode2_unit_t=15 <- c_t=14_encode2_unit_t=14_0_split_3
I1223 00:14:23.632167 25375 net.cpp:406] encode2_unit_t=15 <- gate_input_15
I1223 00:14:23.632171 25375 net.cpp:406] encode2_unit_t=15 <- cont_t=15_encode2_cont_slice_14_split_1
I1223 00:14:23.632176 25375 net.cpp:380] encode2_unit_t=15 -> c_t=15
I1223 00:14:23.632195 25375 net.cpp:380] encode2_unit_t=15 -> h_t=15
I1223 00:14:23.632272 25375 net.cpp:122] Setting up encode2_unit_t=15
I1223 00:14:23.632279 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632283 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632299 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:23.632302 25375 layer_factory.hpp:77] Creating layer c_t=15_encode2_unit_t=15_0_split
I1223 00:14:23.632309 25375 net.cpp:84] Creating Layer c_t=15_encode2_unit_t=15_0_split
I1223 00:14:23.632313 25375 net.cpp:406] c_t=15_encode2_unit_t=15_0_split <- c_t=15
I1223 00:14:23.632318 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_0
I1223 00:14:23.632325 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_1
I1223 00:14:23.632333 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_2
I1223 00:14:23.632338 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_3
I1223 00:14:23.632411 25375 net.cpp:122] Setting up c_t=15_encode2_unit_t=15_0_split
I1223 00:14:23.632418 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632421 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632426 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632429 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632432 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:23.632434 25375 layer_factory.hpp:77] Creating layer h_t=15_encode2_unit_t=15_1_split
I1223 00:14:23.632453 25375 net.cpp:84] Creating Layer h_t=15_encode2_unit_t=15_1_split
I1223 00:14:23.632457 25375 net.cpp:406] h_t=15_encode2_unit_t=15_1_split <- h_t=15
I1223 00:14:23.632462 25375 net.cpp:380] h_t=15_encode2_unit_t=15_1_split -> h_t=15_encode2_unit_t=15_1_split_0
I1223 00:14:23.632469 25375 net.cpp:380] h_t=15_encode2_unit_t=15_1_split -> h_t=15_encode2_unit_t=15_1_split_1
I1223 00:14:23.632517 25375 net.cpp:122] Setting up h_t=15_encode2_unit_t=15_1_split
I1223 00:14:23.632524 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632527 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632530 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:23.632534 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=15
I1223 00:14:23.632537 25375 net.cpp:84] Creating Layer encode2_h_conted_t=15
I1223 00:14:23.632541 25375 net.cpp:406] encode2_h_conted_t=15 <- h_t=15_encode2_unit_t=15_1_split_0
I1223 00:14:23.632558 25375 net.cpp:406] encode2_h_conted_t=15 <- cont_t=16_encode2_cont_slice_15_split_0
I1223 00:14:23.632563 25375 net.cpp:380] encode2_h_conted_t=15 -> h_conted_t=15
I1223 00:14:23.632654 25375 net.cpp:122] Setting up encode2_h_conted_t=15
I1223 00:14:23.632661 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.632664 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:23.632668 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->15
I1223 00:14:23.632675 25375 net.cpp:84] Creating Layer encode2_hidden->transform->15
I1223 00:14:23.632679 25375 net.cpp:406] encode2_hidden->transform->15 <- h_conted_t=15
I1223 00:14:23.632688 25375 net.cpp:380] encode2_hidden->transform->15 -> hidden->transform->15
I1223 00:14:23.633206 25375 net.cpp:122] Setting up encode2_hidden->transform->15
I1223 00:14:23.633215 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.633219 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:23.633221 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:23.633226 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:23.633229 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=15
I1223 00:14:23.633234 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=15
I1223 00:14:23.633239 25375 net.cpp:406] encode2_hadamard->input_t=15 <- c_t=15_encode2_unit_t=15_0_split_0
I1223 00:14:23.633257 25375 net.cpp:380] encode2_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:23.633361 25375 net.cpp:122] Setting up encode2_hadamard->input_t=15
I1223 00:14:23.633370 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.633373 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:23.633378 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:23.633380 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=15
I1223 00:14:23.633399 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=15
I1223 00:14:23.633401 25375 net.cpp:406] encode2_hadamard->forget_t=15 <- c_t=15_encode2_unit_t=15_0_split_1
I1223 00:14:23.633424 25375 net.cpp:380] encode2_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:23.633529 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=15
I1223 00:14:23.633536 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.633539 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:23.633543 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:23.633546 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=15
I1223 00:14:23.633564 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=15
I1223 00:14:23.633568 25375 net.cpp:406] encode2_hadamard->output_t=15 <- c_t=15_encode2_unit_t=15_0_split_2
I1223 00:14:23.633586 25375 net.cpp:380] encode2_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:23.633689 25375 net.cpp:122] Setting up encode2_hadamard->output_t=15
I1223 00:14:23.633697 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.633700 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:23.633703 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:23.633707 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=16
I1223 00:14:23.633711 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=16
I1223 00:14:23.633718 25375 net.cpp:380] encode2_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:23.633796 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=16
I1223 00:14:23.633803 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.633806 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:23.633810 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=16
I1223 00:14:23.633816 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=16
I1223 00:14:23.633819 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:23.633823 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:23.633827 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:23.633831 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:23.633848 25375 net.cpp:380] encode2_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:23.633872 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=16
I1223 00:14:23.633878 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.633882 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:23.633884 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_16
I1223 00:14:23.633890 25375 net.cpp:84] Creating Layer encode2_gate_input_16
I1223 00:14:23.633895 25375 net.cpp:406] encode2_gate_input_16 <- hidden->transform->15
I1223 00:14:23.633899 25375 net.cpp:406] encode2_gate_input_16 <- x->transform->t=16
I1223 00:14:23.633903 25375 net.cpp:406] encode2_gate_input_16 <- hadamard_t=16
I1223 00:14:23.633908 25375 net.cpp:380] encode2_gate_input_16 -> gate_input_16
I1223 00:14:23.633931 25375 net.cpp:122] Setting up encode2_gate_input_16
I1223 00:14:23.633937 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.633940 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:23.633942 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=16
I1223 00:14:23.633947 25375 net.cpp:84] Creating Layer encode2_unit_t=16
I1223 00:14:23.633951 25375 net.cpp:406] encode2_unit_t=16 <- c_t=15_encode2_unit_t=15_0_split_3
I1223 00:14:23.633955 25375 net.cpp:406] encode2_unit_t=16 <- gate_input_16
I1223 00:14:23.633960 25375 net.cpp:406] encode2_unit_t=16 <- cont_t=16_encode2_cont_slice_15_split_1
I1223 00:14:23.633965 25375 net.cpp:380] encode2_unit_t=16 -> c_t=16
I1223 00:14:23.633971 25375 net.cpp:380] encode2_unit_t=16 -> h_t=16
I1223 00:14:23.634021 25375 net.cpp:122] Setting up encode2_unit_t=16
I1223 00:14:23.634027 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.634032 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.634034 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:23.634050 25375 layer_factory.hpp:77] Creating layer h_t=16_encode2_unit_t=16_1_split
I1223 00:14:23.634054 25375 net.cpp:84] Creating Layer h_t=16_encode2_unit_t=16_1_split
I1223 00:14:23.634058 25375 net.cpp:406] h_t=16_encode2_unit_t=16_1_split <- h_t=16
I1223 00:14:23.634078 25375 net.cpp:380] h_t=16_encode2_unit_t=16_1_split -> h_t=16_encode2_unit_t=16_1_split_0
I1223 00:14:23.634084 25375 net.cpp:380] h_t=16_encode2_unit_t=16_1_split -> h_t=16_encode2_unit_t=16_1_split_1
I1223 00:14:23.634120 25375 net.cpp:122] Setting up h_t=16_encode2_unit_t=16_1_split
I1223 00:14:23.634127 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.634131 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.634135 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:23.634137 25375 layer_factory.hpp:77] Creating layer encode2_h_concat
I1223 00:14:23.634145 25375 net.cpp:84] Creating Layer encode2_h_concat
I1223 00:14:23.634150 25375 net.cpp:406] encode2_h_concat <- h_t=1_encode2_unit_t=1_1_split_1
I1223 00:14:23.634153 25375 net.cpp:406] encode2_h_concat <- h_t=2_encode2_unit_t=2_1_split_1
I1223 00:14:23.634157 25375 net.cpp:406] encode2_h_concat <- h_t=3_encode2_unit_t=3_1_split_1
I1223 00:14:23.634161 25375 net.cpp:406] encode2_h_concat <- h_t=4_encode2_unit_t=4_1_split_1
I1223 00:14:23.634165 25375 net.cpp:406] encode2_h_concat <- h_t=5_encode2_unit_t=5_1_split_1
I1223 00:14:23.634168 25375 net.cpp:406] encode2_h_concat <- h_t=6_encode2_unit_t=6_1_split_1
I1223 00:14:23.634171 25375 net.cpp:406] encode2_h_concat <- h_t=7_encode2_unit_t=7_1_split_1
I1223 00:14:23.634176 25375 net.cpp:406] encode2_h_concat <- h_t=8_encode2_unit_t=8_1_split_1
I1223 00:14:23.634178 25375 net.cpp:406] encode2_h_concat <- h_t=9_encode2_unit_t=9_1_split_1
I1223 00:14:23.634181 25375 net.cpp:406] encode2_h_concat <- h_t=10_encode2_unit_t=10_1_split_1
I1223 00:14:23.634186 25375 net.cpp:406] encode2_h_concat <- h_t=11_encode2_unit_t=11_1_split_1
I1223 00:14:23.634188 25375 net.cpp:406] encode2_h_concat <- h_t=12_encode2_unit_t=12_1_split_1
I1223 00:14:23.634192 25375 net.cpp:406] encode2_h_concat <- h_t=13_encode2_unit_t=13_1_split_1
I1223 00:14:23.634196 25375 net.cpp:406] encode2_h_concat <- h_t=14_encode2_unit_t=14_1_split_1
I1223 00:14:23.634197 25375 net.cpp:406] encode2_h_concat <- h_t=15_encode2_unit_t=15_1_split_1
I1223 00:14:23.634202 25375 net.cpp:406] encode2_h_concat <- h_t=16_encode2_unit_t=16_1_split_0
I1223 00:14:23.634207 25375 net.cpp:380] encode2_h_concat -> h
I1223 00:14:23.634234 25375 net.cpp:122] Setting up encode2_h_concat
I1223 00:14:23.634241 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.634244 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:23.634248 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_h
I1223 00:14:23.634251 25375 net.cpp:84] Creating Layer encode2_dummy_forward_h
I1223 00:14:23.634254 25375 net.cpp:406] encode2_dummy_forward_h <- h_t=16_encode2_unit_t=16_1_split_1
I1223 00:14:23.634259 25375 net.cpp:380] encode2_dummy_forward_h -> h_t=T
I1223 00:14:23.634299 25375 net.cpp:122] Setting up encode2_dummy_forward_h
I1223 00:14:23.634305 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.634307 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:23.634315 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_c
I1223 00:14:23.634318 25375 net.cpp:84] Creating Layer encode2_dummy_forward_c
I1223 00:14:23.634321 25375 net.cpp:406] encode2_dummy_forward_c <- c_t=16
I1223 00:14:23.634326 25375 net.cpp:380] encode2_dummy_forward_c -> c_t=T
I1223 00:14:23.634364 25375 net.cpp:122] Setting up encode2_dummy_forward_c
I1223 00:14:23.634371 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.634373 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:23.634377 25375 layer_factory.hpp:77] Creating layer encode2_h_t=T_pseudoloss
I1223 00:14:23.634382 25375 net.cpp:84] Creating Layer encode2_h_t=T_pseudoloss
I1223 00:14:23.634385 25375 net.cpp:406] encode2_h_t=T_pseudoloss <- h_t=T
I1223 00:14:23.634392 25375 net.cpp:380] encode2_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:23.634457 25375 net.cpp:122] Setting up encode2_h_t=T_pseudoloss
I1223 00:14:23.634464 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.634466 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.634475 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:23.634479 25375 layer_factory.hpp:77] Creating layer encode2_c_t=T_pseudoloss
I1223 00:14:23.634483 25375 net.cpp:84] Creating Layer encode2_c_t=T_pseudoloss
I1223 00:14:23.634486 25375 net.cpp:406] encode2_c_t=T_pseudoloss <- c_t=T
I1223 00:14:23.634491 25375 net.cpp:380] encode2_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:23.634555 25375 net.cpp:122] Setting up encode2_c_t=T_pseudoloss
I1223 00:14:23.634562 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.634565 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.634569 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:23.634572 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:23.634577 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:23.634579 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:23.634585 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:23.635615 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:23.635625 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.635628 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.635632 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:23.635635 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:23.635639 25375 net.cpp:198] encode2_c_t=T_pseudoloss needs backward computation.
I1223 00:14:23.635641 25375 net.cpp:198] encode2_h_t=T_pseudoloss needs backward computation.
I1223 00:14:23.635644 25375 net.cpp:198] encode2_dummy_forward_c needs backward computation.
I1223 00:14:23.635648 25375 net.cpp:198] encode2_dummy_forward_h needs backward computation.
I1223 00:14:23.635650 25375 net.cpp:198] encode2_h_concat needs backward computation.
I1223 00:14:23.635659 25375 net.cpp:198] h_t=16_encode2_unit_t=16_1_split needs backward computation.
I1223 00:14:23.635663 25375 net.cpp:198] encode2_unit_t=16 needs backward computation.
I1223 00:14:23.635668 25375 net.cpp:198] encode2_gate_input_16 needs backward computation.
I1223 00:14:23.635671 25375 net.cpp:198] encode2_concat_hadamard_t=16 needs backward computation.
I1223 00:14:23.635675 25375 net.cpp:200] encode2_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:23.635679 25375 net.cpp:198] encode2_hadamard->output_t=15 needs backward computation.
I1223 00:14:23.635681 25375 net.cpp:198] encode2_hadamard->forget_t=15 needs backward computation.
I1223 00:14:23.635684 25375 net.cpp:198] encode2_hadamard->input_t=15 needs backward computation.
I1223 00:14:23.635687 25375 net.cpp:198] encode2_hidden->transform->15 needs backward computation.
I1223 00:14:23.635690 25375 net.cpp:198] encode2_h_conted_t=15 needs backward computation.
I1223 00:14:23.635694 25375 net.cpp:198] h_t=15_encode2_unit_t=15_1_split needs backward computation.
I1223 00:14:23.635697 25375 net.cpp:198] c_t=15_encode2_unit_t=15_0_split needs backward computation.
I1223 00:14:23.635700 25375 net.cpp:198] encode2_unit_t=15 needs backward computation.
I1223 00:14:23.635704 25375 net.cpp:198] encode2_gate_input_15 needs backward computation.
I1223 00:14:23.635710 25375 net.cpp:198] encode2_concat_hadamard_t=15 needs backward computation.
I1223 00:14:23.635715 25375 net.cpp:200] encode2_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:23.635717 25375 net.cpp:198] encode2_hadamard->output_t=14 needs backward computation.
I1223 00:14:23.635720 25375 net.cpp:198] encode2_hadamard->forget_t=14 needs backward computation.
I1223 00:14:23.635723 25375 net.cpp:198] encode2_hadamard->input_t=14 needs backward computation.
I1223 00:14:23.635727 25375 net.cpp:198] encode2_hidden->transform->14 needs backward computation.
I1223 00:14:23.635730 25375 net.cpp:198] encode2_h_conted_t=14 needs backward computation.
I1223 00:14:23.635735 25375 net.cpp:198] h_t=14_encode2_unit_t=14_1_split needs backward computation.
I1223 00:14:23.635737 25375 net.cpp:198] c_t=14_encode2_unit_t=14_0_split needs backward computation.
I1223 00:14:23.635741 25375 net.cpp:198] encode2_unit_t=14 needs backward computation.
I1223 00:14:23.635746 25375 net.cpp:198] encode2_gate_input_14 needs backward computation.
I1223 00:14:23.635749 25375 net.cpp:198] encode2_concat_hadamard_t=14 needs backward computation.
I1223 00:14:23.635754 25375 net.cpp:200] encode2_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:23.635757 25375 net.cpp:198] encode2_hadamard->output_t=13 needs backward computation.
I1223 00:14:23.635761 25375 net.cpp:198] encode2_hadamard->forget_t=13 needs backward computation.
I1223 00:14:23.635763 25375 net.cpp:198] encode2_hadamard->input_t=13 needs backward computation.
I1223 00:14:23.635766 25375 net.cpp:198] encode2_hidden->transform->13 needs backward computation.
I1223 00:14:23.635771 25375 net.cpp:198] encode2_h_conted_t=13 needs backward computation.
I1223 00:14:23.635774 25375 net.cpp:198] h_t=13_encode2_unit_t=13_1_split needs backward computation.
I1223 00:14:23.635777 25375 net.cpp:198] c_t=13_encode2_unit_t=13_0_split needs backward computation.
I1223 00:14:23.635781 25375 net.cpp:198] encode2_unit_t=13 needs backward computation.
I1223 00:14:23.635787 25375 net.cpp:198] encode2_gate_input_13 needs backward computation.
I1223 00:14:23.635790 25375 net.cpp:198] encode2_concat_hadamard_t=13 needs backward computation.
I1223 00:14:23.635795 25375 net.cpp:200] encode2_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:23.635798 25375 net.cpp:198] encode2_hadamard->output_t=12 needs backward computation.
I1223 00:14:23.635802 25375 net.cpp:198] encode2_hadamard->forget_t=12 needs backward computation.
I1223 00:14:23.635804 25375 net.cpp:198] encode2_hadamard->input_t=12 needs backward computation.
I1223 00:14:23.635807 25375 net.cpp:198] encode2_hidden->transform->12 needs backward computation.
I1223 00:14:23.635810 25375 net.cpp:198] encode2_h_conted_t=12 needs backward computation.
I1223 00:14:23.635815 25375 net.cpp:198] h_t=12_encode2_unit_t=12_1_split needs backward computation.
I1223 00:14:23.635818 25375 net.cpp:198] c_t=12_encode2_unit_t=12_0_split needs backward computation.
I1223 00:14:23.635821 25375 net.cpp:198] encode2_unit_t=12 needs backward computation.
I1223 00:14:23.635826 25375 net.cpp:198] encode2_gate_input_12 needs backward computation.
I1223 00:14:23.635830 25375 net.cpp:198] encode2_concat_hadamard_t=12 needs backward computation.
I1223 00:14:23.635835 25375 net.cpp:200] encode2_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:23.635838 25375 net.cpp:198] encode2_hadamard->output_t=11 needs backward computation.
I1223 00:14:23.635841 25375 net.cpp:198] encode2_hadamard->forget_t=11 needs backward computation.
I1223 00:14:23.635844 25375 net.cpp:198] encode2_hadamard->input_t=11 needs backward computation.
I1223 00:14:23.635848 25375 net.cpp:198] encode2_hidden->transform->11 needs backward computation.
I1223 00:14:23.635851 25375 net.cpp:198] encode2_h_conted_t=11 needs backward computation.
I1223 00:14:23.635856 25375 net.cpp:198] h_t=11_encode2_unit_t=11_1_split needs backward computation.
I1223 00:14:23.635860 25375 net.cpp:198] c_t=11_encode2_unit_t=11_0_split needs backward computation.
I1223 00:14:23.635864 25375 net.cpp:198] encode2_unit_t=11 needs backward computation.
I1223 00:14:23.635867 25375 net.cpp:198] encode2_gate_input_11 needs backward computation.
I1223 00:14:23.635872 25375 net.cpp:198] encode2_concat_hadamard_t=11 needs backward computation.
I1223 00:14:23.635876 25375 net.cpp:200] encode2_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:23.635879 25375 net.cpp:198] encode2_hadamard->output_t=10 needs backward computation.
I1223 00:14:23.635882 25375 net.cpp:198] encode2_hadamard->forget_t=10 needs backward computation.
I1223 00:14:23.635885 25375 net.cpp:198] encode2_hadamard->input_t=10 needs backward computation.
I1223 00:14:23.635890 25375 net.cpp:198] encode2_hidden->transform->10 needs backward computation.
I1223 00:14:23.635892 25375 net.cpp:198] encode2_h_conted_t=10 needs backward computation.
I1223 00:14:23.635896 25375 net.cpp:198] h_t=10_encode2_unit_t=10_1_split needs backward computation.
I1223 00:14:23.635900 25375 net.cpp:198] c_t=10_encode2_unit_t=10_0_split needs backward computation.
I1223 00:14:23.635903 25375 net.cpp:198] encode2_unit_t=10 needs backward computation.
I1223 00:14:23.635908 25375 net.cpp:198] encode2_gate_input_10 needs backward computation.
I1223 00:14:23.635912 25375 net.cpp:198] encode2_concat_hadamard_t=10 needs backward computation.
I1223 00:14:23.635918 25375 net.cpp:200] encode2_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:23.635922 25375 net.cpp:198] encode2_hadamard->output_t=9 needs backward computation.
I1223 00:14:23.635926 25375 net.cpp:198] encode2_hadamard->forget_t=9 needs backward computation.
I1223 00:14:23.635929 25375 net.cpp:198] encode2_hadamard->input_t=9 needs backward computation.
I1223 00:14:23.635932 25375 net.cpp:198] encode2_hidden->transform->9 needs backward computation.
I1223 00:14:23.635936 25375 net.cpp:198] encode2_h_conted_t=9 needs backward computation.
I1223 00:14:23.635941 25375 net.cpp:198] h_t=9_encode2_unit_t=9_1_split needs backward computation.
I1223 00:14:23.635944 25375 net.cpp:198] c_t=9_encode2_unit_t=9_0_split needs backward computation.
I1223 00:14:23.635947 25375 net.cpp:198] encode2_unit_t=9 needs backward computation.
I1223 00:14:23.635953 25375 net.cpp:198] encode2_gate_input_9 needs backward computation.
I1223 00:14:23.635957 25375 net.cpp:198] encode2_concat_hadamard_t=9 needs backward computation.
I1223 00:14:23.635962 25375 net.cpp:200] encode2_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:23.635965 25375 net.cpp:198] encode2_hadamard->output_t=8 needs backward computation.
I1223 00:14:23.635969 25375 net.cpp:198] encode2_hadamard->forget_t=8 needs backward computation.
I1223 00:14:23.635973 25375 net.cpp:198] encode2_hadamard->input_t=8 needs backward computation.
I1223 00:14:23.635977 25375 net.cpp:198] encode2_hidden->transform->8 needs backward computation.
I1223 00:14:23.635979 25375 net.cpp:198] encode2_h_conted_t=8 needs backward computation.
I1223 00:14:23.635984 25375 net.cpp:198] h_t=8_encode2_unit_t=8_1_split needs backward computation.
I1223 00:14:23.635987 25375 net.cpp:198] c_t=8_encode2_unit_t=8_0_split needs backward computation.
I1223 00:14:23.635990 25375 net.cpp:198] encode2_unit_t=8 needs backward computation.
I1223 00:14:23.635995 25375 net.cpp:198] encode2_gate_input_8 needs backward computation.
I1223 00:14:23.636003 25375 net.cpp:198] encode2_concat_hadamard_t=8 needs backward computation.
I1223 00:14:23.636008 25375 net.cpp:200] encode2_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:23.636010 25375 net.cpp:198] encode2_hadamard->output_t=7 needs backward computation.
I1223 00:14:23.636013 25375 net.cpp:198] encode2_hadamard->forget_t=7 needs backward computation.
I1223 00:14:23.636018 25375 net.cpp:198] encode2_hadamard->input_t=7 needs backward computation.
I1223 00:14:23.636020 25375 net.cpp:198] encode2_hidden->transform->7 needs backward computation.
I1223 00:14:23.636024 25375 net.cpp:198] encode2_h_conted_t=7 needs backward computation.
I1223 00:14:23.636029 25375 net.cpp:198] h_t=7_encode2_unit_t=7_1_split needs backward computation.
I1223 00:14:23.636032 25375 net.cpp:198] c_t=7_encode2_unit_t=7_0_split needs backward computation.
I1223 00:14:23.636035 25375 net.cpp:198] encode2_unit_t=7 needs backward computation.
I1223 00:14:23.636039 25375 net.cpp:198] encode2_gate_input_7 needs backward computation.
I1223 00:14:23.636044 25375 net.cpp:198] encode2_concat_hadamard_t=7 needs backward computation.
I1223 00:14:23.636049 25375 net.cpp:200] encode2_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:23.636051 25375 net.cpp:198] encode2_hadamard->output_t=6 needs backward computation.
I1223 00:14:23.636055 25375 net.cpp:198] encode2_hadamard->forget_t=6 needs backward computation.
I1223 00:14:23.636059 25375 net.cpp:198] encode2_hadamard->input_t=6 needs backward computation.
I1223 00:14:23.636062 25375 net.cpp:198] encode2_hidden->transform->6 needs backward computation.
I1223 00:14:23.636065 25375 net.cpp:198] encode2_h_conted_t=6 needs backward computation.
I1223 00:14:23.636070 25375 net.cpp:198] h_t=6_encode2_unit_t=6_1_split needs backward computation.
I1223 00:14:23.636073 25375 net.cpp:198] c_t=6_encode2_unit_t=6_0_split needs backward computation.
I1223 00:14:23.636076 25375 net.cpp:198] encode2_unit_t=6 needs backward computation.
I1223 00:14:23.636082 25375 net.cpp:198] encode2_gate_input_6 needs backward computation.
I1223 00:14:23.636087 25375 net.cpp:198] encode2_concat_hadamard_t=6 needs backward computation.
I1223 00:14:23.636092 25375 net.cpp:200] encode2_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:23.636096 25375 net.cpp:198] encode2_hadamard->output_t=5 needs backward computation.
I1223 00:14:23.636099 25375 net.cpp:198] encode2_hadamard->forget_t=5 needs backward computation.
I1223 00:14:23.636102 25375 net.cpp:198] encode2_hadamard->input_t=5 needs backward computation.
I1223 00:14:23.636106 25375 net.cpp:198] encode2_hidden->transform->5 needs backward computation.
I1223 00:14:23.636109 25375 net.cpp:198] encode2_h_conted_t=5 needs backward computation.
I1223 00:14:23.636113 25375 net.cpp:198] h_t=5_encode2_unit_t=5_1_split needs backward computation.
I1223 00:14:23.636116 25375 net.cpp:198] c_t=5_encode2_unit_t=5_0_split needs backward computation.
I1223 00:14:23.636119 25375 net.cpp:198] encode2_unit_t=5 needs backward computation.
I1223 00:14:23.636124 25375 net.cpp:198] encode2_gate_input_5 needs backward computation.
I1223 00:14:23.636128 25375 net.cpp:198] encode2_concat_hadamard_t=5 needs backward computation.
I1223 00:14:23.636132 25375 net.cpp:200] encode2_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:23.636135 25375 net.cpp:198] encode2_hadamard->output_t=4 needs backward computation.
I1223 00:14:23.636139 25375 net.cpp:198] encode2_hadamard->forget_t=4 needs backward computation.
I1223 00:14:23.636142 25375 net.cpp:198] encode2_hadamard->input_t=4 needs backward computation.
I1223 00:14:23.636147 25375 net.cpp:198] encode2_hidden->transform->4 needs backward computation.
I1223 00:14:23.636149 25375 net.cpp:198] encode2_h_conted_t=4 needs backward computation.
I1223 00:14:23.636154 25375 net.cpp:198] h_t=4_encode2_unit_t=4_1_split needs backward computation.
I1223 00:14:23.636158 25375 net.cpp:198] c_t=4_encode2_unit_t=4_0_split needs backward computation.
I1223 00:14:23.636162 25375 net.cpp:198] encode2_unit_t=4 needs backward computation.
I1223 00:14:23.636167 25375 net.cpp:198] encode2_gate_input_4 needs backward computation.
I1223 00:14:23.636170 25375 net.cpp:198] encode2_concat_hadamard_t=4 needs backward computation.
I1223 00:14:23.636174 25375 net.cpp:200] encode2_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:23.636178 25375 net.cpp:198] encode2_hadamard->output_t=3 needs backward computation.
I1223 00:14:23.636180 25375 net.cpp:198] encode2_hadamard->forget_t=3 needs backward computation.
I1223 00:14:23.636184 25375 net.cpp:198] encode2_hadamard->input_t=3 needs backward computation.
I1223 00:14:23.636188 25375 net.cpp:198] encode2_hidden->transform->3 needs backward computation.
I1223 00:14:23.636190 25375 net.cpp:198] encode2_h_conted_t=3 needs backward computation.
I1223 00:14:23.636194 25375 net.cpp:198] h_t=3_encode2_unit_t=3_1_split needs backward computation.
I1223 00:14:23.636198 25375 net.cpp:198] c_t=3_encode2_unit_t=3_0_split needs backward computation.
I1223 00:14:23.636201 25375 net.cpp:198] encode2_unit_t=3 needs backward computation.
I1223 00:14:23.636205 25375 net.cpp:198] encode2_gate_input_3 needs backward computation.
I1223 00:14:23.636209 25375 net.cpp:198] encode2_concat_hadamard_t=3 needs backward computation.
I1223 00:14:23.636214 25375 net.cpp:200] encode2_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:23.636217 25375 net.cpp:198] encode2_hadamard->output_t=2 needs backward computation.
I1223 00:14:23.636220 25375 net.cpp:198] encode2_hadamard->forget_t=2 needs backward computation.
I1223 00:14:23.636225 25375 net.cpp:198] encode2_hadamard->input_t=2 needs backward computation.
I1223 00:14:23.636229 25375 net.cpp:198] encode2_hidden->transform->2 needs backward computation.
I1223 00:14:23.636232 25375 net.cpp:198] encode2_h_conted_t=2 needs backward computation.
I1223 00:14:23.636236 25375 net.cpp:198] h_t=2_encode2_unit_t=2_1_split needs backward computation.
I1223 00:14:23.636240 25375 net.cpp:198] c_t=2_encode2_unit_t=2_0_split needs backward computation.
I1223 00:14:23.636242 25375 net.cpp:198] encode2_unit_t=2 needs backward computation.
I1223 00:14:23.636247 25375 net.cpp:198] encode2_gate_input_2 needs backward computation.
I1223 00:14:23.636251 25375 net.cpp:198] encode2_concat_hadamard_t=2 needs backward computation.
I1223 00:14:23.636256 25375 net.cpp:200] encode2_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:23.636260 25375 net.cpp:198] encode2_hadamard->output_t=1 needs backward computation.
I1223 00:14:23.636262 25375 net.cpp:198] encode2_hadamard->forget_t=1 needs backward computation.
I1223 00:14:23.636265 25375 net.cpp:198] encode2_hadamard->input_t=1 needs backward computation.
I1223 00:14:23.636270 25375 net.cpp:198] encode2_hidden->transform->1 needs backward computation.
I1223 00:14:23.636273 25375 net.cpp:198] encode2_h_conted_t=1 needs backward computation.
I1223 00:14:23.636277 25375 net.cpp:198] h_t=1_encode2_unit_t=1_1_split needs backward computation.
I1223 00:14:23.636281 25375 net.cpp:198] c_t=1_encode2_unit_t=1_0_split needs backward computation.
I1223 00:14:23.636284 25375 net.cpp:198] encode2_unit_t=1 needs backward computation.
I1223 00:14:23.636289 25375 net.cpp:198] encode2_gate_input_1 needs backward computation.
I1223 00:14:23.636293 25375 net.cpp:198] encode2_concat_hadamard_t=1 needs backward computation.
I1223 00:14:23.636299 25375 net.cpp:200] encode2_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:23.636302 25375 net.cpp:198] encode2_hadamard->output_t=0 needs backward computation.
I1223 00:14:23.636307 25375 net.cpp:198] encode2_hadamard->forget_t=0 needs backward computation.
I1223 00:14:23.636310 25375 net.cpp:198] encode2_hadamard->input_t=0 needs backward computation.
I1223 00:14:23.636313 25375 net.cpp:198] encode2_hidden->transform->0 needs backward computation.
I1223 00:14:23.636317 25375 net.cpp:198] encode2_h_conted_t=0 needs backward computation.
I1223 00:14:23.636322 25375 net.cpp:198] encode2_dummy_forward_h0 needs backward computation.
I1223 00:14:23.636325 25375 net.cpp:198] c_t=0_encode2_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:23.636328 25375 net.cpp:198] encode2_dummy_forward_c0 needs backward computation.
I1223 00:14:23.636332 25375 net.cpp:200] cont_t=16_encode2_cont_slice_15_split does not need backward computation.
I1223 00:14:23.636337 25375 net.cpp:200] cont_t=15_encode2_cont_slice_14_split does not need backward computation.
I1223 00:14:23.636339 25375 net.cpp:200] cont_t=14_encode2_cont_slice_13_split does not need backward computation.
I1223 00:14:23.636343 25375 net.cpp:200] cont_t=13_encode2_cont_slice_12_split does not need backward computation.
I1223 00:14:23.636346 25375 net.cpp:200] cont_t=12_encode2_cont_slice_11_split does not need backward computation.
I1223 00:14:23.636350 25375 net.cpp:200] cont_t=11_encode2_cont_slice_10_split does not need backward computation.
I1223 00:14:23.636354 25375 net.cpp:200] cont_t=10_encode2_cont_slice_9_split does not need backward computation.
I1223 00:14:23.636358 25375 net.cpp:200] cont_t=9_encode2_cont_slice_8_split does not need backward computation.
I1223 00:14:23.636363 25375 net.cpp:200] cont_t=8_encode2_cont_slice_7_split does not need backward computation.
I1223 00:14:23.636366 25375 net.cpp:200] cont_t=7_encode2_cont_slice_6_split does not need backward computation.
I1223 00:14:23.636369 25375 net.cpp:200] cont_t=6_encode2_cont_slice_5_split does not need backward computation.
I1223 00:14:23.636373 25375 net.cpp:200] cont_t=5_encode2_cont_slice_4_split does not need backward computation.
I1223 00:14:23.636376 25375 net.cpp:200] cont_t=4_encode2_cont_slice_3_split does not need backward computation.
I1223 00:14:23.636380 25375 net.cpp:200] cont_t=3_encode2_cont_slice_2_split does not need backward computation.
I1223 00:14:23.636384 25375 net.cpp:200] cont_t=2_encode2_cont_slice_1_split does not need backward computation.
I1223 00:14:23.636389 25375 net.cpp:200] cont_t=1_encode2_cont_slice_0_split does not need backward computation.
I1223 00:14:23.636395 25375 net.cpp:200] encode2_cont_slice does not need backward computation.
I1223 00:14:23.636400 25375 net.cpp:198] encode2_W_xc_x_slice needs backward computation.
I1223 00:14:23.636404 25375 net.cpp:200] encode2_input->cell_hidden does not need backward computation.
I1223 00:14:23.636406 25375 net.cpp:198] encode2_x->transform needs backward computation.
I1223 00:14:23.636411 25375 net.cpp:200] encode2_ does not need backward computation.
I1223 00:14:23.636415 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:23.636417 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:23.636421 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:23.637269 25375 net.cpp:255] Network initialization done.
I1223 00:14:23.637691 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:23.637698 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:23.637702 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:23.637704 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:23.637707 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:23.637709 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:23.637712 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:23.637729 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:23.637732 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:23.637734 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:23.638397 25375 net.cpp:122] Setting up encode2
I1223 00:14:23.638406 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.638411 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.638415 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.638432 25375 net.cpp:137] Memory required for data: 4284612992
I1223 00:14:23.638445 25375 layer_factory.hpp:77] Creating layer encode3
I1223 00:14:23.638468 25375 net.cpp:84] Creating Layer encode3
I1223 00:14:23.638473 25375 net.cpp:406] encode3 <- conv6-reshape_reshape-data_0_split_2
I1223 00:14:23.638490 25375 net.cpp:406] encode3 <- reshape-cm_reshape-cm_0_split_2
I1223 00:14:23.638494 25375 net.cpp:406] encode3 <- dummy_dummy_0_split_4
I1223 00:14:23.638511 25375 net.cpp:406] encode3 <- dummy_dummy_0_split_5
I1223 00:14:23.638519 25375 net.cpp:380] encode3 -> encode3
I1223 00:14:23.638527 25375 net.cpp:380] encode3 -> encode3_h
I1223 00:14:23.638536 25375 net.cpp:380] encode3 -> encode3_c
I1223 00:14:23.638558 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:23.639988 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode3_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode3_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode3_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode3_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode3_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode3_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode3_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode3_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode3_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode3_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode3_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode3_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode3_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode3_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode3_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode3_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode3_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode3_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode3_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transfor
I1223 00:14:23.640898 25375 layer_factory.hpp:77] Creating layer encode3_
I1223 00:14:23.640908 25375 net.cpp:84] Creating Layer encode3_
I1223 00:14:23.640913 25375 net.cpp:380] encode3_ -> x
I1223 00:14:23.640920 25375 net.cpp:380] encode3_ -> cont
I1223 00:14:23.640980 25375 net.cpp:122] Setting up encode3_
I1223 00:14:23.640987 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.640992 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.640995 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:23.640997 25375 layer_factory.hpp:77] Creating layer encode3_x->transform
I1223 00:14:23.641006 25375 net.cpp:84] Creating Layer encode3_x->transform
I1223 00:14:23.641010 25375 net.cpp:406] encode3_x->transform <- x
I1223 00:14:23.641016 25375 net.cpp:380] encode3_x->transform -> x->transform
I1223 00:14:23.641302 25375 net.cpp:122] Setting up encode3_x->transform
I1223 00:14:23.641311 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:23.641314 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:23.641319 25375 layer_factory.hpp:77] Creating layer encode3_input->cell_hidden
I1223 00:14:23.641325 25375 net.cpp:84] Creating Layer encode3_input->cell_hidden
I1223 00:14:23.641330 25375 net.cpp:380] encode3_input->cell_hidden -> c_t=0
I1223 00:14:23.641336 25375 net.cpp:380] encode3_input->cell_hidden -> h_t=0
I1223 00:14:23.641403 25375 net.cpp:122] Setting up encode3_input->cell_hidden
I1223 00:14:23.641410 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.641414 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.641417 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:23.641419 25375 layer_factory.hpp:77] Creating layer encode3_W_xc_x_slice
I1223 00:14:23.641440 25375 net.cpp:84] Creating Layer encode3_W_xc_x_slice
I1223 00:14:23.641443 25375 net.cpp:406] encode3_W_xc_x_slice <- x->transform
I1223 00:14:23.641449 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=1
I1223 00:14:23.641470 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=2
I1223 00:14:23.641476 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=3
I1223 00:14:23.641484 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=4
I1223 00:14:23.641490 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=5
I1223 00:14:23.641499 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=6
I1223 00:14:23.641505 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=7
I1223 00:14:23.641512 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=8
I1223 00:14:23.641520 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=9
I1223 00:14:23.641525 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=10
I1223 00:14:23.641532 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=11
I1223 00:14:23.641538 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=12
I1223 00:14:23.641546 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=13
I1223 00:14:23.641553 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=14
I1223 00:14:23.641561 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=15
I1223 00:14:23.641567 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=16
I1223 00:14:23.641786 25375 net.cpp:122] Setting up encode3_W_xc_x_slice
I1223 00:14:23.641794 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641798 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641803 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641806 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641824 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641827 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641844 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641847 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641851 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641855 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641858 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641862 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641866 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641870 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641873 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641877 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.641880 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:23.641883 25375 layer_factory.hpp:77] Creating layer encode3_cont_slice
I1223 00:14:23.641890 25375 net.cpp:84] Creating Layer encode3_cont_slice
I1223 00:14:23.641893 25375 net.cpp:406] encode3_cont_slice <- cont
I1223 00:14:23.641898 25375 net.cpp:380] encode3_cont_slice -> cont_t=1
I1223 00:14:23.641906 25375 net.cpp:380] encode3_cont_slice -> cont_t=2
I1223 00:14:23.641911 25375 net.cpp:380] encode3_cont_slice -> cont_t=3
I1223 00:14:23.641919 25375 net.cpp:380] encode3_cont_slice -> cont_t=4
I1223 00:14:23.641927 25375 net.cpp:380] encode3_cont_slice -> cont_t=5
I1223 00:14:23.641932 25375 net.cpp:380] encode3_cont_slice -> cont_t=6
I1223 00:14:23.641937 25375 net.cpp:380] encode3_cont_slice -> cont_t=7
I1223 00:14:23.641944 25375 net.cpp:380] encode3_cont_slice -> cont_t=8
I1223 00:14:23.641950 25375 net.cpp:380] encode3_cont_slice -> cont_t=9
I1223 00:14:23.641955 25375 net.cpp:380] encode3_cont_slice -> cont_t=10
I1223 00:14:23.641961 25375 net.cpp:380] encode3_cont_slice -> cont_t=11
I1223 00:14:23.641968 25375 net.cpp:380] encode3_cont_slice -> cont_t=12
I1223 00:14:23.641978 25375 net.cpp:380] encode3_cont_slice -> cont_t=13
I1223 00:14:23.641985 25375 net.cpp:380] encode3_cont_slice -> cont_t=14
I1223 00:14:23.641991 25375 net.cpp:380] encode3_cont_slice -> cont_t=15
I1223 00:14:23.641997 25375 net.cpp:380] encode3_cont_slice -> cont_t=16
I1223 00:14:23.642225 25375 net.cpp:122] Setting up encode3_cont_slice
I1223 00:14:23.642231 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642235 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642238 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642242 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642246 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642248 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642252 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642256 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642258 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642261 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642266 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642268 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642272 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642276 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642278 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642282 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642284 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:23.642287 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode3_cont_slice_0_split
I1223 00:14:23.642294 25375 net.cpp:84] Creating Layer cont_t=1_encode3_cont_slice_0_split
I1223 00:14:23.642297 25375 net.cpp:406] cont_t=1_encode3_cont_slice_0_split <- cont_t=1
I1223 00:14:23.642302 25375 net.cpp:380] cont_t=1_encode3_cont_slice_0_split -> cont_t=1_encode3_cont_slice_0_split_0
I1223 00:14:23.642308 25375 net.cpp:380] cont_t=1_encode3_cont_slice_0_split -> cont_t=1_encode3_cont_slice_0_split_1
I1223 00:14:23.642345 25375 net.cpp:122] Setting up cont_t=1_encode3_cont_slice_0_split
I1223 00:14:23.642352 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642355 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642359 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:23.642361 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode3_cont_slice_1_split
I1223 00:14:23.642365 25375 net.cpp:84] Creating Layer cont_t=2_encode3_cont_slice_1_split
I1223 00:14:23.642369 25375 net.cpp:406] cont_t=2_encode3_cont_slice_1_split <- cont_t=2
I1223 00:14:23.642374 25375 net.cpp:380] cont_t=2_encode3_cont_slice_1_split -> cont_t=2_encode3_cont_slice_1_split_0
I1223 00:14:23.642379 25375 net.cpp:380] cont_t=2_encode3_cont_slice_1_split -> cont_t=2_encode3_cont_slice_1_split_1
I1223 00:14:23.642416 25375 net.cpp:122] Setting up cont_t=2_encode3_cont_slice_1_split
I1223 00:14:23.642422 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642426 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642428 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:23.642431 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode3_cont_slice_2_split
I1223 00:14:23.642434 25375 net.cpp:84] Creating Layer cont_t=3_encode3_cont_slice_2_split
I1223 00:14:23.642437 25375 net.cpp:406] cont_t=3_encode3_cont_slice_2_split <- cont_t=3
I1223 00:14:23.642444 25375 net.cpp:380] cont_t=3_encode3_cont_slice_2_split -> cont_t=3_encode3_cont_slice_2_split_0
I1223 00:14:23.642451 25375 net.cpp:380] cont_t=3_encode3_cont_slice_2_split -> cont_t=3_encode3_cont_slice_2_split_1
I1223 00:14:23.642488 25375 net.cpp:122] Setting up cont_t=3_encode3_cont_slice_2_split
I1223 00:14:23.642494 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642498 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642500 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:23.642503 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode3_cont_slice_3_split
I1223 00:14:23.642508 25375 net.cpp:84] Creating Layer cont_t=4_encode3_cont_slice_3_split
I1223 00:14:23.642513 25375 net.cpp:406] cont_t=4_encode3_cont_slice_3_split <- cont_t=4
I1223 00:14:23.642518 25375 net.cpp:380] cont_t=4_encode3_cont_slice_3_split -> cont_t=4_encode3_cont_slice_3_split_0
I1223 00:14:23.642523 25375 net.cpp:380] cont_t=4_encode3_cont_slice_3_split -> cont_t=4_encode3_cont_slice_3_split_1
I1223 00:14:23.642560 25375 net.cpp:122] Setting up cont_t=4_encode3_cont_slice_3_split
I1223 00:14:23.642566 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642570 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642572 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:23.642575 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode3_cont_slice_4_split
I1223 00:14:23.642580 25375 net.cpp:84] Creating Layer cont_t=5_encode3_cont_slice_4_split
I1223 00:14:23.642583 25375 net.cpp:406] cont_t=5_encode3_cont_slice_4_split <- cont_t=5
I1223 00:14:23.642588 25375 net.cpp:380] cont_t=5_encode3_cont_slice_4_split -> cont_t=5_encode3_cont_slice_4_split_0
I1223 00:14:23.642593 25375 net.cpp:380] cont_t=5_encode3_cont_slice_4_split -> cont_t=5_encode3_cont_slice_4_split_1
I1223 00:14:23.642629 25375 net.cpp:122] Setting up cont_t=5_encode3_cont_slice_4_split
I1223 00:14:23.642635 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642638 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642642 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:23.642644 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode3_cont_slice_5_split
I1223 00:14:23.642648 25375 net.cpp:84] Creating Layer cont_t=6_encode3_cont_slice_5_split
I1223 00:14:23.642652 25375 net.cpp:406] cont_t=6_encode3_cont_slice_5_split <- cont_t=6
I1223 00:14:23.642655 25375 net.cpp:380] cont_t=6_encode3_cont_slice_5_split -> cont_t=6_encode3_cont_slice_5_split_0
I1223 00:14:23.642662 25375 net.cpp:380] cont_t=6_encode3_cont_slice_5_split -> cont_t=6_encode3_cont_slice_5_split_1
I1223 00:14:23.642709 25375 net.cpp:122] Setting up cont_t=6_encode3_cont_slice_5_split
I1223 00:14:23.642715 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642719 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642721 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:23.642737 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode3_cont_slice_6_split
I1223 00:14:23.642741 25375 net.cpp:84] Creating Layer cont_t=7_encode3_cont_slice_6_split
I1223 00:14:23.642745 25375 net.cpp:406] cont_t=7_encode3_cont_slice_6_split <- cont_t=7
I1223 00:14:23.642750 25375 net.cpp:380] cont_t=7_encode3_cont_slice_6_split -> cont_t=7_encode3_cont_slice_6_split_0
I1223 00:14:23.642756 25375 net.cpp:380] cont_t=7_encode3_cont_slice_6_split -> cont_t=7_encode3_cont_slice_6_split_1
I1223 00:14:23.642805 25375 net.cpp:122] Setting up cont_t=7_encode3_cont_slice_6_split
I1223 00:14:23.642812 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642815 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642817 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:23.642820 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode3_cont_slice_7_split
I1223 00:14:23.642824 25375 net.cpp:84] Creating Layer cont_t=8_encode3_cont_slice_7_split
I1223 00:14:23.642828 25375 net.cpp:406] cont_t=8_encode3_cont_slice_7_split <- cont_t=8
I1223 00:14:23.642845 25375 net.cpp:380] cont_t=8_encode3_cont_slice_7_split -> cont_t=8_encode3_cont_slice_7_split_0
I1223 00:14:23.642851 25375 net.cpp:380] cont_t=8_encode3_cont_slice_7_split -> cont_t=8_encode3_cont_slice_7_split_1
I1223 00:14:23.642885 25375 net.cpp:122] Setting up cont_t=8_encode3_cont_slice_7_split
I1223 00:14:23.642892 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642910 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642911 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:23.642913 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode3_cont_slice_8_split
I1223 00:14:23.642918 25375 net.cpp:84] Creating Layer cont_t=9_encode3_cont_slice_8_split
I1223 00:14:23.642921 25375 net.cpp:406] cont_t=9_encode3_cont_slice_8_split <- cont_t=9
I1223 00:14:23.642927 25375 net.cpp:380] cont_t=9_encode3_cont_slice_8_split -> cont_t=9_encode3_cont_slice_8_split_0
I1223 00:14:23.642932 25375 net.cpp:380] cont_t=9_encode3_cont_slice_8_split -> cont_t=9_encode3_cont_slice_8_split_1
I1223 00:14:23.642982 25375 net.cpp:122] Setting up cont_t=9_encode3_cont_slice_8_split
I1223 00:14:23.642988 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642992 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.642994 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:23.642997 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode3_cont_slice_9_split
I1223 00:14:23.643002 25375 net.cpp:84] Creating Layer cont_t=10_encode3_cont_slice_9_split
I1223 00:14:23.643004 25375 net.cpp:406] cont_t=10_encode3_cont_slice_9_split <- cont_t=10
I1223 00:14:23.643009 25375 net.cpp:380] cont_t=10_encode3_cont_slice_9_split -> cont_t=10_encode3_cont_slice_9_split_0
I1223 00:14:23.643015 25375 net.cpp:380] cont_t=10_encode3_cont_slice_9_split -> cont_t=10_encode3_cont_slice_9_split_1
I1223 00:14:23.643054 25375 net.cpp:122] Setting up cont_t=10_encode3_cont_slice_9_split
I1223 00:14:23.643061 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643064 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643067 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:23.643070 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode3_cont_slice_10_split
I1223 00:14:23.643074 25375 net.cpp:84] Creating Layer cont_t=11_encode3_cont_slice_10_split
I1223 00:14:23.643077 25375 net.cpp:406] cont_t=11_encode3_cont_slice_10_split <- cont_t=11
I1223 00:14:23.643084 25375 net.cpp:380] cont_t=11_encode3_cont_slice_10_split -> cont_t=11_encode3_cont_slice_10_split_0
I1223 00:14:23.643090 25375 net.cpp:380] cont_t=11_encode3_cont_slice_10_split -> cont_t=11_encode3_cont_slice_10_split_1
I1223 00:14:23.643126 25375 net.cpp:122] Setting up cont_t=11_encode3_cont_slice_10_split
I1223 00:14:23.643131 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643136 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643137 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:23.643141 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode3_cont_slice_11_split
I1223 00:14:23.643146 25375 net.cpp:84] Creating Layer cont_t=12_encode3_cont_slice_11_split
I1223 00:14:23.643148 25375 net.cpp:406] cont_t=12_encode3_cont_slice_11_split <- cont_t=12
I1223 00:14:23.643153 25375 net.cpp:380] cont_t=12_encode3_cont_slice_11_split -> cont_t=12_encode3_cont_slice_11_split_0
I1223 00:14:23.643158 25375 net.cpp:380] cont_t=12_encode3_cont_slice_11_split -> cont_t=12_encode3_cont_slice_11_split_1
I1223 00:14:23.643193 25375 net.cpp:122] Setting up cont_t=12_encode3_cont_slice_11_split
I1223 00:14:23.643200 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643203 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643220 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:23.643224 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode3_cont_slice_12_split
I1223 00:14:23.643227 25375 net.cpp:84] Creating Layer cont_t=13_encode3_cont_slice_12_split
I1223 00:14:23.643230 25375 net.cpp:406] cont_t=13_encode3_cont_slice_12_split <- cont_t=13
I1223 00:14:23.643236 25375 net.cpp:380] cont_t=13_encode3_cont_slice_12_split -> cont_t=13_encode3_cont_slice_12_split_0
I1223 00:14:23.643242 25375 net.cpp:380] cont_t=13_encode3_cont_slice_12_split -> cont_t=13_encode3_cont_slice_12_split_1
I1223 00:14:23.643290 25375 net.cpp:122] Setting up cont_t=13_encode3_cont_slice_12_split
I1223 00:14:23.643297 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643301 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643302 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:23.643306 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode3_cont_slice_13_split
I1223 00:14:23.643309 25375 net.cpp:84] Creating Layer cont_t=14_encode3_cont_slice_13_split
I1223 00:14:23.643312 25375 net.cpp:406] cont_t=14_encode3_cont_slice_13_split <- cont_t=14
I1223 00:14:23.643317 25375 net.cpp:380] cont_t=14_encode3_cont_slice_13_split -> cont_t=14_encode3_cont_slice_13_split_0
I1223 00:14:23.643323 25375 net.cpp:380] cont_t=14_encode3_cont_slice_13_split -> cont_t=14_encode3_cont_slice_13_split_1
I1223 00:14:23.643362 25375 net.cpp:122] Setting up cont_t=14_encode3_cont_slice_13_split
I1223 00:14:23.643381 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643385 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643388 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:23.643391 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode3_cont_slice_14_split
I1223 00:14:23.643395 25375 net.cpp:84] Creating Layer cont_t=15_encode3_cont_slice_14_split
I1223 00:14:23.643399 25375 net.cpp:406] cont_t=15_encode3_cont_slice_14_split <- cont_t=15
I1223 00:14:23.643405 25375 net.cpp:380] cont_t=15_encode3_cont_slice_14_split -> cont_t=15_encode3_cont_slice_14_split_0
I1223 00:14:23.643424 25375 net.cpp:380] cont_t=15_encode3_cont_slice_14_split -> cont_t=15_encode3_cont_slice_14_split_1
I1223 00:14:23.643458 25375 net.cpp:122] Setting up cont_t=15_encode3_cont_slice_14_split
I1223 00:14:23.643465 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643467 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643483 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:23.643486 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode3_cont_slice_15_split
I1223 00:14:23.643491 25375 net.cpp:84] Creating Layer cont_t=16_encode3_cont_slice_15_split
I1223 00:14:23.643494 25375 net.cpp:406] cont_t=16_encode3_cont_slice_15_split <- cont_t=16
I1223 00:14:23.643499 25375 net.cpp:380] cont_t=16_encode3_cont_slice_15_split -> cont_t=16_encode3_cont_slice_15_split_0
I1223 00:14:23.643504 25375 net.cpp:380] cont_t=16_encode3_cont_slice_15_split -> cont_t=16_encode3_cont_slice_15_split_1
I1223 00:14:23.643553 25375 net.cpp:122] Setting up cont_t=16_encode3_cont_slice_15_split
I1223 00:14:23.643559 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643563 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.643565 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:23.643568 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_c0
I1223 00:14:23.643573 25375 net.cpp:84] Creating Layer encode3_dummy_forward_c0
I1223 00:14:23.643576 25375 net.cpp:406] encode3_dummy_forward_c0 <- c_t=0
I1223 00:14:23.643580 25375 net.cpp:367] encode3_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:23.643604 25375 net.cpp:122] Setting up encode3_dummy_forward_c0
I1223 00:14:23.643610 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.643613 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:23.643620 25375 layer_factory.hpp:77] Creating layer c_t=0_encode3_dummy_forward_c0_0_split
I1223 00:14:23.643625 25375 net.cpp:84] Creating Layer c_t=0_encode3_dummy_forward_c0_0_split
I1223 00:14:23.643628 25375 net.cpp:406] c_t=0_encode3_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:23.643633 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_0
I1223 00:14:23.643642 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_1
I1223 00:14:23.643648 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_2
I1223 00:14:23.643654 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_3
I1223 00:14:23.643723 25375 net.cpp:122] Setting up c_t=0_encode3_dummy_forward_c0_0_split
I1223 00:14:23.643729 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.643733 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.643738 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.643741 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.643744 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:23.643746 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_h0
I1223 00:14:23.643752 25375 net.cpp:84] Creating Layer encode3_dummy_forward_h0
I1223 00:14:23.643756 25375 net.cpp:406] encode3_dummy_forward_h0 <- h_t=0
I1223 00:14:23.643761 25375 net.cpp:367] encode3_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:23.643784 25375 net.cpp:122] Setting up encode3_dummy_forward_h0
I1223 00:14:23.643790 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.643792 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:23.643797 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=0
I1223 00:14:23.643805 25375 net.cpp:84] Creating Layer encode3_h_conted_t=0
I1223 00:14:23.643808 25375 net.cpp:406] encode3_h_conted_t=0 <- h_t=0
I1223 00:14:23.643813 25375 net.cpp:406] encode3_h_conted_t=0 <- cont_t=1_encode3_cont_slice_0_split_0
I1223 00:14:23.643817 25375 net.cpp:380] encode3_h_conted_t=0 -> h_conted_t=0
I1223 00:14:23.643903 25375 net.cpp:122] Setting up encode3_h_conted_t=0
I1223 00:14:23.643910 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.643914 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:23.643918 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->0
I1223 00:14:23.643926 25375 net.cpp:84] Creating Layer encode3_hidden->transform->0
I1223 00:14:23.643930 25375 net.cpp:406] encode3_hidden->transform->0 <- h_conted_t=0
I1223 00:14:23.643937 25375 net.cpp:380] encode3_hidden->transform->0 -> hidden->transform->0
I1223 00:14:23.644460 25375 net.cpp:122] Setting up encode3_hidden->transform->0
I1223 00:14:23.644469 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.644471 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:23.644479 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=0
I1223 00:14:23.644484 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=0
I1223 00:14:23.644489 25375 net.cpp:406] encode3_hadamard->input_t=0 <- c_t=0_encode3_dummy_forward_c0_0_split_0
I1223 00:14:23.644493 25375 net.cpp:380] encode3_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:23.644588 25375 net.cpp:122] Setting up encode3_hadamard->input_t=0
I1223 00:14:23.644595 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.644598 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:23.644603 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=0
I1223 00:14:23.644609 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=0
I1223 00:14:23.644613 25375 net.cpp:406] encode3_hadamard->forget_t=0 <- c_t=0_encode3_dummy_forward_c0_0_split_1
I1223 00:14:23.644618 25375 net.cpp:380] encode3_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:23.644716 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=0
I1223 00:14:23.644723 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.644726 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:23.644731 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=0
I1223 00:14:23.644737 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=0
I1223 00:14:23.644740 25375 net.cpp:406] encode3_hadamard->output_t=0 <- c_t=0_encode3_dummy_forward_c0_0_split_2
I1223 00:14:23.644745 25375 net.cpp:380] encode3_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:23.644840 25375 net.cpp:122] Setting up encode3_hadamard->output_t=0
I1223 00:14:23.644847 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.644850 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:23.644855 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=1
I1223 00:14:23.644861 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=1
I1223 00:14:23.644865 25375 net.cpp:380] encode3_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:23.644923 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=1
I1223 00:14:23.644930 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.644933 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:23.644937 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=1
I1223 00:14:23.644942 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=1
I1223 00:14:23.644946 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:23.644950 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:23.644954 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:23.644958 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:23.644963 25375 net.cpp:380] encode3_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:23.644989 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=1
I1223 00:14:23.644996 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.644999 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:23.645002 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_1
I1223 00:14:23.645007 25375 net.cpp:84] Creating Layer encode3_gate_input_1
I1223 00:14:23.645011 25375 net.cpp:406] encode3_gate_input_1 <- hidden->transform->0
I1223 00:14:23.645015 25375 net.cpp:406] encode3_gate_input_1 <- x->transform->t=1
I1223 00:14:23.645020 25375 net.cpp:406] encode3_gate_input_1 <- hadamard_t=1
I1223 00:14:23.645025 25375 net.cpp:380] encode3_gate_input_1 -> gate_input_1
I1223 00:14:23.645048 25375 net.cpp:122] Setting up encode3_gate_input_1
I1223 00:14:23.645056 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.645058 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:23.645061 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=1
I1223 00:14:23.645073 25375 net.cpp:84] Creating Layer encode3_unit_t=1
I1223 00:14:23.645077 25375 net.cpp:406] encode3_unit_t=1 <- c_t=0_encode3_dummy_forward_c0_0_split_3
I1223 00:14:23.645082 25375 net.cpp:406] encode3_unit_t=1 <- gate_input_1
I1223 00:14:23.645086 25375 net.cpp:406] encode3_unit_t=1 <- cont_t=1_encode3_cont_slice_0_split_1
I1223 00:14:23.645090 25375 net.cpp:380] encode3_unit_t=1 -> c_t=1
I1223 00:14:23.645097 25375 net.cpp:380] encode3_unit_t=1 -> h_t=1
I1223 00:14:23.645150 25375 net.cpp:122] Setting up encode3_unit_t=1
I1223 00:14:23.645157 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645161 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645164 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:23.645166 25375 layer_factory.hpp:77] Creating layer c_t=1_encode3_unit_t=1_0_split
I1223 00:14:23.645172 25375 net.cpp:84] Creating Layer c_t=1_encode3_unit_t=1_0_split
I1223 00:14:23.645175 25375 net.cpp:406] c_t=1_encode3_unit_t=1_0_split <- c_t=1
I1223 00:14:23.645181 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_0
I1223 00:14:23.645189 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_1
I1223 00:14:23.645193 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_2
I1223 00:14:23.645200 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_3
I1223 00:14:23.645262 25375 net.cpp:122] Setting up c_t=1_encode3_unit_t=1_0_split
I1223 00:14:23.645269 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645273 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645277 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645280 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645283 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:23.645285 25375 layer_factory.hpp:77] Creating layer h_t=1_encode3_unit_t=1_1_split
I1223 00:14:23.645290 25375 net.cpp:84] Creating Layer h_t=1_encode3_unit_t=1_1_split
I1223 00:14:23.645293 25375 net.cpp:406] h_t=1_encode3_unit_t=1_1_split <- h_t=1
I1223 00:14:23.645301 25375 net.cpp:380] h_t=1_encode3_unit_t=1_1_split -> h_t=1_encode3_unit_t=1_1_split_0
I1223 00:14:23.645308 25375 net.cpp:380] h_t=1_encode3_unit_t=1_1_split -> h_t=1_encode3_unit_t=1_1_split_1
I1223 00:14:23.645344 25375 net.cpp:122] Setting up h_t=1_encode3_unit_t=1_1_split
I1223 00:14:23.645351 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645355 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645357 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:23.645360 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=1
I1223 00:14:23.645365 25375 net.cpp:84] Creating Layer encode3_h_conted_t=1
I1223 00:14:23.645368 25375 net.cpp:406] encode3_h_conted_t=1 <- h_t=1_encode3_unit_t=1_1_split_0
I1223 00:14:23.645373 25375 net.cpp:406] encode3_h_conted_t=1 <- cont_t=2_encode3_cont_slice_1_split_0
I1223 00:14:23.645377 25375 net.cpp:380] encode3_h_conted_t=1 -> h_conted_t=1
I1223 00:14:23.645472 25375 net.cpp:122] Setting up encode3_h_conted_t=1
I1223 00:14:23.645478 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.645480 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:23.645483 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->1
I1223 00:14:23.645493 25375 net.cpp:84] Creating Layer encode3_hidden->transform->1
I1223 00:14:23.645495 25375 net.cpp:406] encode3_hidden->transform->1 <- h_conted_t=1
I1223 00:14:23.645503 25375 net.cpp:380] encode3_hidden->transform->1 -> hidden->transform->1
I1223 00:14:23.646045 25375 net.cpp:122] Setting up encode3_hidden->transform->1
I1223 00:14:23.646054 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.646056 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:23.646061 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.646066 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.646070 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=1
I1223 00:14:23.646075 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=1
I1223 00:14:23.646078 25375 net.cpp:406] encode3_hadamard->input_t=1 <- c_t=1_encode3_unit_t=1_0_split_0
I1223 00:14:23.646098 25375 net.cpp:380] encode3_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:23.646203 25375 net.cpp:122] Setting up encode3_hadamard->input_t=1
I1223 00:14:23.646210 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.646214 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:23.646216 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.646219 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=1
I1223 00:14:23.646226 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=1
I1223 00:14:23.646229 25375 net.cpp:406] encode3_hadamard->forget_t=1 <- c_t=1_encode3_unit_t=1_0_split_1
I1223 00:14:23.646235 25375 net.cpp:380] encode3_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:23.646378 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=1
I1223 00:14:23.646385 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.646389 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:23.646391 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.646394 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=1
I1223 00:14:23.646414 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=1
I1223 00:14:23.646416 25375 net.cpp:406] encode3_hadamard->output_t=1 <- c_t=1_encode3_unit_t=1_0_split_2
I1223 00:14:23.646420 25375 net.cpp:380] encode3_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:23.646526 25375 net.cpp:122] Setting up encode3_hadamard->output_t=1
I1223 00:14:23.646533 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.646535 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:23.646539 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.646543 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=2
I1223 00:14:23.646561 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=2
I1223 00:14:23.646565 25375 net.cpp:380] encode3_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:23.646662 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=2
I1223 00:14:23.646670 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.646685 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:23.646688 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=2
I1223 00:14:23.646708 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=2
I1223 00:14:23.646710 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:23.646715 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:23.646719 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:23.646723 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:23.646728 25375 net.cpp:380] encode3_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:23.646754 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=2
I1223 00:14:23.646759 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.646762 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:23.646765 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_2
I1223 00:14:23.646770 25375 net.cpp:84] Creating Layer encode3_gate_input_2
I1223 00:14:23.646773 25375 net.cpp:406] encode3_gate_input_2 <- hidden->transform->1
I1223 00:14:23.646778 25375 net.cpp:406] encode3_gate_input_2 <- x->transform->t=2
I1223 00:14:23.646782 25375 net.cpp:406] encode3_gate_input_2 <- hadamard_t=2
I1223 00:14:23.646787 25375 net.cpp:380] encode3_gate_input_2 -> gate_input_2
I1223 00:14:23.646811 25375 net.cpp:122] Setting up encode3_gate_input_2
I1223 00:14:23.646818 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.646821 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:23.646823 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=2
I1223 00:14:23.646831 25375 net.cpp:84] Creating Layer encode3_unit_t=2
I1223 00:14:23.646833 25375 net.cpp:406] encode3_unit_t=2 <- c_t=1_encode3_unit_t=1_0_split_3
I1223 00:14:23.646837 25375 net.cpp:406] encode3_unit_t=2 <- gate_input_2
I1223 00:14:23.646842 25375 net.cpp:406] encode3_unit_t=2 <- cont_t=2_encode3_cont_slice_1_split_1
I1223 00:14:23.646847 25375 net.cpp:380] encode3_unit_t=2 -> c_t=2
I1223 00:14:23.646852 25375 net.cpp:380] encode3_unit_t=2 -> h_t=2
I1223 00:14:23.646919 25375 net.cpp:122] Setting up encode3_unit_t=2
I1223 00:14:23.646925 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.646929 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.646931 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:23.646948 25375 layer_factory.hpp:77] Creating layer c_t=2_encode3_unit_t=2_0_split
I1223 00:14:23.646952 25375 net.cpp:84] Creating Layer c_t=2_encode3_unit_t=2_0_split
I1223 00:14:23.646955 25375 net.cpp:406] c_t=2_encode3_unit_t=2_0_split <- c_t=2
I1223 00:14:23.646962 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_0
I1223 00:14:23.646970 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_1
I1223 00:14:23.646975 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_2
I1223 00:14:23.646982 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_3
I1223 00:14:23.647061 25375 net.cpp:122] Setting up c_t=2_encode3_unit_t=2_0_split
I1223 00:14:23.647068 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.647073 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.647076 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.647079 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.647096 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:23.647099 25375 layer_factory.hpp:77] Creating layer h_t=2_encode3_unit_t=2_1_split
I1223 00:14:23.647105 25375 net.cpp:84] Creating Layer h_t=2_encode3_unit_t=2_1_split
I1223 00:14:23.647109 25375 net.cpp:406] h_t=2_encode3_unit_t=2_1_split <- h_t=2
I1223 00:14:23.647114 25375 net.cpp:380] h_t=2_encode3_unit_t=2_1_split -> h_t=2_encode3_unit_t=2_1_split_0
I1223 00:14:23.647119 25375 net.cpp:380] h_t=2_encode3_unit_t=2_1_split -> h_t=2_encode3_unit_t=2_1_split_1
I1223 00:14:23.647169 25375 net.cpp:122] Setting up h_t=2_encode3_unit_t=2_1_split
I1223 00:14:23.647187 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.647192 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.647208 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:23.647210 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=2
I1223 00:14:23.647215 25375 net.cpp:84] Creating Layer encode3_h_conted_t=2
I1223 00:14:23.647219 25375 net.cpp:406] encode3_h_conted_t=2 <- h_t=2_encode3_unit_t=2_1_split_0
I1223 00:14:23.647223 25375 net.cpp:406] encode3_h_conted_t=2 <- cont_t=3_encode3_cont_slice_2_split_0
I1223 00:14:23.647228 25375 net.cpp:380] encode3_h_conted_t=2 -> h_conted_t=2
I1223 00:14:23.647336 25375 net.cpp:122] Setting up encode3_h_conted_t=2
I1223 00:14:23.647343 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.647359 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:23.647361 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->2
I1223 00:14:23.647382 25375 net.cpp:84] Creating Layer encode3_hidden->transform->2
I1223 00:14:23.647387 25375 net.cpp:406] encode3_hidden->transform->2 <- h_conted_t=2
I1223 00:14:23.647397 25375 net.cpp:380] encode3_hidden->transform->2 -> hidden->transform->2
I1223 00:14:23.647925 25375 net.cpp:122] Setting up encode3_hidden->transform->2
I1223 00:14:23.647933 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.647936 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:23.647940 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.647943 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.647946 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=2
I1223 00:14:23.647965 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=2
I1223 00:14:23.647969 25375 net.cpp:406] encode3_hadamard->input_t=2 <- c_t=2_encode3_unit_t=2_0_split_0
I1223 00:14:23.647975 25375 net.cpp:380] encode3_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:23.648087 25375 net.cpp:122] Setting up encode3_hadamard->input_t=2
I1223 00:14:23.648094 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648097 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:23.648100 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.648103 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=2
I1223 00:14:23.648121 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=2
I1223 00:14:23.648124 25375 net.cpp:406] encode3_hadamard->forget_t=2 <- c_t=2_encode3_unit_t=2_0_split_1
I1223 00:14:23.648130 25375 net.cpp:380] encode3_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:23.648231 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=2
I1223 00:14:23.648238 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648241 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:23.648247 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.648263 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=2
I1223 00:14:23.648268 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=2
I1223 00:14:23.648272 25375 net.cpp:406] encode3_hadamard->output_t=2 <- c_t=2_encode3_unit_t=2_0_split_2
I1223 00:14:23.648291 25375 net.cpp:380] encode3_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:23.648411 25375 net.cpp:122] Setting up encode3_hadamard->output_t=2
I1223 00:14:23.648419 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648422 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:23.648425 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.648428 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=3
I1223 00:14:23.648447 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=3
I1223 00:14:23.648452 25375 net.cpp:380] encode3_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:23.648536 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=3
I1223 00:14:23.648543 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648546 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:23.648563 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=3
I1223 00:14:23.648571 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=3
I1223 00:14:23.648574 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:23.648579 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:23.648582 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:23.648586 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:23.648591 25375 net.cpp:380] encode3_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:23.648615 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=3
I1223 00:14:23.648622 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.648624 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:23.648627 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_3
I1223 00:14:23.648633 25375 net.cpp:84] Creating Layer encode3_gate_input_3
I1223 00:14:23.648638 25375 net.cpp:406] encode3_gate_input_3 <- hidden->transform->2
I1223 00:14:23.648641 25375 net.cpp:406] encode3_gate_input_3 <- x->transform->t=3
I1223 00:14:23.648645 25375 net.cpp:406] encode3_gate_input_3 <- hadamard_t=3
I1223 00:14:23.648653 25375 net.cpp:380] encode3_gate_input_3 -> gate_input_3
I1223 00:14:23.648674 25375 net.cpp:122] Setting up encode3_gate_input_3
I1223 00:14:23.648680 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.648684 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:23.648686 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=3
I1223 00:14:23.648694 25375 net.cpp:84] Creating Layer encode3_unit_t=3
I1223 00:14:23.648696 25375 net.cpp:406] encode3_unit_t=3 <- c_t=2_encode3_unit_t=2_0_split_3
I1223 00:14:23.648700 25375 net.cpp:406] encode3_unit_t=3 <- gate_input_3
I1223 00:14:23.648705 25375 net.cpp:406] encode3_unit_t=3 <- cont_t=3_encode3_cont_slice_2_split_1
I1223 00:14:23.648710 25375 net.cpp:380] encode3_unit_t=3 -> c_t=3
I1223 00:14:23.648715 25375 net.cpp:380] encode3_unit_t=3 -> h_t=3
I1223 00:14:23.648777 25375 net.cpp:122] Setting up encode3_unit_t=3
I1223 00:14:23.648784 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648788 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648792 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:23.648793 25375 layer_factory.hpp:77] Creating layer c_t=3_encode3_unit_t=3_0_split
I1223 00:14:23.648799 25375 net.cpp:84] Creating Layer c_t=3_encode3_unit_t=3_0_split
I1223 00:14:23.648815 25375 net.cpp:406] c_t=3_encode3_unit_t=3_0_split <- c_t=3
I1223 00:14:23.648821 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_0
I1223 00:14:23.648828 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_1
I1223 00:14:23.648834 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_2
I1223 00:14:23.648840 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_3
I1223 00:14:23.648914 25375 net.cpp:122] Setting up c_t=3_encode3_unit_t=3_0_split
I1223 00:14:23.648934 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648938 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648942 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648946 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.648948 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:23.648952 25375 layer_factory.hpp:77] Creating layer h_t=3_encode3_unit_t=3_1_split
I1223 00:14:23.648955 25375 net.cpp:84] Creating Layer h_t=3_encode3_unit_t=3_1_split
I1223 00:14:23.648958 25375 net.cpp:406] h_t=3_encode3_unit_t=3_1_split <- h_t=3
I1223 00:14:23.648977 25375 net.cpp:380] h_t=3_encode3_unit_t=3_1_split -> h_t=3_encode3_unit_t=3_1_split_0
I1223 00:14:23.648983 25375 net.cpp:380] h_t=3_encode3_unit_t=3_1_split -> h_t=3_encode3_unit_t=3_1_split_1
I1223 00:14:23.649019 25375 net.cpp:122] Setting up h_t=3_encode3_unit_t=3_1_split
I1223 00:14:23.649025 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.649029 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.649032 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:23.649035 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=3
I1223 00:14:23.649044 25375 net.cpp:84] Creating Layer encode3_h_conted_t=3
I1223 00:14:23.649046 25375 net.cpp:406] encode3_h_conted_t=3 <- h_t=3_encode3_unit_t=3_1_split_0
I1223 00:14:23.649051 25375 net.cpp:406] encode3_h_conted_t=3 <- cont_t=4_encode3_cont_slice_3_split_0
I1223 00:14:23.649056 25375 net.cpp:380] encode3_h_conted_t=3 -> h_conted_t=3
I1223 00:14:23.649158 25375 net.cpp:122] Setting up encode3_h_conted_t=3
I1223 00:14:23.649166 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.649170 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:23.649186 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->3
I1223 00:14:23.649196 25375 net.cpp:84] Creating Layer encode3_hidden->transform->3
I1223 00:14:23.649200 25375 net.cpp:406] encode3_hidden->transform->3 <- h_conted_t=3
I1223 00:14:23.649206 25375 net.cpp:380] encode3_hidden->transform->3 -> hidden->transform->3
I1223 00:14:23.649737 25375 net.cpp:122] Setting up encode3_hidden->transform->3
I1223 00:14:23.649745 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.649749 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:23.649752 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.649755 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.649760 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=3
I1223 00:14:23.649782 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=3
I1223 00:14:23.649799 25375 net.cpp:406] encode3_hadamard->input_t=3 <- c_t=3_encode3_unit_t=3_0_split_0
I1223 00:14:23.649804 25375 net.cpp:380] encode3_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:23.649912 25375 net.cpp:122] Setting up encode3_hadamard->input_t=3
I1223 00:14:23.649919 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.649922 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:23.649925 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.649929 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=3
I1223 00:14:23.649948 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=3
I1223 00:14:23.649951 25375 net.cpp:406] encode3_hadamard->forget_t=3 <- c_t=3_encode3_unit_t=3_0_split_1
I1223 00:14:23.649969 25375 net.cpp:380] encode3_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:23.650096 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=3
I1223 00:14:23.650102 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650105 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:23.650108 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.650111 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=3
I1223 00:14:23.650130 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=3
I1223 00:14:23.650132 25375 net.cpp:406] encode3_hadamard->output_t=3 <- c_t=3_encode3_unit_t=3_0_split_2
I1223 00:14:23.650140 25375 net.cpp:380] encode3_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:23.650274 25375 net.cpp:122] Setting up encode3_hadamard->output_t=3
I1223 00:14:23.650281 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650285 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:23.650288 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.650291 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=4
I1223 00:14:23.650296 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=4
I1223 00:14:23.650301 25375 net.cpp:380] encode3_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:23.650368 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=4
I1223 00:14:23.650375 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650378 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:23.650394 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=4
I1223 00:14:23.650401 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=4
I1223 00:14:23.650404 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:23.650409 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:23.650413 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:23.650418 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:23.650421 25375 net.cpp:380] encode3_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:23.650445 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=4
I1223 00:14:23.650465 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.650467 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:23.650470 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_4
I1223 00:14:23.650480 25375 net.cpp:84] Creating Layer encode3_gate_input_4
I1223 00:14:23.650485 25375 net.cpp:406] encode3_gate_input_4 <- hidden->transform->3
I1223 00:14:23.650502 25375 net.cpp:406] encode3_gate_input_4 <- x->transform->t=4
I1223 00:14:23.650506 25375 net.cpp:406] encode3_gate_input_4 <- hadamard_t=4
I1223 00:14:23.650511 25375 net.cpp:380] encode3_gate_input_4 -> gate_input_4
I1223 00:14:23.650539 25375 net.cpp:122] Setting up encode3_gate_input_4
I1223 00:14:23.650547 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.650549 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:23.650552 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=4
I1223 00:14:23.650557 25375 net.cpp:84] Creating Layer encode3_unit_t=4
I1223 00:14:23.650562 25375 net.cpp:406] encode3_unit_t=4 <- c_t=3_encode3_unit_t=3_0_split_3
I1223 00:14:23.650578 25375 net.cpp:406] encode3_unit_t=4 <- gate_input_4
I1223 00:14:23.650581 25375 net.cpp:406] encode3_unit_t=4 <- cont_t=4_encode3_cont_slice_3_split_1
I1223 00:14:23.650600 25375 net.cpp:380] encode3_unit_t=4 -> c_t=4
I1223 00:14:23.650606 25375 net.cpp:380] encode3_unit_t=4 -> h_t=4
I1223 00:14:23.650668 25375 net.cpp:122] Setting up encode3_unit_t=4
I1223 00:14:23.650676 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650692 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650696 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:23.650710 25375 layer_factory.hpp:77] Creating layer c_t=4_encode3_unit_t=4_0_split
I1223 00:14:23.650717 25375 net.cpp:84] Creating Layer c_t=4_encode3_unit_t=4_0_split
I1223 00:14:23.650733 25375 net.cpp:406] c_t=4_encode3_unit_t=4_0_split <- c_t=4
I1223 00:14:23.650738 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_0
I1223 00:14:23.650758 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_1
I1223 00:14:23.650763 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_2
I1223 00:14:23.650769 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_3
I1223 00:14:23.650831 25375 net.cpp:122] Setting up c_t=4_encode3_unit_t=4_0_split
I1223 00:14:23.650851 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650854 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650858 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650876 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650877 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:23.650880 25375 layer_factory.hpp:77] Creating layer h_t=4_encode3_unit_t=4_1_split
I1223 00:14:23.650898 25375 net.cpp:84] Creating Layer h_t=4_encode3_unit_t=4_1_split
I1223 00:14:23.650902 25375 net.cpp:406] h_t=4_encode3_unit_t=4_1_split <- h_t=4
I1223 00:14:23.650907 25375 net.cpp:380] h_t=4_encode3_unit_t=4_1_split -> h_t=4_encode3_unit_t=4_1_split_0
I1223 00:14:23.650913 25375 net.cpp:380] h_t=4_encode3_unit_t=4_1_split -> h_t=4_encode3_unit_t=4_1_split_1
I1223 00:14:23.650948 25375 net.cpp:122] Setting up h_t=4_encode3_unit_t=4_1_split
I1223 00:14:23.650967 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650971 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.650974 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:23.650976 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=4
I1223 00:14:23.650982 25375 net.cpp:84] Creating Layer encode3_h_conted_t=4
I1223 00:14:23.650986 25375 net.cpp:406] encode3_h_conted_t=4 <- h_t=4_encode3_unit_t=4_1_split_0
I1223 00:14:23.650990 25375 net.cpp:406] encode3_h_conted_t=4 <- cont_t=5_encode3_cont_slice_4_split_0
I1223 00:14:23.650997 25375 net.cpp:380] encode3_h_conted_t=4 -> h_conted_t=4
I1223 00:14:23.651094 25375 net.cpp:122] Setting up encode3_h_conted_t=4
I1223 00:14:23.651101 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.651103 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:23.651108 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->4
I1223 00:14:23.651115 25375 net.cpp:84] Creating Layer encode3_hidden->transform->4
I1223 00:14:23.651119 25375 net.cpp:406] encode3_hidden->transform->4 <- h_conted_t=4
I1223 00:14:23.651142 25375 net.cpp:380] encode3_hidden->transform->4 -> hidden->transform->4
I1223 00:14:23.651659 25375 net.cpp:122] Setting up encode3_hidden->transform->4
I1223 00:14:23.651666 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.651669 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:23.651674 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.651677 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.651680 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=4
I1223 00:14:23.651686 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=4
I1223 00:14:23.651690 25375 net.cpp:406] encode3_hadamard->input_t=4 <- c_t=4_encode3_unit_t=4_0_split_0
I1223 00:14:23.651695 25375 net.cpp:380] encode3_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:23.651803 25375 net.cpp:122] Setting up encode3_hadamard->input_t=4
I1223 00:14:23.651810 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.651813 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:23.651818 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.651820 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=4
I1223 00:14:23.651839 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=4
I1223 00:14:23.651842 25375 net.cpp:406] encode3_hadamard->forget_t=4 <- c_t=4_encode3_unit_t=4_0_split_1
I1223 00:14:23.651861 25375 net.cpp:380] encode3_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:23.651960 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=4
I1223 00:14:23.651968 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.651969 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:23.651973 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.651976 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=4
I1223 00:14:23.651995 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=4
I1223 00:14:23.651998 25375 net.cpp:406] encode3_hadamard->output_t=4 <- c_t=4_encode3_unit_t=4_0_split_2
I1223 00:14:23.652004 25375 net.cpp:380] encode3_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:23.652112 25375 net.cpp:122] Setting up encode3_hadamard->output_t=4
I1223 00:14:23.652119 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652122 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:23.652125 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.652129 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=5
I1223 00:14:23.652134 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=5
I1223 00:14:23.652138 25375 net.cpp:380] encode3_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:23.652218 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=5
I1223 00:14:23.652225 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652228 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:23.652231 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=5
I1223 00:14:23.652237 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=5
I1223 00:14:23.652240 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:23.652245 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:23.652249 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:23.652253 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:23.652257 25375 net.cpp:380] encode3_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:23.652297 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=5
I1223 00:14:23.652303 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.652307 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:23.652309 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_5
I1223 00:14:23.652315 25375 net.cpp:84] Creating Layer encode3_gate_input_5
I1223 00:14:23.652318 25375 net.cpp:406] encode3_gate_input_5 <- hidden->transform->4
I1223 00:14:23.652323 25375 net.cpp:406] encode3_gate_input_5 <- x->transform->t=5
I1223 00:14:23.652326 25375 net.cpp:406] encode3_gate_input_5 <- hadamard_t=5
I1223 00:14:23.652331 25375 net.cpp:380] encode3_gate_input_5 -> gate_input_5
I1223 00:14:23.652355 25375 net.cpp:122] Setting up encode3_gate_input_5
I1223 00:14:23.652362 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.652365 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:23.652367 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=5
I1223 00:14:23.652372 25375 net.cpp:84] Creating Layer encode3_unit_t=5
I1223 00:14:23.652376 25375 net.cpp:406] encode3_unit_t=5 <- c_t=4_encode3_unit_t=4_0_split_3
I1223 00:14:23.652380 25375 net.cpp:406] encode3_unit_t=5 <- gate_input_5
I1223 00:14:23.652384 25375 net.cpp:406] encode3_unit_t=5 <- cont_t=5_encode3_cont_slice_4_split_1
I1223 00:14:23.652389 25375 net.cpp:380] encode3_unit_t=5 -> c_t=5
I1223 00:14:23.652395 25375 net.cpp:380] encode3_unit_t=5 -> h_t=5
I1223 00:14:23.652472 25375 net.cpp:122] Setting up encode3_unit_t=5
I1223 00:14:23.652478 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652482 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652485 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:23.652488 25375 layer_factory.hpp:77] Creating layer c_t=5_encode3_unit_t=5_0_split
I1223 00:14:23.652494 25375 net.cpp:84] Creating Layer c_t=5_encode3_unit_t=5_0_split
I1223 00:14:23.652498 25375 net.cpp:406] c_t=5_encode3_unit_t=5_0_split <- c_t=5
I1223 00:14:23.652504 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_0
I1223 00:14:23.652510 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_1
I1223 00:14:23.652516 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_2
I1223 00:14:23.652521 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_3
I1223 00:14:23.652609 25375 net.cpp:122] Setting up c_t=5_encode3_unit_t=5_0_split
I1223 00:14:23.652618 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652622 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652626 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652642 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652645 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:23.652647 25375 layer_factory.hpp:77] Creating layer h_t=5_encode3_unit_t=5_1_split
I1223 00:14:23.652652 25375 net.cpp:84] Creating Layer h_t=5_encode3_unit_t=5_1_split
I1223 00:14:23.652655 25375 net.cpp:406] h_t=5_encode3_unit_t=5_1_split <- h_t=5
I1223 00:14:23.652662 25375 net.cpp:380] h_t=5_encode3_unit_t=5_1_split -> h_t=5_encode3_unit_t=5_1_split_0
I1223 00:14:23.652668 25375 net.cpp:380] h_t=5_encode3_unit_t=5_1_split -> h_t=5_encode3_unit_t=5_1_split_1
I1223 00:14:23.652731 25375 net.cpp:122] Setting up h_t=5_encode3_unit_t=5_1_split
I1223 00:14:23.652739 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652755 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652757 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:23.652760 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=5
I1223 00:14:23.652765 25375 net.cpp:84] Creating Layer encode3_h_conted_t=5
I1223 00:14:23.652768 25375 net.cpp:406] encode3_h_conted_t=5 <- h_t=5_encode3_unit_t=5_1_split_0
I1223 00:14:23.652772 25375 net.cpp:406] encode3_h_conted_t=5 <- cont_t=6_encode3_cont_slice_5_split_0
I1223 00:14:23.652777 25375 net.cpp:380] encode3_h_conted_t=5 -> h_conted_t=5
I1223 00:14:23.652875 25375 net.cpp:122] Setting up encode3_h_conted_t=5
I1223 00:14:23.652882 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.652885 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:23.652889 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->5
I1223 00:14:23.652909 25375 net.cpp:84] Creating Layer encode3_hidden->transform->5
I1223 00:14:23.652914 25375 net.cpp:406] encode3_hidden->transform->5 <- h_conted_t=5
I1223 00:14:23.652920 25375 net.cpp:380] encode3_hidden->transform->5 -> hidden->transform->5
I1223 00:14:23.653479 25375 net.cpp:122] Setting up encode3_hidden->transform->5
I1223 00:14:23.653491 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.653493 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:23.653497 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.653501 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.653506 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=5
I1223 00:14:23.653525 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=5
I1223 00:14:23.653529 25375 net.cpp:406] encode3_hadamard->input_t=5 <- c_t=5_encode3_unit_t=5_0_split_0
I1223 00:14:23.653534 25375 net.cpp:380] encode3_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:23.653650 25375 net.cpp:122] Setting up encode3_hadamard->input_t=5
I1223 00:14:23.653657 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.653661 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:23.653663 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.653667 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=5
I1223 00:14:23.653687 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=5
I1223 00:14:23.653690 25375 net.cpp:406] encode3_hadamard->forget_t=5 <- c_t=5_encode3_unit_t=5_0_split_1
I1223 00:14:23.653697 25375 net.cpp:380] encode3_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:23.653807 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=5
I1223 00:14:23.653815 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.653816 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:23.653820 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.653823 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=5
I1223 00:14:23.653841 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=5
I1223 00:14:23.653843 25375 net.cpp:406] encode3_hadamard->output_t=5 <- c_t=5_encode3_unit_t=5_0_split_2
I1223 00:14:23.653848 25375 net.cpp:380] encode3_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:23.653949 25375 net.cpp:122] Setting up encode3_hadamard->output_t=5
I1223 00:14:23.653955 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.653957 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:23.653964 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.653967 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=6
I1223 00:14:23.653985 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=6
I1223 00:14:23.653990 25375 net.cpp:380] encode3_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:23.654057 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=6
I1223 00:14:23.654064 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654067 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:23.654069 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=6
I1223 00:14:23.654076 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=6
I1223 00:14:23.654094 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:23.654098 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:23.654115 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:23.654119 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:23.654125 25375 net.cpp:380] encode3_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:23.654151 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=6
I1223 00:14:23.654158 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.654161 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:23.654165 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_6
I1223 00:14:23.654170 25375 net.cpp:84] Creating Layer encode3_gate_input_6
I1223 00:14:23.654172 25375 net.cpp:406] encode3_gate_input_6 <- hidden->transform->5
I1223 00:14:23.654189 25375 net.cpp:406] encode3_gate_input_6 <- x->transform->t=6
I1223 00:14:23.654193 25375 net.cpp:406] encode3_gate_input_6 <- hadamard_t=6
I1223 00:14:23.654212 25375 net.cpp:380] encode3_gate_input_6 -> gate_input_6
I1223 00:14:23.654248 25375 net.cpp:122] Setting up encode3_gate_input_6
I1223 00:14:23.654254 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.654258 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:23.654260 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=6
I1223 00:14:23.654265 25375 net.cpp:84] Creating Layer encode3_unit_t=6
I1223 00:14:23.654268 25375 net.cpp:406] encode3_unit_t=6 <- c_t=5_encode3_unit_t=5_0_split_3
I1223 00:14:23.654273 25375 net.cpp:406] encode3_unit_t=6 <- gate_input_6
I1223 00:14:23.654276 25375 net.cpp:406] encode3_unit_t=6 <- cont_t=6_encode3_cont_slice_5_split_1
I1223 00:14:23.654284 25375 net.cpp:380] encode3_unit_t=6 -> c_t=6
I1223 00:14:23.654304 25375 net.cpp:380] encode3_unit_t=6 -> h_t=6
I1223 00:14:23.654368 25375 net.cpp:122] Setting up encode3_unit_t=6
I1223 00:14:23.654374 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654379 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654381 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:23.654397 25375 layer_factory.hpp:77] Creating layer c_t=6_encode3_unit_t=6_0_split
I1223 00:14:23.654403 25375 net.cpp:84] Creating Layer c_t=6_encode3_unit_t=6_0_split
I1223 00:14:23.654407 25375 net.cpp:406] c_t=6_encode3_unit_t=6_0_split <- c_t=6
I1223 00:14:23.654412 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_0
I1223 00:14:23.654419 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_1
I1223 00:14:23.654425 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_2
I1223 00:14:23.654430 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_3
I1223 00:14:23.654494 25375 net.cpp:122] Setting up c_t=6_encode3_unit_t=6_0_split
I1223 00:14:23.654515 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654518 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654536 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654539 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654542 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:23.654546 25375 layer_factory.hpp:77] Creating layer h_t=6_encode3_unit_t=6_1_split
I1223 00:14:23.654551 25375 net.cpp:84] Creating Layer h_t=6_encode3_unit_t=6_1_split
I1223 00:14:23.654554 25375 net.cpp:406] h_t=6_encode3_unit_t=6_1_split <- h_t=6
I1223 00:14:23.654559 25375 net.cpp:380] h_t=6_encode3_unit_t=6_1_split -> h_t=6_encode3_unit_t=6_1_split_0
I1223 00:14:23.654566 25375 net.cpp:380] h_t=6_encode3_unit_t=6_1_split -> h_t=6_encode3_unit_t=6_1_split_1
I1223 00:14:23.654603 25375 net.cpp:122] Setting up h_t=6_encode3_unit_t=6_1_split
I1223 00:14:23.654623 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654628 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654630 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:23.654633 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=6
I1223 00:14:23.654637 25375 net.cpp:84] Creating Layer encode3_h_conted_t=6
I1223 00:14:23.654641 25375 net.cpp:406] encode3_h_conted_t=6 <- h_t=6_encode3_unit_t=6_1_split_0
I1223 00:14:23.654645 25375 net.cpp:406] encode3_h_conted_t=6 <- cont_t=7_encode3_cont_slice_6_split_0
I1223 00:14:23.654665 25375 net.cpp:380] encode3_h_conted_t=6 -> h_conted_t=6
I1223 00:14:23.654762 25375 net.cpp:122] Setting up encode3_h_conted_t=6
I1223 00:14:23.654769 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.654772 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:23.654775 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->6
I1223 00:14:23.654783 25375 net.cpp:84] Creating Layer encode3_hidden->transform->6
I1223 00:14:23.654788 25375 net.cpp:406] encode3_hidden->transform->6 <- h_conted_t=6
I1223 00:14:23.654794 25375 net.cpp:380] encode3_hidden->transform->6 -> hidden->transform->6
I1223 00:14:23.655328 25375 net.cpp:122] Setting up encode3_hidden->transform->6
I1223 00:14:23.655335 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.655339 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:23.655342 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.655346 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.655349 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=6
I1223 00:14:23.655354 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=6
I1223 00:14:23.655371 25375 net.cpp:406] encode3_hadamard->input_t=6 <- c_t=6_encode3_unit_t=6_0_split_0
I1223 00:14:23.655378 25375 net.cpp:380] encode3_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:23.655485 25375 net.cpp:122] Setting up encode3_hadamard->input_t=6
I1223 00:14:23.655493 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.655495 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:23.655499 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.655503 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=6
I1223 00:14:23.655508 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=6
I1223 00:14:23.655524 25375 net.cpp:406] encode3_hadamard->forget_t=6 <- c_t=6_encode3_unit_t=6_0_split_1
I1223 00:14:23.655544 25375 net.cpp:380] encode3_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:23.655660 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=6
I1223 00:14:23.655668 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.655671 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:23.655674 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.655678 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=6
I1223 00:14:23.655695 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=6
I1223 00:14:23.655699 25375 net.cpp:406] encode3_hadamard->output_t=6 <- c_t=6_encode3_unit_t=6_0_split_2
I1223 00:14:23.655717 25375 net.cpp:380] encode3_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:23.655833 25375 net.cpp:122] Setting up encode3_hadamard->output_t=6
I1223 00:14:23.655841 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.655843 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:23.655848 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.655850 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=7
I1223 00:14:23.655855 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=7
I1223 00:14:23.655874 25375 net.cpp:380] encode3_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:23.655956 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=7
I1223 00:14:23.655962 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.655966 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:23.655968 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=7
I1223 00:14:23.655975 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=7
I1223 00:14:23.655980 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:23.655985 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:23.655988 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:23.655992 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:23.655997 25375 net.cpp:380] encode3_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:23.656023 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=7
I1223 00:14:23.656028 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.656031 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:23.656033 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_7
I1223 00:14:23.656039 25375 net.cpp:84] Creating Layer encode3_gate_input_7
I1223 00:14:23.656042 25375 net.cpp:406] encode3_gate_input_7 <- hidden->transform->6
I1223 00:14:23.656060 25375 net.cpp:406] encode3_gate_input_7 <- x->transform->t=7
I1223 00:14:23.656064 25375 net.cpp:406] encode3_gate_input_7 <- hadamard_t=7
I1223 00:14:23.656071 25375 net.cpp:380] encode3_gate_input_7 -> gate_input_7
I1223 00:14:23.656095 25375 net.cpp:122] Setting up encode3_gate_input_7
I1223 00:14:23.656101 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.656105 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:23.656107 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=7
I1223 00:14:23.656113 25375 net.cpp:84] Creating Layer encode3_unit_t=7
I1223 00:14:23.656116 25375 net.cpp:406] encode3_unit_t=7 <- c_t=6_encode3_unit_t=6_0_split_3
I1223 00:14:23.656121 25375 net.cpp:406] encode3_unit_t=7 <- gate_input_7
I1223 00:14:23.656126 25375 net.cpp:406] encode3_unit_t=7 <- cont_t=7_encode3_cont_slice_6_split_1
I1223 00:14:23.656131 25375 net.cpp:380] encode3_unit_t=7 -> c_t=7
I1223 00:14:23.656152 25375 net.cpp:380] encode3_unit_t=7 -> h_t=7
I1223 00:14:23.656219 25375 net.cpp:122] Setting up encode3_unit_t=7
I1223 00:14:23.656225 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656244 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656246 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:23.656250 25375 layer_factory.hpp:77] Creating layer c_t=7_encode3_unit_t=7_0_split
I1223 00:14:23.656255 25375 net.cpp:84] Creating Layer c_t=7_encode3_unit_t=7_0_split
I1223 00:14:23.656257 25375 net.cpp:406] c_t=7_encode3_unit_t=7_0_split <- c_t=7
I1223 00:14:23.656263 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_0
I1223 00:14:23.656283 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_1
I1223 00:14:23.656289 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_2
I1223 00:14:23.656294 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_3
I1223 00:14:23.656370 25375 net.cpp:122] Setting up c_t=7_encode3_unit_t=7_0_split
I1223 00:14:23.656378 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656381 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656385 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656389 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656391 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:23.656394 25375 layer_factory.hpp:77] Creating layer h_t=7_encode3_unit_t=7_1_split
I1223 00:14:23.656399 25375 net.cpp:84] Creating Layer h_t=7_encode3_unit_t=7_1_split
I1223 00:14:23.656402 25375 net.cpp:406] h_t=7_encode3_unit_t=7_1_split <- h_t=7
I1223 00:14:23.656406 25375 net.cpp:380] h_t=7_encode3_unit_t=7_1_split -> h_t=7_encode3_unit_t=7_1_split_0
I1223 00:14:23.656412 25375 net.cpp:380] h_t=7_encode3_unit_t=7_1_split -> h_t=7_encode3_unit_t=7_1_split_1
I1223 00:14:23.656461 25375 net.cpp:122] Setting up h_t=7_encode3_unit_t=7_1_split
I1223 00:14:23.656467 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656471 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.656474 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:23.656477 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=7
I1223 00:14:23.656482 25375 net.cpp:84] Creating Layer encode3_h_conted_t=7
I1223 00:14:23.656486 25375 net.cpp:406] encode3_h_conted_t=7 <- h_t=7_encode3_unit_t=7_1_split_0
I1223 00:14:23.656491 25375 net.cpp:406] encode3_h_conted_t=7 <- cont_t=8_encode3_cont_slice_7_split_0
I1223 00:14:23.656497 25375 net.cpp:380] encode3_h_conted_t=7 -> h_conted_t=7
I1223 00:14:23.657364 25375 net.cpp:122] Setting up encode3_h_conted_t=7
I1223 00:14:23.657375 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.657392 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:23.657395 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->7
I1223 00:14:23.657403 25375 net.cpp:84] Creating Layer encode3_hidden->transform->7
I1223 00:14:23.657408 25375 net.cpp:406] encode3_hidden->transform->7 <- h_conted_t=7
I1223 00:14:23.657416 25375 net.cpp:380] encode3_hidden->transform->7 -> hidden->transform->7
I1223 00:14:23.658049 25375 net.cpp:122] Setting up encode3_hidden->transform->7
I1223 00:14:23.658057 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.658061 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:23.658064 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.658082 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.658085 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=7
I1223 00:14:23.658090 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=7
I1223 00:14:23.658094 25375 net.cpp:406] encode3_hadamard->input_t=7 <- c_t=7_encode3_unit_t=7_0_split_0
I1223 00:14:23.658102 25375 net.cpp:380] encode3_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:23.658208 25375 net.cpp:122] Setting up encode3_hadamard->input_t=7
I1223 00:14:23.658216 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658219 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:23.658222 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.658226 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=7
I1223 00:14:23.658232 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=7
I1223 00:14:23.658236 25375 net.cpp:406] encode3_hadamard->forget_t=7 <- c_t=7_encode3_unit_t=7_0_split_1
I1223 00:14:23.658242 25375 net.cpp:380] encode3_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:23.658354 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=7
I1223 00:14:23.658361 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658365 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:23.658367 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.658370 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=7
I1223 00:14:23.658375 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=7
I1223 00:14:23.658393 25375 net.cpp:406] encode3_hadamard->output_t=7 <- c_t=7_encode3_unit_t=7_0_split_2
I1223 00:14:23.658399 25375 net.cpp:380] encode3_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:23.658505 25375 net.cpp:122] Setting up encode3_hadamard->output_t=7
I1223 00:14:23.658514 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658516 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:23.658520 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.658524 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=8
I1223 00:14:23.658542 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=8
I1223 00:14:23.658548 25375 net.cpp:380] encode3_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:23.658613 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=8
I1223 00:14:23.658620 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658623 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:23.658627 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=8
I1223 00:14:23.658648 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=8
I1223 00:14:23.658650 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:23.658654 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:23.658659 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:23.658663 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:23.658668 25375 net.cpp:380] encode3_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:23.658692 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=8
I1223 00:14:23.658699 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.658701 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:23.658704 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_8
I1223 00:14:23.658710 25375 net.cpp:84] Creating Layer encode3_gate_input_8
I1223 00:14:23.658713 25375 net.cpp:406] encode3_gate_input_8 <- hidden->transform->7
I1223 00:14:23.658717 25375 net.cpp:406] encode3_gate_input_8 <- x->transform->t=8
I1223 00:14:23.658720 25375 net.cpp:406] encode3_gate_input_8 <- hadamard_t=8
I1223 00:14:23.658727 25375 net.cpp:380] encode3_gate_input_8 -> gate_input_8
I1223 00:14:23.658752 25375 net.cpp:122] Setting up encode3_gate_input_8
I1223 00:14:23.658758 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.658761 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:23.658764 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=8
I1223 00:14:23.658769 25375 net.cpp:84] Creating Layer encode3_unit_t=8
I1223 00:14:23.658773 25375 net.cpp:406] encode3_unit_t=8 <- c_t=7_encode3_unit_t=7_0_split_3
I1223 00:14:23.658777 25375 net.cpp:406] encode3_unit_t=8 <- gate_input_8
I1223 00:14:23.658782 25375 net.cpp:406] encode3_unit_t=8 <- cont_t=8_encode3_cont_slice_7_split_1
I1223 00:14:23.658787 25375 net.cpp:380] encode3_unit_t=8 -> c_t=8
I1223 00:14:23.658794 25375 net.cpp:380] encode3_unit_t=8 -> h_t=8
I1223 00:14:23.658859 25375 net.cpp:122] Setting up encode3_unit_t=8
I1223 00:14:23.658867 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658871 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658874 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:23.658877 25375 layer_factory.hpp:77] Creating layer c_t=8_encode3_unit_t=8_0_split
I1223 00:14:23.658882 25375 net.cpp:84] Creating Layer c_t=8_encode3_unit_t=8_0_split
I1223 00:14:23.658886 25375 net.cpp:406] c_t=8_encode3_unit_t=8_0_split <- c_t=8
I1223 00:14:23.658891 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_0
I1223 00:14:23.658900 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_1
I1223 00:14:23.658905 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_2
I1223 00:14:23.658912 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_3
I1223 00:14:23.658977 25375 net.cpp:122] Setting up c_t=8_encode3_unit_t=8_0_split
I1223 00:14:23.658983 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658987 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658991 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658994 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.658998 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:23.659000 25375 layer_factory.hpp:77] Creating layer h_t=8_encode3_unit_t=8_1_split
I1223 00:14:23.659006 25375 net.cpp:84] Creating Layer h_t=8_encode3_unit_t=8_1_split
I1223 00:14:23.659010 25375 net.cpp:406] h_t=8_encode3_unit_t=8_1_split <- h_t=8
I1223 00:14:23.659014 25375 net.cpp:380] h_t=8_encode3_unit_t=8_1_split -> h_t=8_encode3_unit_t=8_1_split_0
I1223 00:14:23.659020 25375 net.cpp:380] h_t=8_encode3_unit_t=8_1_split -> h_t=8_encode3_unit_t=8_1_split_1
I1223 00:14:23.659061 25375 net.cpp:122] Setting up h_t=8_encode3_unit_t=8_1_split
I1223 00:14:23.659068 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.659072 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.659075 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:23.659078 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=8
I1223 00:14:23.659083 25375 net.cpp:84] Creating Layer encode3_h_conted_t=8
I1223 00:14:23.659086 25375 net.cpp:406] encode3_h_conted_t=8 <- h_t=8_encode3_unit_t=8_1_split_0
I1223 00:14:23.659090 25375 net.cpp:406] encode3_h_conted_t=8 <- cont_t=9_encode3_cont_slice_8_split_0
I1223 00:14:23.659097 25375 net.cpp:380] encode3_h_conted_t=8 -> h_conted_t=8
I1223 00:14:23.659178 25375 net.cpp:122] Setting up encode3_h_conted_t=8
I1223 00:14:23.659186 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.659188 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:23.659193 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->8
I1223 00:14:23.659201 25375 net.cpp:84] Creating Layer encode3_hidden->transform->8
I1223 00:14:23.659205 25375 net.cpp:406] encode3_hidden->transform->8 <- h_conted_t=8
I1223 00:14:23.659212 25375 net.cpp:380] encode3_hidden->transform->8 -> hidden->transform->8
I1223 00:14:23.659723 25375 net.cpp:122] Setting up encode3_hidden->transform->8
I1223 00:14:23.659730 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.659734 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:23.659737 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.659742 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.659745 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=8
I1223 00:14:23.659750 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=8
I1223 00:14:23.659754 25375 net.cpp:406] encode3_hadamard->input_t=8 <- c_t=8_encode3_unit_t=8_0_split_0
I1223 00:14:23.659760 25375 net.cpp:380] encode3_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:23.659875 25375 net.cpp:122] Setting up encode3_hadamard->input_t=8
I1223 00:14:23.659883 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.659885 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:23.659889 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.659893 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=8
I1223 00:14:23.659898 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=8
I1223 00:14:23.659914 25375 net.cpp:406] encode3_hadamard->forget_t=8 <- c_t=8_encode3_unit_t=8_0_split_1
I1223 00:14:23.659921 25375 net.cpp:380] encode3_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:23.660032 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=8
I1223 00:14:23.660039 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660055 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:23.660059 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.660063 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=8
I1223 00:14:23.660069 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=8
I1223 00:14:23.660073 25375 net.cpp:406] encode3_hadamard->output_t=8 <- c_t=8_encode3_unit_t=8_0_split_2
I1223 00:14:23.660079 25375 net.cpp:380] encode3_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:23.660177 25375 net.cpp:122] Setting up encode3_hadamard->output_t=8
I1223 00:14:23.660184 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660187 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:23.660192 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.660194 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=9
I1223 00:14:23.660199 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=9
I1223 00:14:23.660204 25375 net.cpp:380] encode3_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:23.660271 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=9
I1223 00:14:23.660291 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660295 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:23.660297 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=9
I1223 00:14:23.660305 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=9
I1223 00:14:23.660310 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:23.660313 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:23.660331 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:23.660334 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:23.660339 25375 net.cpp:380] encode3_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:23.660364 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=9
I1223 00:14:23.660370 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.660373 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:23.660377 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_9
I1223 00:14:23.660394 25375 net.cpp:84] Creating Layer encode3_gate_input_9
I1223 00:14:23.660398 25375 net.cpp:406] encode3_gate_input_9 <- hidden->transform->8
I1223 00:14:23.660401 25375 net.cpp:406] encode3_gate_input_9 <- x->transform->t=9
I1223 00:14:23.660418 25375 net.cpp:406] encode3_gate_input_9 <- hadamard_t=9
I1223 00:14:23.660425 25375 net.cpp:380] encode3_gate_input_9 -> gate_input_9
I1223 00:14:23.660451 25375 net.cpp:122] Setting up encode3_gate_input_9
I1223 00:14:23.660457 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.660460 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:23.660464 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=9
I1223 00:14:23.660468 25375 net.cpp:84] Creating Layer encode3_unit_t=9
I1223 00:14:23.660472 25375 net.cpp:406] encode3_unit_t=9 <- c_t=8_encode3_unit_t=8_0_split_3
I1223 00:14:23.660476 25375 net.cpp:406] encode3_unit_t=9 <- gate_input_9
I1223 00:14:23.660480 25375 net.cpp:406] encode3_unit_t=9 <- cont_t=9_encode3_cont_slice_8_split_1
I1223 00:14:23.660486 25375 net.cpp:380] encode3_unit_t=9 -> c_t=9
I1223 00:14:23.660493 25375 net.cpp:380] encode3_unit_t=9 -> h_t=9
I1223 00:14:23.660547 25375 net.cpp:122] Setting up encode3_unit_t=9
I1223 00:14:23.660555 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660559 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660562 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:23.660565 25375 layer_factory.hpp:77] Creating layer c_t=9_encode3_unit_t=9_0_split
I1223 00:14:23.660570 25375 net.cpp:84] Creating Layer c_t=9_encode3_unit_t=9_0_split
I1223 00:14:23.660573 25375 net.cpp:406] c_t=9_encode3_unit_t=9_0_split <- c_t=9
I1223 00:14:23.660579 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_0
I1223 00:14:23.660586 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_1
I1223 00:14:23.660593 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_2
I1223 00:14:23.660598 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_3
I1223 00:14:23.660660 25375 net.cpp:122] Setting up c_t=9_encode3_unit_t=9_0_split
I1223 00:14:23.660667 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660671 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660676 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660679 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660681 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:23.660684 25375 layer_factory.hpp:77] Creating layer h_t=9_encode3_unit_t=9_1_split
I1223 00:14:23.660689 25375 net.cpp:84] Creating Layer h_t=9_encode3_unit_t=9_1_split
I1223 00:14:23.660694 25375 net.cpp:406] h_t=9_encode3_unit_t=9_1_split <- h_t=9
I1223 00:14:23.660699 25375 net.cpp:380] h_t=9_encode3_unit_t=9_1_split -> h_t=9_encode3_unit_t=9_1_split_0
I1223 00:14:23.660704 25375 net.cpp:380] h_t=9_encode3_unit_t=9_1_split -> h_t=9_encode3_unit_t=9_1_split_1
I1223 00:14:23.660742 25375 net.cpp:122] Setting up h_t=9_encode3_unit_t=9_1_split
I1223 00:14:23.660748 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660751 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660754 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:23.660758 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=9
I1223 00:14:23.660763 25375 net.cpp:84] Creating Layer encode3_h_conted_t=9
I1223 00:14:23.660766 25375 net.cpp:406] encode3_h_conted_t=9 <- h_t=9_encode3_unit_t=9_1_split_0
I1223 00:14:23.660770 25375 net.cpp:406] encode3_h_conted_t=9 <- cont_t=10_encode3_cont_slice_9_split_0
I1223 00:14:23.660776 25375 net.cpp:380] encode3_h_conted_t=9 -> h_conted_t=9
I1223 00:14:23.660871 25375 net.cpp:122] Setting up encode3_h_conted_t=9
I1223 00:14:23.660877 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.660881 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:23.660883 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->9
I1223 00:14:23.660909 25375 net.cpp:84] Creating Layer encode3_hidden->transform->9
I1223 00:14:23.660913 25375 net.cpp:406] encode3_hidden->transform->9 <- h_conted_t=9
I1223 00:14:23.660920 25375 net.cpp:380] encode3_hidden->transform->9 -> hidden->transform->9
I1223 00:14:23.661459 25375 net.cpp:122] Setting up encode3_hidden->transform->9
I1223 00:14:23.661468 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.661471 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:23.661475 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.661478 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.661483 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=9
I1223 00:14:23.661489 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=9
I1223 00:14:23.661492 25375 net.cpp:406] encode3_hadamard->input_t=9 <- c_t=9_encode3_unit_t=9_0_split_0
I1223 00:14:23.661514 25375 net.cpp:380] encode3_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:23.661612 25375 net.cpp:122] Setting up encode3_hadamard->input_t=9
I1223 00:14:23.661619 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.661623 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:23.661625 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.661629 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=9
I1223 00:14:23.661635 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=9
I1223 00:14:23.661639 25375 net.cpp:406] encode3_hadamard->forget_t=9 <- c_t=9_encode3_unit_t=9_0_split_1
I1223 00:14:23.661645 25375 net.cpp:380] encode3_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:23.661763 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=9
I1223 00:14:23.661783 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.661787 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:23.661790 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.661793 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=9
I1223 00:14:23.661799 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=9
I1223 00:14:23.661803 25375 net.cpp:406] encode3_hadamard->output_t=9 <- c_t=9_encode3_unit_t=9_0_split_2
I1223 00:14:23.661808 25375 net.cpp:380] encode3_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:23.661928 25375 net.cpp:122] Setting up encode3_hadamard->output_t=9
I1223 00:14:23.661936 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.661938 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:23.661942 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.661947 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=10
I1223 00:14:23.661957 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=10
I1223 00:14:23.661962 25375 net.cpp:380] encode3_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:23.662029 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=10
I1223 00:14:23.662036 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662039 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:23.662042 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=10
I1223 00:14:23.662047 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=10
I1223 00:14:23.662051 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:23.662056 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:23.662060 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:23.662065 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:23.662070 25375 net.cpp:380] encode3_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:23.662094 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=10
I1223 00:14:23.662101 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.662103 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:23.662106 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_10
I1223 00:14:23.662111 25375 net.cpp:84] Creating Layer encode3_gate_input_10
I1223 00:14:23.662115 25375 net.cpp:406] encode3_gate_input_10 <- hidden->transform->9
I1223 00:14:23.662119 25375 net.cpp:406] encode3_gate_input_10 <- x->transform->t=10
I1223 00:14:23.662123 25375 net.cpp:406] encode3_gate_input_10 <- hadamard_t=10
I1223 00:14:23.662129 25375 net.cpp:380] encode3_gate_input_10 -> gate_input_10
I1223 00:14:23.662153 25375 net.cpp:122] Setting up encode3_gate_input_10
I1223 00:14:23.662159 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.662163 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:23.662165 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=10
I1223 00:14:23.662170 25375 net.cpp:84] Creating Layer encode3_unit_t=10
I1223 00:14:23.662174 25375 net.cpp:406] encode3_unit_t=10 <- c_t=9_encode3_unit_t=9_0_split_3
I1223 00:14:23.662178 25375 net.cpp:406] encode3_unit_t=10 <- gate_input_10
I1223 00:14:23.662183 25375 net.cpp:406] encode3_unit_t=10 <- cont_t=10_encode3_cont_slice_9_split_1
I1223 00:14:23.662187 25375 net.cpp:380] encode3_unit_t=10 -> c_t=10
I1223 00:14:23.662194 25375 net.cpp:380] encode3_unit_t=10 -> h_t=10
I1223 00:14:23.662262 25375 net.cpp:122] Setting up encode3_unit_t=10
I1223 00:14:23.662268 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662272 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662276 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:23.662292 25375 layer_factory.hpp:77] Creating layer c_t=10_encode3_unit_t=10_0_split
I1223 00:14:23.662297 25375 net.cpp:84] Creating Layer c_t=10_encode3_unit_t=10_0_split
I1223 00:14:23.662300 25375 net.cpp:406] c_t=10_encode3_unit_t=10_0_split <- c_t=10
I1223 00:14:23.662305 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_0
I1223 00:14:23.662312 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_1
I1223 00:14:23.662318 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_2
I1223 00:14:23.662324 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_3
I1223 00:14:23.662389 25375 net.cpp:122] Setting up c_t=10_encode3_unit_t=10_0_split
I1223 00:14:23.662408 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662412 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662416 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662420 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662423 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:23.662425 25375 layer_factory.hpp:77] Creating layer h_t=10_encode3_unit_t=10_1_split
I1223 00:14:23.662436 25375 net.cpp:84] Creating Layer h_t=10_encode3_unit_t=10_1_split
I1223 00:14:23.662452 25375 net.cpp:406] h_t=10_encode3_unit_t=10_1_split <- h_t=10
I1223 00:14:23.662458 25375 net.cpp:380] h_t=10_encode3_unit_t=10_1_split -> h_t=10_encode3_unit_t=10_1_split_0
I1223 00:14:23.662466 25375 net.cpp:380] h_t=10_encode3_unit_t=10_1_split -> h_t=10_encode3_unit_t=10_1_split_1
I1223 00:14:23.662503 25375 net.cpp:122] Setting up h_t=10_encode3_unit_t=10_1_split
I1223 00:14:23.662523 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662528 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662529 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:23.662533 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=10
I1223 00:14:23.662537 25375 net.cpp:84] Creating Layer encode3_h_conted_t=10
I1223 00:14:23.662541 25375 net.cpp:406] encode3_h_conted_t=10 <- h_t=10_encode3_unit_t=10_1_split_0
I1223 00:14:23.662559 25375 net.cpp:406] encode3_h_conted_t=10 <- cont_t=11_encode3_cont_slice_10_split_0
I1223 00:14:23.662564 25375 net.cpp:380] encode3_h_conted_t=10 -> h_conted_t=10
I1223 00:14:23.662644 25375 net.cpp:122] Setting up encode3_h_conted_t=10
I1223 00:14:23.662652 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.662654 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:23.662657 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->10
I1223 00:14:23.662680 25375 net.cpp:84] Creating Layer encode3_hidden->transform->10
I1223 00:14:23.662698 25375 net.cpp:406] encode3_hidden->transform->10 <- h_conted_t=10
I1223 00:14:23.662704 25375 net.cpp:380] encode3_hidden->transform->10 -> hidden->transform->10
I1223 00:14:23.663241 25375 net.cpp:122] Setting up encode3_hidden->transform->10
I1223 00:14:23.663264 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.663267 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:23.663270 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.663275 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.663278 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=10
I1223 00:14:23.663283 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=10
I1223 00:14:23.663287 25375 net.cpp:406] encode3_hadamard->input_t=10 <- c_t=10_encode3_unit_t=10_0_split_0
I1223 00:14:23.663295 25375 net.cpp:380] encode3_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:23.663400 25375 net.cpp:122] Setting up encode3_hadamard->input_t=10
I1223 00:14:23.663409 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.663413 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:23.663416 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.663419 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=10
I1223 00:14:23.663424 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=10
I1223 00:14:23.663429 25375 net.cpp:406] encode3_hadamard->forget_t=10 <- c_t=10_encode3_unit_t=10_0_split_1
I1223 00:14:23.663434 25375 net.cpp:380] encode3_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:23.663547 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=10
I1223 00:14:23.663554 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.663558 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:23.663576 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.663579 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=10
I1223 00:14:23.663584 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=10
I1223 00:14:23.663588 25375 net.cpp:406] encode3_hadamard->output_t=10 <- c_t=10_encode3_unit_t=10_0_split_2
I1223 00:14:23.663594 25375 net.cpp:380] encode3_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:23.663713 25375 net.cpp:122] Setting up encode3_hadamard->output_t=10
I1223 00:14:23.663720 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.663723 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:23.663727 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.663730 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=11
I1223 00:14:23.663735 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=11
I1223 00:14:23.663740 25375 net.cpp:380] encode3_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:23.663794 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=11
I1223 00:14:23.663800 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.663803 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:23.663806 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=11
I1223 00:14:23.663815 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=11
I1223 00:14:23.663832 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:23.663837 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:23.663841 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:23.663846 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:23.663851 25375 net.cpp:380] encode3_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:23.663877 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=11
I1223 00:14:23.663883 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.663887 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:23.663903 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_11
I1223 00:14:23.663910 25375 net.cpp:84] Creating Layer encode3_gate_input_11
I1223 00:14:23.663914 25375 net.cpp:406] encode3_gate_input_11 <- hidden->transform->10
I1223 00:14:23.663918 25375 net.cpp:406] encode3_gate_input_11 <- x->transform->t=11
I1223 00:14:23.663923 25375 net.cpp:406] encode3_gate_input_11 <- hadamard_t=11
I1223 00:14:23.663942 25375 net.cpp:380] encode3_gate_input_11 -> gate_input_11
I1223 00:14:23.663967 25375 net.cpp:122] Setting up encode3_gate_input_11
I1223 00:14:23.663974 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.663976 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:23.663980 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=11
I1223 00:14:23.663985 25375 net.cpp:84] Creating Layer encode3_unit_t=11
I1223 00:14:23.663987 25375 net.cpp:406] encode3_unit_t=11 <- c_t=10_encode3_unit_t=10_0_split_3
I1223 00:14:23.663992 25375 net.cpp:406] encode3_unit_t=11 <- gate_input_11
I1223 00:14:23.663996 25375 net.cpp:406] encode3_unit_t=11 <- cont_t=11_encode3_cont_slice_10_split_1
I1223 00:14:23.664002 25375 net.cpp:380] encode3_unit_t=11 -> c_t=11
I1223 00:14:23.664010 25375 net.cpp:380] encode3_unit_t=11 -> h_t=11
I1223 00:14:23.664062 25375 net.cpp:122] Setting up encode3_unit_t=11
I1223 00:14:23.664068 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664072 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664075 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:23.664078 25375 layer_factory.hpp:77] Creating layer c_t=11_encode3_unit_t=11_0_split
I1223 00:14:23.664083 25375 net.cpp:84] Creating Layer c_t=11_encode3_unit_t=11_0_split
I1223 00:14:23.664086 25375 net.cpp:406] c_t=11_encode3_unit_t=11_0_split <- c_t=11
I1223 00:14:23.664093 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_0
I1223 00:14:23.664098 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_1
I1223 00:14:23.664103 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_2
I1223 00:14:23.664109 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_3
I1223 00:14:23.664186 25375 net.cpp:122] Setting up c_t=11_encode3_unit_t=11_0_split
I1223 00:14:23.664194 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664198 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664202 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664206 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664208 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:23.664211 25375 layer_factory.hpp:77] Creating layer h_t=11_encode3_unit_t=11_1_split
I1223 00:14:23.664216 25375 net.cpp:84] Creating Layer h_t=11_encode3_unit_t=11_1_split
I1223 00:14:23.664218 25375 net.cpp:406] h_t=11_encode3_unit_t=11_1_split <- h_t=11
I1223 00:14:23.664223 25375 net.cpp:380] h_t=11_encode3_unit_t=11_1_split -> h_t=11_encode3_unit_t=11_1_split_0
I1223 00:14:23.664229 25375 net.cpp:380] h_t=11_encode3_unit_t=11_1_split -> h_t=11_encode3_unit_t=11_1_split_1
I1223 00:14:23.664280 25375 net.cpp:122] Setting up h_t=11_encode3_unit_t=11_1_split
I1223 00:14:23.664286 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664290 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664294 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:23.664296 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=11
I1223 00:14:23.664301 25375 net.cpp:84] Creating Layer encode3_h_conted_t=11
I1223 00:14:23.664304 25375 net.cpp:406] encode3_h_conted_t=11 <- h_t=11_encode3_unit_t=11_1_split_0
I1223 00:14:23.664309 25375 net.cpp:406] encode3_h_conted_t=11 <- cont_t=12_encode3_cont_slice_11_split_0
I1223 00:14:23.664315 25375 net.cpp:380] encode3_h_conted_t=11 -> h_conted_t=11
I1223 00:14:23.664409 25375 net.cpp:122] Setting up encode3_h_conted_t=11
I1223 00:14:23.664415 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.664419 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:23.664422 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->11
I1223 00:14:23.664432 25375 net.cpp:84] Creating Layer encode3_hidden->transform->11
I1223 00:14:23.664436 25375 net.cpp:406] encode3_hidden->transform->11 <- h_conted_t=11
I1223 00:14:23.664443 25375 net.cpp:380] encode3_hidden->transform->11 -> hidden->transform->11
I1223 00:14:23.664983 25375 net.cpp:122] Setting up encode3_hidden->transform->11
I1223 00:14:23.664991 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.664994 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:23.664997 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.665001 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.665005 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=11
I1223 00:14:23.665012 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=11
I1223 00:14:23.665016 25375 net.cpp:406] encode3_hadamard->input_t=11 <- c_t=11_encode3_unit_t=11_0_split_0
I1223 00:14:23.665022 25375 net.cpp:380] encode3_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:23.665139 25375 net.cpp:122] Setting up encode3_hadamard->input_t=11
I1223 00:14:23.665148 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.665150 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:23.665168 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.665171 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=11
I1223 00:14:23.665177 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=11
I1223 00:14:23.665181 25375 net.cpp:406] encode3_hadamard->forget_t=11 <- c_t=11_encode3_unit_t=11_0_split_1
I1223 00:14:23.665187 25375 net.cpp:380] encode3_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:23.665295 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=11
I1223 00:14:23.665302 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.665305 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:23.665323 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.665325 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=11
I1223 00:14:23.665331 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=11
I1223 00:14:23.665335 25375 net.cpp:406] encode3_hadamard->output_t=11 <- c_t=11_encode3_unit_t=11_0_split_2
I1223 00:14:23.665340 25375 net.cpp:380] encode3_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:23.665458 25375 net.cpp:122] Setting up encode3_hadamard->output_t=11
I1223 00:14:23.665465 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.665482 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:23.665485 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.665501 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=12
I1223 00:14:23.665506 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=12
I1223 00:14:23.665511 25375 net.cpp:380] encode3_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:23.665567 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=12
I1223 00:14:23.665575 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.665578 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:23.665581 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=12
I1223 00:14:23.665586 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=12
I1223 00:14:23.665590 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:23.665607 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:23.665611 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:23.665628 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:23.665633 25375 net.cpp:380] encode3_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:23.665671 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=12
I1223 00:14:23.665678 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.665681 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:23.665684 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_12
I1223 00:14:23.665690 25375 net.cpp:84] Creating Layer encode3_gate_input_12
I1223 00:14:23.665707 25375 net.cpp:406] encode3_gate_input_12 <- hidden->transform->11
I1223 00:14:23.665711 25375 net.cpp:406] encode3_gate_input_12 <- x->transform->t=12
I1223 00:14:23.665715 25375 net.cpp:406] encode3_gate_input_12 <- hadamard_t=12
I1223 00:14:23.665733 25375 net.cpp:380] encode3_gate_input_12 -> gate_input_12
I1223 00:14:23.665765 25375 net.cpp:122] Setting up encode3_gate_input_12
I1223 00:14:23.665771 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.665773 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:23.665776 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=12
I1223 00:14:23.665781 25375 net.cpp:84] Creating Layer encode3_unit_t=12
I1223 00:14:23.665786 25375 net.cpp:406] encode3_unit_t=12 <- c_t=11_encode3_unit_t=11_0_split_3
I1223 00:14:23.665789 25375 net.cpp:406] encode3_unit_t=12 <- gate_input_12
I1223 00:14:23.665793 25375 net.cpp:406] encode3_unit_t=12 <- cont_t=12_encode3_cont_slice_11_split_1
I1223 00:14:23.665798 25375 net.cpp:380] encode3_unit_t=12 -> c_t=12
I1223 00:14:23.665805 25375 net.cpp:380] encode3_unit_t=12 -> h_t=12
I1223 00:14:23.665868 25375 net.cpp:122] Setting up encode3_unit_t=12
I1223 00:14:23.665874 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.665879 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.665881 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:23.665884 25375 layer_factory.hpp:77] Creating layer c_t=12_encode3_unit_t=12_0_split
I1223 00:14:23.665902 25375 net.cpp:84] Creating Layer c_t=12_encode3_unit_t=12_0_split
I1223 00:14:23.665906 25375 net.cpp:406] c_t=12_encode3_unit_t=12_0_split <- c_t=12
I1223 00:14:23.665911 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_0
I1223 00:14:23.665918 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_1
I1223 00:14:23.665925 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_2
I1223 00:14:23.665931 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_3
I1223 00:14:23.665993 25375 net.cpp:122] Setting up c_t=12_encode3_unit_t=12_0_split
I1223 00:14:23.665999 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.666003 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.666007 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.666012 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.666014 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:23.666016 25375 layer_factory.hpp:77] Creating layer h_t=12_encode3_unit_t=12_1_split
I1223 00:14:23.666023 25375 net.cpp:84] Creating Layer h_t=12_encode3_unit_t=12_1_split
I1223 00:14:23.666028 25375 net.cpp:406] h_t=12_encode3_unit_t=12_1_split <- h_t=12
I1223 00:14:23.666033 25375 net.cpp:380] h_t=12_encode3_unit_t=12_1_split -> h_t=12_encode3_unit_t=12_1_split_0
I1223 00:14:23.666039 25375 net.cpp:380] h_t=12_encode3_unit_t=12_1_split -> h_t=12_encode3_unit_t=12_1_split_1
I1223 00:14:23.666076 25375 net.cpp:122] Setting up h_t=12_encode3_unit_t=12_1_split
I1223 00:14:23.666082 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.666086 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.666088 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:23.666091 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=12
I1223 00:14:23.666097 25375 net.cpp:84] Creating Layer encode3_h_conted_t=12
I1223 00:14:23.666101 25375 net.cpp:406] encode3_h_conted_t=12 <- h_t=12_encode3_unit_t=12_1_split_0
I1223 00:14:23.666105 25375 net.cpp:406] encode3_h_conted_t=12 <- cont_t=13_encode3_cont_slice_12_split_0
I1223 00:14:23.666111 25375 net.cpp:380] encode3_h_conted_t=12 -> h_conted_t=12
I1223 00:14:23.666965 25375 net.cpp:122] Setting up encode3_h_conted_t=12
I1223 00:14:23.666976 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.666980 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:23.666983 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->12
I1223 00:14:23.666992 25375 net.cpp:84] Creating Layer encode3_hidden->transform->12
I1223 00:14:23.666996 25375 net.cpp:406] encode3_hidden->transform->12 <- h_conted_t=12
I1223 00:14:23.667004 25375 net.cpp:380] encode3_hidden->transform->12 -> hidden->transform->12
I1223 00:14:23.667574 25375 net.cpp:122] Setting up encode3_hidden->transform->12
I1223 00:14:23.667582 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.667585 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:23.667589 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.667598 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.667603 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=12
I1223 00:14:23.667610 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=12
I1223 00:14:23.667613 25375 net.cpp:406] encode3_hadamard->input_t=12 <- c_t=12_encode3_unit_t=12_0_split_0
I1223 00:14:23.667632 25375 net.cpp:380] encode3_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:23.667740 25375 net.cpp:122] Setting up encode3_hadamard->input_t=12
I1223 00:14:23.667747 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.667750 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:23.667753 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.667757 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=12
I1223 00:14:23.667776 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=12
I1223 00:14:23.667779 25375 net.cpp:406] encode3_hadamard->forget_t=12 <- c_t=12_encode3_unit_t=12_0_split_1
I1223 00:14:23.667799 25375 net.cpp:380] encode3_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:23.667906 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=12
I1223 00:14:23.667912 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.667915 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:23.667918 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.667934 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=12
I1223 00:14:23.667939 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=12
I1223 00:14:23.667943 25375 net.cpp:406] encode3_hadamard->output_t=12 <- c_t=12_encode3_unit_t=12_0_split_2
I1223 00:14:23.667963 25375 net.cpp:380] encode3_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:23.668092 25375 net.cpp:122] Setting up encode3_hadamard->output_t=12
I1223 00:14:23.668100 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668102 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:23.668107 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.668109 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=13
I1223 00:14:23.668128 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=13
I1223 00:14:23.668133 25375 net.cpp:380] encode3_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:23.668222 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=13
I1223 00:14:23.668229 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668244 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:23.668247 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=13
I1223 00:14:23.668267 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=13
I1223 00:14:23.668272 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:23.668275 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:23.668278 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:23.668295 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:23.668300 25375 net.cpp:380] encode3_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:23.668351 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=13
I1223 00:14:23.668370 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.668371 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:23.668375 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_13
I1223 00:14:23.668380 25375 net.cpp:84] Creating Layer encode3_gate_input_13
I1223 00:14:23.668396 25375 net.cpp:406] encode3_gate_input_13 <- hidden->transform->12
I1223 00:14:23.668401 25375 net.cpp:406] encode3_gate_input_13 <- x->transform->t=13
I1223 00:14:23.668417 25375 net.cpp:406] encode3_gate_input_13 <- hadamard_t=13
I1223 00:14:23.668423 25375 net.cpp:380] encode3_gate_input_13 -> gate_input_13
I1223 00:14:23.668488 25375 net.cpp:122] Setting up encode3_gate_input_13
I1223 00:14:23.668509 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.668510 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:23.668514 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=13
I1223 00:14:23.668519 25375 net.cpp:84] Creating Layer encode3_unit_t=13
I1223 00:14:23.668521 25375 net.cpp:406] encode3_unit_t=13 <- c_t=12_encode3_unit_t=12_0_split_3
I1223 00:14:23.668540 25375 net.cpp:406] encode3_unit_t=13 <- gate_input_13
I1223 00:14:23.668543 25375 net.cpp:406] encode3_unit_t=13 <- cont_t=13_encode3_cont_slice_12_split_1
I1223 00:14:23.668550 25375 net.cpp:380] encode3_unit_t=13 -> c_t=13
I1223 00:14:23.668556 25375 net.cpp:380] encode3_unit_t=13 -> h_t=13
I1223 00:14:23.668620 25375 net.cpp:122] Setting up encode3_unit_t=13
I1223 00:14:23.668627 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668632 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668634 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:23.668650 25375 layer_factory.hpp:77] Creating layer c_t=13_encode3_unit_t=13_0_split
I1223 00:14:23.668655 25375 net.cpp:84] Creating Layer c_t=13_encode3_unit_t=13_0_split
I1223 00:14:23.668673 25375 net.cpp:406] c_t=13_encode3_unit_t=13_0_split <- c_t=13
I1223 00:14:23.668678 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_0
I1223 00:14:23.668699 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_1
I1223 00:14:23.668717 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_2
I1223 00:14:23.668722 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_3
I1223 00:14:23.668786 25375 net.cpp:122] Setting up c_t=13_encode3_unit_t=13_0_split
I1223 00:14:23.668792 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668795 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668799 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668817 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668819 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:23.668823 25375 layer_factory.hpp:77] Creating layer h_t=13_encode3_unit_t=13_1_split
I1223 00:14:23.668845 25375 net.cpp:84] Creating Layer h_t=13_encode3_unit_t=13_1_split
I1223 00:14:23.668861 25375 net.cpp:406] h_t=13_encode3_unit_t=13_1_split <- h_t=13
I1223 00:14:23.668866 25375 net.cpp:380] h_t=13_encode3_unit_t=13_1_split -> h_t=13_encode3_unit_t=13_1_split_0
I1223 00:14:23.668885 25375 net.cpp:380] h_t=13_encode3_unit_t=13_1_split -> h_t=13_encode3_unit_t=13_1_split_1
I1223 00:14:23.668921 25375 net.cpp:122] Setting up h_t=13_encode3_unit_t=13_1_split
I1223 00:14:23.668928 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668932 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.668936 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:23.668937 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=13
I1223 00:14:23.668942 25375 net.cpp:84] Creating Layer encode3_h_conted_t=13
I1223 00:14:23.668946 25375 net.cpp:406] encode3_h_conted_t=13 <- h_t=13_encode3_unit_t=13_1_split_0
I1223 00:14:23.668951 25375 net.cpp:406] encode3_h_conted_t=13 <- cont_t=14_encode3_cont_slice_13_split_0
I1223 00:14:23.668956 25375 net.cpp:380] encode3_h_conted_t=13 -> h_conted_t=13
I1223 00:14:23.669080 25375 net.cpp:122] Setting up encode3_h_conted_t=13
I1223 00:14:23.669087 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.669090 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:23.669093 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->13
I1223 00:14:23.669116 25375 net.cpp:84] Creating Layer encode3_hidden->transform->13
I1223 00:14:23.669121 25375 net.cpp:406] encode3_hidden->transform->13 <- h_conted_t=13
I1223 00:14:23.669139 25375 net.cpp:380] encode3_hidden->transform->13 -> hidden->transform->13
I1223 00:14:23.669668 25375 net.cpp:122] Setting up encode3_hidden->transform->13
I1223 00:14:23.669677 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.669679 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:23.669682 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.669685 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.669689 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=13
I1223 00:14:23.669710 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=13
I1223 00:14:23.669713 25375 net.cpp:406] encode3_hadamard->input_t=13 <- c_t=13_encode3_unit_t=13_0_split_0
I1223 00:14:23.669719 25375 net.cpp:380] encode3_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:23.669843 25375 net.cpp:122] Setting up encode3_hadamard->input_t=13
I1223 00:14:23.669852 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.669854 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:23.669858 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.669862 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=13
I1223 00:14:23.669884 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=13
I1223 00:14:23.669888 25375 net.cpp:406] encode3_hadamard->forget_t=13 <- c_t=13_encode3_unit_t=13_0_split_1
I1223 00:14:23.669909 25375 net.cpp:380] encode3_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:23.670016 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=13
I1223 00:14:23.670023 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670027 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:23.670029 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.670033 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=13
I1223 00:14:23.670053 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=13
I1223 00:14:23.670056 25375 net.cpp:406] encode3_hadamard->output_t=13 <- c_t=13_encode3_unit_t=13_0_split_2
I1223 00:14:23.670061 25375 net.cpp:380] encode3_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:23.670171 25375 net.cpp:122] Setting up encode3_hadamard->output_t=13
I1223 00:14:23.670181 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670183 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:23.670186 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.670191 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=14
I1223 00:14:23.670198 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=14
I1223 00:14:23.670203 25375 net.cpp:380] encode3_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:23.670284 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=14
I1223 00:14:23.670294 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670296 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:23.670300 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=14
I1223 00:14:23.670305 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=14
I1223 00:14:23.670310 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:23.670315 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:23.670320 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:23.670337 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:23.670342 25375 net.cpp:380] encode3_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:23.670370 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=14
I1223 00:14:23.670378 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.670382 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:23.670384 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_14
I1223 00:14:23.670403 25375 net.cpp:84] Creating Layer encode3_gate_input_14
I1223 00:14:23.670408 25375 net.cpp:406] encode3_gate_input_14 <- hidden->transform->13
I1223 00:14:23.670424 25375 net.cpp:406] encode3_gate_input_14 <- x->transform->t=14
I1223 00:14:23.670428 25375 net.cpp:406] encode3_gate_input_14 <- hadamard_t=14
I1223 00:14:23.670449 25375 net.cpp:380] encode3_gate_input_14 -> gate_input_14
I1223 00:14:23.670472 25375 net.cpp:122] Setting up encode3_gate_input_14
I1223 00:14:23.670480 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.670482 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:23.670485 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=14
I1223 00:14:23.670492 25375 net.cpp:84] Creating Layer encode3_unit_t=14
I1223 00:14:23.670509 25375 net.cpp:406] encode3_unit_t=14 <- c_t=13_encode3_unit_t=13_0_split_3
I1223 00:14:23.670514 25375 net.cpp:406] encode3_unit_t=14 <- gate_input_14
I1223 00:14:23.670532 25375 net.cpp:406] encode3_unit_t=14 <- cont_t=14_encode3_cont_slice_13_split_1
I1223 00:14:23.670537 25375 net.cpp:380] encode3_unit_t=14 -> c_t=14
I1223 00:14:23.670543 25375 net.cpp:380] encode3_unit_t=14 -> h_t=14
I1223 00:14:23.670598 25375 net.cpp:122] Setting up encode3_unit_t=14
I1223 00:14:23.670619 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670622 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670624 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:23.670627 25375 layer_factory.hpp:77] Creating layer c_t=14_encode3_unit_t=14_0_split
I1223 00:14:23.670634 25375 net.cpp:84] Creating Layer c_t=14_encode3_unit_t=14_0_split
I1223 00:14:23.670637 25375 net.cpp:406] c_t=14_encode3_unit_t=14_0_split <- c_t=14
I1223 00:14:23.670656 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_0
I1223 00:14:23.670665 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_1
I1223 00:14:23.670670 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_2
I1223 00:14:23.670675 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_3
I1223 00:14:23.670750 25375 net.cpp:122] Setting up c_t=14_encode3_unit_t=14_0_split
I1223 00:14:23.670758 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670761 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670765 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670768 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670771 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:23.670774 25375 layer_factory.hpp:77] Creating layer h_t=14_encode3_unit_t=14_1_split
I1223 00:14:23.670778 25375 net.cpp:84] Creating Layer h_t=14_encode3_unit_t=14_1_split
I1223 00:14:23.670783 25375 net.cpp:406] h_t=14_encode3_unit_t=14_1_split <- h_t=14
I1223 00:14:23.670788 25375 net.cpp:380] h_t=14_encode3_unit_t=14_1_split -> h_t=14_encode3_unit_t=14_1_split_0
I1223 00:14:23.670794 25375 net.cpp:380] h_t=14_encode3_unit_t=14_1_split -> h_t=14_encode3_unit_t=14_1_split_1
I1223 00:14:23.670842 25375 net.cpp:122] Setting up h_t=14_encode3_unit_t=14_1_split
I1223 00:14:23.670850 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670853 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.670855 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:23.670858 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=14
I1223 00:14:23.670878 25375 net.cpp:84] Creating Layer encode3_h_conted_t=14
I1223 00:14:23.670882 25375 net.cpp:406] encode3_h_conted_t=14 <- h_t=14_encode3_unit_t=14_1_split_0
I1223 00:14:23.670900 25375 net.cpp:406] encode3_h_conted_t=14 <- cont_t=15_encode3_cont_slice_14_split_0
I1223 00:14:23.670905 25375 net.cpp:380] encode3_h_conted_t=14 -> h_conted_t=14
I1223 00:14:23.670999 25375 net.cpp:122] Setting up encode3_h_conted_t=14
I1223 00:14:23.671005 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.671008 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:23.671011 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->14
I1223 00:14:23.671022 25375 net.cpp:84] Creating Layer encode3_hidden->transform->14
I1223 00:14:23.671027 25375 net.cpp:406] encode3_hidden->transform->14 <- h_conted_t=14
I1223 00:14:23.671036 25375 net.cpp:380] encode3_hidden->transform->14 -> hidden->transform->14
I1223 00:14:23.671607 25375 net.cpp:122] Setting up encode3_hidden->transform->14
I1223 00:14:23.671614 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.671617 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:23.671634 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.671638 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.671641 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=14
I1223 00:14:23.671646 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=14
I1223 00:14:23.671650 25375 net.cpp:406] encode3_hadamard->input_t=14 <- c_t=14_encode3_unit_t=14_0_split_0
I1223 00:14:23.671655 25375 net.cpp:380] encode3_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:23.671764 25375 net.cpp:122] Setting up encode3_hadamard->input_t=14
I1223 00:14:23.671772 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.671774 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:23.671778 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.671782 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=14
I1223 00:14:23.671799 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=14
I1223 00:14:23.671803 25375 net.cpp:406] encode3_hadamard->forget_t=14 <- c_t=14_encode3_unit_t=14_0_split_1
I1223 00:14:23.671808 25375 net.cpp:380] encode3_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:23.671924 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=14
I1223 00:14:23.671932 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.671934 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:23.671937 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.671941 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=14
I1223 00:14:23.671959 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=14
I1223 00:14:23.671962 25375 net.cpp:406] encode3_hadamard->output_t=14 <- c_t=14_encode3_unit_t=14_0_split_2
I1223 00:14:23.671968 25375 net.cpp:380] encode3_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:23.672086 25375 net.cpp:122] Setting up encode3_hadamard->output_t=14
I1223 00:14:23.672096 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672097 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:23.672101 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.672104 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=15
I1223 00:14:23.672122 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=15
I1223 00:14:23.672128 25375 net.cpp:380] encode3_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:23.672209 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=15
I1223 00:14:23.672215 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672231 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:23.672235 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=15
I1223 00:14:23.672240 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=15
I1223 00:14:23.672243 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:23.672248 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:23.672251 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:23.672255 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:23.672262 25375 net.cpp:380] encode3_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:23.672302 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=15
I1223 00:14:23.672309 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.672312 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:23.672314 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_15
I1223 00:14:23.672320 25375 net.cpp:84] Creating Layer encode3_gate_input_15
I1223 00:14:23.672323 25375 net.cpp:406] encode3_gate_input_15 <- hidden->transform->14
I1223 00:14:23.672327 25375 net.cpp:406] encode3_gate_input_15 <- x->transform->t=15
I1223 00:14:23.672332 25375 net.cpp:406] encode3_gate_input_15 <- hadamard_t=15
I1223 00:14:23.672338 25375 net.cpp:380] encode3_gate_input_15 -> gate_input_15
I1223 00:14:23.672375 25375 net.cpp:122] Setting up encode3_gate_input_15
I1223 00:14:23.672384 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.672385 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:23.672389 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=15
I1223 00:14:23.672406 25375 net.cpp:84] Creating Layer encode3_unit_t=15
I1223 00:14:23.672410 25375 net.cpp:406] encode3_unit_t=15 <- c_t=14_encode3_unit_t=14_0_split_3
I1223 00:14:23.672428 25375 net.cpp:406] encode3_unit_t=15 <- gate_input_15
I1223 00:14:23.672432 25375 net.cpp:406] encode3_unit_t=15 <- cont_t=15_encode3_cont_slice_14_split_1
I1223 00:14:23.672437 25375 net.cpp:380] encode3_unit_t=15 -> c_t=15
I1223 00:14:23.672444 25375 net.cpp:380] encode3_unit_t=15 -> h_t=15
I1223 00:14:23.672495 25375 net.cpp:122] Setting up encode3_unit_t=15
I1223 00:14:23.672515 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672519 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672521 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:23.672524 25375 layer_factory.hpp:77] Creating layer c_t=15_encode3_unit_t=15_0_split
I1223 00:14:23.672529 25375 net.cpp:84] Creating Layer c_t=15_encode3_unit_t=15_0_split
I1223 00:14:23.672533 25375 net.cpp:406] c_t=15_encode3_unit_t=15_0_split <- c_t=15
I1223 00:14:23.672538 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_0
I1223 00:14:23.672559 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_1
I1223 00:14:23.672565 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_2
I1223 00:14:23.672570 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_3
I1223 00:14:23.672646 25375 net.cpp:122] Setting up c_t=15_encode3_unit_t=15_0_split
I1223 00:14:23.672653 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672657 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672660 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672664 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672667 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:23.672670 25375 layer_factory.hpp:77] Creating layer h_t=15_encode3_unit_t=15_1_split
I1223 00:14:23.672675 25375 net.cpp:84] Creating Layer h_t=15_encode3_unit_t=15_1_split
I1223 00:14:23.672678 25375 net.cpp:406] h_t=15_encode3_unit_t=15_1_split <- h_t=15
I1223 00:14:23.672683 25375 net.cpp:380] h_t=15_encode3_unit_t=15_1_split -> h_t=15_encode3_unit_t=15_1_split_0
I1223 00:14:23.672689 25375 net.cpp:380] h_t=15_encode3_unit_t=15_1_split -> h_t=15_encode3_unit_t=15_1_split_1
I1223 00:14:23.672740 25375 net.cpp:122] Setting up h_t=15_encode3_unit_t=15_1_split
I1223 00:14:23.672746 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672750 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672754 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:23.672756 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=15
I1223 00:14:23.672775 25375 net.cpp:84] Creating Layer encode3_h_conted_t=15
I1223 00:14:23.672777 25375 net.cpp:406] encode3_h_conted_t=15 <- h_t=15_encode3_unit_t=15_1_split_0
I1223 00:14:23.672796 25375 net.cpp:406] encode3_h_conted_t=15 <- cont_t=16_encode3_cont_slice_15_split_0
I1223 00:14:23.672801 25375 net.cpp:380] encode3_h_conted_t=15 -> h_conted_t=15
I1223 00:14:23.672893 25375 net.cpp:122] Setting up encode3_h_conted_t=15
I1223 00:14:23.672899 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.672902 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:23.672905 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->15
I1223 00:14:23.672927 25375 net.cpp:84] Creating Layer encode3_hidden->transform->15
I1223 00:14:23.672931 25375 net.cpp:406] encode3_hidden->transform->15 <- h_conted_t=15
I1223 00:14:23.672938 25375 net.cpp:380] encode3_hidden->transform->15 -> hidden->transform->15
I1223 00:14:23.673502 25375 net.cpp:122] Setting up encode3_hidden->transform->15
I1223 00:14:23.673511 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.673514 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:23.673518 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:23.673535 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:23.673538 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=15
I1223 00:14:23.673544 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=15
I1223 00:14:23.673548 25375 net.cpp:406] encode3_hadamard->input_t=15 <- c_t=15_encode3_unit_t=15_0_split_0
I1223 00:14:23.673553 25375 net.cpp:380] encode3_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:23.673665 25375 net.cpp:122] Setting up encode3_hadamard->input_t=15
I1223 00:14:23.673672 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.673676 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:23.673692 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:23.673696 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=15
I1223 00:14:23.673702 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=15
I1223 00:14:23.673704 25375 net.cpp:406] encode3_hadamard->forget_t=15 <- c_t=15_encode3_unit_t=15_0_split_1
I1223 00:14:23.673710 25375 net.cpp:380] encode3_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:23.673820 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=15
I1223 00:14:23.673827 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.673830 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:23.673835 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:23.673851 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=15
I1223 00:14:23.673856 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=15
I1223 00:14:23.673861 25375 net.cpp:406] encode3_hadamard->output_t=15 <- c_t=15_encode3_unit_t=15_0_split_2
I1223 00:14:23.673866 25375 net.cpp:380] encode3_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:23.673972 25375 net.cpp:122] Setting up encode3_hadamard->output_t=15
I1223 00:14:23.673979 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.673982 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:23.673985 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:23.673988 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=16
I1223 00:14:23.673995 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=16
I1223 00:14:23.674000 25375 net.cpp:380] encode3_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:23.674054 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=16
I1223 00:14:23.674062 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.674064 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:23.674067 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=16
I1223 00:14:23.674072 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=16
I1223 00:14:23.674077 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:23.674080 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:23.674084 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:23.674088 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:23.674093 25375 net.cpp:380] encode3_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:23.674132 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=16
I1223 00:14:23.674139 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.674142 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:23.674144 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_16
I1223 00:14:23.674149 25375 net.cpp:84] Creating Layer encode3_gate_input_16
I1223 00:14:23.674154 25375 net.cpp:406] encode3_gate_input_16 <- hidden->transform->15
I1223 00:14:23.674157 25375 net.cpp:406] encode3_gate_input_16 <- x->transform->t=16
I1223 00:14:23.674161 25375 net.cpp:406] encode3_gate_input_16 <- hadamard_t=16
I1223 00:14:23.674167 25375 net.cpp:380] encode3_gate_input_16 -> gate_input_16
I1223 00:14:23.674190 25375 net.cpp:122] Setting up encode3_gate_input_16
I1223 00:14:23.674196 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.674199 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:23.674202 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=16
I1223 00:14:23.674208 25375 net.cpp:84] Creating Layer encode3_unit_t=16
I1223 00:14:23.674212 25375 net.cpp:406] encode3_unit_t=16 <- c_t=15_encode3_unit_t=15_0_split_3
I1223 00:14:23.674216 25375 net.cpp:406] encode3_unit_t=16 <- gate_input_16
I1223 00:14:23.674221 25375 net.cpp:406] encode3_unit_t=16 <- cont_t=16_encode3_cont_slice_15_split_1
I1223 00:14:23.674226 25375 net.cpp:380] encode3_unit_t=16 -> c_t=16
I1223 00:14:23.674230 25375 net.cpp:380] encode3_unit_t=16 -> h_t=16
I1223 00:14:23.674296 25375 net.cpp:122] Setting up encode3_unit_t=16
I1223 00:14:23.674304 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.674307 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.674324 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:23.674326 25375 layer_factory.hpp:77] Creating layer h_t=16_encode3_unit_t=16_1_split
I1223 00:14:23.674331 25375 net.cpp:84] Creating Layer h_t=16_encode3_unit_t=16_1_split
I1223 00:14:23.674335 25375 net.cpp:406] h_t=16_encode3_unit_t=16_1_split <- h_t=16
I1223 00:14:23.674340 25375 net.cpp:380] h_t=16_encode3_unit_t=16_1_split -> h_t=16_encode3_unit_t=16_1_split_0
I1223 00:14:23.674346 25375 net.cpp:380] h_t=16_encode3_unit_t=16_1_split -> h_t=16_encode3_unit_t=16_1_split_1
I1223 00:14:23.674397 25375 net.cpp:122] Setting up h_t=16_encode3_unit_t=16_1_split
I1223 00:14:23.674403 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.674407 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.674410 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:23.674413 25375 layer_factory.hpp:77] Creating layer encode3_h_concat
I1223 00:14:23.674433 25375 net.cpp:84] Creating Layer encode3_h_concat
I1223 00:14:23.674437 25375 net.cpp:406] encode3_h_concat <- h_t=1_encode3_unit_t=1_1_split_1
I1223 00:14:23.674441 25375 net.cpp:406] encode3_h_concat <- h_t=2_encode3_unit_t=2_1_split_1
I1223 00:14:23.674444 25375 net.cpp:406] encode3_h_concat <- h_t=3_encode3_unit_t=3_1_split_1
I1223 00:14:23.674448 25375 net.cpp:406] encode3_h_concat <- h_t=4_encode3_unit_t=4_1_split_1
I1223 00:14:23.674453 25375 net.cpp:406] encode3_h_concat <- h_t=5_encode3_unit_t=5_1_split_1
I1223 00:14:23.674455 25375 net.cpp:406] encode3_h_concat <- h_t=6_encode3_unit_t=6_1_split_1
I1223 00:14:23.674458 25375 net.cpp:406] encode3_h_concat <- h_t=7_encode3_unit_t=7_1_split_1
I1223 00:14:23.674463 25375 net.cpp:406] encode3_h_concat <- h_t=8_encode3_unit_t=8_1_split_1
I1223 00:14:23.674465 25375 net.cpp:406] encode3_h_concat <- h_t=9_encode3_unit_t=9_1_split_1
I1223 00:14:23.674469 25375 net.cpp:406] encode3_h_concat <- h_t=10_encode3_unit_t=10_1_split_1
I1223 00:14:23.674473 25375 net.cpp:406] encode3_h_concat <- h_t=11_encode3_unit_t=11_1_split_1
I1223 00:14:23.674476 25375 net.cpp:406] encode3_h_concat <- h_t=12_encode3_unit_t=12_1_split_1
I1223 00:14:23.674479 25375 net.cpp:406] encode3_h_concat <- h_t=13_encode3_unit_t=13_1_split_1
I1223 00:14:23.674482 25375 net.cpp:406] encode3_h_concat <- h_t=14_encode3_unit_t=14_1_split_1
I1223 00:14:23.674485 25375 net.cpp:406] encode3_h_concat <- h_t=15_encode3_unit_t=15_1_split_1
I1223 00:14:23.674489 25375 net.cpp:406] encode3_h_concat <- h_t=16_encode3_unit_t=16_1_split_0
I1223 00:14:23.674496 25375 net.cpp:380] encode3_h_concat -> h
I1223 00:14:23.674522 25375 net.cpp:122] Setting up encode3_h_concat
I1223 00:14:23.674528 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.674546 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:23.674547 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_h
I1223 00:14:23.674552 25375 net.cpp:84] Creating Layer encode3_dummy_forward_h
I1223 00:14:23.674556 25375 net.cpp:406] encode3_dummy_forward_h <- h_t=16_encode3_unit_t=16_1_split_1
I1223 00:14:23.674561 25375 net.cpp:380] encode3_dummy_forward_h -> h_t=T
I1223 00:14:23.674600 25375 net.cpp:122] Setting up encode3_dummy_forward_h
I1223 00:14:23.674607 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.674610 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:23.674616 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_c
I1223 00:14:23.674620 25375 net.cpp:84] Creating Layer encode3_dummy_forward_c
I1223 00:14:23.674624 25375 net.cpp:406] encode3_dummy_forward_c <- c_t=16
I1223 00:14:23.674641 25375 net.cpp:380] encode3_dummy_forward_c -> c_t=T
I1223 00:14:23.674679 25375 net.cpp:122] Setting up encode3_dummy_forward_c
I1223 00:14:23.674686 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.674701 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:23.674706 25375 layer_factory.hpp:77] Creating layer encode3_h_t=T_pseudoloss
I1223 00:14:23.674712 25375 net.cpp:84] Creating Layer encode3_h_t=T_pseudoloss
I1223 00:14:23.674715 25375 net.cpp:406] encode3_h_t=T_pseudoloss <- h_t=T
I1223 00:14:23.674721 25375 net.cpp:380] encode3_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:23.674801 25375 net.cpp:122] Setting up encode3_h_t=T_pseudoloss
I1223 00:14:23.674808 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.674810 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.674819 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:23.674823 25375 layer_factory.hpp:77] Creating layer encode3_c_t=T_pseudoloss
I1223 00:14:23.674827 25375 net.cpp:84] Creating Layer encode3_c_t=T_pseudoloss
I1223 00:14:23.674830 25375 net.cpp:406] encode3_c_t=T_pseudoloss <- c_t=T
I1223 00:14:23.674835 25375 net.cpp:380] encode3_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:23.674916 25375 net.cpp:122] Setting up encode3_c_t=T_pseudoloss
I1223 00:14:23.674921 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.674924 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.674927 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:23.674932 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:23.674937 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:23.674952 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:23.674957 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:23.676065 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:23.676079 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.676081 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.676086 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:23.676090 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:23.676093 25375 net.cpp:198] encode3_c_t=T_pseudoloss needs backward computation.
I1223 00:14:23.676096 25375 net.cpp:198] encode3_h_t=T_pseudoloss needs backward computation.
I1223 00:14:23.676100 25375 net.cpp:198] encode3_dummy_forward_c needs backward computation.
I1223 00:14:23.676102 25375 net.cpp:198] encode3_dummy_forward_h needs backward computation.
I1223 00:14:23.676120 25375 net.cpp:198] encode3_h_concat needs backward computation.
I1223 00:14:23.676127 25375 net.cpp:198] h_t=16_encode3_unit_t=16_1_split needs backward computation.
I1223 00:14:23.676131 25375 net.cpp:198] encode3_unit_t=16 needs backward computation.
I1223 00:14:23.676136 25375 net.cpp:198] encode3_gate_input_16 needs backward computation.
I1223 00:14:23.676139 25375 net.cpp:198] encode3_concat_hadamard_t=16 needs backward computation.
I1223 00:14:23.676143 25375 net.cpp:200] encode3_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:23.676146 25375 net.cpp:198] encode3_hadamard->output_t=15 needs backward computation.
I1223 00:14:23.676149 25375 net.cpp:198] encode3_hadamard->forget_t=15 needs backward computation.
I1223 00:14:23.676153 25375 net.cpp:198] encode3_hadamard->input_t=15 needs backward computation.
I1223 00:14:23.676156 25375 net.cpp:198] encode3_hidden->transform->15 needs backward computation.
I1223 00:14:23.676159 25375 net.cpp:198] encode3_h_conted_t=15 needs backward computation.
I1223 00:14:23.676165 25375 net.cpp:198] h_t=15_encode3_unit_t=15_1_split needs backward computation.
I1223 00:14:23.676168 25375 net.cpp:198] c_t=15_encode3_unit_t=15_0_split needs backward computation.
I1223 00:14:23.676172 25375 net.cpp:198] encode3_unit_t=15 needs backward computation.
I1223 00:14:23.676177 25375 net.cpp:198] encode3_gate_input_15 needs backward computation.
I1223 00:14:23.676180 25375 net.cpp:198] encode3_concat_hadamard_t=15 needs backward computation.
I1223 00:14:23.676185 25375 net.cpp:200] encode3_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:23.676188 25375 net.cpp:198] encode3_hadamard->output_t=14 needs backward computation.
I1223 00:14:23.676192 25375 net.cpp:198] encode3_hadamard->forget_t=14 needs backward computation.
I1223 00:14:23.676194 25375 net.cpp:198] encode3_hadamard->input_t=14 needs backward computation.
I1223 00:14:23.676198 25375 net.cpp:198] encode3_hidden->transform->14 needs backward computation.
I1223 00:14:23.676201 25375 net.cpp:198] encode3_h_conted_t=14 needs backward computation.
I1223 00:14:23.676205 25375 net.cpp:198] h_t=14_encode3_unit_t=14_1_split needs backward computation.
I1223 00:14:23.676208 25375 net.cpp:198] c_t=14_encode3_unit_t=14_0_split needs backward computation.
I1223 00:14:23.676213 25375 net.cpp:198] encode3_unit_t=14 needs backward computation.
I1223 00:14:23.676216 25375 net.cpp:198] encode3_gate_input_14 needs backward computation.
I1223 00:14:23.676220 25375 net.cpp:198] encode3_concat_hadamard_t=14 needs backward computation.
I1223 00:14:23.676225 25375 net.cpp:200] encode3_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:23.676229 25375 net.cpp:198] encode3_hadamard->output_t=13 needs backward computation.
I1223 00:14:23.676232 25375 net.cpp:198] encode3_hadamard->forget_t=13 needs backward computation.
I1223 00:14:23.676235 25375 net.cpp:198] encode3_hadamard->input_t=13 needs backward computation.
I1223 00:14:23.676239 25375 net.cpp:198] encode3_hidden->transform->13 needs backward computation.
I1223 00:14:23.676242 25375 net.cpp:198] encode3_h_conted_t=13 needs backward computation.
I1223 00:14:23.676246 25375 net.cpp:198] h_t=13_encode3_unit_t=13_1_split needs backward computation.
I1223 00:14:23.676250 25375 net.cpp:198] c_t=13_encode3_unit_t=13_0_split needs backward computation.
I1223 00:14:23.676252 25375 net.cpp:198] encode3_unit_t=13 needs backward computation.
I1223 00:14:23.676257 25375 net.cpp:198] encode3_gate_input_13 needs backward computation.
I1223 00:14:23.676261 25375 net.cpp:198] encode3_concat_hadamard_t=13 needs backward computation.
I1223 00:14:23.676266 25375 net.cpp:200] encode3_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:23.676268 25375 net.cpp:198] encode3_hadamard->output_t=12 needs backward computation.
I1223 00:14:23.676272 25375 net.cpp:198] encode3_hadamard->forget_t=12 needs backward computation.
I1223 00:14:23.676275 25375 net.cpp:198] encode3_hadamard->input_t=12 needs backward computation.
I1223 00:14:23.676280 25375 net.cpp:198] encode3_hidden->transform->12 needs backward computation.
I1223 00:14:23.676282 25375 net.cpp:198] encode3_h_conted_t=12 needs backward computation.
I1223 00:14:23.676286 25375 net.cpp:198] h_t=12_encode3_unit_t=12_1_split needs backward computation.
I1223 00:14:23.676290 25375 net.cpp:198] c_t=12_encode3_unit_t=12_0_split needs backward computation.
I1223 00:14:23.676293 25375 net.cpp:198] encode3_unit_t=12 needs backward computation.
I1223 00:14:23.676297 25375 net.cpp:198] encode3_gate_input_12 needs backward computation.
I1223 00:14:23.676302 25375 net.cpp:198] encode3_concat_hadamard_t=12 needs backward computation.
I1223 00:14:23.676309 25375 net.cpp:200] encode3_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:23.676312 25375 net.cpp:198] encode3_hadamard->output_t=11 needs backward computation.
I1223 00:14:23.676316 25375 net.cpp:198] encode3_hadamard->forget_t=11 needs backward computation.
I1223 00:14:23.676319 25375 net.cpp:198] encode3_hadamard->input_t=11 needs backward computation.
I1223 00:14:23.676322 25375 net.cpp:198] encode3_hidden->transform->11 needs backward computation.
I1223 00:14:23.676326 25375 net.cpp:198] encode3_h_conted_t=11 needs backward computation.
I1223 00:14:23.676329 25375 net.cpp:198] h_t=11_encode3_unit_t=11_1_split needs backward computation.
I1223 00:14:23.676333 25375 net.cpp:198] c_t=11_encode3_unit_t=11_0_split needs backward computation.
I1223 00:14:23.676336 25375 net.cpp:198] encode3_unit_t=11 needs backward computation.
I1223 00:14:23.676340 25375 net.cpp:198] encode3_gate_input_11 needs backward computation.
I1223 00:14:23.676344 25375 net.cpp:198] encode3_concat_hadamard_t=11 needs backward computation.
I1223 00:14:23.676349 25375 net.cpp:200] encode3_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:23.676352 25375 net.cpp:198] encode3_hadamard->output_t=10 needs backward computation.
I1223 00:14:23.676355 25375 net.cpp:198] encode3_hadamard->forget_t=10 needs backward computation.
I1223 00:14:23.676358 25375 net.cpp:198] encode3_hadamard->input_t=10 needs backward computation.
I1223 00:14:23.676362 25375 net.cpp:198] encode3_hidden->transform->10 needs backward computation.
I1223 00:14:23.676365 25375 net.cpp:198] encode3_h_conted_t=10 needs backward computation.
I1223 00:14:23.676369 25375 net.cpp:198] h_t=10_encode3_unit_t=10_1_split needs backward computation.
I1223 00:14:23.676373 25375 net.cpp:198] c_t=10_encode3_unit_t=10_0_split needs backward computation.
I1223 00:14:23.676375 25375 net.cpp:198] encode3_unit_t=10 needs backward computation.
I1223 00:14:23.676383 25375 net.cpp:198] encode3_gate_input_10 needs backward computation.
I1223 00:14:23.676386 25375 net.cpp:198] encode3_concat_hadamard_t=10 needs backward computation.
I1223 00:14:23.676391 25375 net.cpp:200] encode3_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:23.676394 25375 net.cpp:198] encode3_hadamard->output_t=9 needs backward computation.
I1223 00:14:23.676398 25375 net.cpp:198] encode3_hadamard->forget_t=9 needs backward computation.
I1223 00:14:23.676401 25375 net.cpp:198] encode3_hadamard->input_t=9 needs backward computation.
I1223 00:14:23.676404 25375 net.cpp:198] encode3_hidden->transform->9 needs backward computation.
I1223 00:14:23.676409 25375 net.cpp:198] encode3_h_conted_t=9 needs backward computation.
I1223 00:14:23.676414 25375 net.cpp:198] h_t=9_encode3_unit_t=9_1_split needs backward computation.
I1223 00:14:23.676416 25375 net.cpp:198] c_t=9_encode3_unit_t=9_0_split needs backward computation.
I1223 00:14:23.676419 25375 net.cpp:198] encode3_unit_t=9 needs backward computation.
I1223 00:14:23.676424 25375 net.cpp:198] encode3_gate_input_9 needs backward computation.
I1223 00:14:23.676429 25375 net.cpp:198] encode3_concat_hadamard_t=9 needs backward computation.
I1223 00:14:23.676434 25375 net.cpp:200] encode3_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:23.676437 25375 net.cpp:198] encode3_hadamard->output_t=8 needs backward computation.
I1223 00:14:23.676441 25375 net.cpp:198] encode3_hadamard->forget_t=8 needs backward computation.
I1223 00:14:23.676445 25375 net.cpp:198] encode3_hadamard->input_t=8 needs backward computation.
I1223 00:14:23.676448 25375 net.cpp:198] encode3_hidden->transform->8 needs backward computation.
I1223 00:14:23.676451 25375 net.cpp:198] encode3_h_conted_t=8 needs backward computation.
I1223 00:14:23.676458 25375 net.cpp:198] h_t=8_encode3_unit_t=8_1_split needs backward computation.
I1223 00:14:23.676463 25375 net.cpp:198] c_t=8_encode3_unit_t=8_0_split needs backward computation.
I1223 00:14:23.676466 25375 net.cpp:198] encode3_unit_t=8 needs backward computation.
I1223 00:14:23.676471 25375 net.cpp:198] encode3_gate_input_8 needs backward computation.
I1223 00:14:23.676476 25375 net.cpp:198] encode3_concat_hadamard_t=8 needs backward computation.
I1223 00:14:23.676482 25375 net.cpp:200] encode3_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:23.676486 25375 net.cpp:198] encode3_hadamard->output_t=7 needs backward computation.
I1223 00:14:23.676488 25375 net.cpp:198] encode3_hadamard->forget_t=7 needs backward computation.
I1223 00:14:23.676491 25375 net.cpp:198] encode3_hadamard->input_t=7 needs backward computation.
I1223 00:14:23.676496 25375 net.cpp:198] encode3_hidden->transform->7 needs backward computation.
I1223 00:14:23.676498 25375 net.cpp:198] encode3_h_conted_t=7 needs backward computation.
I1223 00:14:23.676502 25375 net.cpp:198] h_t=7_encode3_unit_t=7_1_split needs backward computation.
I1223 00:14:23.676506 25375 net.cpp:198] c_t=7_encode3_unit_t=7_0_split needs backward computation.
I1223 00:14:23.676509 25375 net.cpp:198] encode3_unit_t=7 needs backward computation.
I1223 00:14:23.676514 25375 net.cpp:198] encode3_gate_input_7 needs backward computation.
I1223 00:14:23.676518 25375 net.cpp:198] encode3_concat_hadamard_t=7 needs backward computation.
I1223 00:14:23.676523 25375 net.cpp:200] encode3_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:23.676527 25375 net.cpp:198] encode3_hadamard->output_t=6 needs backward computation.
I1223 00:14:23.676529 25375 net.cpp:198] encode3_hadamard->forget_t=6 needs backward computation.
I1223 00:14:23.676534 25375 net.cpp:198] encode3_hadamard->input_t=6 needs backward computation.
I1223 00:14:23.676538 25375 net.cpp:198] encode3_hidden->transform->6 needs backward computation.
I1223 00:14:23.676542 25375 net.cpp:198] encode3_h_conted_t=6 needs backward computation.
I1223 00:14:23.676545 25375 net.cpp:198] h_t=6_encode3_unit_t=6_1_split needs backward computation.
I1223 00:14:23.676549 25375 net.cpp:198] c_t=6_encode3_unit_t=6_0_split needs backward computation.
I1223 00:14:23.676553 25375 net.cpp:198] encode3_unit_t=6 needs backward computation.
I1223 00:14:23.676558 25375 net.cpp:198] encode3_gate_input_6 needs backward computation.
I1223 00:14:23.676561 25375 net.cpp:198] encode3_concat_hadamard_t=6 needs backward computation.
I1223 00:14:23.676566 25375 net.cpp:200] encode3_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:23.676569 25375 net.cpp:198] encode3_hadamard->output_t=5 needs backward computation.
I1223 00:14:23.676573 25375 net.cpp:198] encode3_hadamard->forget_t=5 needs backward computation.
I1223 00:14:23.676576 25375 net.cpp:198] encode3_hadamard->input_t=5 needs backward computation.
I1223 00:14:23.676579 25375 net.cpp:198] encode3_hidden->transform->5 needs backward computation.
I1223 00:14:23.676584 25375 net.cpp:198] encode3_h_conted_t=5 needs backward computation.
I1223 00:14:23.676587 25375 net.cpp:198] h_t=5_encode3_unit_t=5_1_split needs backward computation.
I1223 00:14:23.676590 25375 net.cpp:198] c_t=5_encode3_unit_t=5_0_split needs backward computation.
I1223 00:14:23.676594 25375 net.cpp:198] encode3_unit_t=5 needs backward computation.
I1223 00:14:23.676599 25375 net.cpp:198] encode3_gate_input_5 needs backward computation.
I1223 00:14:23.676604 25375 net.cpp:198] encode3_concat_hadamard_t=5 needs backward computation.
I1223 00:14:23.676609 25375 net.cpp:200] encode3_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:23.676614 25375 net.cpp:198] encode3_hadamard->output_t=4 needs backward computation.
I1223 00:14:23.676617 25375 net.cpp:198] encode3_hadamard->forget_t=4 needs backward computation.
I1223 00:14:23.676620 25375 net.cpp:198] encode3_hadamard->input_t=4 needs backward computation.
I1223 00:14:23.676625 25375 net.cpp:198] encode3_hidden->transform->4 needs backward computation.
I1223 00:14:23.676627 25375 net.cpp:198] encode3_h_conted_t=4 needs backward computation.
I1223 00:14:23.676631 25375 net.cpp:198] h_t=4_encode3_unit_t=4_1_split needs backward computation.
I1223 00:14:23.676635 25375 net.cpp:198] c_t=4_encode3_unit_t=4_0_split needs backward computation.
I1223 00:14:23.676638 25375 net.cpp:198] encode3_unit_t=4 needs backward computation.
I1223 00:14:23.676642 25375 net.cpp:198] encode3_gate_input_4 needs backward computation.
I1223 00:14:23.676647 25375 net.cpp:198] encode3_concat_hadamard_t=4 needs backward computation.
I1223 00:14:23.676652 25375 net.cpp:200] encode3_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:23.676656 25375 net.cpp:198] encode3_hadamard->output_t=3 needs backward computation.
I1223 00:14:23.676659 25375 net.cpp:198] encode3_hadamard->forget_t=3 needs backward computation.
I1223 00:14:23.676662 25375 net.cpp:198] encode3_hadamard->input_t=3 needs backward computation.
I1223 00:14:23.676666 25375 net.cpp:198] encode3_hidden->transform->3 needs backward computation.
I1223 00:14:23.676669 25375 net.cpp:198] encode3_h_conted_t=3 needs backward computation.
I1223 00:14:23.676673 25375 net.cpp:198] h_t=3_encode3_unit_t=3_1_split needs backward computation.
I1223 00:14:23.676676 25375 net.cpp:198] c_t=3_encode3_unit_t=3_0_split needs backward computation.
I1223 00:14:23.676681 25375 net.cpp:198] encode3_unit_t=3 needs backward computation.
I1223 00:14:23.676686 25375 net.cpp:198] encode3_gate_input_3 needs backward computation.
I1223 00:14:23.676690 25375 net.cpp:198] encode3_concat_hadamard_t=3 needs backward computation.
I1223 00:14:23.676694 25375 net.cpp:200] encode3_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:23.676697 25375 net.cpp:198] encode3_hadamard->output_t=2 needs backward computation.
I1223 00:14:23.676702 25375 net.cpp:198] encode3_hadamard->forget_t=2 needs backward computation.
I1223 00:14:23.676704 25375 net.cpp:198] encode3_hadamard->input_t=2 needs backward computation.
I1223 00:14:23.676708 25375 net.cpp:198] encode3_hidden->transform->2 needs backward computation.
I1223 00:14:23.676712 25375 net.cpp:198] encode3_h_conted_t=2 needs backward computation.
I1223 00:14:23.676715 25375 net.cpp:198] h_t=2_encode3_unit_t=2_1_split needs backward computation.
I1223 00:14:23.676718 25375 net.cpp:198] c_t=2_encode3_unit_t=2_0_split needs backward computation.
I1223 00:14:23.676722 25375 net.cpp:198] encode3_unit_t=2 needs backward computation.
I1223 00:14:23.676726 25375 net.cpp:198] encode3_gate_input_2 needs backward computation.
I1223 00:14:23.676730 25375 net.cpp:198] encode3_concat_hadamard_t=2 needs backward computation.
I1223 00:14:23.676734 25375 net.cpp:200] encode3_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:23.676738 25375 net.cpp:198] encode3_hadamard->output_t=1 needs backward computation.
I1223 00:14:23.676741 25375 net.cpp:198] encode3_hadamard->forget_t=1 needs backward computation.
I1223 00:14:23.676744 25375 net.cpp:198] encode3_hadamard->input_t=1 needs backward computation.
I1223 00:14:23.676748 25375 net.cpp:198] encode3_hidden->transform->1 needs backward computation.
I1223 00:14:23.676751 25375 net.cpp:198] encode3_h_conted_t=1 needs backward computation.
I1223 00:14:23.676755 25375 net.cpp:198] h_t=1_encode3_unit_t=1_1_split needs backward computation.
I1223 00:14:23.676760 25375 net.cpp:198] c_t=1_encode3_unit_t=1_0_split needs backward computation.
I1223 00:14:23.676764 25375 net.cpp:198] encode3_unit_t=1 needs backward computation.
I1223 00:14:23.676769 25375 net.cpp:198] encode3_gate_input_1 needs backward computation.
I1223 00:14:23.676772 25375 net.cpp:198] encode3_concat_hadamard_t=1 needs backward computation.
I1223 00:14:23.676779 25375 net.cpp:200] encode3_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:23.676780 25375 net.cpp:198] encode3_hadamard->output_t=0 needs backward computation.
I1223 00:14:23.676784 25375 net.cpp:198] encode3_hadamard->forget_t=0 needs backward computation.
I1223 00:14:23.676789 25375 net.cpp:198] encode3_hadamard->input_t=0 needs backward computation.
I1223 00:14:23.676791 25375 net.cpp:198] encode3_hidden->transform->0 needs backward computation.
I1223 00:14:23.676795 25375 net.cpp:198] encode3_h_conted_t=0 needs backward computation.
I1223 00:14:23.676800 25375 net.cpp:198] encode3_dummy_forward_h0 needs backward computation.
I1223 00:14:23.676803 25375 net.cpp:198] c_t=0_encode3_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:23.676806 25375 net.cpp:198] encode3_dummy_forward_c0 needs backward computation.
I1223 00:14:23.676810 25375 net.cpp:200] cont_t=16_encode3_cont_slice_15_split does not need backward computation.
I1223 00:14:23.676813 25375 net.cpp:200] cont_t=15_encode3_cont_slice_14_split does not need backward computation.
I1223 00:14:23.676818 25375 net.cpp:200] cont_t=14_encode3_cont_slice_13_split does not need backward computation.
I1223 00:14:23.676821 25375 net.cpp:200] cont_t=13_encode3_cont_slice_12_split does not need backward computation.
I1223 00:14:23.676826 25375 net.cpp:200] cont_t=12_encode3_cont_slice_11_split does not need backward computation.
I1223 00:14:23.676828 25375 net.cpp:200] cont_t=11_encode3_cont_slice_10_split does not need backward computation.
I1223 00:14:23.676832 25375 net.cpp:200] cont_t=10_encode3_cont_slice_9_split does not need backward computation.
I1223 00:14:23.676836 25375 net.cpp:200] cont_t=9_encode3_cont_slice_8_split does not need backward computation.
I1223 00:14:23.676841 25375 net.cpp:200] cont_t=8_encode3_cont_slice_7_split does not need backward computation.
I1223 00:14:23.676843 25375 net.cpp:200] cont_t=7_encode3_cont_slice_6_split does not need backward computation.
I1223 00:14:23.676848 25375 net.cpp:200] cont_t=6_encode3_cont_slice_5_split does not need backward computation.
I1223 00:14:23.676853 25375 net.cpp:200] cont_t=5_encode3_cont_slice_4_split does not need backward computation.
I1223 00:14:23.676857 25375 net.cpp:200] cont_t=4_encode3_cont_slice_3_split does not need backward computation.
I1223 00:14:23.676861 25375 net.cpp:200] cont_t=3_encode3_cont_slice_2_split does not need backward computation.
I1223 00:14:23.676864 25375 net.cpp:200] cont_t=2_encode3_cont_slice_1_split does not need backward computation.
I1223 00:14:23.676868 25375 net.cpp:200] cont_t=1_encode3_cont_slice_0_split does not need backward computation.
I1223 00:14:23.676875 25375 net.cpp:200] encode3_cont_slice does not need backward computation.
I1223 00:14:23.676879 25375 net.cpp:198] encode3_W_xc_x_slice needs backward computation.
I1223 00:14:23.676883 25375 net.cpp:200] encode3_input->cell_hidden does not need backward computation.
I1223 00:14:23.676887 25375 net.cpp:198] encode3_x->transform needs backward computation.
I1223 00:14:23.676889 25375 net.cpp:200] encode3_ does not need backward computation.
I1223 00:14:23.676892 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:23.676897 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:23.676900 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:23.677809 25375 net.cpp:255] Network initialization done.
I1223 00:14:23.678350 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:23.678359 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:23.678362 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:23.678365 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:23.678367 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:23.678370 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:23.678373 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:23.678390 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:23.678391 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:23.678395 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:23.679239 25375 net.cpp:122] Setting up encode3
I1223 00:14:23.679250 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.679255 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.679258 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.679275 25375 net.cpp:137] Memory required for data: 4286972288
I1223 00:14:23.679297 25375 layer_factory.hpp:77] Creating layer encode4
I1223 00:14:23.679323 25375 net.cpp:84] Creating Layer encode4
I1223 00:14:23.679328 25375 net.cpp:406] encode4 <- conv6-reshape_reshape-data_0_split_3
I1223 00:14:23.679333 25375 net.cpp:406] encode4 <- reshape-cm_reshape-cm_0_split_3
I1223 00:14:23.679338 25375 net.cpp:406] encode4 <- dummy_dummy_0_split_6
I1223 00:14:23.679342 25375 net.cpp:406] encode4 <- dummy_dummy_0_split_7
I1223 00:14:23.679348 25375 net.cpp:380] encode4 -> encode4
I1223 00:14:23.679358 25375 net.cpp:380] encode4 -> encode4_h
I1223 00:14:23.679368 25375 net.cpp:380] encode4 -> encode4_c
I1223 00:14:23.679376 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:23.680820 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode4_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode4_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode4_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode4_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode4_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode4_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode4_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode4_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode4_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode4_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode4_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode4_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode4_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode4_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode4_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode4_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode4_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode4_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode4_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transfor
I1223 00:14:23.681756 25375 layer_factory.hpp:77] Creating layer encode4_
I1223 00:14:23.681768 25375 net.cpp:84] Creating Layer encode4_
I1223 00:14:23.681772 25375 net.cpp:380] encode4_ -> x
I1223 00:14:23.681780 25375 net.cpp:380] encode4_ -> cont
I1223 00:14:23.681864 25375 net.cpp:122] Setting up encode4_
I1223 00:14:23.681872 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:23.681876 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:23.681879 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:23.681882 25375 layer_factory.hpp:77] Creating layer encode4_x->transform
I1223 00:14:23.681905 25375 net.cpp:84] Creating Layer encode4_x->transform
I1223 00:14:23.681908 25375 net.cpp:406] encode4_x->transform <- x
I1223 00:14:23.681915 25375 net.cpp:380] encode4_x->transform -> x->transform
I1223 00:14:23.682288 25375 net.cpp:122] Setting up encode4_x->transform
I1223 00:14:23.682296 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:23.682299 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:23.682304 25375 layer_factory.hpp:77] Creating layer encode4_input->cell_hidden
I1223 00:14:23.682325 25375 net.cpp:84] Creating Layer encode4_input->cell_hidden
I1223 00:14:23.682330 25375 net.cpp:380] encode4_input->cell_hidden -> c_t=0
I1223 00:14:23.682337 25375 net.cpp:380] encode4_input->cell_hidden -> h_t=0
I1223 00:14:23.682394 25375 net.cpp:122] Setting up encode4_input->cell_hidden
I1223 00:14:23.682399 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.682404 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.682405 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:23.682409 25375 layer_factory.hpp:77] Creating layer encode4_W_xc_x_slice
I1223 00:14:23.682415 25375 net.cpp:84] Creating Layer encode4_W_xc_x_slice
I1223 00:14:23.682417 25375 net.cpp:406] encode4_W_xc_x_slice <- x->transform
I1223 00:14:23.682425 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=1
I1223 00:14:23.682433 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=2
I1223 00:14:23.682440 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=3
I1223 00:14:23.682447 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=4
I1223 00:14:23.682456 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=5
I1223 00:14:23.682463 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=6
I1223 00:14:23.682471 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=7
I1223 00:14:23.682477 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=8
I1223 00:14:23.682483 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=9
I1223 00:14:23.682490 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=10
I1223 00:14:23.682498 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=11
I1223 00:14:23.682504 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=12
I1223 00:14:23.682512 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=13
I1223 00:14:23.682519 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=14
I1223 00:14:23.682526 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=15
I1223 00:14:23.682533 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=16
I1223 00:14:23.682765 25375 net.cpp:122] Setting up encode4_W_xc_x_slice
I1223 00:14:23.682773 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682777 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682780 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682785 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682803 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682806 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682811 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682814 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682818 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682821 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682838 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682842 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682847 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682849 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682853 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682857 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.682860 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:23.682863 25375 layer_factory.hpp:77] Creating layer encode4_cont_slice
I1223 00:14:23.682868 25375 net.cpp:84] Creating Layer encode4_cont_slice
I1223 00:14:23.682873 25375 net.cpp:406] encode4_cont_slice <- cont
I1223 00:14:23.682878 25375 net.cpp:380] encode4_cont_slice -> cont_t=1
I1223 00:14:23.682886 25375 net.cpp:380] encode4_cont_slice -> cont_t=2
I1223 00:14:23.682893 25375 net.cpp:380] encode4_cont_slice -> cont_t=3
I1223 00:14:23.682899 25375 net.cpp:380] encode4_cont_slice -> cont_t=4
I1223 00:14:23.682906 25375 net.cpp:380] encode4_cont_slice -> cont_t=5
I1223 00:14:23.682912 25375 net.cpp:380] encode4_cont_slice -> cont_t=6
I1223 00:14:23.682919 25375 net.cpp:380] encode4_cont_slice -> cont_t=7
I1223 00:14:23.682924 25375 net.cpp:380] encode4_cont_slice -> cont_t=8
I1223 00:14:23.682930 25375 net.cpp:380] encode4_cont_slice -> cont_t=9
I1223 00:14:23.682936 25375 net.cpp:380] encode4_cont_slice -> cont_t=10
I1223 00:14:23.682942 25375 net.cpp:380] encode4_cont_slice -> cont_t=11
I1223 00:14:23.682950 25375 net.cpp:380] encode4_cont_slice -> cont_t=12
I1223 00:14:23.682960 25375 net.cpp:380] encode4_cont_slice -> cont_t=13
I1223 00:14:23.682965 25375 net.cpp:380] encode4_cont_slice -> cont_t=14
I1223 00:14:23.682971 25375 net.cpp:380] encode4_cont_slice -> cont_t=15
I1223 00:14:23.682977 25375 net.cpp:380] encode4_cont_slice -> cont_t=16
I1223 00:14:23.683214 25375 net.cpp:122] Setting up encode4_cont_slice
I1223 00:14:23.683221 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683224 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683228 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683231 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683234 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683250 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683254 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683256 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683260 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683264 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683266 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683270 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683274 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683276 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683279 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683284 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683285 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:23.683288 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode4_cont_slice_0_split
I1223 00:14:23.683307 25375 net.cpp:84] Creating Layer cont_t=1_encode4_cont_slice_0_split
I1223 00:14:23.683310 25375 net.cpp:406] cont_t=1_encode4_cont_slice_0_split <- cont_t=1
I1223 00:14:23.683315 25375 net.cpp:380] cont_t=1_encode4_cont_slice_0_split -> cont_t=1_encode4_cont_slice_0_split_0
I1223 00:14:23.683321 25375 net.cpp:380] cont_t=1_encode4_cont_slice_0_split -> cont_t=1_encode4_cont_slice_0_split_1
I1223 00:14:23.683360 25375 net.cpp:122] Setting up cont_t=1_encode4_cont_slice_0_split
I1223 00:14:23.683367 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683382 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683384 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:23.683387 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode4_cont_slice_1_split
I1223 00:14:23.683404 25375 net.cpp:84] Creating Layer cont_t=2_encode4_cont_slice_1_split
I1223 00:14:23.683408 25375 net.cpp:406] cont_t=2_encode4_cont_slice_1_split <- cont_t=2
I1223 00:14:23.683424 25375 net.cpp:380] cont_t=2_encode4_cont_slice_1_split -> cont_t=2_encode4_cont_slice_1_split_0
I1223 00:14:23.683430 25375 net.cpp:380] cont_t=2_encode4_cont_slice_1_split -> cont_t=2_encode4_cont_slice_1_split_1
I1223 00:14:23.683495 25375 net.cpp:122] Setting up cont_t=2_encode4_cont_slice_1_split
I1223 00:14:23.683501 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683506 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683507 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:23.683511 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode4_cont_slice_2_split
I1223 00:14:23.683514 25375 net.cpp:84] Creating Layer cont_t=3_encode4_cont_slice_2_split
I1223 00:14:23.683531 25375 net.cpp:406] cont_t=3_encode4_cont_slice_2_split <- cont_t=3
I1223 00:14:23.683537 25375 net.cpp:380] cont_t=3_encode4_cont_slice_2_split -> cont_t=3_encode4_cont_slice_2_split_0
I1223 00:14:23.683557 25375 net.cpp:380] cont_t=3_encode4_cont_slice_2_split -> cont_t=3_encode4_cont_slice_2_split_1
I1223 00:14:23.683594 25375 net.cpp:122] Setting up cont_t=3_encode4_cont_slice_2_split
I1223 00:14:23.683600 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683604 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683619 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:23.683622 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode4_cont_slice_3_split
I1223 00:14:23.683641 25375 net.cpp:84] Creating Layer cont_t=4_encode4_cont_slice_3_split
I1223 00:14:23.683645 25375 net.cpp:406] cont_t=4_encode4_cont_slice_3_split <- cont_t=4
I1223 00:14:23.683665 25375 net.cpp:380] cont_t=4_encode4_cont_slice_3_split -> cont_t=4_encode4_cont_slice_3_split_0
I1223 00:14:23.683670 25375 net.cpp:380] cont_t=4_encode4_cont_slice_3_split -> cont_t=4_encode4_cont_slice_3_split_1
I1223 00:14:23.683706 25375 net.cpp:122] Setting up cont_t=4_encode4_cont_slice_3_split
I1223 00:14:23.683713 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683730 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683732 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:23.683735 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode4_cont_slice_4_split
I1223 00:14:23.683753 25375 net.cpp:84] Creating Layer cont_t=5_encode4_cont_slice_4_split
I1223 00:14:23.683755 25375 net.cpp:406] cont_t=5_encode4_cont_slice_4_split <- cont_t=5
I1223 00:14:23.683774 25375 net.cpp:380] cont_t=5_encode4_cont_slice_4_split -> cont_t=5_encode4_cont_slice_4_split_0
I1223 00:14:23.683780 25375 net.cpp:380] cont_t=5_encode4_cont_slice_4_split -> cont_t=5_encode4_cont_slice_4_split_1
I1223 00:14:23.683816 25375 net.cpp:122] Setting up cont_t=5_encode4_cont_slice_4_split
I1223 00:14:23.683822 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683826 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683828 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:23.683843 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode4_cont_slice_5_split
I1223 00:14:23.683850 25375 net.cpp:84] Creating Layer cont_t=6_encode4_cont_slice_5_split
I1223 00:14:23.683866 25375 net.cpp:406] cont_t=6_encode4_cont_slice_5_split <- cont_t=6
I1223 00:14:23.683871 25375 net.cpp:380] cont_t=6_encode4_cont_slice_5_split -> cont_t=6_encode4_cont_slice_5_split_0
I1223 00:14:23.683889 25375 net.cpp:380] cont_t=6_encode4_cont_slice_5_split -> cont_t=6_encode4_cont_slice_5_split_1
I1223 00:14:23.683925 25375 net.cpp:122] Setting up cont_t=6_encode4_cont_slice_5_split
I1223 00:14:23.683931 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683934 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.683936 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:23.683954 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode4_cont_slice_6_split
I1223 00:14:23.683957 25375 net.cpp:84] Creating Layer cont_t=7_encode4_cont_slice_6_split
I1223 00:14:23.683959 25375 net.cpp:406] cont_t=7_encode4_cont_slice_6_split <- cont_t=7
I1223 00:14:23.683977 25375 net.cpp:380] cont_t=7_encode4_cont_slice_6_split -> cont_t=7_encode4_cont_slice_6_split_0
I1223 00:14:23.683985 25375 net.cpp:380] cont_t=7_encode4_cont_slice_6_split -> cont_t=7_encode4_cont_slice_6_split_1
I1223 00:14:23.684021 25375 net.cpp:122] Setting up cont_t=7_encode4_cont_slice_6_split
I1223 00:14:23.684028 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684044 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684047 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:23.684051 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode4_cont_slice_7_split
I1223 00:14:23.684056 25375 net.cpp:84] Creating Layer cont_t=8_encode4_cont_slice_7_split
I1223 00:14:23.684058 25375 net.cpp:406] cont_t=8_encode4_cont_slice_7_split <- cont_t=8
I1223 00:14:23.684063 25375 net.cpp:380] cont_t=8_encode4_cont_slice_7_split -> cont_t=8_encode4_cont_slice_7_split_0
I1223 00:14:23.684069 25375 net.cpp:380] cont_t=8_encode4_cont_slice_7_split -> cont_t=8_encode4_cont_slice_7_split_1
I1223 00:14:23.684118 25375 net.cpp:122] Setting up cont_t=8_encode4_cont_slice_7_split
I1223 00:14:23.684123 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684128 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684130 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:23.684134 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode4_cont_slice_8_split
I1223 00:14:23.684137 25375 net.cpp:84] Creating Layer cont_t=9_encode4_cont_slice_8_split
I1223 00:14:23.684140 25375 net.cpp:406] cont_t=9_encode4_cont_slice_8_split <- cont_t=9
I1223 00:14:23.684145 25375 net.cpp:380] cont_t=9_encode4_cont_slice_8_split -> cont_t=9_encode4_cont_slice_8_split_0
I1223 00:14:23.684151 25375 net.cpp:380] cont_t=9_encode4_cont_slice_8_split -> cont_t=9_encode4_cont_slice_8_split_1
I1223 00:14:23.684191 25375 net.cpp:122] Setting up cont_t=9_encode4_cont_slice_8_split
I1223 00:14:23.684197 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684201 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684203 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:23.684206 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode4_cont_slice_9_split
I1223 00:14:23.684212 25375 net.cpp:84] Creating Layer cont_t=10_encode4_cont_slice_9_split
I1223 00:14:23.684216 25375 net.cpp:406] cont_t=10_encode4_cont_slice_9_split <- cont_t=10
I1223 00:14:23.684221 25375 net.cpp:380] cont_t=10_encode4_cont_slice_9_split -> cont_t=10_encode4_cont_slice_9_split_0
I1223 00:14:23.684227 25375 net.cpp:380] cont_t=10_encode4_cont_slice_9_split -> cont_t=10_encode4_cont_slice_9_split_1
I1223 00:14:23.684264 25375 net.cpp:122] Setting up cont_t=10_encode4_cont_slice_9_split
I1223 00:14:23.684270 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684274 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684276 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:23.684278 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode4_cont_slice_10_split
I1223 00:14:23.684283 25375 net.cpp:84] Creating Layer cont_t=11_encode4_cont_slice_10_split
I1223 00:14:23.684288 25375 net.cpp:406] cont_t=11_encode4_cont_slice_10_split <- cont_t=11
I1223 00:14:23.684291 25375 net.cpp:380] cont_t=11_encode4_cont_slice_10_split -> cont_t=11_encode4_cont_slice_10_split_0
I1223 00:14:23.684298 25375 net.cpp:380] cont_t=11_encode4_cont_slice_10_split -> cont_t=11_encode4_cont_slice_10_split_1
I1223 00:14:23.684334 25375 net.cpp:122] Setting up cont_t=11_encode4_cont_slice_10_split
I1223 00:14:23.684340 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684343 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684346 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:23.684350 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode4_cont_slice_11_split
I1223 00:14:23.684355 25375 net.cpp:84] Creating Layer cont_t=12_encode4_cont_slice_11_split
I1223 00:14:23.684360 25375 net.cpp:406] cont_t=12_encode4_cont_slice_11_split <- cont_t=12
I1223 00:14:23.684365 25375 net.cpp:380] cont_t=12_encode4_cont_slice_11_split -> cont_t=12_encode4_cont_slice_11_split_0
I1223 00:14:23.684370 25375 net.cpp:380] cont_t=12_encode4_cont_slice_11_split -> cont_t=12_encode4_cont_slice_11_split_1
I1223 00:14:23.684408 25375 net.cpp:122] Setting up cont_t=12_encode4_cont_slice_11_split
I1223 00:14:23.684414 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684417 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684420 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:23.684423 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode4_cont_slice_12_split
I1223 00:14:23.684427 25375 net.cpp:84] Creating Layer cont_t=13_encode4_cont_slice_12_split
I1223 00:14:23.684430 25375 net.cpp:406] cont_t=13_encode4_cont_slice_12_split <- cont_t=13
I1223 00:14:23.684435 25375 net.cpp:380] cont_t=13_encode4_cont_slice_12_split -> cont_t=13_encode4_cont_slice_12_split_0
I1223 00:14:23.684442 25375 net.cpp:380] cont_t=13_encode4_cont_slice_12_split -> cont_t=13_encode4_cont_slice_12_split_1
I1223 00:14:23.684478 25375 net.cpp:122] Setting up cont_t=13_encode4_cont_slice_12_split
I1223 00:14:23.684484 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684489 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684491 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:23.684494 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode4_cont_slice_13_split
I1223 00:14:23.684499 25375 net.cpp:84] Creating Layer cont_t=14_encode4_cont_slice_13_split
I1223 00:14:23.684502 25375 net.cpp:406] cont_t=14_encode4_cont_slice_13_split <- cont_t=14
I1223 00:14:23.684509 25375 net.cpp:380] cont_t=14_encode4_cont_slice_13_split -> cont_t=14_encode4_cont_slice_13_split_0
I1223 00:14:23.684514 25375 net.cpp:380] cont_t=14_encode4_cont_slice_13_split -> cont_t=14_encode4_cont_slice_13_split_1
I1223 00:14:23.684553 25375 net.cpp:122] Setting up cont_t=14_encode4_cont_slice_13_split
I1223 00:14:23.684561 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684564 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684567 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:23.684569 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode4_cont_slice_14_split
I1223 00:14:23.684574 25375 net.cpp:84] Creating Layer cont_t=15_encode4_cont_slice_14_split
I1223 00:14:23.684578 25375 net.cpp:406] cont_t=15_encode4_cont_slice_14_split <- cont_t=15
I1223 00:14:23.684583 25375 net.cpp:380] cont_t=15_encode4_cont_slice_14_split -> cont_t=15_encode4_cont_slice_14_split_0
I1223 00:14:23.684589 25375 net.cpp:380] cont_t=15_encode4_cont_slice_14_split -> cont_t=15_encode4_cont_slice_14_split_1
I1223 00:14:23.684626 25375 net.cpp:122] Setting up cont_t=15_encode4_cont_slice_14_split
I1223 00:14:23.684633 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684635 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684638 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:23.684641 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode4_cont_slice_15_split
I1223 00:14:23.684645 25375 net.cpp:84] Creating Layer cont_t=16_encode4_cont_slice_15_split
I1223 00:14:23.684648 25375 net.cpp:406] cont_t=16_encode4_cont_slice_15_split <- cont_t=16
I1223 00:14:23.684654 25375 net.cpp:380] cont_t=16_encode4_cont_slice_15_split -> cont_t=16_encode4_cont_slice_15_split_0
I1223 00:14:23.684661 25375 net.cpp:380] cont_t=16_encode4_cont_slice_15_split -> cont_t=16_encode4_cont_slice_15_split_1
I1223 00:14:23.684702 25375 net.cpp:122] Setting up cont_t=16_encode4_cont_slice_15_split
I1223 00:14:23.684708 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684711 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:23.684715 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:23.684717 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_c0
I1223 00:14:23.684722 25375 net.cpp:84] Creating Layer encode4_dummy_forward_c0
I1223 00:14:23.684726 25375 net.cpp:406] encode4_dummy_forward_c0 <- c_t=0
I1223 00:14:23.684731 25375 net.cpp:367] encode4_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:23.684756 25375 net.cpp:122] Setting up encode4_dummy_forward_c0
I1223 00:14:23.684762 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.684765 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:23.684772 25375 layer_factory.hpp:77] Creating layer c_t=0_encode4_dummy_forward_c0_0_split
I1223 00:14:23.684780 25375 net.cpp:84] Creating Layer c_t=0_encode4_dummy_forward_c0_0_split
I1223 00:14:23.684784 25375 net.cpp:406] c_t=0_encode4_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:23.684788 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_0
I1223 00:14:23.684797 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_1
I1223 00:14:23.684803 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_2
I1223 00:14:23.684809 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_3
I1223 00:14:23.684880 25375 net.cpp:122] Setting up c_t=0_encode4_dummy_forward_c0_0_split
I1223 00:14:23.684886 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.684890 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.684895 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.684898 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.684902 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:23.684904 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_h0
I1223 00:14:23.684909 25375 net.cpp:84] Creating Layer encode4_dummy_forward_h0
I1223 00:14:23.684913 25375 net.cpp:406] encode4_dummy_forward_h0 <- h_t=0
I1223 00:14:23.684919 25375 net.cpp:367] encode4_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:23.684943 25375 net.cpp:122] Setting up encode4_dummy_forward_h0
I1223 00:14:23.684949 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.684952 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:23.684957 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=0
I1223 00:14:23.684963 25375 net.cpp:84] Creating Layer encode4_h_conted_t=0
I1223 00:14:23.684967 25375 net.cpp:406] encode4_h_conted_t=0 <- h_t=0
I1223 00:14:23.684972 25375 net.cpp:406] encode4_h_conted_t=0 <- cont_t=1_encode4_cont_slice_0_split_0
I1223 00:14:23.684978 25375 net.cpp:380] encode4_h_conted_t=0 -> h_conted_t=0
I1223 00:14:23.685072 25375 net.cpp:122] Setting up encode4_h_conted_t=0
I1223 00:14:23.685081 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.685083 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:23.685086 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->0
I1223 00:14:23.685096 25375 net.cpp:84] Creating Layer encode4_hidden->transform->0
I1223 00:14:23.685101 25375 net.cpp:406] encode4_hidden->transform->0 <- h_conted_t=0
I1223 00:14:23.685106 25375 net.cpp:380] encode4_hidden->transform->0 -> hidden->transform->0
I1223 00:14:23.685650 25375 net.cpp:122] Setting up encode4_hidden->transform->0
I1223 00:14:23.685658 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.685662 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:23.685669 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=0
I1223 00:14:23.685691 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=0
I1223 00:14:23.685695 25375 net.cpp:406] encode4_hadamard->input_t=0 <- c_t=0_encode4_dummy_forward_c0_0_split_0
I1223 00:14:23.685714 25375 net.cpp:380] encode4_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:23.685823 25375 net.cpp:122] Setting up encode4_hadamard->input_t=0
I1223 00:14:23.685832 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.685834 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:23.685838 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=0
I1223 00:14:23.685859 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=0
I1223 00:14:23.685863 25375 net.cpp:406] encode4_hadamard->forget_t=0 <- c_t=0_encode4_dummy_forward_c0_0_split_1
I1223 00:14:23.685883 25375 net.cpp:380] encode4_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:23.685993 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=0
I1223 00:14:23.686002 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686005 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:23.686009 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=0
I1223 00:14:23.686029 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=0
I1223 00:14:23.686033 25375 net.cpp:406] encode4_hadamard->output_t=0 <- c_t=0_encode4_dummy_forward_c0_0_split_2
I1223 00:14:23.686043 25375 net.cpp:380] encode4_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:23.686159 25375 net.cpp:122] Setting up encode4_hadamard->output_t=0
I1223 00:14:23.686167 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686172 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:23.686188 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=1
I1223 00:14:23.686195 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=1
I1223 00:14:23.686200 25375 net.cpp:380] encode4_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:23.686260 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=1
I1223 00:14:23.686269 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686271 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:23.686275 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=1
I1223 00:14:23.686281 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=1
I1223 00:14:23.686285 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:23.686290 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:23.686293 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:23.686297 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:23.686303 25375 net.cpp:380] encode4_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:23.686331 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=1
I1223 00:14:23.686337 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.686341 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:23.686357 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_1
I1223 00:14:23.686362 25375 net.cpp:84] Creating Layer encode4_gate_input_1
I1223 00:14:23.686367 25375 net.cpp:406] encode4_gate_input_1 <- hidden->transform->0
I1223 00:14:23.686372 25375 net.cpp:406] encode4_gate_input_1 <- x->transform->t=1
I1223 00:14:23.686377 25375 net.cpp:406] encode4_gate_input_1 <- hadamard_t=1
I1223 00:14:23.686396 25375 net.cpp:380] encode4_gate_input_1 -> gate_input_1
I1223 00:14:23.686422 25375 net.cpp:122] Setting up encode4_gate_input_1
I1223 00:14:23.686429 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.686434 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:23.686436 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=1
I1223 00:14:23.686444 25375 net.cpp:84] Creating Layer encode4_unit_t=1
I1223 00:14:23.686448 25375 net.cpp:406] encode4_unit_t=1 <- c_t=0_encode4_dummy_forward_c0_0_split_3
I1223 00:14:23.686453 25375 net.cpp:406] encode4_unit_t=1 <- gate_input_1
I1223 00:14:23.686457 25375 net.cpp:406] encode4_unit_t=1 <- cont_t=1_encode4_cont_slice_0_split_1
I1223 00:14:23.686463 25375 net.cpp:380] encode4_unit_t=1 -> c_t=1
I1223 00:14:23.686470 25375 net.cpp:380] encode4_unit_t=1 -> h_t=1
I1223 00:14:23.686522 25375 net.cpp:122] Setting up encode4_unit_t=1
I1223 00:14:23.686529 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686534 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686537 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:23.686540 25375 layer_factory.hpp:77] Creating layer c_t=1_encode4_unit_t=1_0_split
I1223 00:14:23.686545 25375 net.cpp:84] Creating Layer c_t=1_encode4_unit_t=1_0_split
I1223 00:14:23.686549 25375 net.cpp:406] c_t=1_encode4_unit_t=1_0_split <- c_t=1
I1223 00:14:23.686555 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_0
I1223 00:14:23.686563 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_1
I1223 00:14:23.686569 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_2
I1223 00:14:23.686576 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_3
I1223 00:14:23.686638 25375 net.cpp:122] Setting up c_t=1_encode4_unit_t=1_0_split
I1223 00:14:23.686645 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686650 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686655 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686658 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686661 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:23.686664 25375 layer_factory.hpp:77] Creating layer h_t=1_encode4_unit_t=1_1_split
I1223 00:14:23.686669 25375 net.cpp:84] Creating Layer h_t=1_encode4_unit_t=1_1_split
I1223 00:14:23.686673 25375 net.cpp:406] h_t=1_encode4_unit_t=1_1_split <- h_t=1
I1223 00:14:23.686678 25375 net.cpp:380] h_t=1_encode4_unit_t=1_1_split -> h_t=1_encode4_unit_t=1_1_split_0
I1223 00:14:23.686686 25375 net.cpp:380] h_t=1_encode4_unit_t=1_1_split -> h_t=1_encode4_unit_t=1_1_split_1
I1223 00:14:23.686723 25375 net.cpp:122] Setting up h_t=1_encode4_unit_t=1_1_split
I1223 00:14:23.686730 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686734 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686738 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:23.686740 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=1
I1223 00:14:23.686749 25375 net.cpp:84] Creating Layer encode4_h_conted_t=1
I1223 00:14:23.686754 25375 net.cpp:406] encode4_h_conted_t=1 <- h_t=1_encode4_unit_t=1_1_split_0
I1223 00:14:23.686759 25375 net.cpp:406] encode4_h_conted_t=1 <- cont_t=2_encode4_cont_slice_1_split_0
I1223 00:14:23.686765 25375 net.cpp:380] encode4_h_conted_t=1 -> h_conted_t=1
I1223 00:14:23.686849 25375 net.cpp:122] Setting up encode4_h_conted_t=1
I1223 00:14:23.686856 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.686861 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:23.686863 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->1
I1223 00:14:23.686873 25375 net.cpp:84] Creating Layer encode4_hidden->transform->1
I1223 00:14:23.686877 25375 net.cpp:406] encode4_hidden->transform->1 <- h_conted_t=1
I1223 00:14:23.686883 25375 net.cpp:380] encode4_hidden->transform->1 -> hidden->transform->1
I1223 00:14:23.687398 25375 net.cpp:122] Setting up encode4_hidden->transform->1
I1223 00:14:23.687407 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.687410 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:23.687415 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.687420 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.687423 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=1
I1223 00:14:23.687430 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=1
I1223 00:14:23.687435 25375 net.cpp:406] encode4_hadamard->input_t=1 <- c_t=1_encode4_unit_t=1_0_split_0
I1223 00:14:23.687440 25375 net.cpp:380] encode4_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:23.687536 25375 net.cpp:122] Setting up encode4_hadamard->input_t=1
I1223 00:14:23.687543 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.687547 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:23.687551 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.687554 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=1
I1223 00:14:23.687561 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=1
I1223 00:14:23.687564 25375 net.cpp:406] encode4_hadamard->forget_t=1 <- c_t=1_encode4_unit_t=1_0_split_1
I1223 00:14:23.687571 25375 net.cpp:380] encode4_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:23.687678 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=1
I1223 00:14:23.687685 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.687688 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:23.687691 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.687695 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=1
I1223 00:14:23.687700 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=1
I1223 00:14:23.687718 25375 net.cpp:406] encode4_hadamard->output_t=1 <- c_t=1_encode4_unit_t=1_0_split_2
I1223 00:14:23.687724 25375 net.cpp:380] encode4_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:23.687826 25375 net.cpp:122] Setting up encode4_hadamard->output_t=1
I1223 00:14:23.687834 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.687839 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:23.687841 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.687844 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=2
I1223 00:14:23.687849 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=2
I1223 00:14:23.687857 25375 net.cpp:380] encode4_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:23.687939 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=2
I1223 00:14:23.687947 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.687949 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:23.687952 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=2
I1223 00:14:23.687958 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=2
I1223 00:14:23.687960 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:23.687965 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:23.687984 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:23.687988 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:23.687996 25375 net.cpp:380] encode4_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:23.688021 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=2
I1223 00:14:23.688027 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.688030 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:23.688033 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_2
I1223 00:14:23.688038 25375 net.cpp:84] Creating Layer encode4_gate_input_2
I1223 00:14:23.688042 25375 net.cpp:406] encode4_gate_input_2 <- hidden->transform->1
I1223 00:14:23.688047 25375 net.cpp:406] encode4_gate_input_2 <- x->transform->t=2
I1223 00:14:23.688051 25375 net.cpp:406] encode4_gate_input_2 <- hadamard_t=2
I1223 00:14:23.688058 25375 net.cpp:380] encode4_gate_input_2 -> gate_input_2
I1223 00:14:23.688083 25375 net.cpp:122] Setting up encode4_gate_input_2
I1223 00:14:23.688091 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.688093 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:23.688097 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=2
I1223 00:14:23.688102 25375 net.cpp:84] Creating Layer encode4_unit_t=2
I1223 00:14:23.688104 25375 net.cpp:406] encode4_unit_t=2 <- c_t=1_encode4_unit_t=1_0_split_3
I1223 00:14:23.688109 25375 net.cpp:406] encode4_unit_t=2 <- gate_input_2
I1223 00:14:23.688113 25375 net.cpp:406] encode4_unit_t=2 <- cont_t=2_encode4_cont_slice_1_split_1
I1223 00:14:23.688118 25375 net.cpp:380] encode4_unit_t=2 -> c_t=2
I1223 00:14:23.688125 25375 net.cpp:380] encode4_unit_t=2 -> h_t=2
I1223 00:14:23.688202 25375 net.cpp:122] Setting up encode4_unit_t=2
I1223 00:14:23.688208 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688213 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688216 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:23.688220 25375 layer_factory.hpp:77] Creating layer c_t=2_encode4_unit_t=2_0_split
I1223 00:14:23.688238 25375 net.cpp:84] Creating Layer c_t=2_encode4_unit_t=2_0_split
I1223 00:14:23.688242 25375 net.cpp:406] c_t=2_encode4_unit_t=2_0_split <- c_t=2
I1223 00:14:23.688248 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_0
I1223 00:14:23.688256 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_1
I1223 00:14:23.688263 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_2
I1223 00:14:23.688269 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_3
I1223 00:14:23.688360 25375 net.cpp:122] Setting up c_t=2_encode4_unit_t=2_0_split
I1223 00:14:23.688367 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688371 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688376 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688380 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688382 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:23.688385 25375 layer_factory.hpp:77] Creating layer h_t=2_encode4_unit_t=2_1_split
I1223 00:14:23.688405 25375 net.cpp:84] Creating Layer h_t=2_encode4_unit_t=2_1_split
I1223 00:14:23.688408 25375 net.cpp:406] h_t=2_encode4_unit_t=2_1_split <- h_t=2
I1223 00:14:23.688413 25375 net.cpp:380] h_t=2_encode4_unit_t=2_1_split -> h_t=2_encode4_unit_t=2_1_split_0
I1223 00:14:23.688418 25375 net.cpp:380] h_t=2_encode4_unit_t=2_1_split -> h_t=2_encode4_unit_t=2_1_split_1
I1223 00:14:23.688468 25375 net.cpp:122] Setting up h_t=2_encode4_unit_t=2_1_split
I1223 00:14:23.688474 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688478 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688482 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:23.688484 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=2
I1223 00:14:23.688489 25375 net.cpp:84] Creating Layer encode4_h_conted_t=2
I1223 00:14:23.688493 25375 net.cpp:406] encode4_h_conted_t=2 <- h_t=2_encode4_unit_t=2_1_split_0
I1223 00:14:23.688510 25375 net.cpp:406] encode4_h_conted_t=2 <- cont_t=3_encode4_cont_slice_2_split_0
I1223 00:14:23.688516 25375 net.cpp:380] encode4_h_conted_t=2 -> h_conted_t=2
I1223 00:14:23.688611 25375 net.cpp:122] Setting up encode4_h_conted_t=2
I1223 00:14:23.688618 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.688621 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:23.688624 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->2
I1223 00:14:23.688633 25375 net.cpp:84] Creating Layer encode4_hidden->transform->2
I1223 00:14:23.688638 25375 net.cpp:406] encode4_hidden->transform->2 <- h_conted_t=2
I1223 00:14:23.688644 25375 net.cpp:380] encode4_hidden->transform->2 -> hidden->transform->2
I1223 00:14:23.689205 25375 net.cpp:122] Setting up encode4_hidden->transform->2
I1223 00:14:23.689214 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.689218 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:23.689220 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.689224 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.689242 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=2
I1223 00:14:23.689247 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=2
I1223 00:14:23.689250 25375 net.cpp:406] encode4_hadamard->input_t=2 <- c_t=2_encode4_unit_t=2_0_split_0
I1223 00:14:23.689256 25375 net.cpp:380] encode4_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:23.689375 25375 net.cpp:122] Setting up encode4_hadamard->input_t=2
I1223 00:14:23.689383 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.689385 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:23.689389 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.689391 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=2
I1223 00:14:23.689412 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=2
I1223 00:14:23.689415 25375 net.cpp:406] encode4_hadamard->forget_t=2 <- c_t=2_encode4_unit_t=2_0_split_1
I1223 00:14:23.689420 25375 net.cpp:380] encode4_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:23.689569 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=2
I1223 00:14:23.689576 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.689579 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:23.689585 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.689602 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=2
I1223 00:14:23.689607 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=2
I1223 00:14:23.689610 25375 net.cpp:406] encode4_hadamard->output_t=2 <- c_t=2_encode4_unit_t=2_0_split_2
I1223 00:14:23.689617 25375 net.cpp:380] encode4_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:23.689729 25375 net.cpp:122] Setting up encode4_hadamard->output_t=2
I1223 00:14:23.689738 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.689740 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:23.689744 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.689748 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=3
I1223 00:14:23.689766 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=3
I1223 00:14:23.689784 25375 net.cpp:380] encode4_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:23.689865 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=3
I1223 00:14:23.689872 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.689875 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:23.689877 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=3
I1223 00:14:23.689883 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=3
I1223 00:14:23.689900 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:23.689905 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:23.689909 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:23.689913 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:23.689919 25375 net.cpp:380] encode4_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:23.689960 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=3
I1223 00:14:23.689965 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.689970 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:23.689972 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_3
I1223 00:14:23.689976 25375 net.cpp:84] Creating Layer encode4_gate_input_3
I1223 00:14:23.689980 25375 net.cpp:406] encode4_gate_input_3 <- hidden->transform->2
I1223 00:14:23.689985 25375 net.cpp:406] encode4_gate_input_3 <- x->transform->t=3
I1223 00:14:23.689988 25375 net.cpp:406] encode4_gate_input_3 <- hadamard_t=3
I1223 00:14:23.689995 25375 net.cpp:380] encode4_gate_input_3 -> gate_input_3
I1223 00:14:23.690017 25375 net.cpp:122] Setting up encode4_gate_input_3
I1223 00:14:23.690028 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.690044 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:23.690047 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=3
I1223 00:14:23.690053 25375 net.cpp:84] Creating Layer encode4_unit_t=3
I1223 00:14:23.690057 25375 net.cpp:406] encode4_unit_t=3 <- c_t=2_encode4_unit_t=2_0_split_3
I1223 00:14:23.690060 25375 net.cpp:406] encode4_unit_t=3 <- gate_input_3
I1223 00:14:23.690064 25375 net.cpp:406] encode4_unit_t=3 <- cont_t=3_encode4_cont_slice_2_split_1
I1223 00:14:23.690068 25375 net.cpp:380] encode4_unit_t=3 -> c_t=3
I1223 00:14:23.690076 25375 net.cpp:380] encode4_unit_t=3 -> h_t=3
I1223 00:14:23.690142 25375 net.cpp:122] Setting up encode4_unit_t=3
I1223 00:14:23.690150 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690153 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690156 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:23.690172 25375 layer_factory.hpp:77] Creating layer c_t=3_encode4_unit_t=3_0_split
I1223 00:14:23.690178 25375 net.cpp:84] Creating Layer c_t=3_encode4_unit_t=3_0_split
I1223 00:14:23.690181 25375 net.cpp:406] c_t=3_encode4_unit_t=3_0_split <- c_t=3
I1223 00:14:23.690186 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_0
I1223 00:14:23.690192 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_1
I1223 00:14:23.690212 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_2
I1223 00:14:23.690218 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_3
I1223 00:14:23.690296 25375 net.cpp:122] Setting up c_t=3_encode4_unit_t=3_0_split
I1223 00:14:23.690304 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690307 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690325 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690330 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690331 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:23.690335 25375 layer_factory.hpp:77] Creating layer h_t=3_encode4_unit_t=3_1_split
I1223 00:14:23.690340 25375 net.cpp:84] Creating Layer h_t=3_encode4_unit_t=3_1_split
I1223 00:14:23.690345 25375 net.cpp:406] h_t=3_encode4_unit_t=3_1_split <- h_t=3
I1223 00:14:23.690348 25375 net.cpp:380] h_t=3_encode4_unit_t=3_1_split -> h_t=3_encode4_unit_t=3_1_split_0
I1223 00:14:23.690354 25375 net.cpp:380] h_t=3_encode4_unit_t=3_1_split -> h_t=3_encode4_unit_t=3_1_split_1
I1223 00:14:23.690392 25375 net.cpp:122] Setting up h_t=3_encode4_unit_t=3_1_split
I1223 00:14:23.690397 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690402 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690404 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:23.690407 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=3
I1223 00:14:23.690412 25375 net.cpp:84] Creating Layer encode4_h_conted_t=3
I1223 00:14:23.690415 25375 net.cpp:406] encode4_h_conted_t=3 <- h_t=3_encode4_unit_t=3_1_split_0
I1223 00:14:23.690419 25375 net.cpp:406] encode4_h_conted_t=3 <- cont_t=4_encode4_cont_slice_3_split_0
I1223 00:14:23.690424 25375 net.cpp:380] encode4_h_conted_t=3 -> h_conted_t=3
I1223 00:14:23.690522 25375 net.cpp:122] Setting up encode4_h_conted_t=3
I1223 00:14:23.690529 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.690531 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:23.690534 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->3
I1223 00:14:23.690544 25375 net.cpp:84] Creating Layer encode4_hidden->transform->3
I1223 00:14:23.690548 25375 net.cpp:406] encode4_hidden->transform->3 <- h_conted_t=3
I1223 00:14:23.690554 25375 net.cpp:380] encode4_hidden->transform->3 -> hidden->transform->3
I1223 00:14:23.691089 25375 net.cpp:122] Setting up encode4_hidden->transform->3
I1223 00:14:23.691097 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.691100 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:23.691104 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.691107 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.691112 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=3
I1223 00:14:23.691117 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=3
I1223 00:14:23.691119 25375 net.cpp:406] encode4_hadamard->input_t=3 <- c_t=3_encode4_unit_t=3_0_split_0
I1223 00:14:23.691126 25375 net.cpp:380] encode4_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:23.691231 25375 net.cpp:122] Setting up encode4_hadamard->input_t=3
I1223 00:14:23.691239 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.691241 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:23.691246 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.691248 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=3
I1223 00:14:23.691269 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=3
I1223 00:14:23.691272 25375 net.cpp:406] encode4_hadamard->forget_t=3 <- c_t=3_encode4_unit_t=3_0_split_1
I1223 00:14:23.691293 25375 net.cpp:380] encode4_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:23.691406 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=3
I1223 00:14:23.691414 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.691416 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:23.691419 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.691423 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=3
I1223 00:14:23.691442 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=3
I1223 00:14:23.691445 25375 net.cpp:406] encode4_hadamard->output_t=3 <- c_t=3_encode4_unit_t=3_0_split_2
I1223 00:14:23.691464 25375 net.cpp:380] encode4_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:23.691565 25375 net.cpp:122] Setting up encode4_hadamard->output_t=3
I1223 00:14:23.691571 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.691575 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:23.691577 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.691581 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=4
I1223 00:14:23.691601 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=4
I1223 00:14:23.691606 25375 net.cpp:380] encode4_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:23.691692 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=4
I1223 00:14:23.691699 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.691702 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:23.691705 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=4
I1223 00:14:23.691711 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=4
I1223 00:14:23.691727 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:23.691733 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:23.691737 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:23.691741 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:23.691746 25375 net.cpp:380] encode4_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:23.691772 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=4
I1223 00:14:23.691792 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.691794 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:23.691797 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_4
I1223 00:14:23.691807 25375 net.cpp:84] Creating Layer encode4_gate_input_4
I1223 00:14:23.691812 25375 net.cpp:406] encode4_gate_input_4 <- hidden->transform->3
I1223 00:14:23.691815 25375 net.cpp:406] encode4_gate_input_4 <- x->transform->t=4
I1223 00:14:23.691820 25375 net.cpp:406] encode4_gate_input_4 <- hadamard_t=4
I1223 00:14:23.691838 25375 net.cpp:380] encode4_gate_input_4 -> gate_input_4
I1223 00:14:23.691866 25375 net.cpp:122] Setting up encode4_gate_input_4
I1223 00:14:23.691874 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.691877 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:23.691880 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=4
I1223 00:14:23.691885 25375 net.cpp:84] Creating Layer encode4_unit_t=4
I1223 00:14:23.691889 25375 net.cpp:406] encode4_unit_t=4 <- c_t=3_encode4_unit_t=3_0_split_3
I1223 00:14:23.691892 25375 net.cpp:406] encode4_unit_t=4 <- gate_input_4
I1223 00:14:23.691895 25375 net.cpp:406] encode4_unit_t=4 <- cont_t=4_encode4_cont_slice_3_split_1
I1223 00:14:23.691900 25375 net.cpp:380] encode4_unit_t=4 -> c_t=4
I1223 00:14:23.691905 25375 net.cpp:380] encode4_unit_t=4 -> h_t=4
I1223 00:14:23.691970 25375 net.cpp:122] Setting up encode4_unit_t=4
I1223 00:14:23.691977 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.691982 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.691983 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:23.691987 25375 layer_factory.hpp:77] Creating layer c_t=4_encode4_unit_t=4_0_split
I1223 00:14:23.691992 25375 net.cpp:84] Creating Layer c_t=4_encode4_unit_t=4_0_split
I1223 00:14:23.691994 25375 net.cpp:406] c_t=4_encode4_unit_t=4_0_split <- c_t=4
I1223 00:14:23.692003 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_0
I1223 00:14:23.692011 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_1
I1223 00:14:23.692030 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_2
I1223 00:14:23.692036 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_3
I1223 00:14:23.692111 25375 net.cpp:122] Setting up c_t=4_encode4_unit_t=4_0_split
I1223 00:14:23.692117 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692121 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692122 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692124 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692126 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:23.692127 25375 layer_factory.hpp:77] Creating layer h_t=4_encode4_unit_t=4_1_split
I1223 00:14:23.692131 25375 net.cpp:84] Creating Layer h_t=4_encode4_unit_t=4_1_split
I1223 00:14:23.692134 25375 net.cpp:406] h_t=4_encode4_unit_t=4_1_split <- h_t=4
I1223 00:14:23.692152 25375 net.cpp:380] h_t=4_encode4_unit_t=4_1_split -> h_t=4_encode4_unit_t=4_1_split_0
I1223 00:14:23.692155 25375 net.cpp:380] h_t=4_encode4_unit_t=4_1_split -> h_t=4_encode4_unit_t=4_1_split_1
I1223 00:14:23.692181 25375 net.cpp:122] Setting up h_t=4_encode4_unit_t=4_1_split
I1223 00:14:23.692185 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692188 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692189 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:23.692190 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=4
I1223 00:14:23.692195 25375 net.cpp:84] Creating Layer encode4_h_conted_t=4
I1223 00:14:23.692198 25375 net.cpp:406] encode4_h_conted_t=4 <- h_t=4_encode4_unit_t=4_1_split_0
I1223 00:14:23.692200 25375 net.cpp:406] encode4_h_conted_t=4 <- cont_t=5_encode4_cont_slice_4_split_0
I1223 00:14:23.692203 25375 net.cpp:380] encode4_h_conted_t=4 -> h_conted_t=4
I1223 00:14:23.692265 25375 net.cpp:122] Setting up encode4_h_conted_t=4
I1223 00:14:23.692268 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692270 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:23.692271 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->4
I1223 00:14:23.692277 25375 net.cpp:84] Creating Layer encode4_hidden->transform->4
I1223 00:14:23.692281 25375 net.cpp:406] encode4_hidden->transform->4 <- h_conted_t=4
I1223 00:14:23.692284 25375 net.cpp:380] encode4_hidden->transform->4 -> hidden->transform->4
I1223 00:14:23.692699 25375 net.cpp:122] Setting up encode4_hidden->transform->4
I1223 00:14:23.692709 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.692713 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:23.692716 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.692721 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.692724 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=4
I1223 00:14:23.692733 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=4
I1223 00:14:23.692737 25375 net.cpp:406] encode4_hadamard->input_t=4 <- c_t=4_encode4_unit_t=4_0_split_0
I1223 00:14:23.692744 25375 net.cpp:380] encode4_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:23.692858 25375 net.cpp:122] Setting up encode4_hadamard->input_t=4
I1223 00:14:23.692867 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.692870 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:23.692873 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.692878 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=4
I1223 00:14:23.692884 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=4
I1223 00:14:23.692888 25375 net.cpp:406] encode4_hadamard->forget_t=4 <- c_t=4_encode4_unit_t=4_0_split_1
I1223 00:14:23.692896 25375 net.cpp:380] encode4_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:23.693027 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=4
I1223 00:14:23.693035 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.693038 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:23.693042 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.693044 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=4
I1223 00:14:23.693066 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=4
I1223 00:14:23.693078 25375 net.cpp:406] encode4_hadamard->output_t=4 <- c_t=4_encode4_unit_t=4_0_split_2
I1223 00:14:23.693084 25375 net.cpp:380] encode4_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:23.693192 25375 net.cpp:122] Setting up encode4_hadamard->output_t=4
I1223 00:14:23.693199 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.693202 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:23.693205 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.693208 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=5
I1223 00:14:23.693230 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=5
I1223 00:14:23.693234 25375 net.cpp:380] encode4_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:23.694125 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=5
I1223 00:14:23.694136 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694139 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:23.694144 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=5
I1223 00:14:23.694150 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=5
I1223 00:14:23.694154 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:23.694172 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:23.694176 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:23.694180 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:23.694187 25375 net.cpp:380] encode4_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:23.694242 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=5
I1223 00:14:23.694247 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.694250 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:23.694253 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_5
I1223 00:14:23.694272 25375 net.cpp:84] Creating Layer encode4_gate_input_5
I1223 00:14:23.694277 25375 net.cpp:406] encode4_gate_input_5 <- hidden->transform->4
I1223 00:14:23.694280 25375 net.cpp:406] encode4_gate_input_5 <- x->transform->t=5
I1223 00:14:23.694298 25375 net.cpp:406] encode4_gate_input_5 <- hadamard_t=5
I1223 00:14:23.694319 25375 net.cpp:380] encode4_gate_input_5 -> gate_input_5
I1223 00:14:23.694344 25375 net.cpp:122] Setting up encode4_gate_input_5
I1223 00:14:23.694351 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.694353 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:23.694357 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=5
I1223 00:14:23.694362 25375 net.cpp:84] Creating Layer encode4_unit_t=5
I1223 00:14:23.694365 25375 net.cpp:406] encode4_unit_t=5 <- c_t=4_encode4_unit_t=4_0_split_3
I1223 00:14:23.694370 25375 net.cpp:406] encode4_unit_t=5 <- gate_input_5
I1223 00:14:23.694375 25375 net.cpp:406] encode4_unit_t=5 <- cont_t=5_encode4_cont_slice_4_split_1
I1223 00:14:23.694380 25375 net.cpp:380] encode4_unit_t=5 -> c_t=5
I1223 00:14:23.694398 25375 net.cpp:380] encode4_unit_t=5 -> h_t=5
I1223 00:14:23.694479 25375 net.cpp:122] Setting up encode4_unit_t=5
I1223 00:14:23.694486 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694490 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694492 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:23.694495 25375 layer_factory.hpp:77] Creating layer c_t=5_encode4_unit_t=5_0_split
I1223 00:14:23.694502 25375 net.cpp:84] Creating Layer c_t=5_encode4_unit_t=5_0_split
I1223 00:14:23.694519 25375 net.cpp:406] c_t=5_encode4_unit_t=5_0_split <- c_t=5
I1223 00:14:23.694524 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_0
I1223 00:14:23.694530 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_1
I1223 00:14:23.694550 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_2
I1223 00:14:23.694556 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_3
I1223 00:14:23.694633 25375 net.cpp:122] Setting up c_t=5_encode4_unit_t=5_0_split
I1223 00:14:23.694639 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694643 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694648 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694650 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694653 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:23.694655 25375 layer_factory.hpp:77] Creating layer h_t=5_encode4_unit_t=5_1_split
I1223 00:14:23.694674 25375 net.cpp:84] Creating Layer h_t=5_encode4_unit_t=5_1_split
I1223 00:14:23.694677 25375 net.cpp:406] h_t=5_encode4_unit_t=5_1_split <- h_t=5
I1223 00:14:23.694682 25375 net.cpp:380] h_t=5_encode4_unit_t=5_1_split -> h_t=5_encode4_unit_t=5_1_split_0
I1223 00:14:23.694689 25375 net.cpp:380] h_t=5_encode4_unit_t=5_1_split -> h_t=5_encode4_unit_t=5_1_split_1
I1223 00:14:23.694738 25375 net.cpp:122] Setting up h_t=5_encode4_unit_t=5_1_split
I1223 00:14:23.694746 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694749 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694751 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:23.694754 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=5
I1223 00:14:23.694759 25375 net.cpp:84] Creating Layer encode4_h_conted_t=5
I1223 00:14:23.694777 25375 net.cpp:406] encode4_h_conted_t=5 <- h_t=5_encode4_unit_t=5_1_split_0
I1223 00:14:23.694782 25375 net.cpp:406] encode4_h_conted_t=5 <- cont_t=6_encode4_cont_slice_5_split_0
I1223 00:14:23.694799 25375 net.cpp:380] encode4_h_conted_t=5 -> h_conted_t=5
I1223 00:14:23.694885 25375 net.cpp:122] Setting up encode4_h_conted_t=5
I1223 00:14:23.694895 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.694897 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:23.694900 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->5
I1223 00:14:23.694911 25375 net.cpp:84] Creating Layer encode4_hidden->transform->5
I1223 00:14:23.694916 25375 net.cpp:406] encode4_hidden->transform->5 <- h_conted_t=5
I1223 00:14:23.694921 25375 net.cpp:380] encode4_hidden->transform->5 -> hidden->transform->5
I1223 00:14:23.695502 25375 net.cpp:122] Setting up encode4_hidden->transform->5
I1223 00:14:23.695510 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.695513 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:23.695518 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.695536 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.695539 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=5
I1223 00:14:23.695544 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=5
I1223 00:14:23.695549 25375 net.cpp:406] encode4_hadamard->input_t=5 <- c_t=5_encode4_unit_t=5_0_split_0
I1223 00:14:23.695555 25375 net.cpp:380] encode4_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:23.695667 25375 net.cpp:122] Setting up encode4_hadamard->input_t=5
I1223 00:14:23.695675 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.695678 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:23.695695 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.695698 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=5
I1223 00:14:23.695703 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=5
I1223 00:14:23.695708 25375 net.cpp:406] encode4_hadamard->forget_t=5 <- c_t=5_encode4_unit_t=5_0_split_1
I1223 00:14:23.695714 25375 net.cpp:380] encode4_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:23.695837 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=5
I1223 00:14:23.695843 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.695847 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:23.695850 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.695853 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=5
I1223 00:14:23.695858 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=5
I1223 00:14:23.695863 25375 net.cpp:406] encode4_hadamard->output_t=5 <- c_t=5_encode4_unit_t=5_0_split_2
I1223 00:14:23.695868 25375 net.cpp:380] encode4_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:23.695986 25375 net.cpp:122] Setting up encode4_hadamard->output_t=5
I1223 00:14:23.695993 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.695996 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:23.696002 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.696007 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=6
I1223 00:14:23.696013 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=6
I1223 00:14:23.696018 25375 net.cpp:380] encode4_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:23.696089 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=6
I1223 00:14:23.696096 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696112 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:23.696115 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=6
I1223 00:14:23.696121 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=6
I1223 00:14:23.696125 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:23.696128 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:23.696133 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:23.696136 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:23.696154 25375 net.cpp:380] encode4_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:23.696182 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=6
I1223 00:14:23.696187 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.696190 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:23.696193 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_6
I1223 00:14:23.696198 25375 net.cpp:84] Creating Layer encode4_gate_input_6
I1223 00:14:23.696202 25375 net.cpp:406] encode4_gate_input_6 <- hidden->transform->5
I1223 00:14:23.696207 25375 net.cpp:406] encode4_gate_input_6 <- x->transform->t=6
I1223 00:14:23.696210 25375 net.cpp:406] encode4_gate_input_6 <- hadamard_t=6
I1223 00:14:23.696216 25375 net.cpp:380] encode4_gate_input_6 -> gate_input_6
I1223 00:14:23.696240 25375 net.cpp:122] Setting up encode4_gate_input_6
I1223 00:14:23.696247 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.696249 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:23.696252 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=6
I1223 00:14:23.696276 25375 net.cpp:84] Creating Layer encode4_unit_t=6
I1223 00:14:23.696280 25375 net.cpp:406] encode4_unit_t=6 <- c_t=5_encode4_unit_t=5_0_split_3
I1223 00:14:23.696297 25375 net.cpp:406] encode4_unit_t=6 <- gate_input_6
I1223 00:14:23.696301 25375 net.cpp:406] encode4_unit_t=6 <- cont_t=6_encode4_cont_slice_5_split_1
I1223 00:14:23.696306 25375 net.cpp:380] encode4_unit_t=6 -> c_t=6
I1223 00:14:23.696312 25375 net.cpp:380] encode4_unit_t=6 -> h_t=6
I1223 00:14:23.696365 25375 net.cpp:122] Setting up encode4_unit_t=6
I1223 00:14:23.696384 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696403 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696404 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:23.696408 25375 layer_factory.hpp:77] Creating layer c_t=6_encode4_unit_t=6_0_split
I1223 00:14:23.696429 25375 net.cpp:84] Creating Layer c_t=6_encode4_unit_t=6_0_split
I1223 00:14:23.696432 25375 net.cpp:406] c_t=6_encode4_unit_t=6_0_split <- c_t=6
I1223 00:14:23.696437 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_0
I1223 00:14:23.696445 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_1
I1223 00:14:23.696451 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_2
I1223 00:14:23.696457 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_3
I1223 00:14:23.696519 25375 net.cpp:122] Setting up c_t=6_encode4_unit_t=6_0_split
I1223 00:14:23.696527 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696530 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696534 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696552 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696554 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:23.696557 25375 layer_factory.hpp:77] Creating layer h_t=6_encode4_unit_t=6_1_split
I1223 00:14:23.696574 25375 net.cpp:84] Creating Layer h_t=6_encode4_unit_t=6_1_split
I1223 00:14:23.696578 25375 net.cpp:406] h_t=6_encode4_unit_t=6_1_split <- h_t=6
I1223 00:14:23.696595 25375 net.cpp:380] h_t=6_encode4_unit_t=6_1_split -> h_t=6_encode4_unit_t=6_1_split_0
I1223 00:14:23.696602 25375 net.cpp:380] h_t=6_encode4_unit_t=6_1_split -> h_t=6_encode4_unit_t=6_1_split_1
I1223 00:14:23.696637 25375 net.cpp:122] Setting up h_t=6_encode4_unit_t=6_1_split
I1223 00:14:23.696657 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696661 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696663 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:23.696666 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=6
I1223 00:14:23.696673 25375 net.cpp:84] Creating Layer encode4_h_conted_t=6
I1223 00:14:23.696676 25375 net.cpp:406] encode4_h_conted_t=6 <- h_t=6_encode4_unit_t=6_1_split_0
I1223 00:14:23.696681 25375 net.cpp:406] encode4_h_conted_t=6 <- cont_t=7_encode4_cont_slice_6_split_0
I1223 00:14:23.696699 25375 net.cpp:380] encode4_h_conted_t=6 -> h_conted_t=6
I1223 00:14:23.696795 25375 net.cpp:122] Setting up encode4_h_conted_t=6
I1223 00:14:23.696802 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.696805 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:23.696808 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->6
I1223 00:14:23.696818 25375 net.cpp:84] Creating Layer encode4_hidden->transform->6
I1223 00:14:23.696822 25375 net.cpp:406] encode4_hidden->transform->6 <- h_conted_t=6
I1223 00:14:23.696830 25375 net.cpp:380] encode4_hidden->transform->6 -> hidden->transform->6
I1223 00:14:23.697407 25375 net.cpp:122] Setting up encode4_hidden->transform->6
I1223 00:14:23.697417 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.697419 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:23.697422 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.697427 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.697430 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=6
I1223 00:14:23.697435 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=6
I1223 00:14:23.697439 25375 net.cpp:406] encode4_hadamard->input_t=6 <- c_t=6_encode4_unit_t=6_0_split_0
I1223 00:14:23.697444 25375 net.cpp:380] encode4_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:23.697546 25375 net.cpp:122] Setting up encode4_hadamard->input_t=6
I1223 00:14:23.697553 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.697556 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:23.697559 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.697563 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=6
I1223 00:14:23.697582 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=6
I1223 00:14:23.697584 25375 net.cpp:406] encode4_hadamard->forget_t=6 <- c_t=6_encode4_unit_t=6_0_split_1
I1223 00:14:23.697603 25375 net.cpp:380] encode4_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:23.697721 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=6
I1223 00:14:23.697728 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.697731 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:23.697736 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.697737 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=6
I1223 00:14:23.697762 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=6
I1223 00:14:23.697764 25375 net.cpp:406] encode4_hadamard->output_t=6 <- c_t=6_encode4_unit_t=6_0_split_2
I1223 00:14:23.697770 25375 net.cpp:380] encode4_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:23.697916 25375 net.cpp:122] Setting up encode4_hadamard->output_t=6
I1223 00:14:23.697922 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.697924 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:23.697928 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.697932 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=7
I1223 00:14:23.697952 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=7
I1223 00:14:23.697957 25375 net.cpp:380] encode4_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:23.698036 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=7
I1223 00:14:23.698043 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698046 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:23.698048 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=7
I1223 00:14:23.698055 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=7
I1223 00:14:23.698057 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:23.698076 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:23.698081 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:23.698084 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:23.698091 25375 net.cpp:380] encode4_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:23.698128 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=7
I1223 00:14:23.698137 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.698139 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:23.698143 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_7
I1223 00:14:23.698148 25375 net.cpp:84] Creating Layer encode4_gate_input_7
I1223 00:14:23.698151 25375 net.cpp:406] encode4_gate_input_7 <- hidden->transform->6
I1223 00:14:23.698155 25375 net.cpp:406] encode4_gate_input_7 <- x->transform->t=7
I1223 00:14:23.698159 25375 net.cpp:406] encode4_gate_input_7 <- hadamard_t=7
I1223 00:14:23.698164 25375 net.cpp:380] encode4_gate_input_7 -> gate_input_7
I1223 00:14:23.698218 25375 net.cpp:122] Setting up encode4_gate_input_7
I1223 00:14:23.698237 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.698240 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:23.698242 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=7
I1223 00:14:23.698261 25375 net.cpp:84] Creating Layer encode4_unit_t=7
I1223 00:14:23.698266 25375 net.cpp:406] encode4_unit_t=7 <- c_t=6_encode4_unit_t=6_0_split_3
I1223 00:14:23.698269 25375 net.cpp:406] encode4_unit_t=7 <- gate_input_7
I1223 00:14:23.698285 25375 net.cpp:406] encode4_unit_t=7 <- cont_t=7_encode4_cont_slice_6_split_1
I1223 00:14:23.698290 25375 net.cpp:380] encode4_unit_t=7 -> c_t=7
I1223 00:14:23.698310 25375 net.cpp:380] encode4_unit_t=7 -> h_t=7
I1223 00:14:23.698388 25375 net.cpp:122] Setting up encode4_unit_t=7
I1223 00:14:23.698407 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698411 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698415 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:23.698416 25375 layer_factory.hpp:77] Creating layer c_t=7_encode4_unit_t=7_0_split
I1223 00:14:23.698436 25375 net.cpp:84] Creating Layer c_t=7_encode4_unit_t=7_0_split
I1223 00:14:23.698439 25375 net.cpp:406] c_t=7_encode4_unit_t=7_0_split <- c_t=7
I1223 00:14:23.698459 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_0
I1223 00:14:23.698467 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_1
I1223 00:14:23.698472 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_2
I1223 00:14:23.698478 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_3
I1223 00:14:23.698556 25375 net.cpp:122] Setting up c_t=7_encode4_unit_t=7_0_split
I1223 00:14:23.698577 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698580 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698585 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698588 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698590 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:23.698593 25375 layer_factory.hpp:77] Creating layer h_t=7_encode4_unit_t=7_1_split
I1223 00:14:23.698611 25375 net.cpp:84] Creating Layer h_t=7_encode4_unit_t=7_1_split
I1223 00:14:23.698614 25375 net.cpp:406] h_t=7_encode4_unit_t=7_1_split <- h_t=7
I1223 00:14:23.698623 25375 net.cpp:380] h_t=7_encode4_unit_t=7_1_split -> h_t=7_encode4_unit_t=7_1_split_0
I1223 00:14:23.698629 25375 net.cpp:380] h_t=7_encode4_unit_t=7_1_split -> h_t=7_encode4_unit_t=7_1_split_1
I1223 00:14:23.698679 25375 net.cpp:122] Setting up h_t=7_encode4_unit_t=7_1_split
I1223 00:14:23.698686 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698690 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698693 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:23.698695 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=7
I1223 00:14:23.698700 25375 net.cpp:84] Creating Layer encode4_h_conted_t=7
I1223 00:14:23.698717 25375 net.cpp:406] encode4_h_conted_t=7 <- h_t=7_encode4_unit_t=7_1_split_0
I1223 00:14:23.698721 25375 net.cpp:406] encode4_h_conted_t=7 <- cont_t=8_encode4_cont_slice_7_split_0
I1223 00:14:23.698726 25375 net.cpp:380] encode4_h_conted_t=7 -> h_conted_t=7
I1223 00:14:23.698818 25375 net.cpp:122] Setting up encode4_h_conted_t=7
I1223 00:14:23.698827 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.698829 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:23.698832 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->7
I1223 00:14:23.698842 25375 net.cpp:84] Creating Layer encode4_hidden->transform->7
I1223 00:14:23.698845 25375 net.cpp:406] encode4_hidden->transform->7 <- h_conted_t=7
I1223 00:14:23.698853 25375 net.cpp:380] encode4_hidden->transform->7 -> hidden->transform->7
I1223 00:14:23.699432 25375 net.cpp:122] Setting up encode4_hidden->transform->7
I1223 00:14:23.699441 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.699445 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:23.699448 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.699452 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.699455 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=7
I1223 00:14:23.699475 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=7
I1223 00:14:23.699478 25375 net.cpp:406] encode4_hadamard->input_t=7 <- c_t=7_encode4_unit_t=7_0_split_0
I1223 00:14:23.699484 25375 net.cpp:380] encode4_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:23.699589 25375 net.cpp:122] Setting up encode4_hadamard->input_t=7
I1223 00:14:23.699595 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.699599 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:23.699602 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.699605 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=7
I1223 00:14:23.699626 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=7
I1223 00:14:23.699630 25375 net.cpp:406] encode4_hadamard->forget_t=7 <- c_t=7_encode4_unit_t=7_0_split_1
I1223 00:14:23.699647 25375 net.cpp:380] encode4_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:23.699769 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=7
I1223 00:14:23.699777 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.699779 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:23.699784 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.699786 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=7
I1223 00:14:23.699805 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=7
I1223 00:14:23.699808 25375 net.cpp:406] encode4_hadamard->output_t=7 <- c_t=7_encode4_unit_t=7_0_split_2
I1223 00:14:23.699815 25375 net.cpp:380] encode4_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:23.699957 25375 net.cpp:122] Setting up encode4_hadamard->output_t=7
I1223 00:14:23.699968 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.699972 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:23.699975 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.699992 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=8
I1223 00:14:23.699997 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=8
I1223 00:14:23.700003 25375 net.cpp:380] encode4_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:23.700080 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=8
I1223 00:14:23.700088 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700090 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:23.700093 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=8
I1223 00:14:23.700098 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=8
I1223 00:14:23.700116 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:23.700121 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:23.700139 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:23.700142 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:23.700147 25375 net.cpp:380] encode4_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:23.700214 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=8
I1223 00:14:23.700220 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.700223 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:23.700227 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_8
I1223 00:14:23.700230 25375 net.cpp:84] Creating Layer encode4_gate_input_8
I1223 00:14:23.700249 25375 net.cpp:406] encode4_gate_input_8 <- hidden->transform->7
I1223 00:14:23.700253 25375 net.cpp:406] encode4_gate_input_8 <- x->transform->t=8
I1223 00:14:23.700270 25375 net.cpp:406] encode4_gate_input_8 <- hadamard_t=8
I1223 00:14:23.700276 25375 net.cpp:380] encode4_gate_input_8 -> gate_input_8
I1223 00:14:23.700314 25375 net.cpp:122] Setting up encode4_gate_input_8
I1223 00:14:23.700320 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.700323 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:23.700326 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=8
I1223 00:14:23.700331 25375 net.cpp:84] Creating Layer encode4_unit_t=8
I1223 00:14:23.700335 25375 net.cpp:406] encode4_unit_t=8 <- c_t=7_encode4_unit_t=7_0_split_3
I1223 00:14:23.700338 25375 net.cpp:406] encode4_unit_t=8 <- gate_input_8
I1223 00:14:23.700342 25375 net.cpp:406] encode4_unit_t=8 <- cont_t=8_encode4_cont_slice_7_split_1
I1223 00:14:23.700348 25375 net.cpp:380] encode4_unit_t=8 -> c_t=8
I1223 00:14:23.700354 25375 net.cpp:380] encode4_unit_t=8 -> h_t=8
I1223 00:14:23.700446 25375 net.cpp:122] Setting up encode4_unit_t=8
I1223 00:14:23.700453 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700456 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700459 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:23.700461 25375 layer_factory.hpp:77] Creating layer c_t=8_encode4_unit_t=8_0_split
I1223 00:14:23.700466 25375 net.cpp:84] Creating Layer c_t=8_encode4_unit_t=8_0_split
I1223 00:14:23.700469 25375 net.cpp:406] c_t=8_encode4_unit_t=8_0_split <- c_t=8
I1223 00:14:23.700474 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_0
I1223 00:14:23.700481 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_1
I1223 00:14:23.700500 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_2
I1223 00:14:23.700505 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_3
I1223 00:14:23.700595 25375 net.cpp:122] Setting up c_t=8_encode4_unit_t=8_0_split
I1223 00:14:23.700615 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700619 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700623 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700626 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700629 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:23.700633 25375 layer_factory.hpp:77] Creating layer h_t=8_encode4_unit_t=8_1_split
I1223 00:14:23.700651 25375 net.cpp:84] Creating Layer h_t=8_encode4_unit_t=8_1_split
I1223 00:14:23.700654 25375 net.cpp:406] h_t=8_encode4_unit_t=8_1_split <- h_t=8
I1223 00:14:23.700660 25375 net.cpp:380] h_t=8_encode4_unit_t=8_1_split -> h_t=8_encode4_unit_t=8_1_split_0
I1223 00:14:23.700665 25375 net.cpp:380] h_t=8_encode4_unit_t=8_1_split -> h_t=8_encode4_unit_t=8_1_split_1
I1223 00:14:23.700701 25375 net.cpp:122] Setting up h_t=8_encode4_unit_t=8_1_split
I1223 00:14:23.700708 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700712 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700727 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:23.700731 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=8
I1223 00:14:23.700736 25375 net.cpp:84] Creating Layer encode4_h_conted_t=8
I1223 00:14:23.700753 25375 net.cpp:406] encode4_h_conted_t=8 <- h_t=8_encode4_unit_t=8_1_split_0
I1223 00:14:23.700757 25375 net.cpp:406] encode4_h_conted_t=8 <- cont_t=9_encode4_cont_slice_8_split_0
I1223 00:14:23.700763 25375 net.cpp:380] encode4_h_conted_t=8 -> h_conted_t=8
I1223 00:14:23.700855 25375 net.cpp:122] Setting up encode4_h_conted_t=8
I1223 00:14:23.700862 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.700865 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:23.700867 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->8
I1223 00:14:23.700891 25375 net.cpp:84] Creating Layer encode4_hidden->transform->8
I1223 00:14:23.700896 25375 net.cpp:406] encode4_hidden->transform->8 <- h_conted_t=8
I1223 00:14:23.700901 25375 net.cpp:380] encode4_hidden->transform->8 -> hidden->transform->8
I1223 00:14:23.701452 25375 net.cpp:122] Setting up encode4_hidden->transform->8
I1223 00:14:23.701460 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.701478 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:23.701480 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.701498 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.701500 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=8
I1223 00:14:23.701506 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=8
I1223 00:14:23.701509 25375 net.cpp:406] encode4_hadamard->input_t=8 <- c_t=8_encode4_unit_t=8_0_split_0
I1223 00:14:23.701516 25375 net.cpp:380] encode4_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:23.701629 25375 net.cpp:122] Setting up encode4_hadamard->input_t=8
I1223 00:14:23.701637 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.701639 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:23.701642 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.701645 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=8
I1223 00:14:23.701665 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=8
I1223 00:14:23.701668 25375 net.cpp:406] encode4_hadamard->forget_t=8 <- c_t=8_encode4_unit_t=8_0_split_1
I1223 00:14:23.701675 25375 net.cpp:380] encode4_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:23.701812 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=8
I1223 00:14:23.701818 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.701822 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:23.701824 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.701828 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=8
I1223 00:14:23.701848 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=8
I1223 00:14:23.701850 25375 net.cpp:406] encode4_hadamard->output_t=8 <- c_t=8_encode4_unit_t=8_0_split_2
I1223 00:14:23.701869 25375 net.cpp:380] encode4_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:23.701992 25375 net.cpp:122] Setting up encode4_hadamard->output_t=8
I1223 00:14:23.702000 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702003 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:23.702005 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.702008 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=9
I1223 00:14:23.702028 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=9
I1223 00:14:23.702033 25375 net.cpp:380] encode4_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:23.702124 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=9
I1223 00:14:23.702131 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702134 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:23.702150 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=9
I1223 00:14:23.702173 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=9
I1223 00:14:23.702177 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:23.702194 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:23.702198 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:23.702201 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:23.702206 25375 net.cpp:380] encode4_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:23.702231 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=9
I1223 00:14:23.702237 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.702240 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:23.702244 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_9
I1223 00:14:23.702261 25375 net.cpp:84] Creating Layer encode4_gate_input_9
I1223 00:14:23.702265 25375 net.cpp:406] encode4_gate_input_9 <- hidden->transform->8
I1223 00:14:23.702268 25375 net.cpp:406] encode4_gate_input_9 <- x->transform->t=9
I1223 00:14:23.702286 25375 net.cpp:406] encode4_gate_input_9 <- hadamard_t=9
I1223 00:14:23.702292 25375 net.cpp:380] encode4_gate_input_9 -> gate_input_9
I1223 00:14:23.702318 25375 net.cpp:122] Setting up encode4_gate_input_9
I1223 00:14:23.702324 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.702327 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:23.702330 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=9
I1223 00:14:23.702335 25375 net.cpp:84] Creating Layer encode4_unit_t=9
I1223 00:14:23.702338 25375 net.cpp:406] encode4_unit_t=9 <- c_t=8_encode4_unit_t=8_0_split_3
I1223 00:14:23.702342 25375 net.cpp:406] encode4_unit_t=9 <- gate_input_9
I1223 00:14:23.702347 25375 net.cpp:406] encode4_unit_t=9 <- cont_t=9_encode4_cont_slice_8_split_1
I1223 00:14:23.702353 25375 net.cpp:380] encode4_unit_t=9 -> c_t=9
I1223 00:14:23.702359 25375 net.cpp:380] encode4_unit_t=9 -> h_t=9
I1223 00:14:23.702438 25375 net.cpp:122] Setting up encode4_unit_t=9
I1223 00:14:23.702445 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702450 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702452 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:23.702455 25375 layer_factory.hpp:77] Creating layer c_t=9_encode4_unit_t=9_0_split
I1223 00:14:23.702461 25375 net.cpp:84] Creating Layer c_t=9_encode4_unit_t=9_0_split
I1223 00:14:23.702476 25375 net.cpp:406] c_t=9_encode4_unit_t=9_0_split <- c_t=9
I1223 00:14:23.702482 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_0
I1223 00:14:23.702489 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_1
I1223 00:14:23.702495 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_2
I1223 00:14:23.702500 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_3
I1223 00:14:23.702589 25375 net.cpp:122] Setting up c_t=9_encode4_unit_t=9_0_split
I1223 00:14:23.702595 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702600 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702605 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702607 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702610 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:23.702613 25375 layer_factory.hpp:77] Creating layer h_t=9_encode4_unit_t=9_1_split
I1223 00:14:23.702618 25375 net.cpp:84] Creating Layer h_t=9_encode4_unit_t=9_1_split
I1223 00:14:23.702635 25375 net.cpp:406] h_t=9_encode4_unit_t=9_1_split <- h_t=9
I1223 00:14:23.702639 25375 net.cpp:380] h_t=9_encode4_unit_t=9_1_split -> h_t=9_encode4_unit_t=9_1_split_0
I1223 00:14:23.702646 25375 net.cpp:380] h_t=9_encode4_unit_t=9_1_split -> h_t=9_encode4_unit_t=9_1_split_1
I1223 00:14:23.702682 25375 net.cpp:122] Setting up h_t=9_encode4_unit_t=9_1_split
I1223 00:14:23.702702 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702706 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702709 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:23.702713 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=9
I1223 00:14:23.702718 25375 net.cpp:84] Creating Layer encode4_h_conted_t=9
I1223 00:14:23.702720 25375 net.cpp:406] encode4_h_conted_t=9 <- h_t=9_encode4_unit_t=9_1_split_0
I1223 00:14:23.702725 25375 net.cpp:406] encode4_h_conted_t=9 <- cont_t=10_encode4_cont_slice_9_split_0
I1223 00:14:23.702744 25375 net.cpp:380] encode4_h_conted_t=9 -> h_conted_t=9
I1223 00:14:23.702838 25375 net.cpp:122] Setting up encode4_h_conted_t=9
I1223 00:14:23.702846 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.702848 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:23.702852 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->9
I1223 00:14:23.702859 25375 net.cpp:84] Creating Layer encode4_hidden->transform->9
I1223 00:14:23.702863 25375 net.cpp:406] encode4_hidden->transform->9 <- h_conted_t=9
I1223 00:14:23.702870 25375 net.cpp:380] encode4_hidden->transform->9 -> hidden->transform->9
I1223 00:14:23.703420 25375 net.cpp:122] Setting up encode4_hidden->transform->9
I1223 00:14:23.703428 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.703445 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:23.703449 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.703454 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.703456 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=9
I1223 00:14:23.703464 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=9
I1223 00:14:23.703467 25375 net.cpp:406] encode4_hadamard->input_t=9 <- c_t=9_encode4_unit_t=9_0_split_0
I1223 00:14:23.703474 25375 net.cpp:380] encode4_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:23.703583 25375 net.cpp:122] Setting up encode4_hadamard->input_t=9
I1223 00:14:23.703590 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.703593 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:23.703598 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.703599 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=9
I1223 00:14:23.703620 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=9
I1223 00:14:23.703624 25375 net.cpp:406] encode4_hadamard->forget_t=9 <- c_t=9_encode4_unit_t=9_0_split_1
I1223 00:14:23.703629 25375 net.cpp:380] encode4_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:23.703757 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=9
I1223 00:14:23.703763 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.703766 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:23.703769 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.703773 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=9
I1223 00:14:23.703794 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=9
I1223 00:14:23.703797 25375 net.cpp:406] encode4_hadamard->output_t=9 <- c_t=9_encode4_unit_t=9_0_split_2
I1223 00:14:23.703802 25375 net.cpp:380] encode4_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:23.703946 25375 net.cpp:122] Setting up encode4_hadamard->output_t=9
I1223 00:14:23.703953 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.703956 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:23.703960 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.703963 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=10
I1223 00:14:23.703986 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=10
I1223 00:14:23.703992 25375 net.cpp:380] encode4_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:23.704830 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=10
I1223 00:14:23.704841 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.704844 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:23.704847 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=10
I1223 00:14:23.704867 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=10
I1223 00:14:23.704871 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:23.704876 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:23.704880 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:23.704885 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:23.704890 25375 net.cpp:380] encode4_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:23.704937 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=10
I1223 00:14:23.704944 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.704947 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:23.704949 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_10
I1223 00:14:23.704955 25375 net.cpp:84] Creating Layer encode4_gate_input_10
I1223 00:14:23.704958 25375 net.cpp:406] encode4_gate_input_10 <- hidden->transform->9
I1223 00:14:23.704962 25375 net.cpp:406] encode4_gate_input_10 <- x->transform->t=10
I1223 00:14:23.704967 25375 net.cpp:406] encode4_gate_input_10 <- hadamard_t=10
I1223 00:14:23.704972 25375 net.cpp:380] encode4_gate_input_10 -> gate_input_10
I1223 00:14:23.705008 25375 net.cpp:122] Setting up encode4_gate_input_10
I1223 00:14:23.705015 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.705030 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:23.705032 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=10
I1223 00:14:23.705054 25375 net.cpp:84] Creating Layer encode4_unit_t=10
I1223 00:14:23.705057 25375 net.cpp:406] encode4_unit_t=10 <- c_t=9_encode4_unit_t=9_0_split_3
I1223 00:14:23.705061 25375 net.cpp:406] encode4_unit_t=10 <- gate_input_10
I1223 00:14:23.705083 25375 net.cpp:406] encode4_unit_t=10 <- cont_t=10_encode4_cont_slice_9_split_1
I1223 00:14:23.705090 25375 net.cpp:380] encode4_unit_t=10 -> c_t=10
I1223 00:14:23.705097 25375 net.cpp:380] encode4_unit_t=10 -> h_t=10
I1223 00:14:23.705176 25375 net.cpp:122] Setting up encode4_unit_t=10
I1223 00:14:23.705183 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705188 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705189 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:23.705193 25375 layer_factory.hpp:77] Creating layer c_t=10_encode4_unit_t=10_0_split
I1223 00:14:23.705214 25375 net.cpp:84] Creating Layer c_t=10_encode4_unit_t=10_0_split
I1223 00:14:23.705217 25375 net.cpp:406] c_t=10_encode4_unit_t=10_0_split <- c_t=10
I1223 00:14:23.705222 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_0
I1223 00:14:23.705243 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_1
I1223 00:14:23.705250 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_2
I1223 00:14:23.705255 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_3
I1223 00:14:23.705334 25375 net.cpp:122] Setting up c_t=10_encode4_unit_t=10_0_split
I1223 00:14:23.705341 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705345 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705348 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705353 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705355 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:23.705371 25375 layer_factory.hpp:77] Creating layer h_t=10_encode4_unit_t=10_1_split
I1223 00:14:23.705376 25375 net.cpp:84] Creating Layer h_t=10_encode4_unit_t=10_1_split
I1223 00:14:23.705379 25375 net.cpp:406] h_t=10_encode4_unit_t=10_1_split <- h_t=10
I1223 00:14:23.705384 25375 net.cpp:380] h_t=10_encode4_unit_t=10_1_split -> h_t=10_encode4_unit_t=10_1_split_0
I1223 00:14:23.705391 25375 net.cpp:380] h_t=10_encode4_unit_t=10_1_split -> h_t=10_encode4_unit_t=10_1_split_1
I1223 00:14:23.705440 25375 net.cpp:122] Setting up h_t=10_encode4_unit_t=10_1_split
I1223 00:14:23.705447 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705451 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705453 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:23.705456 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=10
I1223 00:14:23.705463 25375 net.cpp:84] Creating Layer encode4_h_conted_t=10
I1223 00:14:23.705466 25375 net.cpp:406] encode4_h_conted_t=10 <- h_t=10_encode4_unit_t=10_1_split_0
I1223 00:14:23.705471 25375 net.cpp:406] encode4_h_conted_t=10 <- cont_t=11_encode4_cont_slice_10_split_0
I1223 00:14:23.705476 25375 net.cpp:380] encode4_h_conted_t=10 -> h_conted_t=10
I1223 00:14:23.705598 25375 net.cpp:122] Setting up encode4_h_conted_t=10
I1223 00:14:23.705605 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.705607 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:23.705610 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->10
I1223 00:14:23.705633 25375 net.cpp:84] Creating Layer encode4_hidden->transform->10
I1223 00:14:23.705636 25375 net.cpp:406] encode4_hidden->transform->10 <- h_conted_t=10
I1223 00:14:23.705644 25375 net.cpp:380] encode4_hidden->transform->10 -> hidden->transform->10
I1223 00:14:23.706185 25375 net.cpp:122] Setting up encode4_hidden->transform->10
I1223 00:14:23.706194 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.706197 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:23.706200 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.706204 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.706207 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=10
I1223 00:14:23.706212 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=10
I1223 00:14:23.706229 25375 net.cpp:406] encode4_hadamard->input_t=10 <- c_t=10_encode4_unit_t=10_0_split_0
I1223 00:14:23.706234 25375 net.cpp:380] encode4_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:23.706346 25375 net.cpp:122] Setting up encode4_hadamard->input_t=10
I1223 00:14:23.706352 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.706356 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:23.706359 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.706363 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=10
I1223 00:14:23.706369 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=10
I1223 00:14:23.706372 25375 net.cpp:406] encode4_hadamard->forget_t=10 <- c_t=10_encode4_unit_t=10_0_split_1
I1223 00:14:23.706390 25375 net.cpp:380] encode4_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:23.706504 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=10
I1223 00:14:23.706512 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.706514 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:23.706518 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.706521 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=10
I1223 00:14:23.706527 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=10
I1223 00:14:23.706544 25375 net.cpp:406] encode4_hadamard->output_t=10 <- c_t=10_encode4_unit_t=10_0_split_2
I1223 00:14:23.706549 25375 net.cpp:380] encode4_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:23.706660 25375 net.cpp:122] Setting up encode4_hadamard->output_t=10
I1223 00:14:23.706667 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.706670 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:23.706673 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.706677 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=11
I1223 00:14:23.706682 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=11
I1223 00:14:23.706686 25375 net.cpp:380] encode4_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:23.706754 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=11
I1223 00:14:23.706774 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.706778 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:23.706780 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=11
I1223 00:14:23.706785 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=11
I1223 00:14:23.706789 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:23.706794 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:23.706810 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:23.706814 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:23.706820 25375 net.cpp:380] encode4_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:23.706845 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=11
I1223 00:14:23.706852 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.706856 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:23.706858 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_11
I1223 00:14:23.706878 25375 net.cpp:84] Creating Layer encode4_gate_input_11
I1223 00:14:23.706881 25375 net.cpp:406] encode4_gate_input_11 <- hidden->transform->10
I1223 00:14:23.706885 25375 net.cpp:406] encode4_gate_input_11 <- x->transform->t=11
I1223 00:14:23.706889 25375 net.cpp:406] encode4_gate_input_11 <- hadamard_t=11
I1223 00:14:23.706894 25375 net.cpp:380] encode4_gate_input_11 -> gate_input_11
I1223 00:14:23.706933 25375 net.cpp:122] Setting up encode4_gate_input_11
I1223 00:14:23.706939 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.706943 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:23.706944 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=11
I1223 00:14:23.706950 25375 net.cpp:84] Creating Layer encode4_unit_t=11
I1223 00:14:23.706954 25375 net.cpp:406] encode4_unit_t=11 <- c_t=10_encode4_unit_t=10_0_split_3
I1223 00:14:23.706959 25375 net.cpp:406] encode4_unit_t=11 <- gate_input_11
I1223 00:14:23.706962 25375 net.cpp:406] encode4_unit_t=11 <- cont_t=11_encode4_cont_slice_10_split_1
I1223 00:14:23.706966 25375 net.cpp:380] encode4_unit_t=11 -> c_t=11
I1223 00:14:23.706972 25375 net.cpp:380] encode4_unit_t=11 -> h_t=11
I1223 00:14:23.707052 25375 net.cpp:122] Setting up encode4_unit_t=11
I1223 00:14:23.707059 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707063 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707065 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:23.707068 25375 layer_factory.hpp:77] Creating layer c_t=11_encode4_unit_t=11_0_split
I1223 00:14:23.707073 25375 net.cpp:84] Creating Layer c_t=11_encode4_unit_t=11_0_split
I1223 00:14:23.707077 25375 net.cpp:406] c_t=11_encode4_unit_t=11_0_split <- c_t=11
I1223 00:14:23.707082 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_0
I1223 00:14:23.707106 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_1
I1223 00:14:23.707113 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_2
I1223 00:14:23.707119 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_3
I1223 00:14:23.707211 25375 net.cpp:122] Setting up c_t=11_encode4_unit_t=11_0_split
I1223 00:14:23.707217 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707221 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707226 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707228 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707247 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:23.707249 25375 layer_factory.hpp:77] Creating layer h_t=11_encode4_unit_t=11_1_split
I1223 00:14:23.707253 25375 net.cpp:84] Creating Layer h_t=11_encode4_unit_t=11_1_split
I1223 00:14:23.707257 25375 net.cpp:406] h_t=11_encode4_unit_t=11_1_split <- h_t=11
I1223 00:14:23.707263 25375 net.cpp:380] h_t=11_encode4_unit_t=11_1_split -> h_t=11_encode4_unit_t=11_1_split_0
I1223 00:14:23.707270 25375 net.cpp:380] h_t=11_encode4_unit_t=11_1_split -> h_t=11_encode4_unit_t=11_1_split_1
I1223 00:14:23.707321 25375 net.cpp:122] Setting up h_t=11_encode4_unit_t=11_1_split
I1223 00:14:23.707327 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707332 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707334 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:23.707337 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=11
I1223 00:14:23.707356 25375 net.cpp:84] Creating Layer encode4_h_conted_t=11
I1223 00:14:23.707360 25375 net.cpp:406] encode4_h_conted_t=11 <- h_t=11_encode4_unit_t=11_1_split_0
I1223 00:14:23.707363 25375 net.cpp:406] encode4_h_conted_t=11 <- cont_t=12_encode4_cont_slice_11_split_0
I1223 00:14:23.707368 25375 net.cpp:380] encode4_h_conted_t=11 -> h_conted_t=11
I1223 00:14:23.707460 25375 net.cpp:122] Setting up encode4_h_conted_t=11
I1223 00:14:23.707468 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.707470 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:23.707473 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->11
I1223 00:14:23.707495 25375 net.cpp:84] Creating Layer encode4_hidden->transform->11
I1223 00:14:23.707499 25375 net.cpp:406] encode4_hidden->transform->11 <- h_conted_t=11
I1223 00:14:23.707507 25375 net.cpp:380] encode4_hidden->transform->11 -> hidden->transform->11
I1223 00:14:23.708058 25375 net.cpp:122] Setting up encode4_hidden->transform->11
I1223 00:14:23.708066 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.708070 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:23.708086 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.708091 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.708093 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=11
I1223 00:14:23.708099 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=11
I1223 00:14:23.708102 25375 net.cpp:406] encode4_hadamard->input_t=11 <- c_t=11_encode4_unit_t=11_0_split_0
I1223 00:14:23.708109 25375 net.cpp:380] encode4_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:23.708226 25375 net.cpp:122] Setting up encode4_hadamard->input_t=11
I1223 00:14:23.708235 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.708237 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:23.708241 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.708245 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=11
I1223 00:14:23.708250 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=11
I1223 00:14:23.708252 25375 net.cpp:406] encode4_hadamard->forget_t=11 <- c_t=11_encode4_unit_t=11_0_split_1
I1223 00:14:23.708261 25375 net.cpp:380] encode4_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:23.708371 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=11
I1223 00:14:23.708379 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.708381 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:23.708384 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.708387 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=11
I1223 00:14:23.708408 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=11
I1223 00:14:23.708412 25375 net.cpp:406] encode4_hadamard->output_t=11 <- c_t=11_encode4_unit_t=11_0_split_2
I1223 00:14:23.708417 25375 net.cpp:380] encode4_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:23.708513 25375 net.cpp:122] Setting up encode4_hadamard->output_t=11
I1223 00:14:23.708520 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.708523 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:23.708526 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.708529 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=12
I1223 00:14:23.708536 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=12
I1223 00:14:23.708540 25375 net.cpp:380] encode4_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:23.708607 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=12
I1223 00:14:23.708626 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.708629 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:23.708632 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=12
I1223 00:14:23.708653 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=12
I1223 00:14:23.708670 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:23.708675 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:23.708679 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:23.708683 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:23.708688 25375 net.cpp:380] encode4_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:23.708714 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=12
I1223 00:14:23.708720 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.708722 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:23.708725 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_12
I1223 00:14:23.708745 25375 net.cpp:84] Creating Layer encode4_gate_input_12
I1223 00:14:23.708748 25375 net.cpp:406] encode4_gate_input_12 <- hidden->transform->11
I1223 00:14:23.708767 25375 net.cpp:406] encode4_gate_input_12 <- x->transform->t=12
I1223 00:14:23.708771 25375 net.cpp:406] encode4_gate_input_12 <- hadamard_t=12
I1223 00:14:23.708791 25375 net.cpp:380] encode4_gate_input_12 -> gate_input_12
I1223 00:14:23.708823 25375 net.cpp:122] Setting up encode4_gate_input_12
I1223 00:14:23.708832 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.708834 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:23.708850 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=12
I1223 00:14:23.708855 25375 net.cpp:84] Creating Layer encode4_unit_t=12
I1223 00:14:23.708858 25375 net.cpp:406] encode4_unit_t=12 <- c_t=11_encode4_unit_t=11_0_split_3
I1223 00:14:23.708863 25375 net.cpp:406] encode4_unit_t=12 <- gate_input_12
I1223 00:14:23.708866 25375 net.cpp:406] encode4_unit_t=12 <- cont_t=12_encode4_cont_slice_11_split_1
I1223 00:14:23.708871 25375 net.cpp:380] encode4_unit_t=12 -> c_t=12
I1223 00:14:23.708878 25375 net.cpp:380] encode4_unit_t=12 -> h_t=12
I1223 00:14:23.708942 25375 net.cpp:122] Setting up encode4_unit_t=12
I1223 00:14:23.708950 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.708953 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.708956 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:23.708972 25375 layer_factory.hpp:77] Creating layer c_t=12_encode4_unit_t=12_0_split
I1223 00:14:23.708977 25375 net.cpp:84] Creating Layer c_t=12_encode4_unit_t=12_0_split
I1223 00:14:23.708981 25375 net.cpp:406] c_t=12_encode4_unit_t=12_0_split <- c_t=12
I1223 00:14:23.708986 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_0
I1223 00:14:23.708992 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_1
I1223 00:14:23.708998 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_2
I1223 00:14:23.709003 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_3
I1223 00:14:23.709086 25375 net.cpp:122] Setting up c_t=12_encode4_unit_t=12_0_split
I1223 00:14:23.709095 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.709100 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.709102 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.709106 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.709122 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:23.709125 25375 layer_factory.hpp:77] Creating layer h_t=12_encode4_unit_t=12_1_split
I1223 00:14:23.709130 25375 net.cpp:84] Creating Layer h_t=12_encode4_unit_t=12_1_split
I1223 00:14:23.709133 25375 net.cpp:406] h_t=12_encode4_unit_t=12_1_split <- h_t=12
I1223 00:14:23.709139 25375 net.cpp:380] h_t=12_encode4_unit_t=12_1_split -> h_t=12_encode4_unit_t=12_1_split_0
I1223 00:14:23.709146 25375 net.cpp:380] h_t=12_encode4_unit_t=12_1_split -> h_t=12_encode4_unit_t=12_1_split_1
I1223 00:14:23.709198 25375 net.cpp:122] Setting up h_t=12_encode4_unit_t=12_1_split
I1223 00:14:23.709204 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.709208 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.709211 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:23.709214 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=12
I1223 00:14:23.709233 25375 net.cpp:84] Creating Layer encode4_h_conted_t=12
I1223 00:14:23.709236 25375 net.cpp:406] encode4_h_conted_t=12 <- h_t=12_encode4_unit_t=12_1_split_0
I1223 00:14:23.709254 25375 net.cpp:406] encode4_h_conted_t=12 <- cont_t=13_encode4_cont_slice_12_split_0
I1223 00:14:23.709261 25375 net.cpp:380] encode4_h_conted_t=12 -> h_conted_t=12
I1223 00:14:23.709357 25375 net.cpp:122] Setting up encode4_h_conted_t=12
I1223 00:14:23.709364 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.709381 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:23.709384 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->12
I1223 00:14:23.709394 25375 net.cpp:84] Creating Layer encode4_hidden->transform->12
I1223 00:14:23.709399 25375 net.cpp:406] encode4_hidden->transform->12 <- h_conted_t=12
I1223 00:14:23.709406 25375 net.cpp:380] encode4_hidden->transform->12 -> hidden->transform->12
I1223 00:14:23.709965 25375 net.cpp:122] Setting up encode4_hidden->transform->12
I1223 00:14:23.709974 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.709976 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:23.709980 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.709987 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.709991 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=12
I1223 00:14:23.710000 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=12
I1223 00:14:23.710002 25375 net.cpp:406] encode4_hadamard->input_t=12 <- c_t=12_encode4_unit_t=12_0_split_0
I1223 00:14:23.710008 25375 net.cpp:380] encode4_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:23.710125 25375 net.cpp:122] Setting up encode4_hadamard->input_t=12
I1223 00:14:23.710132 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710134 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:23.710139 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.710155 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=12
I1223 00:14:23.710161 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=12
I1223 00:14:23.710165 25375 net.cpp:406] encode4_hadamard->forget_t=12 <- c_t=12_encode4_unit_t=12_0_split_1
I1223 00:14:23.710171 25375 net.cpp:380] encode4_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:23.710285 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=12
I1223 00:14:23.710292 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710294 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:23.710311 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.710314 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=12
I1223 00:14:23.710319 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=12
I1223 00:14:23.710322 25375 net.cpp:406] encode4_hadamard->output_t=12 <- c_t=12_encode4_unit_t=12_0_split_2
I1223 00:14:23.710328 25375 net.cpp:380] encode4_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:23.710440 25375 net.cpp:122] Setting up encode4_hadamard->output_t=12
I1223 00:14:23.710450 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710453 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:23.710458 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.710474 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=13
I1223 00:14:23.710479 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=13
I1223 00:14:23.710484 25375 net.cpp:380] encode4_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:23.710539 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=13
I1223 00:14:23.710546 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710549 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:23.710551 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=13
I1223 00:14:23.710559 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=13
I1223 00:14:23.710562 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:23.710566 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:23.710571 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:23.710573 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:23.710578 25375 net.cpp:380] encode4_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:23.710605 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=13
I1223 00:14:23.710613 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.710615 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:23.710618 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_13
I1223 00:14:23.710636 25375 net.cpp:84] Creating Layer encode4_gate_input_13
I1223 00:14:23.710640 25375 net.cpp:406] encode4_gate_input_13 <- hidden->transform->12
I1223 00:14:23.710644 25375 net.cpp:406] encode4_gate_input_13 <- x->transform->t=13
I1223 00:14:23.710649 25375 net.cpp:406] encode4_gate_input_13 <- hadamard_t=13
I1223 00:14:23.710655 25375 net.cpp:380] encode4_gate_input_13 -> gate_input_13
I1223 00:14:23.710695 25375 net.cpp:122] Setting up encode4_gate_input_13
I1223 00:14:23.710702 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.710705 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:23.710707 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=13
I1223 00:14:23.710712 25375 net.cpp:84] Creating Layer encode4_unit_t=13
I1223 00:14:23.710716 25375 net.cpp:406] encode4_unit_t=13 <- c_t=12_encode4_unit_t=12_0_split_3
I1223 00:14:23.710721 25375 net.cpp:406] encode4_unit_t=13 <- gate_input_13
I1223 00:14:23.710726 25375 net.cpp:406] encode4_unit_t=13 <- cont_t=13_encode4_cont_slice_12_split_1
I1223 00:14:23.710731 25375 net.cpp:380] encode4_unit_t=13 -> c_t=13
I1223 00:14:23.710738 25375 net.cpp:380] encode4_unit_t=13 -> h_t=13
I1223 00:14:23.710808 25375 net.cpp:122] Setting up encode4_unit_t=13
I1223 00:14:23.710816 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710820 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710824 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:23.710839 25375 layer_factory.hpp:77] Creating layer c_t=13_encode4_unit_t=13_0_split
I1223 00:14:23.710844 25375 net.cpp:84] Creating Layer c_t=13_encode4_unit_t=13_0_split
I1223 00:14:23.710847 25375 net.cpp:406] c_t=13_encode4_unit_t=13_0_split <- c_t=13
I1223 00:14:23.710852 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_0
I1223 00:14:23.710860 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_1
I1223 00:14:23.710867 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_2
I1223 00:14:23.710873 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_3
I1223 00:14:23.710958 25375 net.cpp:122] Setting up c_t=13_encode4_unit_t=13_0_split
I1223 00:14:23.710966 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710970 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710974 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710978 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.710981 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:23.710983 25375 layer_factory.hpp:77] Creating layer h_t=13_encode4_unit_t=13_1_split
I1223 00:14:23.710989 25375 net.cpp:84] Creating Layer h_t=13_encode4_unit_t=13_1_split
I1223 00:14:23.710994 25375 net.cpp:406] h_t=13_encode4_unit_t=13_1_split <- h_t=13
I1223 00:14:23.710999 25375 net.cpp:380] h_t=13_encode4_unit_t=13_1_split -> h_t=13_encode4_unit_t=13_1_split_0
I1223 00:14:23.711005 25375 net.cpp:380] h_t=13_encode4_unit_t=13_1_split -> h_t=13_encode4_unit_t=13_1_split_1
I1223 00:14:23.711062 25375 net.cpp:122] Setting up h_t=13_encode4_unit_t=13_1_split
I1223 00:14:23.711071 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.711076 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.711078 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:23.711081 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=13
I1223 00:14:23.711086 25375 net.cpp:84] Creating Layer encode4_h_conted_t=13
I1223 00:14:23.711091 25375 net.cpp:406] encode4_h_conted_t=13 <- h_t=13_encode4_unit_t=13_1_split_0
I1223 00:14:23.711094 25375 net.cpp:406] encode4_h_conted_t=13 <- cont_t=14_encode4_cont_slice_13_split_0
I1223 00:14:23.711102 25375 net.cpp:380] encode4_h_conted_t=13 -> h_conted_t=13
I1223 00:14:23.711186 25375 net.cpp:122] Setting up encode4_h_conted_t=13
I1223 00:14:23.711194 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.711196 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:23.711199 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->13
I1223 00:14:23.711210 25375 net.cpp:84] Creating Layer encode4_hidden->transform->13
I1223 00:14:23.711215 25375 net.cpp:406] encode4_hidden->transform->13 <- h_conted_t=13
I1223 00:14:23.711221 25375 net.cpp:380] encode4_hidden->transform->13 -> hidden->transform->13
I1223 00:14:23.711772 25375 net.cpp:122] Setting up encode4_hidden->transform->13
I1223 00:14:23.711781 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.711783 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:23.711787 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.711791 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.711807 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=13
I1223 00:14:23.711815 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=13
I1223 00:14:23.711822 25375 net.cpp:406] encode4_hadamard->input_t=13 <- c_t=13_encode4_unit_t=13_0_split_0
I1223 00:14:23.711827 25375 net.cpp:380] encode4_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:23.711959 25375 net.cpp:122] Setting up encode4_hadamard->input_t=13
I1223 00:14:23.711966 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.711969 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:23.711972 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.711977 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=13
I1223 00:14:23.712000 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=13
I1223 00:14:23.712003 25375 net.cpp:406] encode4_hadamard->forget_t=13 <- c_t=13_encode4_unit_t=13_0_split_1
I1223 00:14:23.712010 25375 net.cpp:380] encode4_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:23.712151 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=13
I1223 00:14:23.712157 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712160 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:23.712163 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.712167 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=13
I1223 00:14:23.712172 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=13
I1223 00:14:23.712175 25375 net.cpp:406] encode4_hadamard->output_t=13 <- c_t=13_encode4_unit_t=13_0_split_2
I1223 00:14:23.712194 25375 net.cpp:380] encode4_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:23.712316 25375 net.cpp:122] Setting up encode4_hadamard->output_t=13
I1223 00:14:23.712322 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712326 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:23.712328 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.712332 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=14
I1223 00:14:23.712339 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=14
I1223 00:14:23.712343 25375 net.cpp:380] encode4_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:23.712414 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=14
I1223 00:14:23.712422 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712425 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:23.712429 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=14
I1223 00:14:23.712446 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=14
I1223 00:14:23.712450 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:23.712455 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:23.712458 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:23.712462 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:23.712467 25375 net.cpp:380] encode4_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:23.712494 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=14
I1223 00:14:23.712514 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.712517 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:23.712520 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_14
I1223 00:14:23.712525 25375 net.cpp:84] Creating Layer encode4_gate_input_14
I1223 00:14:23.712528 25375 net.cpp:406] encode4_gate_input_14 <- hidden->transform->13
I1223 00:14:23.712533 25375 net.cpp:406] encode4_gate_input_14 <- x->transform->t=14
I1223 00:14:23.712538 25375 net.cpp:406] encode4_gate_input_14 <- hadamard_t=14
I1223 00:14:23.712556 25375 net.cpp:380] encode4_gate_input_14 -> gate_input_14
I1223 00:14:23.712580 25375 net.cpp:122] Setting up encode4_gate_input_14
I1223 00:14:23.712586 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.712589 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:23.712592 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=14
I1223 00:14:23.712599 25375 net.cpp:84] Creating Layer encode4_unit_t=14
I1223 00:14:23.712602 25375 net.cpp:406] encode4_unit_t=14 <- c_t=13_encode4_unit_t=13_0_split_3
I1223 00:14:23.712606 25375 net.cpp:406] encode4_unit_t=14 <- gate_input_14
I1223 00:14:23.712610 25375 net.cpp:406] encode4_unit_t=14 <- cont_t=14_encode4_cont_slice_13_split_1
I1223 00:14:23.712615 25375 net.cpp:380] encode4_unit_t=14 -> c_t=14
I1223 00:14:23.712621 25375 net.cpp:380] encode4_unit_t=14 -> h_t=14
I1223 00:14:23.712687 25375 net.cpp:122] Setting up encode4_unit_t=14
I1223 00:14:23.712693 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712697 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712700 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:23.712718 25375 layer_factory.hpp:77] Creating layer c_t=14_encode4_unit_t=14_0_split
I1223 00:14:23.712723 25375 net.cpp:84] Creating Layer c_t=14_encode4_unit_t=14_0_split
I1223 00:14:23.712726 25375 net.cpp:406] c_t=14_encode4_unit_t=14_0_split <- c_t=14
I1223 00:14:23.712731 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_0
I1223 00:14:23.712738 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_1
I1223 00:14:23.712744 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_2
I1223 00:14:23.712750 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_3
I1223 00:14:23.712827 25375 net.cpp:122] Setting up c_t=14_encode4_unit_t=14_0_split
I1223 00:14:23.712834 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712852 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712855 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712872 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712874 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:23.712877 25375 layer_factory.hpp:77] Creating layer h_t=14_encode4_unit_t=14_1_split
I1223 00:14:23.712882 25375 net.cpp:84] Creating Layer h_t=14_encode4_unit_t=14_1_split
I1223 00:14:23.712884 25375 net.cpp:406] h_t=14_encode4_unit_t=14_1_split <- h_t=14
I1223 00:14:23.712889 25375 net.cpp:380] h_t=14_encode4_unit_t=14_1_split -> h_t=14_encode4_unit_t=14_1_split_0
I1223 00:14:23.712898 25375 net.cpp:380] h_t=14_encode4_unit_t=14_1_split -> h_t=14_encode4_unit_t=14_1_split_1
I1223 00:14:23.712947 25375 net.cpp:122] Setting up h_t=14_encode4_unit_t=14_1_split
I1223 00:14:23.712954 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712958 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.712960 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:23.712976 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=14
I1223 00:14:23.712982 25375 net.cpp:84] Creating Layer encode4_h_conted_t=14
I1223 00:14:23.712986 25375 net.cpp:406] encode4_h_conted_t=14 <- h_t=14_encode4_unit_t=14_1_split_0
I1223 00:14:23.712990 25375 net.cpp:406] encode4_h_conted_t=14 <- cont_t=15_encode4_cont_slice_14_split_0
I1223 00:14:23.712996 25375 net.cpp:380] encode4_h_conted_t=14 -> h_conted_t=14
I1223 00:14:23.713096 25375 net.cpp:122] Setting up encode4_h_conted_t=14
I1223 00:14:23.713104 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.713107 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:23.713110 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->14
I1223 00:14:23.713132 25375 net.cpp:84] Creating Layer encode4_hidden->transform->14
I1223 00:14:23.713137 25375 net.cpp:406] encode4_hidden->transform->14 <- h_conted_t=14
I1223 00:14:23.713145 25375 net.cpp:380] encode4_hidden->transform->14 -> hidden->transform->14
I1223 00:14:23.713695 25375 net.cpp:122] Setting up encode4_hidden->transform->14
I1223 00:14:23.713702 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.713706 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:23.713709 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.713714 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.713717 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=14
I1223 00:14:23.713722 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=14
I1223 00:14:23.713739 25375 net.cpp:406] encode4_hadamard->input_t=14 <- c_t=14_encode4_unit_t=14_0_split_0
I1223 00:14:23.713744 25375 net.cpp:380] encode4_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:23.713855 25375 net.cpp:122] Setting up encode4_hadamard->input_t=14
I1223 00:14:23.713863 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.713865 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:23.713870 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.713872 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=14
I1223 00:14:23.713893 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=14
I1223 00:14:23.713897 25375 net.cpp:406] encode4_hadamard->forget_t=14 <- c_t=14_encode4_unit_t=14_0_split_1
I1223 00:14:23.713902 25375 net.cpp:380] encode4_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:23.714012 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=14
I1223 00:14:23.714020 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.714022 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:23.714026 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.714028 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=14
I1223 00:14:23.714037 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=14
I1223 00:14:23.714040 25375 net.cpp:406] encode4_hadamard->output_t=14 <- c_t=14_encode4_unit_t=14_0_split_2
I1223 00:14:23.714046 25375 net.cpp:380] encode4_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:23.714169 25375 net.cpp:122] Setting up encode4_hadamard->output_t=14
I1223 00:14:23.714176 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.714179 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:23.714182 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.714185 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=15
I1223 00:14:23.714190 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=15
I1223 00:14:23.714195 25375 net.cpp:380] encode4_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:23.714988 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=15
I1223 00:14:23.714998 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715003 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:23.715004 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=15
I1223 00:14:23.715011 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=15
I1223 00:14:23.715015 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:23.715020 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:23.715024 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:23.715028 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:23.715032 25375 net.cpp:380] encode4_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:23.715093 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=15
I1223 00:14:23.715101 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.715102 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:23.715106 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_15
I1223 00:14:23.715111 25375 net.cpp:84] Creating Layer encode4_gate_input_15
I1223 00:14:23.715116 25375 net.cpp:406] encode4_gate_input_15 <- hidden->transform->14
I1223 00:14:23.715119 25375 net.cpp:406] encode4_gate_input_15 <- x->transform->t=15
I1223 00:14:23.715123 25375 net.cpp:406] encode4_gate_input_15 <- hadamard_t=15
I1223 00:14:23.715128 25375 net.cpp:380] encode4_gate_input_15 -> gate_input_15
I1223 00:14:23.715169 25375 net.cpp:122] Setting up encode4_gate_input_15
I1223 00:14:23.715188 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.715190 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:23.715193 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=15
I1223 00:14:23.715198 25375 net.cpp:84] Creating Layer encode4_unit_t=15
I1223 00:14:23.715201 25375 net.cpp:406] encode4_unit_t=15 <- c_t=14_encode4_unit_t=14_0_split_3
I1223 00:14:23.715205 25375 net.cpp:406] encode4_unit_t=15 <- gate_input_15
I1223 00:14:23.715210 25375 net.cpp:406] encode4_unit_t=15 <- cont_t=15_encode4_cont_slice_14_split_1
I1223 00:14:23.715215 25375 net.cpp:380] encode4_unit_t=15 -> c_t=15
I1223 00:14:23.715221 25375 net.cpp:380] encode4_unit_t=15 -> h_t=15
I1223 00:14:23.715302 25375 net.cpp:122] Setting up encode4_unit_t=15
I1223 00:14:23.715309 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715313 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715315 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:23.715318 25375 layer_factory.hpp:77] Creating layer c_t=15_encode4_unit_t=15_0_split
I1223 00:14:23.715325 25375 net.cpp:84] Creating Layer c_t=15_encode4_unit_t=15_0_split
I1223 00:14:23.715328 25375 net.cpp:406] c_t=15_encode4_unit_t=15_0_split <- c_t=15
I1223 00:14:23.715334 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_0
I1223 00:14:23.715340 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_1
I1223 00:14:23.715346 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_2
I1223 00:14:23.715351 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_3
I1223 00:14:23.715440 25375 net.cpp:122] Setting up c_t=15_encode4_unit_t=15_0_split
I1223 00:14:23.715447 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715451 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715456 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715458 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715461 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:23.715463 25375 layer_factory.hpp:77] Creating layer h_t=15_encode4_unit_t=15_1_split
I1223 00:14:23.715468 25375 net.cpp:84] Creating Layer h_t=15_encode4_unit_t=15_1_split
I1223 00:14:23.715471 25375 net.cpp:406] h_t=15_encode4_unit_t=15_1_split <- h_t=15
I1223 00:14:23.715481 25375 net.cpp:380] h_t=15_encode4_unit_t=15_1_split -> h_t=15_encode4_unit_t=15_1_split_0
I1223 00:14:23.715487 25375 net.cpp:380] h_t=15_encode4_unit_t=15_1_split -> h_t=15_encode4_unit_t=15_1_split_1
I1223 00:14:23.715549 25375 net.cpp:122] Setting up h_t=15_encode4_unit_t=15_1_split
I1223 00:14:23.715556 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715559 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715562 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:23.715565 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=15
I1223 00:14:23.715571 25375 net.cpp:84] Creating Layer encode4_h_conted_t=15
I1223 00:14:23.715574 25375 net.cpp:406] encode4_h_conted_t=15 <- h_t=15_encode4_unit_t=15_1_split_0
I1223 00:14:23.715579 25375 net.cpp:406] encode4_h_conted_t=15 <- cont_t=16_encode4_cont_slice_15_split_0
I1223 00:14:23.715584 25375 net.cpp:380] encode4_h_conted_t=15 -> h_conted_t=15
I1223 00:14:23.715693 25375 net.cpp:122] Setting up encode4_h_conted_t=15
I1223 00:14:23.715699 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.715703 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:23.715705 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->15
I1223 00:14:23.715713 25375 net.cpp:84] Creating Layer encode4_hidden->transform->15
I1223 00:14:23.715718 25375 net.cpp:406] encode4_hidden->transform->15 <- h_conted_t=15
I1223 00:14:23.715724 25375 net.cpp:380] encode4_hidden->transform->15 -> hidden->transform->15
I1223 00:14:23.716266 25375 net.cpp:122] Setting up encode4_hidden->transform->15
I1223 00:14:23.716275 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.716279 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:23.716282 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:23.716302 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:23.716305 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=15
I1223 00:14:23.716311 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=15
I1223 00:14:23.716315 25375 net.cpp:406] encode4_hadamard->input_t=15 <- c_t=15_encode4_unit_t=15_0_split_0
I1223 00:14:23.716320 25375 net.cpp:380] encode4_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:23.716446 25375 net.cpp:122] Setting up encode4_hadamard->input_t=15
I1223 00:14:23.716454 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.716456 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:23.716460 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:23.716464 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=15
I1223 00:14:23.716485 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=15
I1223 00:14:23.716487 25375 net.cpp:406] encode4_hadamard->forget_t=15 <- c_t=15_encode4_unit_t=15_0_split_1
I1223 00:14:23.716497 25375 net.cpp:380] encode4_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:23.716622 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=15
I1223 00:14:23.716631 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.716634 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:23.716637 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:23.716640 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=15
I1223 00:14:23.716660 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=15
I1223 00:14:23.716663 25375 net.cpp:406] encode4_hadamard->output_t=15 <- c_t=15_encode4_unit_t=15_0_split_2
I1223 00:14:23.716670 25375 net.cpp:380] encode4_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:23.716776 25375 net.cpp:122] Setting up encode4_hadamard->output_t=15
I1223 00:14:23.716784 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.716787 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:23.716790 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:23.716794 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=16
I1223 00:14:23.716812 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=16
I1223 00:14:23.716817 25375 net.cpp:380] encode4_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:23.716883 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=16
I1223 00:14:23.716903 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.716907 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:23.716909 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=16
I1223 00:14:23.716915 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=16
I1223 00:14:23.716933 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:23.716938 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:23.716954 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:23.716958 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:23.716962 25375 net.cpp:380] encode4_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:23.716989 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=16
I1223 00:14:23.716995 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.716997 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:23.717000 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_16
I1223 00:14:23.717005 25375 net.cpp:84] Creating Layer encode4_gate_input_16
I1223 00:14:23.717008 25375 net.cpp:406] encode4_gate_input_16 <- hidden->transform->15
I1223 00:14:23.717012 25375 net.cpp:406] encode4_gate_input_16 <- x->transform->t=16
I1223 00:14:23.717016 25375 net.cpp:406] encode4_gate_input_16 <- hadamard_t=16
I1223 00:14:23.717023 25375 net.cpp:380] encode4_gate_input_16 -> gate_input_16
I1223 00:14:23.717051 25375 net.cpp:122] Setting up encode4_gate_input_16
I1223 00:14:23.717056 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:23.717059 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:23.717062 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=16
I1223 00:14:23.717067 25375 net.cpp:84] Creating Layer encode4_unit_t=16
I1223 00:14:23.717077 25375 net.cpp:406] encode4_unit_t=16 <- c_t=15_encode4_unit_t=15_0_split_3
I1223 00:14:23.717082 25375 net.cpp:406] encode4_unit_t=16 <- gate_input_16
I1223 00:14:23.717085 25375 net.cpp:406] encode4_unit_t=16 <- cont_t=16_encode4_cont_slice_15_split_1
I1223 00:14:23.717092 25375 net.cpp:380] encode4_unit_t=16 -> c_t=16
I1223 00:14:23.717098 25375 net.cpp:380] encode4_unit_t=16 -> h_t=16
I1223 00:14:23.717151 25375 net.cpp:122] Setting up encode4_unit_t=16
I1223 00:14:23.717159 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.717176 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.717180 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:23.717182 25375 layer_factory.hpp:77] Creating layer h_t=16_encode4_unit_t=16_1_split
I1223 00:14:23.717186 25375 net.cpp:84] Creating Layer h_t=16_encode4_unit_t=16_1_split
I1223 00:14:23.717190 25375 net.cpp:406] h_t=16_encode4_unit_t=16_1_split <- h_t=16
I1223 00:14:23.717195 25375 net.cpp:380] h_t=16_encode4_unit_t=16_1_split -> h_t=16_encode4_unit_t=16_1_split_0
I1223 00:14:23.717200 25375 net.cpp:380] h_t=16_encode4_unit_t=16_1_split -> h_t=16_encode4_unit_t=16_1_split_1
I1223 00:14:23.717253 25375 net.cpp:122] Setting up h_t=16_encode4_unit_t=16_1_split
I1223 00:14:23.717260 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.717264 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.717267 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:23.717269 25375 layer_factory.hpp:77] Creating layer encode4_h_concat
I1223 00:14:23.717291 25375 net.cpp:84] Creating Layer encode4_h_concat
I1223 00:14:23.717309 25375 net.cpp:406] encode4_h_concat <- h_t=1_encode4_unit_t=1_1_split_1
I1223 00:14:23.717314 25375 net.cpp:406] encode4_h_concat <- h_t=2_encode4_unit_t=2_1_split_1
I1223 00:14:23.717316 25375 net.cpp:406] encode4_h_concat <- h_t=3_encode4_unit_t=3_1_split_1
I1223 00:14:23.717320 25375 net.cpp:406] encode4_h_concat <- h_t=4_encode4_unit_t=4_1_split_1
I1223 00:14:23.717324 25375 net.cpp:406] encode4_h_concat <- h_t=5_encode4_unit_t=5_1_split_1
I1223 00:14:23.717327 25375 net.cpp:406] encode4_h_concat <- h_t=6_encode4_unit_t=6_1_split_1
I1223 00:14:23.717330 25375 net.cpp:406] encode4_h_concat <- h_t=7_encode4_unit_t=7_1_split_1
I1223 00:14:23.717334 25375 net.cpp:406] encode4_h_concat <- h_t=8_encode4_unit_t=8_1_split_1
I1223 00:14:23.717337 25375 net.cpp:406] encode4_h_concat <- h_t=9_encode4_unit_t=9_1_split_1
I1223 00:14:23.717341 25375 net.cpp:406] encode4_h_concat <- h_t=10_encode4_unit_t=10_1_split_1
I1223 00:14:23.717344 25375 net.cpp:406] encode4_h_concat <- h_t=11_encode4_unit_t=11_1_split_1
I1223 00:14:23.717348 25375 net.cpp:406] encode4_h_concat <- h_t=12_encode4_unit_t=12_1_split_1
I1223 00:14:23.717351 25375 net.cpp:406] encode4_h_concat <- h_t=13_encode4_unit_t=13_1_split_1
I1223 00:14:23.717355 25375 net.cpp:406] encode4_h_concat <- h_t=14_encode4_unit_t=14_1_split_1
I1223 00:14:23.717357 25375 net.cpp:406] encode4_h_concat <- h_t=15_encode4_unit_t=15_1_split_1
I1223 00:14:23.717360 25375 net.cpp:406] encode4_h_concat <- h_t=16_encode4_unit_t=16_1_split_0
I1223 00:14:23.717367 25375 net.cpp:380] encode4_h_concat -> h
I1223 00:14:23.717393 25375 net.cpp:122] Setting up encode4_h_concat
I1223 00:14:23.717401 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.717403 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:23.717406 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_h
I1223 00:14:23.717412 25375 net.cpp:84] Creating Layer encode4_dummy_forward_h
I1223 00:14:23.717417 25375 net.cpp:406] encode4_dummy_forward_h <- h_t=16_encode4_unit_t=16_1_split_1
I1223 00:14:23.717422 25375 net.cpp:380] encode4_dummy_forward_h -> h_t=T
I1223 00:14:23.717460 25375 net.cpp:122] Setting up encode4_dummy_forward_h
I1223 00:14:23.717468 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.717471 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:23.717490 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_c
I1223 00:14:23.717495 25375 net.cpp:84] Creating Layer encode4_dummy_forward_c
I1223 00:14:23.717499 25375 net.cpp:406] encode4_dummy_forward_c <- c_t=16
I1223 00:14:23.717516 25375 net.cpp:380] encode4_dummy_forward_c -> c_t=T
I1223 00:14:23.717557 25375 net.cpp:122] Setting up encode4_dummy_forward_c
I1223 00:14:23.717566 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.717567 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:23.717572 25375 layer_factory.hpp:77] Creating layer encode4_h_t=T_pseudoloss
I1223 00:14:23.717576 25375 net.cpp:84] Creating Layer encode4_h_t=T_pseudoloss
I1223 00:14:23.717581 25375 net.cpp:406] encode4_h_t=T_pseudoloss <- h_t=T
I1223 00:14:23.717584 25375 net.cpp:380] encode4_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:23.717666 25375 net.cpp:122] Setting up encode4_h_t=T_pseudoloss
I1223 00:14:23.717672 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.717676 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.717697 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:23.717701 25375 layer_factory.hpp:77] Creating layer encode4_c_t=T_pseudoloss
I1223 00:14:23.717707 25375 net.cpp:84] Creating Layer encode4_c_t=T_pseudoloss
I1223 00:14:23.717711 25375 net.cpp:406] encode4_c_t=T_pseudoloss <- c_t=T
I1223 00:14:23.717716 25375 net.cpp:380] encode4_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:23.717783 25375 net.cpp:122] Setting up encode4_c_t=T_pseudoloss
I1223 00:14:23.717803 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.717806 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.717810 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:23.717813 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:23.717818 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:23.717820 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:23.717826 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:23.718894 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:23.718904 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.718906 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.718924 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:23.718927 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:23.718930 25375 net.cpp:198] encode4_c_t=T_pseudoloss needs backward computation.
I1223 00:14:23.718933 25375 net.cpp:198] encode4_h_t=T_pseudoloss needs backward computation.
I1223 00:14:23.718936 25375 net.cpp:198] encode4_dummy_forward_c needs backward computation.
I1223 00:14:23.718938 25375 net.cpp:198] encode4_dummy_forward_h needs backward computation.
I1223 00:14:23.718941 25375 net.cpp:198] encode4_h_concat needs backward computation.
I1223 00:14:23.718951 25375 net.cpp:198] h_t=16_encode4_unit_t=16_1_split needs backward computation.
I1223 00:14:23.718955 25375 net.cpp:198] encode4_unit_t=16 needs backward computation.
I1223 00:14:23.718958 25375 net.cpp:198] encode4_gate_input_16 needs backward computation.
I1223 00:14:23.718961 25375 net.cpp:198] encode4_concat_hadamard_t=16 needs backward computation.
I1223 00:14:23.718966 25375 net.cpp:200] encode4_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:23.718969 25375 net.cpp:198] encode4_hadamard->output_t=15 needs backward computation.
I1223 00:14:23.718972 25375 net.cpp:198] encode4_hadamard->forget_t=15 needs backward computation.
I1223 00:14:23.718976 25375 net.cpp:198] encode4_hadamard->input_t=15 needs backward computation.
I1223 00:14:23.718978 25375 net.cpp:198] encode4_hidden->transform->15 needs backward computation.
I1223 00:14:23.718981 25375 net.cpp:198] encode4_h_conted_t=15 needs backward computation.
I1223 00:14:23.718986 25375 net.cpp:198] h_t=15_encode4_unit_t=15_1_split needs backward computation.
I1223 00:14:23.718988 25375 net.cpp:198] c_t=15_encode4_unit_t=15_0_split needs backward computation.
I1223 00:14:23.718992 25375 net.cpp:198] encode4_unit_t=15 needs backward computation.
I1223 00:14:23.718997 25375 net.cpp:198] encode4_gate_input_15 needs backward computation.
I1223 00:14:23.719000 25375 net.cpp:198] encode4_concat_hadamard_t=15 needs backward computation.
I1223 00:14:23.719005 25375 net.cpp:200] encode4_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:23.719008 25375 net.cpp:198] encode4_hadamard->output_t=14 needs backward computation.
I1223 00:14:23.719012 25375 net.cpp:198] encode4_hadamard->forget_t=14 needs backward computation.
I1223 00:14:23.719015 25375 net.cpp:198] encode4_hadamard->input_t=14 needs backward computation.
I1223 00:14:23.719018 25375 net.cpp:198] encode4_hidden->transform->14 needs backward computation.
I1223 00:14:23.719022 25375 net.cpp:198] encode4_h_conted_t=14 needs backward computation.
I1223 00:14:23.719027 25375 net.cpp:198] h_t=14_encode4_unit_t=14_1_split needs backward computation.
I1223 00:14:23.719029 25375 net.cpp:198] c_t=14_encode4_unit_t=14_0_split needs backward computation.
I1223 00:14:23.719033 25375 net.cpp:198] encode4_unit_t=14 needs backward computation.
I1223 00:14:23.719038 25375 net.cpp:198] encode4_gate_input_14 needs backward computation.
I1223 00:14:23.719041 25375 net.cpp:198] encode4_concat_hadamard_t=14 needs backward computation.
I1223 00:14:23.719045 25375 net.cpp:200] encode4_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:23.719048 25375 net.cpp:198] encode4_hadamard->output_t=13 needs backward computation.
I1223 00:14:23.719053 25375 net.cpp:198] encode4_hadamard->forget_t=13 needs backward computation.
I1223 00:14:23.719054 25375 net.cpp:198] encode4_hadamard->input_t=13 needs backward computation.
I1223 00:14:23.719058 25375 net.cpp:198] encode4_hidden->transform->13 needs backward computation.
I1223 00:14:23.719061 25375 net.cpp:198] encode4_h_conted_t=13 needs backward computation.
I1223 00:14:23.719065 25375 net.cpp:198] h_t=13_encode4_unit_t=13_1_split needs backward computation.
I1223 00:14:23.719069 25375 net.cpp:198] c_t=13_encode4_unit_t=13_0_split needs backward computation.
I1223 00:14:23.719071 25375 net.cpp:198] encode4_unit_t=13 needs backward computation.
I1223 00:14:23.719075 25375 net.cpp:198] encode4_gate_input_13 needs backward computation.
I1223 00:14:23.719081 25375 net.cpp:198] encode4_concat_hadamard_t=13 needs backward computation.
I1223 00:14:23.719086 25375 net.cpp:200] encode4_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:23.719089 25375 net.cpp:198] encode4_hadamard->output_t=12 needs backward computation.
I1223 00:14:23.719092 25375 net.cpp:198] encode4_hadamard->forget_t=12 needs backward computation.
I1223 00:14:23.719096 25375 net.cpp:198] encode4_hadamard->input_t=12 needs backward computation.
I1223 00:14:23.719099 25375 net.cpp:198] encode4_hidden->transform->12 needs backward computation.
I1223 00:14:23.719102 25375 net.cpp:198] encode4_h_conted_t=12 needs backward computation.
I1223 00:14:23.719106 25375 net.cpp:198] h_t=12_encode4_unit_t=12_1_split needs backward computation.
I1223 00:14:23.719110 25375 net.cpp:198] c_t=12_encode4_unit_t=12_0_split needs backward computation.
I1223 00:14:23.719113 25375 net.cpp:198] encode4_unit_t=12 needs backward computation.
I1223 00:14:23.719117 25375 net.cpp:198] encode4_gate_input_12 needs backward computation.
I1223 00:14:23.719121 25375 net.cpp:198] encode4_concat_hadamard_t=12 needs backward computation.
I1223 00:14:23.719126 25375 net.cpp:200] encode4_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:23.719130 25375 net.cpp:198] encode4_hadamard->output_t=11 needs backward computation.
I1223 00:14:23.719132 25375 net.cpp:198] encode4_hadamard->forget_t=11 needs backward computation.
I1223 00:14:23.719135 25375 net.cpp:198] encode4_hadamard->input_t=11 needs backward computation.
I1223 00:14:23.719139 25375 net.cpp:198] encode4_hidden->transform->11 needs backward computation.
I1223 00:14:23.719142 25375 net.cpp:198] encode4_h_conted_t=11 needs backward computation.
I1223 00:14:23.719146 25375 net.cpp:198] h_t=11_encode4_unit_t=11_1_split needs backward computation.
I1223 00:14:23.719149 25375 net.cpp:198] c_t=11_encode4_unit_t=11_0_split needs backward computation.
I1223 00:14:23.719153 25375 net.cpp:198] encode4_unit_t=11 needs backward computation.
I1223 00:14:23.719158 25375 net.cpp:198] encode4_gate_input_11 needs backward computation.
I1223 00:14:23.719163 25375 net.cpp:198] encode4_concat_hadamard_t=11 needs backward computation.
I1223 00:14:23.719167 25375 net.cpp:200] encode4_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:23.719171 25375 net.cpp:198] encode4_hadamard->output_t=10 needs backward computation.
I1223 00:14:23.719174 25375 net.cpp:198] encode4_hadamard->forget_t=10 needs backward computation.
I1223 00:14:23.719177 25375 net.cpp:198] encode4_hadamard->input_t=10 needs backward computation.
I1223 00:14:23.719180 25375 net.cpp:198] encode4_hidden->transform->10 needs backward computation.
I1223 00:14:23.719184 25375 net.cpp:198] encode4_h_conted_t=10 needs backward computation.
I1223 00:14:23.719188 25375 net.cpp:198] h_t=10_encode4_unit_t=10_1_split needs backward computation.
I1223 00:14:23.719192 25375 net.cpp:198] c_t=10_encode4_unit_t=10_0_split needs backward computation.
I1223 00:14:23.719194 25375 net.cpp:198] encode4_unit_t=10 needs backward computation.
I1223 00:14:23.719199 25375 net.cpp:198] encode4_gate_input_10 needs backward computation.
I1223 00:14:23.719203 25375 net.cpp:198] encode4_concat_hadamard_t=10 needs backward computation.
I1223 00:14:23.719208 25375 net.cpp:200] encode4_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:23.719211 25375 net.cpp:198] encode4_hadamard->output_t=9 needs backward computation.
I1223 00:14:23.719215 25375 net.cpp:198] encode4_hadamard->forget_t=9 needs backward computation.
I1223 00:14:23.719218 25375 net.cpp:198] encode4_hadamard->input_t=9 needs backward computation.
I1223 00:14:23.719221 25375 net.cpp:198] encode4_hidden->transform->9 needs backward computation.
I1223 00:14:23.719226 25375 net.cpp:198] encode4_h_conted_t=9 needs backward computation.
I1223 00:14:23.719230 25375 net.cpp:198] h_t=9_encode4_unit_t=9_1_split needs backward computation.
I1223 00:14:23.719234 25375 net.cpp:198] c_t=9_encode4_unit_t=9_0_split needs backward computation.
I1223 00:14:23.719238 25375 net.cpp:198] encode4_unit_t=9 needs backward computation.
I1223 00:14:23.719243 25375 net.cpp:198] encode4_gate_input_9 needs backward computation.
I1223 00:14:23.719247 25375 net.cpp:198] encode4_concat_hadamard_t=9 needs backward computation.
I1223 00:14:23.719252 25375 net.cpp:200] encode4_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:23.719255 25375 net.cpp:198] encode4_hadamard->output_t=8 needs backward computation.
I1223 00:14:23.719259 25375 net.cpp:198] encode4_hadamard->forget_t=8 needs backward computation.
I1223 00:14:23.719262 25375 net.cpp:198] encode4_hadamard->input_t=8 needs backward computation.
I1223 00:14:23.719265 25375 net.cpp:198] encode4_hidden->transform->8 needs backward computation.
I1223 00:14:23.719269 25375 net.cpp:198] encode4_h_conted_t=8 needs backward computation.
I1223 00:14:23.719274 25375 net.cpp:198] h_t=8_encode4_unit_t=8_1_split needs backward computation.
I1223 00:14:23.719277 25375 net.cpp:198] c_t=8_encode4_unit_t=8_0_split needs backward computation.
I1223 00:14:23.719280 25375 net.cpp:198] encode4_unit_t=8 needs backward computation.
I1223 00:14:23.719285 25375 net.cpp:198] encode4_gate_input_8 needs backward computation.
I1223 00:14:23.719290 25375 net.cpp:198] encode4_concat_hadamard_t=8 needs backward computation.
I1223 00:14:23.719297 25375 net.cpp:200] encode4_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:23.719300 25375 net.cpp:198] encode4_hadamard->output_t=7 needs backward computation.
I1223 00:14:23.719305 25375 net.cpp:198] encode4_hadamard->forget_t=7 needs backward computation.
I1223 00:14:23.719307 25375 net.cpp:198] encode4_hadamard->input_t=7 needs backward computation.
I1223 00:14:23.719311 25375 net.cpp:198] encode4_hidden->transform->7 needs backward computation.
I1223 00:14:23.719314 25375 net.cpp:198] encode4_h_conted_t=7 needs backward computation.
I1223 00:14:23.719318 25375 net.cpp:198] h_t=7_encode4_unit_t=7_1_split needs backward computation.
I1223 00:14:23.719322 25375 net.cpp:198] c_t=7_encode4_unit_t=7_0_split needs backward computation.
I1223 00:14:23.719326 25375 net.cpp:198] encode4_unit_t=7 needs backward computation.
I1223 00:14:23.719331 25375 net.cpp:198] encode4_gate_input_7 needs backward computation.
I1223 00:14:23.719334 25375 net.cpp:198] encode4_concat_hadamard_t=7 needs backward computation.
I1223 00:14:23.719339 25375 net.cpp:200] encode4_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:23.719342 25375 net.cpp:198] encode4_hadamard->output_t=6 needs backward computation.
I1223 00:14:23.719346 25375 net.cpp:198] encode4_hadamard->forget_t=6 needs backward computation.
I1223 00:14:23.719348 25375 net.cpp:198] encode4_hadamard->input_t=6 needs backward computation.
I1223 00:14:23.719352 25375 net.cpp:198] encode4_hidden->transform->6 needs backward computation.
I1223 00:14:23.719355 25375 net.cpp:198] encode4_h_conted_t=6 needs backward computation.
I1223 00:14:23.719359 25375 net.cpp:198] h_t=6_encode4_unit_t=6_1_split needs backward computation.
I1223 00:14:23.719363 25375 net.cpp:198] c_t=6_encode4_unit_t=6_0_split needs backward computation.
I1223 00:14:23.719367 25375 net.cpp:198] encode4_unit_t=6 needs backward computation.
I1223 00:14:23.719372 25375 net.cpp:198] encode4_gate_input_6 needs backward computation.
I1223 00:14:23.719377 25375 net.cpp:198] encode4_concat_hadamard_t=6 needs backward computation.
I1223 00:14:23.719383 25375 net.cpp:200] encode4_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:23.719385 25375 net.cpp:198] encode4_hadamard->output_t=5 needs backward computation.
I1223 00:14:23.719389 25375 net.cpp:198] encode4_hadamard->forget_t=5 needs backward computation.
I1223 00:14:23.719393 25375 net.cpp:198] encode4_hadamard->input_t=5 needs backward computation.
I1223 00:14:23.719395 25375 net.cpp:198] encode4_hidden->transform->5 needs backward computation.
I1223 00:14:23.719398 25375 net.cpp:198] encode4_h_conted_t=5 needs backward computation.
I1223 00:14:23.719403 25375 net.cpp:198] h_t=5_encode4_unit_t=5_1_split needs backward computation.
I1223 00:14:23.719406 25375 net.cpp:198] c_t=5_encode4_unit_t=5_0_split needs backward computation.
I1223 00:14:23.719410 25375 net.cpp:198] encode4_unit_t=5 needs backward computation.
I1223 00:14:23.719414 25375 net.cpp:198] encode4_gate_input_5 needs backward computation.
I1223 00:14:23.719419 25375 net.cpp:198] encode4_concat_hadamard_t=5 needs backward computation.
I1223 00:14:23.719424 25375 net.cpp:200] encode4_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:23.719426 25375 net.cpp:198] encode4_hadamard->output_t=4 needs backward computation.
I1223 00:14:23.719429 25375 net.cpp:198] encode4_hadamard->forget_t=4 needs backward computation.
I1223 00:14:23.719434 25375 net.cpp:198] encode4_hadamard->input_t=4 needs backward computation.
I1223 00:14:23.719436 25375 net.cpp:198] encode4_hidden->transform->4 needs backward computation.
I1223 00:14:23.719440 25375 net.cpp:198] encode4_h_conted_t=4 needs backward computation.
I1223 00:14:23.719444 25375 net.cpp:198] h_t=4_encode4_unit_t=4_1_split needs backward computation.
I1223 00:14:23.719447 25375 net.cpp:198] c_t=4_encode4_unit_t=4_0_split needs backward computation.
I1223 00:14:23.719450 25375 net.cpp:198] encode4_unit_t=4 needs backward computation.
I1223 00:14:23.719456 25375 net.cpp:198] encode4_gate_input_4 needs backward computation.
I1223 00:14:23.719461 25375 net.cpp:198] encode4_concat_hadamard_t=4 needs backward computation.
I1223 00:14:23.719466 25375 net.cpp:200] encode4_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:23.719470 25375 net.cpp:198] encode4_hadamard->output_t=3 needs backward computation.
I1223 00:14:23.719472 25375 net.cpp:198] encode4_hadamard->forget_t=3 needs backward computation.
I1223 00:14:23.719475 25375 net.cpp:198] encode4_hadamard->input_t=3 needs backward computation.
I1223 00:14:23.719480 25375 net.cpp:198] encode4_hidden->transform->3 needs backward computation.
I1223 00:14:23.719482 25375 net.cpp:198] encode4_h_conted_t=3 needs backward computation.
I1223 00:14:23.719486 25375 net.cpp:198] h_t=3_encode4_unit_t=3_1_split needs backward computation.
I1223 00:14:23.719489 25375 net.cpp:198] c_t=3_encode4_unit_t=3_0_split needs backward computation.
I1223 00:14:23.719492 25375 net.cpp:198] encode4_unit_t=3 needs backward computation.
I1223 00:14:23.719497 25375 net.cpp:198] encode4_gate_input_3 needs backward computation.
I1223 00:14:23.719501 25375 net.cpp:198] encode4_concat_hadamard_t=3 needs backward computation.
I1223 00:14:23.719506 25375 net.cpp:200] encode4_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:23.719509 25375 net.cpp:198] encode4_hadamard->output_t=2 needs backward computation.
I1223 00:14:23.719512 25375 net.cpp:198] encode4_hadamard->forget_t=2 needs backward computation.
I1223 00:14:23.719516 25375 net.cpp:198] encode4_hadamard->input_t=2 needs backward computation.
I1223 00:14:23.719519 25375 net.cpp:198] encode4_hidden->transform->2 needs backward computation.
I1223 00:14:23.719522 25375 net.cpp:198] encode4_h_conted_t=2 needs backward computation.
I1223 00:14:23.719527 25375 net.cpp:198] h_t=2_encode4_unit_t=2_1_split needs backward computation.
I1223 00:14:23.719532 25375 net.cpp:198] c_t=2_encode4_unit_t=2_0_split needs backward computation.
I1223 00:14:23.719534 25375 net.cpp:198] encode4_unit_t=2 needs backward computation.
I1223 00:14:23.719539 25375 net.cpp:198] encode4_gate_input_2 needs backward computation.
I1223 00:14:23.719543 25375 net.cpp:198] encode4_concat_hadamard_t=2 needs backward computation.
I1223 00:14:23.719548 25375 net.cpp:200] encode4_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:23.719550 25375 net.cpp:198] encode4_hadamard->output_t=1 needs backward computation.
I1223 00:14:23.719554 25375 net.cpp:198] encode4_hadamard->forget_t=1 needs backward computation.
I1223 00:14:23.719558 25375 net.cpp:198] encode4_hadamard->input_t=1 needs backward computation.
I1223 00:14:23.719560 25375 net.cpp:198] encode4_hidden->transform->1 needs backward computation.
I1223 00:14:23.719564 25375 net.cpp:198] encode4_h_conted_t=1 needs backward computation.
I1223 00:14:23.719568 25375 net.cpp:198] h_t=1_encode4_unit_t=1_1_split needs backward computation.
I1223 00:14:23.719573 25375 net.cpp:198] c_t=1_encode4_unit_t=1_0_split needs backward computation.
I1223 00:14:23.719575 25375 net.cpp:198] encode4_unit_t=1 needs backward computation.
I1223 00:14:23.719580 25375 net.cpp:198] encode4_gate_input_1 needs backward computation.
I1223 00:14:23.719584 25375 net.cpp:198] encode4_concat_hadamard_t=1 needs backward computation.
I1223 00:14:23.719589 25375 net.cpp:200] encode4_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:23.719593 25375 net.cpp:198] encode4_hadamard->output_t=0 needs backward computation.
I1223 00:14:23.719595 25375 net.cpp:198] encode4_hadamard->forget_t=0 needs backward computation.
I1223 00:14:23.719604 25375 net.cpp:198] encode4_hadamard->input_t=0 needs backward computation.
I1223 00:14:23.719609 25375 net.cpp:198] encode4_hidden->transform->0 needs backward computation.
I1223 00:14:23.719612 25375 net.cpp:198] encode4_h_conted_t=0 needs backward computation.
I1223 00:14:23.719616 25375 net.cpp:198] encode4_dummy_forward_h0 needs backward computation.
I1223 00:14:23.719620 25375 net.cpp:198] c_t=0_encode4_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:23.719624 25375 net.cpp:198] encode4_dummy_forward_c0 needs backward computation.
I1223 00:14:23.719641 25375 net.cpp:200] cont_t=16_encode4_cont_slice_15_split does not need backward computation.
I1223 00:14:23.719645 25375 net.cpp:200] cont_t=15_encode4_cont_slice_14_split does not need backward computation.
I1223 00:14:23.719650 25375 net.cpp:200] cont_t=14_encode4_cont_slice_13_split does not need backward computation.
I1223 00:14:23.719652 25375 net.cpp:200] cont_t=13_encode4_cont_slice_12_split does not need backward computation.
I1223 00:14:23.719655 25375 net.cpp:200] cont_t=12_encode4_cont_slice_11_split does not need backward computation.
I1223 00:14:23.719660 25375 net.cpp:200] cont_t=11_encode4_cont_slice_10_split does not need backward computation.
I1223 00:14:23.719676 25375 net.cpp:200] cont_t=10_encode4_cont_slice_9_split does not need backward computation.
I1223 00:14:23.719681 25375 net.cpp:200] cont_t=9_encode4_cont_slice_8_split does not need backward computation.
I1223 00:14:23.719684 25375 net.cpp:200] cont_t=8_encode4_cont_slice_7_split does not need backward computation.
I1223 00:14:23.719687 25375 net.cpp:200] cont_t=7_encode4_cont_slice_6_split does not need backward computation.
I1223 00:14:23.719691 25375 net.cpp:200] cont_t=6_encode4_cont_slice_5_split does not need backward computation.
I1223 00:14:23.719696 25375 net.cpp:200] cont_t=5_encode4_cont_slice_4_split does not need backward computation.
I1223 00:14:23.719698 25375 net.cpp:200] cont_t=4_encode4_cont_slice_3_split does not need backward computation.
I1223 00:14:23.719702 25375 net.cpp:200] cont_t=3_encode4_cont_slice_2_split does not need backward computation.
I1223 00:14:23.719707 25375 net.cpp:200] cont_t=2_encode4_cont_slice_1_split does not need backward computation.
I1223 00:14:23.719710 25375 net.cpp:200] cont_t=1_encode4_cont_slice_0_split does not need backward computation.
I1223 00:14:23.719717 25375 net.cpp:200] encode4_cont_slice does not need backward computation.
I1223 00:14:23.719722 25375 net.cpp:198] encode4_W_xc_x_slice needs backward computation.
I1223 00:14:23.719727 25375 net.cpp:200] encode4_input->cell_hidden does not need backward computation.
I1223 00:14:23.719729 25375 net.cpp:198] encode4_x->transform needs backward computation.
I1223 00:14:23.719732 25375 net.cpp:200] encode4_ does not need backward computation.
I1223 00:14:23.719734 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:23.719738 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:23.719743 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:23.720594 25375 net.cpp:255] Network initialization done.
I1223 00:14:23.721076 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:23.721083 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:23.721086 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:23.721088 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:23.721091 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:23.721093 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:23.721096 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:23.721098 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:23.721101 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:23.721103 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:23.721846 25375 net.cpp:122] Setting up encode4
I1223 00:14:23.721856 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:23.721861 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.721865 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:23.721868 25375 net.cpp:137] Memory required for data: 4289331584
I1223 00:14:23.721880 25375 layer_factory.hpp:77] Creating layer reshape_encode1
I1223 00:14:23.721889 25375 net.cpp:84] Creating Layer reshape_encode1
I1223 00:14:23.721891 25375 net.cpp:406] reshape_encode1 <- encode1
I1223 00:14:23.721897 25375 net.cpp:380] reshape_encode1 -> reshape_encode1
I1223 00:14:23.721959 25375 net.cpp:122] Setting up reshape_encode1
I1223 00:14:23.721966 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:23.721969 25375 net.cpp:137] Memory required for data: 4291428736
I1223 00:14:23.721971 25375 layer_factory.hpp:77] Creating layer reshape_encode2
I1223 00:14:23.721976 25375 net.cpp:84] Creating Layer reshape_encode2
I1223 00:14:23.721979 25375 net.cpp:406] reshape_encode2 <- encode2
I1223 00:14:23.721984 25375 net.cpp:380] reshape_encode2 -> reshape_encode2
I1223 00:14:23.722012 25375 net.cpp:122] Setting up reshape_encode2
I1223 00:14:23.722034 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:23.722038 25375 net.cpp:137] Memory required for data: 4293525888
I1223 00:14:23.722054 25375 layer_factory.hpp:77] Creating layer reshape_encode3
I1223 00:14:23.722057 25375 net.cpp:84] Creating Layer reshape_encode3
I1223 00:14:23.722060 25375 net.cpp:406] reshape_encode3 <- encode3
I1223 00:14:23.722079 25375 net.cpp:380] reshape_encode3 -> reshape_encode3
I1223 00:14:23.722134 25375 net.cpp:122] Setting up reshape_encode3
I1223 00:14:23.722153 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:23.722157 25375 net.cpp:137] Memory required for data: 4295623040
I1223 00:14:23.722162 25375 layer_factory.hpp:77] Creating layer reshape_encode4
I1223 00:14:23.722182 25375 net.cpp:84] Creating Layer reshape_encode4
I1223 00:14:23.722185 25375 net.cpp:406] reshape_encode4 <- encode4
I1223 00:14:23.722190 25375 net.cpp:380] reshape_encode4 -> reshape_encode4
I1223 00:14:23.722247 25375 net.cpp:122] Setting up reshape_encode4
I1223 00:14:23.722254 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:23.722256 25375 net.cpp:137] Memory required for data: 4297720192
I1223 00:14:23.722261 25375 layer_factory.hpp:77] Creating layer concat_encode1234
I1223 00:14:23.722266 25375 net.cpp:84] Creating Layer concat_encode1234
I1223 00:14:23.722283 25375 net.cpp:406] concat_encode1234 <- reshape_encode1
I1223 00:14:23.722287 25375 net.cpp:406] concat_encode1234 <- reshape_encode2
I1223 00:14:23.722290 25375 net.cpp:406] concat_encode1234 <- reshape_encode3
I1223 00:14:23.722293 25375 net.cpp:406] concat_encode1234 <- reshape_encode4
I1223 00:14:23.722298 25375 net.cpp:380] concat_encode1234 -> concat_encode1234
I1223 00:14:23.722326 25375 net.cpp:122] Setting up concat_encode1234
I1223 00:14:23.722332 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:23.722347 25375 net.cpp:137] Memory required for data: 4306108800
I1223 00:14:23.722350 25375 layer_factory.hpp:77] Creating layer conv7_
I1223 00:14:23.722370 25375 net.cpp:84] Creating Layer conv7_
I1223 00:14:23.722375 25375 net.cpp:406] conv7_ <- concat_encode1234
I1223 00:14:23.722394 25375 net.cpp:380] conv7_ -> conv7
I1223 00:14:23.722697 25375 net.cpp:122] Setting up conv7_
I1223 00:14:23.722703 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:23.722707 25375 net.cpp:137] Memory required for data: 4306174336
I1223 00:14:23.722712 25375 layer_factory.hpp:77] Creating layer conv7_interp
I1223 00:14:23.722717 25375 net.cpp:84] Creating Layer conv7_interp
I1223 00:14:23.722719 25375 net.cpp:406] conv7_interp <- conv7
I1223 00:14:23.722724 25375 net.cpp:380] conv7_interp -> conv7_interp
I1223 00:14:23.722765 25375 net.cpp:122] Setting up conv7_interp
I1223 00:14:23.722772 25375 net.cpp:129] Top shape: 16 1 256 256 (1048576)
I1223 00:14:23.722774 25375 net.cpp:137] Memory required for data: 4310368640
I1223 00:14:23.722777 25375 layer_factory.hpp:77] Creating layer loss
I1223 00:14:23.722784 25375 net.cpp:84] Creating Layer loss
I1223 00:14:23.722787 25375 net.cpp:406] loss <- conv7_interp
I1223 00:14:23.722791 25375 net.cpp:406] loss <- label
I1223 00:14:23.722795 25375 net.cpp:380] loss -> loss
I1223 00:14:23.722853 25375 net.cpp:122] Setting up loss
I1223 00:14:23.722859 25375 net.cpp:129] Top shape: (1)
I1223 00:14:23.722862 25375 net.cpp:132]     with loss weight 1
I1223 00:14:23.722867 25375 net.cpp:137] Memory required for data: 4310368644
I1223 00:14:23.722870 25375 layer_factory.hpp:77] Creating layer silence
I1223 00:14:23.722887 25375 net.cpp:84] Creating Layer silence
I1223 00:14:23.722890 25375 net.cpp:406] silence <- encode1_h
I1223 00:14:23.722908 25375 net.cpp:406] silence <- encode2_h
I1223 00:14:23.722911 25375 net.cpp:406] silence <- encode3_h
I1223 00:14:23.722915 25375 net.cpp:406] silence <- encode4_h
I1223 00:14:23.722931 25375 net.cpp:406] silence <- encode1_c
I1223 00:14:23.722934 25375 net.cpp:406] silence <- encode2_c
I1223 00:14:23.722937 25375 net.cpp:406] silence <- encode3_c
I1223 00:14:23.722940 25375 net.cpp:406] silence <- encode4_c
I1223 00:14:23.722944 25375 net.cpp:122] Setting up silence
I1223 00:14:23.722946 25375 net.cpp:137] Memory required for data: 4310368644
I1223 00:14:23.722949 25375 net.cpp:200] silence does not need backward computation.
I1223 00:14:23.722954 25375 net.cpp:198] loss needs backward computation.
I1223 00:14:23.722957 25375 net.cpp:198] conv7_interp needs backward computation.
I1223 00:14:23.722960 25375 net.cpp:198] conv7_ needs backward computation.
I1223 00:14:23.722964 25375 net.cpp:198] concat_encode1234 needs backward computation.
I1223 00:14:23.722967 25375 net.cpp:198] reshape_encode4 needs backward computation.
I1223 00:14:23.722970 25375 net.cpp:198] reshape_encode3 needs backward computation.
I1223 00:14:23.722973 25375 net.cpp:198] reshape_encode2 needs backward computation.
I1223 00:14:23.722976 25375 net.cpp:198] reshape_encode1 needs backward computation.
I1223 00:14:23.722980 25375 net.cpp:198] encode4 needs backward computation.
I1223 00:14:23.722985 25375 net.cpp:198] encode3 needs backward computation.
I1223 00:14:23.722990 25375 net.cpp:198] encode2 needs backward computation.
I1223 00:14:23.722995 25375 net.cpp:198] encode1 needs backward computation.
I1223 00:14:23.723001 25375 net.cpp:200] dummy_dummy_0_split does not need backward computation.
I1223 00:14:23.723006 25375 net.cpp:200] dummy does not need backward computation.
I1223 00:14:23.723008 25375 net.cpp:198] conv6-reshape_reshape-data_0_split needs backward computation.
I1223 00:14:23.723012 25375 net.cpp:198] reshape-data needs backward computation.
I1223 00:14:23.723016 25375 net.cpp:200] reshape-cm_reshape-cm_0_split does not need backward computation.
I1223 00:14:23.723021 25375 net.cpp:200] reshape-cm does not need backward computation.
I1223 00:14:23.723023 25375 net.cpp:198] relu6 needs backward computation.
I1223 00:14:23.723027 25375 net.cpp:198] conv6/bn needs backward computation.
I1223 00:14:23.723031 25375 net.cpp:198] conv6 needs backward computation.
I1223 00:14:23.723033 25375 net.cpp:198] conv5_4/dropout needs backward computation.
I1223 00:14:23.723037 25375 net.cpp:198] conv5_4/relu needs backward computation.
I1223 00:14:23.723040 25375 net.cpp:198] conv5_4/bn needs backward computation.
I1223 00:14:23.723042 25375 net.cpp:198] conv5_4 needs backward computation.
I1223 00:14:23.723047 25375 net.cpp:198] relu_sum needs backward computation.
I1223 00:14:23.723049 25375 net.cpp:198] sum_5_concat4 needs backward computation.
I1223 00:14:23.723053 25375 net.cpp:198] concat4_512 needs backward computation.
I1223 00:14:23.723057 25375 net.cpp:198] concat4 needs backward computation.
I1223 00:14:23.723062 25375 net.cpp:198] relu6_4 needs backward computation.
I1223 00:14:23.723063 25375 net.cpp:198] fc6_4 needs backward computation.
I1223 00:14:23.723067 25375 net.cpp:198] relu6_3 needs backward computation.
I1223 00:14:23.723069 25375 net.cpp:198] fc6_3 needs backward computation.
I1223 00:14:23.723073 25375 net.cpp:198] relu6_2 needs backward computation.
I1223 00:14:23.723076 25375 net.cpp:198] fc6_2 needs backward computation.
I1223 00:14:23.723079 25375 net.cpp:198] relu6_1 needs backward computation.
I1223 00:14:23.723083 25375 net.cpp:198] fc6_1 needs backward computation.
I1223 00:14:23.723085 25375 net.cpp:198] relu5_relu5_0_split needs backward computation.
I1223 00:14:23.723089 25375 net.cpp:198] relu5 needs backward computation.
I1223 00:14:23.723093 25375 net.cpp:198] conv5_conv5_0_split needs backward computation.
I1223 00:14:23.723096 25375 net.cpp:198] conv5 needs backward computation.
I1223 00:14:23.723100 25375 net.cpp:198] conv5_3_bn needs backward computation.
I1223 00:14:23.723103 25375 net.cpp:198] conv5_3 needs backward computation.
I1223 00:14:23.723106 25375 net.cpp:198] relu5_2 needs backward computation.
I1223 00:14:23.723109 25375 net.cpp:198] conv5_2_bn needs backward computation.
I1223 00:14:23.723112 25375 net.cpp:198] conv5_2 needs backward computation.
I1223 00:14:23.723115 25375 net.cpp:198] relu5_1 needs backward computation.
I1223 00:14:23.723119 25375 net.cpp:198] conv5_1_bn needs backward computation.
I1223 00:14:23.723121 25375 net.cpp:198] conv5_1 needs backward computation.
I1223 00:14:23.723124 25375 net.cpp:198] relu4_3 needs backward computation.
I1223 00:14:23.723129 25375 net.cpp:198] conv4_3_conv4_3_bn_0_split needs backward computation.
I1223 00:14:23.723131 25375 net.cpp:198] conv4_3_bn needs backward computation.
I1223 00:14:23.723134 25375 net.cpp:198] conv4_3 needs backward computation.
I1223 00:14:23.723137 25375 net.cpp:198] relu4_2 needs backward computation.
I1223 00:14:23.723140 25375 net.cpp:198] conv4_2_bn needs backward computation.
I1223 00:14:23.723143 25375 net.cpp:198] conv4_2 needs backward computation.
I1223 00:14:23.723146 25375 net.cpp:198] relu4_1 needs backward computation.
I1223 00:14:23.723150 25375 net.cpp:198] conv4_1_bn needs backward computation.
I1223 00:14:23.723152 25375 net.cpp:198] conv4_1 needs backward computation.
I1223 00:14:23.723155 25375 net.cpp:198] pool3 needs backward computation.
I1223 00:14:23.723158 25375 net.cpp:198] relu3_3 needs backward computation.
I1223 00:14:23.723161 25375 net.cpp:198] conv3_3_bn needs backward computation.
I1223 00:14:23.723165 25375 net.cpp:198] conv3_3 needs backward computation.
I1223 00:14:23.723167 25375 net.cpp:198] relu3_2 needs backward computation.
I1223 00:14:23.723170 25375 net.cpp:198] conv3_2_bn needs backward computation.
I1223 00:14:23.723173 25375 net.cpp:198] conv3_2 needs backward computation.
I1223 00:14:23.723176 25375 net.cpp:198] relu3_1 needs backward computation.
I1223 00:14:23.723179 25375 net.cpp:198] conv3_1_bn needs backward computation.
I1223 00:14:23.723182 25375 net.cpp:198] conv3_1 needs backward computation.
I1223 00:14:23.723186 25375 net.cpp:198] pool2 needs backward computation.
I1223 00:14:23.723188 25375 net.cpp:198] relu2_2 needs backward computation.
I1223 00:14:23.723191 25375 net.cpp:198] conv2_2_bn needs backward computation.
I1223 00:14:23.723193 25375 net.cpp:198] conv2_2 needs backward computation.
I1223 00:14:23.723197 25375 net.cpp:198] relu2_1 needs backward computation.
I1223 00:14:23.723201 25375 net.cpp:198] conv2_1_bn needs backward computation.
I1223 00:14:23.723202 25375 net.cpp:198] conv2_1 needs backward computation.
I1223 00:14:23.723206 25375 net.cpp:198] pool1 needs backward computation.
I1223 00:14:23.723209 25375 net.cpp:198] relu1_2 needs backward computation.
I1223 00:14:23.723212 25375 net.cpp:198] conv1_2_bn needs backward computation.
I1223 00:14:23.723215 25375 net.cpp:198] conv1_2 needs backward computation.
I1223 00:14:23.723218 25375 net.cpp:198] relu1_1 needs backward computation.
I1223 00:14:23.723222 25375 net.cpp:198] conv1_1_bn needs backward computation.
I1223 00:14:23.723224 25375 net.cpp:198] conv1_1 needs backward computation.
I1223 00:14:23.723228 25375 net.cpp:200] data does not need backward computation.
I1223 00:14:23.723232 25375 net.cpp:242] This network produces output loss
I1223 00:14:23.723294 25375 net.cpp:255] Network initialization done.
I1223 00:14:23.724318 25375 solver.cpp:173] Creating test net (#0) specified by net file: /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/c20.prototxt
I1223 00:14:23.724457 25375 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1223 00:14:23.725077 25375 net.cpp:51] Initializing net from parameters: 
name: "May_lstm"
state {
  phase: TEST
  stage: "test-on-test"
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  top: "clip_markers"
  include {
    phase: TEST
    stage: "test-on-test"
  }
  python_param {
    module: "sequence_input_layer"
    layer: "videoReadTest_RGB"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    name: "conv1_1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv1_1_bn"
  type: "BN"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    name: "conv1_2_w"
    lr_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv1_2_bn"
  type: "BN"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    name: "conv2_1_w"
    lr_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv2_1_bn"
  type: "BN"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    name: "conv2_2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv2_2_bn"
  type: "BN"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    name: "conv3_1_w"
    lr_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv3_1_bn"
  type: "BN"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    name: "conv3_2_w"
    lr_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv3_2_bn"
  type: "BN"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    name: "conv3_3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv3_3_bn"
  type: "BN"
  bottom: "conv3_3"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    name: "conv4_1_w"
    lr_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv4_1_bn"
  type: "BN"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    name: "conv4_2_w"
    lr_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv4_2_bn"
  type: "BN"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    name: "conv4_3_w"
    lr_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "conv4_3_bn"
  type: "BN"
  bottom: "conv4_3"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "relu4_3"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "relu4_3"
  top: "conv5_1"
  param {
    name: "conv5_1_w"
    lr_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "conv5_1_bn"
  type: "BN"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    name: "conv5_2_w"
    lr_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 4
    kernel_size: 3
    dilation: 4
  }
}
layer {
  name: "conv5_2_bn"
  type: "BN"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    name: "conv5_3_w"
    lr_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 8
    kernel_size: 3
    dilation: 8
  }
}
layer {
  name: "conv5_3_bn"
  type: "BN"
  bottom: "conv5_3"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "conv5"
  type: "Eltwise"
  bottom: "conv4_3"
  bottom: "conv5_3"
  top: "conv5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "fc6_1"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_1"
  param {
    name: "fc6_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_1_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "fc6_1"
  top: "fc6_1"
}
layer {
  name: "fc6_2"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_2"
  param {
    name: "fc6_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_2_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 4
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 4
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "fc6_2"
  top: "fc6_2"
}
layer {
  name: "fc6_3"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_3"
  param {
    name: "fc6_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_3_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 8
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 8
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "fc6_3"
  top: "fc6_3"
}
layer {
  name: "fc6_4"
  type: "Convolution"
  bottom: "relu5"
  top: "fc6_4"
  param {
    name: "fc6_4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_4_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 16
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    dilation: 16
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "fc6_4"
  top: "fc6_4"
}
layer {
  name: "concat4"
  type: "Concat"
  bottom: "fc6_1"
  bottom: "fc6_2"
  bottom: "fc6_3"
  bottom: "fc6_4"
  top: "concat4"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "concat4_512"
  type: "Convolution"
  bottom: "concat4"
  top: "concat4_512"
  param {
    name: "concat4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "concat4_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "sum_5_concat4"
  type: "Eltwise"
  bottom: "concat4_512"
  bottom: "conv5"
  top: "sum_5_concat4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum"
  type: "ReLU"
  bottom: "sum_5_concat4"
  top: "sum_5_concat4"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "sum_5_concat4"
  top: "conv5_4"
  param {
    name: "conv5_4_w"
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/bn"
  type: "BN"
  bottom: "conv5_4"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "conv5_4/relu"
  type: "ReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "conv5_4/dropout"
  type: "Dropout"
  bottom: "conv5_4"
  top: "conv5_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5_4"
  top: "conv6"
  param {
    name: "conv6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv6_b"
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BN"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    momentum: 0.95
    frozen: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "relu6"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "reshape-cm"
  type: "Reshape"
  bottom: "clip_markers"
  top: "reshape-cm"
  reshape_param {
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "reshape-data"
  type: "Reshape"
  bottom: "relu6"
  top: "conv6-reshape"
  reshape_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "dummy"
  type: "DummyData"
  top: "dummy"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode1"
  top: "encode1_h"
  top: "encode1_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "encode2"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode2"
  top: "encode2_h"
  top: "encode2_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "encode3"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode3"
  top: "encode3_h"
  top: "encode3_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 4
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "encode4"
  type: "ConvLSTM"
  bottom: "conv6-reshape"
  bottom: "reshape-cm"
  bottom: "dummy"
  bottom: "dummy"
  top: "encode4"
  top: "encode4_h"
  top: "encode4_c"
  recurrent_param {
    expose_hidden: true
  }
  lstm_conv_param {
    num_output: 32
    pad: 8
    kernel_size: 3
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 8
  }
  lstm_debug_param {
    axis_hadamard: 3
    num_axes_hadamard: 2
  }
}
layer {
  name: "reshape_encode1"
  type: "Reshape"
  bottom: "encode1"
  top: "reshape_encode1"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "reshape_encode2"
  type: "Reshape"
  bottom: "encode2"
  top: "reshape_encode2"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "reshape_encode3"
  type: "Reshape"
  bottom: "encode3"
  top: "reshape_encode3"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "reshape_encode4"
  type: "Reshape"
  bottom: "encode4"
  top: "reshape_encode4"
  reshape_param {
    shape {
      dim: 16
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "concat_encode1234"
  type: "Concat"
  bottom: "reshape_encode1"
  bottom: "reshape_encode2"
  bottom: "reshape_encode3"
  bottom: "reshape_encode4"
  top: "concat_encode1234"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv7_"
  type: "Convolution"
  bottom: "concat_encode1234"
  top: "conv7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1
    pad: 0
    kernel_size: 1
  }
}
layer {
  name: "conv7_interp"
  type: "Interp"
  bottom: "conv7"
  top: "conv7_interp"
  interp_param {
    height: 256
    width: 256
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "conv7_interp"
  bottom: "label"
  top: "loss"
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "encode1_h"
  bottom: "encode2_h"
  bottom: "encode3_h"
  bottom: "encode4_h"
  bottom: "encode1_c"
  bottom: "encode2_c"
  bottom: "encode3_c"
  bottom: "encode4_c"
}
I1223 00:14:23.725461 25375 layer_factory.hpp:77] Creating layer data
I1223 00:14:23.725530 25375 net.cpp:84] Creating Layer data
I1223 00:14:23.725538 25375 net.cpp:380] data -> data
I1223 00:14:23.725559 25375 net.cpp:380] data -> label
I1223 00:14:23.725582 25375 net.cpp:380] data -> clip_markers
I1223 00:14:24.342480 25375 net.cpp:122] Setting up data
I1223 00:14:24.342506 25375 net.cpp:129] Top shape: 16 3 256 256 (3145728)
I1223 00:14:24.342509 25375 net.cpp:129] Top shape: 16 1 256 256 (1048576)
I1223 00:14:24.342512 25375 net.cpp:129] Top shape: 16 (16)
I1223 00:14:24.342514 25375 net.cpp:137] Memory required for data: 16777280
I1223 00:14:24.342519 25375 layer_factory.hpp:77] Creating layer conv1_1
I1223 00:14:24.342543 25375 net.cpp:84] Creating Layer conv1_1
I1223 00:14:24.342547 25375 net.cpp:406] conv1_1 <- data
I1223 00:14:24.342566 25375 net.cpp:380] conv1_1 -> conv1_1
I1223 00:14:24.343039 25375 net.cpp:122] Setting up conv1_1
I1223 00:14:24.343044 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:24.343046 25375 net.cpp:137] Memory required for data: 285212736
I1223 00:14:24.343057 25375 layer_factory.hpp:77] Creating layer conv1_1_bn
I1223 00:14:24.343070 25375 net.cpp:84] Creating Layer conv1_1_bn
I1223 00:14:24.343072 25375 net.cpp:406] conv1_1_bn <- conv1_1
I1223 00:14:24.343078 25375 net.cpp:367] conv1_1_bn -> conv1_1 (in-place)
I1223 00:14:24.343302 25375 net.cpp:122] Setting up conv1_1_bn
I1223 00:14:24.343307 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:24.343308 25375 net.cpp:137] Memory required for data: 553648192
I1223 00:14:24.343318 25375 layer_factory.hpp:77] Creating layer relu1_1
I1223 00:14:24.343322 25375 net.cpp:84] Creating Layer relu1_1
I1223 00:14:24.343324 25375 net.cpp:406] relu1_1 <- conv1_1
I1223 00:14:24.343327 25375 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I1223 00:14:24.343331 25375 net.cpp:122] Setting up relu1_1
I1223 00:14:24.343334 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:24.343335 25375 net.cpp:137] Memory required for data: 822083648
I1223 00:14:24.343338 25375 layer_factory.hpp:77] Creating layer conv1_2
I1223 00:14:24.343346 25375 net.cpp:84] Creating Layer conv1_2
I1223 00:14:24.343349 25375 net.cpp:406] conv1_2 <- conv1_1
I1223 00:14:24.343353 25375 net.cpp:380] conv1_2 -> conv1_2
I1223 00:14:24.343621 25375 net.cpp:122] Setting up conv1_2
I1223 00:14:24.343626 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:24.343627 25375 net.cpp:137] Memory required for data: 1090519104
I1223 00:14:24.343631 25375 layer_factory.hpp:77] Creating layer conv1_2_bn
I1223 00:14:24.343649 25375 net.cpp:84] Creating Layer conv1_2_bn
I1223 00:14:24.343652 25375 net.cpp:406] conv1_2_bn <- conv1_2
I1223 00:14:24.343655 25375 net.cpp:367] conv1_2_bn -> conv1_2 (in-place)
I1223 00:14:24.344491 25375 net.cpp:122] Setting up conv1_2_bn
I1223 00:14:24.344501 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:24.344502 25375 net.cpp:137] Memory required for data: 1358954560
I1223 00:14:24.344525 25375 layer_factory.hpp:77] Creating layer relu1_2
I1223 00:14:24.344530 25375 net.cpp:84] Creating Layer relu1_2
I1223 00:14:24.344532 25375 net.cpp:406] relu1_2 <- conv1_2
I1223 00:14:24.344550 25375 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I1223 00:14:24.344554 25375 net.cpp:122] Setting up relu1_2
I1223 00:14:24.344557 25375 net.cpp:129] Top shape: 16 64 256 256 (67108864)
I1223 00:14:24.344558 25375 net.cpp:137] Memory required for data: 1627390016
I1223 00:14:24.344560 25375 layer_factory.hpp:77] Creating layer pool1
I1223 00:14:24.344563 25375 net.cpp:84] Creating Layer pool1
I1223 00:14:24.344564 25375 net.cpp:406] pool1 <- conv1_2
I1223 00:14:24.344566 25375 net.cpp:380] pool1 -> pool1
I1223 00:14:24.344600 25375 net.cpp:122] Setting up pool1
I1223 00:14:24.344604 25375 net.cpp:129] Top shape: 16 64 128 128 (16777216)
I1223 00:14:24.344605 25375 net.cpp:137] Memory required for data: 1694498880
I1223 00:14:24.344609 25375 layer_factory.hpp:77] Creating layer conv2_1
I1223 00:14:24.344619 25375 net.cpp:84] Creating Layer conv2_1
I1223 00:14:24.344621 25375 net.cpp:406] conv2_1 <- pool1
I1223 00:14:24.344624 25375 net.cpp:380] conv2_1 -> conv2_1
I1223 00:14:24.344899 25375 net.cpp:122] Setting up conv2_1
I1223 00:14:24.344905 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:24.344907 25375 net.cpp:137] Memory required for data: 1828716608
I1223 00:14:24.344913 25375 layer_factory.hpp:77] Creating layer conv2_1_bn
I1223 00:14:24.344931 25375 net.cpp:84] Creating Layer conv2_1_bn
I1223 00:14:24.344933 25375 net.cpp:406] conv2_1_bn <- conv2_1
I1223 00:14:24.344938 25375 net.cpp:367] conv2_1_bn -> conv2_1 (in-place)
I1223 00:14:24.345150 25375 net.cpp:122] Setting up conv2_1_bn
I1223 00:14:24.345155 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:24.345157 25375 net.cpp:137] Memory required for data: 1962934336
I1223 00:14:24.345165 25375 layer_factory.hpp:77] Creating layer relu2_1
I1223 00:14:24.345168 25375 net.cpp:84] Creating Layer relu2_1
I1223 00:14:24.345185 25375 net.cpp:406] relu2_1 <- conv2_1
I1223 00:14:24.345188 25375 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1223 00:14:24.345191 25375 net.cpp:122] Setting up relu2_1
I1223 00:14:24.345193 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:24.345196 25375 net.cpp:137] Memory required for data: 2097152064
I1223 00:14:24.345196 25375 layer_factory.hpp:77] Creating layer conv2_2
I1223 00:14:24.345201 25375 net.cpp:84] Creating Layer conv2_2
I1223 00:14:24.345202 25375 net.cpp:406] conv2_2 <- conv2_1
I1223 00:14:24.345206 25375 net.cpp:380] conv2_2 -> conv2_2
I1223 00:14:24.345497 25375 net.cpp:122] Setting up conv2_2
I1223 00:14:24.345502 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:24.345504 25375 net.cpp:137] Memory required for data: 2231369792
I1223 00:14:24.345508 25375 layer_factory.hpp:77] Creating layer conv2_2_bn
I1223 00:14:24.345528 25375 net.cpp:84] Creating Layer conv2_2_bn
I1223 00:14:24.345530 25375 net.cpp:406] conv2_2_bn <- conv2_2
I1223 00:14:24.345533 25375 net.cpp:367] conv2_2_bn -> conv2_2 (in-place)
I1223 00:14:24.345741 25375 net.cpp:122] Setting up conv2_2_bn
I1223 00:14:24.345746 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:24.345746 25375 net.cpp:137] Memory required for data: 2365587520
I1223 00:14:24.345752 25375 layer_factory.hpp:77] Creating layer relu2_2
I1223 00:14:24.345755 25375 net.cpp:84] Creating Layer relu2_2
I1223 00:14:24.345769 25375 net.cpp:406] relu2_2 <- conv2_2
I1223 00:14:24.345773 25375 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1223 00:14:24.345777 25375 net.cpp:122] Setting up relu2_2
I1223 00:14:24.345793 25375 net.cpp:129] Top shape: 16 128 128 128 (33554432)
I1223 00:14:24.345795 25375 net.cpp:137] Memory required for data: 2499805248
I1223 00:14:24.345798 25375 layer_factory.hpp:77] Creating layer pool2
I1223 00:14:24.345800 25375 net.cpp:84] Creating Layer pool2
I1223 00:14:24.345815 25375 net.cpp:406] pool2 <- conv2_2
I1223 00:14:24.345819 25375 net.cpp:380] pool2 -> pool2
I1223 00:14:24.345849 25375 net.cpp:122] Setting up pool2
I1223 00:14:24.345852 25375 net.cpp:129] Top shape: 16 128 64 64 (8388608)
I1223 00:14:24.345854 25375 net.cpp:137] Memory required for data: 2533359680
I1223 00:14:24.345857 25375 layer_factory.hpp:77] Creating layer conv3_1
I1223 00:14:24.345862 25375 net.cpp:84] Creating Layer conv3_1
I1223 00:14:24.345865 25375 net.cpp:406] conv3_1 <- pool2
I1223 00:14:24.345867 25375 net.cpp:380] conv3_1 -> conv3_1
I1223 00:14:24.346757 25375 net.cpp:122] Setting up conv3_1
I1223 00:14:24.346765 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.346767 25375 net.cpp:137] Memory required for data: 2600468544
I1223 00:14:24.346771 25375 layer_factory.hpp:77] Creating layer conv3_1_bn
I1223 00:14:24.346801 25375 net.cpp:84] Creating Layer conv3_1_bn
I1223 00:14:24.346803 25375 net.cpp:406] conv3_1_bn <- conv3_1
I1223 00:14:24.346815 25375 net.cpp:367] conv3_1_bn -> conv3_1 (in-place)
I1223 00:14:24.346994 25375 net.cpp:122] Setting up conv3_1_bn
I1223 00:14:24.346998 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.347000 25375 net.cpp:137] Memory required for data: 2667577408
I1223 00:14:24.347005 25375 layer_factory.hpp:77] Creating layer relu3_1
I1223 00:14:24.347008 25375 net.cpp:84] Creating Layer relu3_1
I1223 00:14:24.347009 25375 net.cpp:406] relu3_1 <- conv3_1
I1223 00:14:24.347028 25375 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1223 00:14:24.347030 25375 net.cpp:122] Setting up relu3_1
I1223 00:14:24.347033 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.347034 25375 net.cpp:137] Memory required for data: 2734686272
I1223 00:14:24.347051 25375 layer_factory.hpp:77] Creating layer conv3_2
I1223 00:14:24.347060 25375 net.cpp:84] Creating Layer conv3_2
I1223 00:14:24.347062 25375 net.cpp:406] conv3_2 <- conv3_1
I1223 00:14:24.347067 25375 net.cpp:380] conv3_2 -> conv3_2
I1223 00:14:24.348059 25375 net.cpp:122] Setting up conv3_2
I1223 00:14:24.348067 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.348069 25375 net.cpp:137] Memory required for data: 2801795136
I1223 00:14:24.348073 25375 layer_factory.hpp:77] Creating layer conv3_2_bn
I1223 00:14:24.348078 25375 net.cpp:84] Creating Layer conv3_2_bn
I1223 00:14:24.348095 25375 net.cpp:406] conv3_2_bn <- conv3_2
I1223 00:14:24.348099 25375 net.cpp:367] conv3_2_bn -> conv3_2 (in-place)
I1223 00:14:24.348299 25375 net.cpp:122] Setting up conv3_2_bn
I1223 00:14:24.348304 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.348305 25375 net.cpp:137] Memory required for data: 2868904000
I1223 00:14:24.348315 25375 layer_factory.hpp:77] Creating layer relu3_2
I1223 00:14:24.348332 25375 net.cpp:84] Creating Layer relu3_2
I1223 00:14:24.348335 25375 net.cpp:406] relu3_2 <- conv3_2
I1223 00:14:24.348337 25375 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I1223 00:14:24.348340 25375 net.cpp:122] Setting up relu3_2
I1223 00:14:24.348342 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.348345 25375 net.cpp:137] Memory required for data: 2936012864
I1223 00:14:24.348347 25375 layer_factory.hpp:77] Creating layer conv3_3
I1223 00:14:24.348353 25375 net.cpp:84] Creating Layer conv3_3
I1223 00:14:24.348356 25375 net.cpp:406] conv3_3 <- conv3_2
I1223 00:14:24.348361 25375 net.cpp:380] conv3_3 -> conv3_3
I1223 00:14:24.349850 25375 net.cpp:122] Setting up conv3_3
I1223 00:14:24.349861 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.349864 25375 net.cpp:137] Memory required for data: 3003121728
I1223 00:14:24.349867 25375 layer_factory.hpp:77] Creating layer conv3_3_bn
I1223 00:14:24.349890 25375 net.cpp:84] Creating Layer conv3_3_bn
I1223 00:14:24.349894 25375 net.cpp:406] conv3_3_bn <- conv3_3
I1223 00:14:24.349897 25375 net.cpp:367] conv3_3_bn -> conv3_3 (in-place)
I1223 00:14:24.350064 25375 net.cpp:122] Setting up conv3_3_bn
I1223 00:14:24.350069 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.350070 25375 net.cpp:137] Memory required for data: 3070230592
I1223 00:14:24.350075 25375 layer_factory.hpp:77] Creating layer relu3_3
I1223 00:14:24.350093 25375 net.cpp:84] Creating Layer relu3_3
I1223 00:14:24.350095 25375 net.cpp:406] relu3_3 <- conv3_3
I1223 00:14:24.350097 25375 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I1223 00:14:24.350101 25375 net.cpp:122] Setting up relu3_3
I1223 00:14:24.350105 25375 net.cpp:129] Top shape: 16 256 64 64 (16777216)
I1223 00:14:24.350106 25375 net.cpp:137] Memory required for data: 3137339456
I1223 00:14:24.350107 25375 layer_factory.hpp:77] Creating layer pool3
I1223 00:14:24.350119 25375 net.cpp:84] Creating Layer pool3
I1223 00:14:24.350121 25375 net.cpp:406] pool3 <- conv3_3
I1223 00:14:24.350124 25375 net.cpp:380] pool3 -> pool3
I1223 00:14:24.350373 25375 net.cpp:122] Setting up pool3
I1223 00:14:24.350378 25375 net.cpp:129] Top shape: 16 256 32 32 (4194304)
I1223 00:14:24.350379 25375 net.cpp:137] Memory required for data: 3154116672
I1223 00:14:24.350381 25375 layer_factory.hpp:77] Creating layer conv4_1
I1223 00:14:24.350389 25375 net.cpp:84] Creating Layer conv4_1
I1223 00:14:24.350405 25375 net.cpp:406] conv4_1 <- pool3
I1223 00:14:24.350410 25375 net.cpp:380] conv4_1 -> conv4_1
I1223 00:14:24.353158 25375 net.cpp:122] Setting up conv4_1
I1223 00:14:24.353180 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.353185 25375 net.cpp:137] Memory required for data: 3187671104
I1223 00:14:24.353193 25375 layer_factory.hpp:77] Creating layer conv4_1_bn
I1223 00:14:24.353205 25375 net.cpp:84] Creating Layer conv4_1_bn
I1223 00:14:24.353210 25375 net.cpp:406] conv4_1_bn <- conv4_1
I1223 00:14:24.353216 25375 net.cpp:367] conv4_1_bn -> conv4_1 (in-place)
I1223 00:14:24.353425 25375 net.cpp:122] Setting up conv4_1_bn
I1223 00:14:24.353432 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.353435 25375 net.cpp:137] Memory required for data: 3221225536
I1223 00:14:24.353442 25375 layer_factory.hpp:77] Creating layer relu4_1
I1223 00:14:24.353447 25375 net.cpp:84] Creating Layer relu4_1
I1223 00:14:24.353449 25375 net.cpp:406] relu4_1 <- conv4_1
I1223 00:14:24.353453 25375 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1223 00:14:24.353458 25375 net.cpp:122] Setting up relu4_1
I1223 00:14:24.353461 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.353463 25375 net.cpp:137] Memory required for data: 3254779968
I1223 00:14:24.353479 25375 layer_factory.hpp:77] Creating layer conv4_2
I1223 00:14:24.353507 25375 net.cpp:84] Creating Layer conv4_2
I1223 00:14:24.353509 25375 net.cpp:406] conv4_2 <- conv4_1
I1223 00:14:24.353513 25375 net.cpp:380] conv4_2 -> conv4_2
I1223 00:14:24.357139 25375 net.cpp:122] Setting up conv4_2
I1223 00:14:24.357164 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.357167 25375 net.cpp:137] Memory required for data: 3288334400
I1223 00:14:24.357189 25375 layer_factory.hpp:77] Creating layer conv4_2_bn
I1223 00:14:24.357213 25375 net.cpp:84] Creating Layer conv4_2_bn
I1223 00:14:24.357216 25375 net.cpp:406] conv4_2_bn <- conv4_2
I1223 00:14:24.357236 25375 net.cpp:367] conv4_2_bn -> conv4_2 (in-place)
I1223 00:14:24.357455 25375 net.cpp:122] Setting up conv4_2_bn
I1223 00:14:24.357462 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.357465 25375 net.cpp:137] Memory required for data: 3321888832
I1223 00:14:24.357471 25375 layer_factory.hpp:77] Creating layer relu4_2
I1223 00:14:24.357491 25375 net.cpp:84] Creating Layer relu4_2
I1223 00:14:24.357494 25375 net.cpp:406] relu4_2 <- conv4_2
I1223 00:14:24.357497 25375 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1223 00:14:24.357502 25375 net.cpp:122] Setting up relu4_2
I1223 00:14:24.357511 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.357512 25375 net.cpp:137] Memory required for data: 3355443264
I1223 00:14:24.357514 25375 layer_factory.hpp:77] Creating layer conv4_3
I1223 00:14:24.357525 25375 net.cpp:84] Creating Layer conv4_3
I1223 00:14:24.357527 25375 net.cpp:406] conv4_3 <- conv4_2
I1223 00:14:24.357549 25375 net.cpp:380] conv4_3 -> conv4_3
I1223 00:14:24.361253 25375 net.cpp:122] Setting up conv4_3
I1223 00:14:24.361279 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.361281 25375 net.cpp:137] Memory required for data: 3388997696
I1223 00:14:24.361305 25375 layer_factory.hpp:77] Creating layer conv4_3_bn
I1223 00:14:24.361343 25375 net.cpp:84] Creating Layer conv4_3_bn
I1223 00:14:24.361348 25375 net.cpp:406] conv4_3_bn <- conv4_3
I1223 00:14:24.361353 25375 net.cpp:367] conv4_3_bn -> conv4_3 (in-place)
I1223 00:14:24.361567 25375 net.cpp:122] Setting up conv4_3_bn
I1223 00:14:24.361573 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.361575 25375 net.cpp:137] Memory required for data: 3422552128
I1223 00:14:24.361583 25375 layer_factory.hpp:77] Creating layer conv4_3_conv4_3_bn_0_split
I1223 00:14:24.361603 25375 net.cpp:84] Creating Layer conv4_3_conv4_3_bn_0_split
I1223 00:14:24.361605 25375 net.cpp:406] conv4_3_conv4_3_bn_0_split <- conv4_3
I1223 00:14:24.361609 25375 net.cpp:380] conv4_3_conv4_3_bn_0_split -> conv4_3_conv4_3_bn_0_split_0
I1223 00:14:24.361618 25375 net.cpp:380] conv4_3_conv4_3_bn_0_split -> conv4_3_conv4_3_bn_0_split_1
I1223 00:14:24.361665 25375 net.cpp:122] Setting up conv4_3_conv4_3_bn_0_split
I1223 00:14:24.361671 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.361675 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.361676 25375 net.cpp:137] Memory required for data: 3489660992
I1223 00:14:24.361680 25375 layer_factory.hpp:77] Creating layer relu4_3
I1223 00:14:24.361683 25375 net.cpp:84] Creating Layer relu4_3
I1223 00:14:24.361685 25375 net.cpp:406] relu4_3 <- conv4_3_conv4_3_bn_0_split_0
I1223 00:14:24.361690 25375 net.cpp:380] relu4_3 -> relu4_3
I1223 00:14:24.361708 25375 net.cpp:122] Setting up relu4_3
I1223 00:14:24.361726 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.361728 25375 net.cpp:137] Memory required for data: 3523215424
I1223 00:14:24.361730 25375 layer_factory.hpp:77] Creating layer conv5_1
I1223 00:14:24.361753 25375 net.cpp:84] Creating Layer conv5_1
I1223 00:14:24.361760 25375 net.cpp:406] conv5_1 <- relu4_3
I1223 00:14:24.361764 25375 net.cpp:380] conv5_1 -> conv5_1
I1223 00:14:24.365600 25375 net.cpp:122] Setting up conv5_1
I1223 00:14:24.365623 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.365627 25375 net.cpp:137] Memory required for data: 3556769856
I1223 00:14:24.365649 25375 layer_factory.hpp:77] Creating layer conv5_1_bn
I1223 00:14:24.365664 25375 net.cpp:84] Creating Layer conv5_1_bn
I1223 00:14:24.365669 25375 net.cpp:406] conv5_1_bn <- conv5_1
I1223 00:14:24.365676 25375 net.cpp:367] conv5_1_bn -> conv5_1 (in-place)
I1223 00:14:24.365897 25375 net.cpp:122] Setting up conv5_1_bn
I1223 00:14:24.365903 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.365906 25375 net.cpp:137] Memory required for data: 3590324288
I1223 00:14:24.365934 25375 layer_factory.hpp:77] Creating layer relu5_1
I1223 00:14:24.365942 25375 net.cpp:84] Creating Layer relu5_1
I1223 00:14:24.365943 25375 net.cpp:406] relu5_1 <- conv5_1
I1223 00:14:24.365962 25375 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I1223 00:14:24.365967 25375 net.cpp:122] Setting up relu5_1
I1223 00:14:24.365969 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.365972 25375 net.cpp:137] Memory required for data: 3623878720
I1223 00:14:24.365973 25375 layer_factory.hpp:77] Creating layer conv5_2
I1223 00:14:24.365980 25375 net.cpp:84] Creating Layer conv5_2
I1223 00:14:24.365983 25375 net.cpp:406] conv5_2 <- conv5_1
I1223 00:14:24.365988 25375 net.cpp:380] conv5_2 -> conv5_2
I1223 00:14:24.369705 25375 net.cpp:122] Setting up conv5_2
I1223 00:14:24.369732 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.369735 25375 net.cpp:137] Memory required for data: 3657433152
I1223 00:14:24.369761 25375 layer_factory.hpp:77] Creating layer conv5_2_bn
I1223 00:14:24.369773 25375 net.cpp:84] Creating Layer conv5_2_bn
I1223 00:14:24.369777 25375 net.cpp:406] conv5_2_bn <- conv5_2
I1223 00:14:24.369783 25375 net.cpp:367] conv5_2_bn -> conv5_2 (in-place)
I1223 00:14:24.370033 25375 net.cpp:122] Setting up conv5_2_bn
I1223 00:14:24.370039 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.370043 25375 net.cpp:137] Memory required for data: 3690987584
I1223 00:14:24.370049 25375 layer_factory.hpp:77] Creating layer relu5_2
I1223 00:14:24.370070 25375 net.cpp:84] Creating Layer relu5_2
I1223 00:14:24.370074 25375 net.cpp:406] relu5_2 <- conv5_2
I1223 00:14:24.370079 25375 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I1223 00:14:24.370084 25375 net.cpp:122] Setting up relu5_2
I1223 00:14:24.370086 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.370090 25375 net.cpp:137] Memory required for data: 3724542016
I1223 00:14:24.370091 25375 layer_factory.hpp:77] Creating layer conv5_3
I1223 00:14:24.370098 25375 net.cpp:84] Creating Layer conv5_3
I1223 00:14:24.370101 25375 net.cpp:406] conv5_3 <- conv5_2
I1223 00:14:24.370118 25375 net.cpp:380] conv5_3 -> conv5_3
I1223 00:14:24.374007 25375 net.cpp:122] Setting up conv5_3
I1223 00:14:24.374032 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374034 25375 net.cpp:137] Memory required for data: 3758096448
I1223 00:14:24.374058 25375 layer_factory.hpp:77] Creating layer conv5_3_bn
I1223 00:14:24.374068 25375 net.cpp:84] Creating Layer conv5_3_bn
I1223 00:14:24.374073 25375 net.cpp:406] conv5_3_bn <- conv5_3
I1223 00:14:24.374078 25375 net.cpp:367] conv5_3_bn -> conv5_3 (in-place)
I1223 00:14:24.374316 25375 net.cpp:122] Setting up conv5_3_bn
I1223 00:14:24.374323 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374325 25375 net.cpp:137] Memory required for data: 3791650880
I1223 00:14:24.374332 25375 layer_factory.hpp:77] Creating layer conv5
I1223 00:14:24.374352 25375 net.cpp:84] Creating Layer conv5
I1223 00:14:24.374356 25375 net.cpp:406] conv5 <- conv4_3_conv4_3_bn_0_split_1
I1223 00:14:24.374372 25375 net.cpp:406] conv5 <- conv5_3
I1223 00:14:24.374377 25375 net.cpp:380] conv5 -> conv5
I1223 00:14:24.374399 25375 net.cpp:122] Setting up conv5
I1223 00:14:24.374404 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374408 25375 net.cpp:137] Memory required for data: 3825205312
I1223 00:14:24.374409 25375 layer_factory.hpp:77] Creating layer conv5_conv5_0_split
I1223 00:14:24.374414 25375 net.cpp:84] Creating Layer conv5_conv5_0_split
I1223 00:14:24.374416 25375 net.cpp:406] conv5_conv5_0_split <- conv5
I1223 00:14:24.374434 25375 net.cpp:380] conv5_conv5_0_split -> conv5_conv5_0_split_0
I1223 00:14:24.374439 25375 net.cpp:380] conv5_conv5_0_split -> conv5_conv5_0_split_1
I1223 00:14:24.374481 25375 net.cpp:122] Setting up conv5_conv5_0_split
I1223 00:14:24.374486 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374490 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374491 25375 net.cpp:137] Memory required for data: 3892314176
I1223 00:14:24.374495 25375 layer_factory.hpp:77] Creating layer relu5
I1223 00:14:24.374500 25375 net.cpp:84] Creating Layer relu5
I1223 00:14:24.374502 25375 net.cpp:406] relu5 <- conv5_conv5_0_split_0
I1223 00:14:24.374506 25375 net.cpp:380] relu5 -> relu5
I1223 00:14:24.374522 25375 net.cpp:122] Setting up relu5
I1223 00:14:24.374527 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374529 25375 net.cpp:137] Memory required for data: 3925868608
I1223 00:14:24.374531 25375 layer_factory.hpp:77] Creating layer relu5_relu5_0_split
I1223 00:14:24.374536 25375 net.cpp:84] Creating Layer relu5_relu5_0_split
I1223 00:14:24.374539 25375 net.cpp:406] relu5_relu5_0_split <- relu5
I1223 00:14:24.374545 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_0
I1223 00:14:24.374550 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_1
I1223 00:14:24.374554 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_2
I1223 00:14:24.374559 25375 net.cpp:380] relu5_relu5_0_split -> relu5_relu5_0_split_3
I1223 00:14:24.374604 25375 net.cpp:122] Setting up relu5_relu5_0_split
I1223 00:14:24.374610 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374614 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374616 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374619 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.374621 25375 net.cpp:137] Memory required for data: 4060086336
I1223 00:14:24.374624 25375 layer_factory.hpp:77] Creating layer fc6_1
I1223 00:14:24.374632 25375 net.cpp:84] Creating Layer fc6_1
I1223 00:14:24.374634 25375 net.cpp:406] fc6_1 <- relu5_relu5_0_split_0
I1223 00:14:24.374653 25375 net.cpp:380] fc6_1 -> fc6_1
I1223 00:14:24.381981 25375 net.cpp:122] Setting up fc6_1
I1223 00:14:24.382001 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.382005 25375 net.cpp:137] Memory required for data: 4068474944
I1223 00:14:24.382014 25375 layer_factory.hpp:77] Creating layer relu6_1
I1223 00:14:24.382022 25375 net.cpp:84] Creating Layer relu6_1
I1223 00:14:24.382026 25375 net.cpp:406] relu6_1 <- fc6_1
I1223 00:14:24.382035 25375 net.cpp:367] relu6_1 -> fc6_1 (in-place)
I1223 00:14:24.382042 25375 net.cpp:122] Setting up relu6_1
I1223 00:14:24.382050 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.382052 25375 net.cpp:137] Memory required for data: 4076863552
I1223 00:14:24.382055 25375 layer_factory.hpp:77] Creating layer fc6_2
I1223 00:14:24.382066 25375 net.cpp:84] Creating Layer fc6_2
I1223 00:14:24.382071 25375 net.cpp:406] fc6_2 <- relu5_relu5_0_split_1
I1223 00:14:24.382078 25375 net.cpp:380] fc6_2 -> fc6_2
I1223 00:14:24.389879 25375 net.cpp:122] Setting up fc6_2
I1223 00:14:24.389900 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.389904 25375 net.cpp:137] Memory required for data: 4085252160
I1223 00:14:24.389912 25375 layer_factory.hpp:77] Creating layer relu6_2
I1223 00:14:24.389921 25375 net.cpp:84] Creating Layer relu6_2
I1223 00:14:24.389925 25375 net.cpp:406] relu6_2 <- fc6_2
I1223 00:14:24.389930 25375 net.cpp:367] relu6_2 -> fc6_2 (in-place)
I1223 00:14:24.389940 25375 net.cpp:122] Setting up relu6_2
I1223 00:14:24.389943 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.389945 25375 net.cpp:137] Memory required for data: 4093640768
I1223 00:14:24.389950 25375 layer_factory.hpp:77] Creating layer fc6_3
I1223 00:14:24.389960 25375 net.cpp:84] Creating Layer fc6_3
I1223 00:14:24.389962 25375 net.cpp:406] fc6_3 <- relu5_relu5_0_split_2
I1223 00:14:24.389968 25375 net.cpp:380] fc6_3 -> fc6_3
I1223 00:14:24.397754 25375 net.cpp:122] Setting up fc6_3
I1223 00:14:24.397775 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.397778 25375 net.cpp:137] Memory required for data: 4102029376
I1223 00:14:24.397800 25375 layer_factory.hpp:77] Creating layer relu6_3
I1223 00:14:24.397821 25375 net.cpp:84] Creating Layer relu6_3
I1223 00:14:24.397825 25375 net.cpp:406] relu6_3 <- fc6_3
I1223 00:14:24.397830 25375 net.cpp:367] relu6_3 -> fc6_3 (in-place)
I1223 00:14:24.397836 25375 net.cpp:122] Setting up relu6_3
I1223 00:14:24.397840 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.397842 25375 net.cpp:137] Memory required for data: 4110417984
I1223 00:14:24.397845 25375 layer_factory.hpp:77] Creating layer fc6_4
I1223 00:14:24.397857 25375 net.cpp:84] Creating Layer fc6_4
I1223 00:14:24.397862 25375 net.cpp:406] fc6_4 <- relu5_relu5_0_split_3
I1223 00:14:24.397869 25375 net.cpp:380] fc6_4 -> fc6_4
I1223 00:14:24.405418 25375 net.cpp:122] Setting up fc6_4
I1223 00:14:24.405431 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.405434 25375 net.cpp:137] Memory required for data: 4118806592
I1223 00:14:24.405457 25375 layer_factory.hpp:77] Creating layer relu6_4
I1223 00:14:24.405462 25375 net.cpp:84] Creating Layer relu6_4
I1223 00:14:24.405467 25375 net.cpp:406] relu6_4 <- fc6_4
I1223 00:14:24.405470 25375 net.cpp:367] relu6_4 -> fc6_4 (in-place)
I1223 00:14:24.405477 25375 net.cpp:122] Setting up relu6_4
I1223 00:14:24.405479 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.405483 25375 net.cpp:137] Memory required for data: 4127195200
I1223 00:14:24.405499 25375 layer_factory.hpp:77] Creating layer concat4
I1223 00:14:24.405505 25375 net.cpp:84] Creating Layer concat4
I1223 00:14:24.405510 25375 net.cpp:406] concat4 <- fc6_1
I1223 00:14:24.405514 25375 net.cpp:406] concat4 <- fc6_2
I1223 00:14:24.405517 25375 net.cpp:406] concat4 <- fc6_3
I1223 00:14:24.405520 25375 net.cpp:406] concat4 <- fc6_4
I1223 00:14:24.405524 25375 net.cpp:380] concat4 -> concat4
I1223 00:14:24.405547 25375 net.cpp:122] Setting up concat4
I1223 00:14:24.405552 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.405555 25375 net.cpp:137] Memory required for data: 4160749632
I1223 00:14:24.405557 25375 layer_factory.hpp:77] Creating layer concat4_512
I1223 00:14:24.405567 25375 net.cpp:84] Creating Layer concat4_512
I1223 00:14:24.405570 25375 net.cpp:406] concat4_512 <- concat4
I1223 00:14:24.405576 25375 net.cpp:380] concat4_512 -> concat4_512
I1223 00:14:24.408668 25375 net.cpp:122] Setting up concat4_512
I1223 00:14:24.408676 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.408679 25375 net.cpp:137] Memory required for data: 4194304064
I1223 00:14:24.408684 25375 layer_factory.hpp:77] Creating layer sum_5_concat4
I1223 00:14:24.408705 25375 net.cpp:84] Creating Layer sum_5_concat4
I1223 00:14:24.408709 25375 net.cpp:406] sum_5_concat4 <- concat4_512
I1223 00:14:24.408712 25375 net.cpp:406] sum_5_concat4 <- conv5_conv5_0_split_1
I1223 00:14:24.408718 25375 net.cpp:380] sum_5_concat4 -> sum_5_concat4
I1223 00:14:24.408738 25375 net.cpp:122] Setting up sum_5_concat4
I1223 00:14:24.408745 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.408746 25375 net.cpp:137] Memory required for data: 4227858496
I1223 00:14:24.408749 25375 layer_factory.hpp:77] Creating layer relu_sum
I1223 00:14:24.408767 25375 net.cpp:84] Creating Layer relu_sum
I1223 00:14:24.408771 25375 net.cpp:406] relu_sum <- sum_5_concat4
I1223 00:14:24.408773 25375 net.cpp:367] relu_sum -> sum_5_concat4 (in-place)
I1223 00:14:24.408778 25375 net.cpp:122] Setting up relu_sum
I1223 00:14:24.408782 25375 net.cpp:129] Top shape: 16 512 32 32 (8388608)
I1223 00:14:24.408784 25375 net.cpp:137] Memory required for data: 4261412928
I1223 00:14:24.408788 25375 layer_factory.hpp:77] Creating layer conv5_4
I1223 00:14:24.408797 25375 net.cpp:84] Creating Layer conv5_4
I1223 00:14:24.408799 25375 net.cpp:406] conv5_4 <- sum_5_concat4
I1223 00:14:24.408805 25375 net.cpp:380] conv5_4 -> conv5_4
I1223 00:14:24.412883 25375 net.cpp:122] Setting up conv5_4
I1223 00:14:24.412897 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:24.412900 25375 net.cpp:137] Memory required for data: 4265607232
I1223 00:14:24.412905 25375 layer_factory.hpp:77] Creating layer conv5_4/bn
I1223 00:14:24.412930 25375 net.cpp:84] Creating Layer conv5_4/bn
I1223 00:14:24.412946 25375 net.cpp:406] conv5_4/bn <- conv5_4
I1223 00:14:24.412951 25375 net.cpp:367] conv5_4/bn -> conv5_4 (in-place)
I1223 00:14:24.413239 25375 net.cpp:122] Setting up conv5_4/bn
I1223 00:14:24.413245 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:24.413249 25375 net.cpp:137] Memory required for data: 4269801536
I1223 00:14:24.413274 25375 layer_factory.hpp:77] Creating layer conv5_4/relu
I1223 00:14:24.413280 25375 net.cpp:84] Creating Layer conv5_4/relu
I1223 00:14:24.413281 25375 net.cpp:406] conv5_4/relu <- conv5_4
I1223 00:14:24.413286 25375 net.cpp:367] conv5_4/relu -> conv5_4 (in-place)
I1223 00:14:24.413291 25375 net.cpp:122] Setting up conv5_4/relu
I1223 00:14:24.413295 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:24.413314 25375 net.cpp:137] Memory required for data: 4273995840
I1223 00:14:24.413317 25375 layer_factory.hpp:77] Creating layer conv5_4/dropout
I1223 00:14:24.413321 25375 net.cpp:84] Creating Layer conv5_4/dropout
I1223 00:14:24.413336 25375 net.cpp:406] conv5_4/dropout <- conv5_4
I1223 00:14:24.413341 25375 net.cpp:367] conv5_4/dropout -> conv5_4 (in-place)
I1223 00:14:24.413377 25375 net.cpp:122] Setting up conv5_4/dropout
I1223 00:14:24.413394 25375 net.cpp:129] Top shape: 16 64 32 32 (1048576)
I1223 00:14:24.413396 25375 net.cpp:137] Memory required for data: 4278190144
I1223 00:14:24.413398 25375 layer_factory.hpp:77] Creating layer conv6
I1223 00:14:24.413419 25375 net.cpp:84] Creating Layer conv6
I1223 00:14:24.413436 25375 net.cpp:406] conv6 <- conv5_4
I1223 00:14:24.413440 25375 net.cpp:380] conv6 -> conv6
I1223 00:14:24.413704 25375 net.cpp:122] Setting up conv6
I1223 00:14:24.413710 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:24.413712 25375 net.cpp:137] Memory required for data: 4278255680
I1223 00:14:24.413717 25375 layer_factory.hpp:77] Creating layer conv6/bn
I1223 00:14:24.413741 25375 net.cpp:84] Creating Layer conv6/bn
I1223 00:14:24.413744 25375 net.cpp:406] conv6/bn <- conv6
I1223 00:14:24.413749 25375 net.cpp:367] conv6/bn -> conv6 (in-place)
I1223 00:14:24.414007 25375 net.cpp:122] Setting up conv6/bn
I1223 00:14:24.414013 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:24.414016 25375 net.cpp:137] Memory required for data: 4278321216
I1223 00:14:24.414022 25375 layer_factory.hpp:77] Creating layer relu6
I1223 00:14:24.414041 25375 net.cpp:84] Creating Layer relu6
I1223 00:14:24.414044 25375 net.cpp:406] relu6 <- conv6
I1223 00:14:24.414048 25375 net.cpp:380] relu6 -> relu6
I1223 00:14:24.414082 25375 net.cpp:122] Setting up relu6
I1223 00:14:24.414100 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:24.414103 25375 net.cpp:137] Memory required for data: 4278386752
I1223 00:14:24.414106 25375 layer_factory.hpp:77] Creating layer reshape-cm
I1223 00:14:24.414125 25375 net.cpp:84] Creating Layer reshape-cm
I1223 00:14:24.414129 25375 net.cpp:406] reshape-cm <- clip_markers
I1223 00:14:24.414147 25375 net.cpp:380] reshape-cm -> reshape-cm
I1223 00:14:24.414186 25375 net.cpp:122] Setting up reshape-cm
I1223 00:14:24.414203 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.414206 25375 net.cpp:137] Memory required for data: 4278386816
I1223 00:14:24.414208 25375 layer_factory.hpp:77] Creating layer reshape-cm_reshape-cm_0_split
I1223 00:14:24.414227 25375 net.cpp:84] Creating Layer reshape-cm_reshape-cm_0_split
I1223 00:14:24.414229 25375 net.cpp:406] reshape-cm_reshape-cm_0_split <- reshape-cm
I1223 00:14:24.414235 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_0
I1223 00:14:24.414242 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_1
I1223 00:14:24.414260 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_2
I1223 00:14:24.414265 25375 net.cpp:380] reshape-cm_reshape-cm_0_split -> reshape-cm_reshape-cm_0_split_3
I1223 00:14:24.414383 25375 net.cpp:122] Setting up reshape-cm_reshape-cm_0_split
I1223 00:14:24.414387 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.414391 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.414394 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.414397 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.414399 25375 net.cpp:137] Memory required for data: 4278387072
I1223 00:14:24.414417 25375 layer_factory.hpp:77] Creating layer reshape-data
I1223 00:14:24.414422 25375 net.cpp:84] Creating Layer reshape-data
I1223 00:14:24.414424 25375 net.cpp:406] reshape-data <- relu6
I1223 00:14:24.414428 25375 net.cpp:380] reshape-data -> conv6-reshape
I1223 00:14:24.414461 25375 net.cpp:122] Setting up reshape-data
I1223 00:14:24.414481 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.414484 25375 net.cpp:137] Memory required for data: 4278452608
I1223 00:14:24.414499 25375 layer_factory.hpp:77] Creating layer conv6-reshape_reshape-data_0_split
I1223 00:14:24.414505 25375 net.cpp:84] Creating Layer conv6-reshape_reshape-data_0_split
I1223 00:14:24.414522 25375 net.cpp:406] conv6-reshape_reshape-data_0_split <- conv6-reshape
I1223 00:14:24.414526 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_0
I1223 00:14:24.414544 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_1
I1223 00:14:24.414566 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_2
I1223 00:14:24.414572 25375 net.cpp:380] conv6-reshape_reshape-data_0_split -> conv6-reshape_reshape-data_0_split_3
I1223 00:14:24.414680 25375 net.cpp:122] Setting up conv6-reshape_reshape-data_0_split
I1223 00:14:24.414685 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.414688 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.414691 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.414695 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.414712 25375 net.cpp:137] Memory required for data: 4278714752
I1223 00:14:24.414714 25375 layer_factory.hpp:77] Creating layer dummy
I1223 00:14:24.414721 25375 net.cpp:84] Creating Layer dummy
I1223 00:14:24.414724 25375 net.cpp:380] dummy -> dummy
I1223 00:14:24.414826 25375 net.cpp:122] Setting up dummy
I1223 00:14:24.414832 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.414834 25375 net.cpp:137] Memory required for data: 4278845824
I1223 00:14:24.414837 25375 layer_factory.hpp:77] Creating layer dummy_dummy_0_split
I1223 00:14:24.414844 25375 net.cpp:84] Creating Layer dummy_dummy_0_split
I1223 00:14:24.414847 25375 net.cpp:406] dummy_dummy_0_split <- dummy
I1223 00:14:24.414866 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_0
I1223 00:14:24.414885 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_1
I1223 00:14:24.414891 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_2
I1223 00:14:24.414911 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_3
I1223 00:14:24.414916 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_4
I1223 00:14:24.414921 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_5
I1223 00:14:24.414925 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_6
I1223 00:14:24.414932 25375 net.cpp:380] dummy_dummy_0_split -> dummy_dummy_0_split_7
I1223 00:14:24.415035 25375 net.cpp:122] Setting up dummy_dummy_0_split
I1223 00:14:24.415053 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415056 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415060 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415065 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415067 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415071 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415074 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415078 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.415081 25375 net.cpp:137] Memory required for data: 4279894400
I1223 00:14:24.415084 25375 layer_factory.hpp:77] Creating layer encode1
I1223 00:14:24.415094 25375 net.cpp:84] Creating Layer encode1
I1223 00:14:24.415097 25375 net.cpp:406] encode1 <- conv6-reshape_reshape-data_0_split_0
I1223 00:14:24.415115 25375 net.cpp:406] encode1 <- reshape-cm_reshape-cm_0_split_0
I1223 00:14:24.415118 25375 net.cpp:406] encode1 <- dummy_dummy_0_split_0
I1223 00:14:24.415122 25375 net.cpp:406] encode1 <- dummy_dummy_0_split_1
I1223 00:14:24.415127 25375 net.cpp:380] encode1 -> encode1
I1223 00:14:24.415135 25375 net.cpp:380] encode1 -> encode1_h
I1223 00:14:24.415143 25375 net.cpp:380] encode1 -> encode1_c
I1223 00:14:24.415151 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:24.416592 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode1_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode1_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode1_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode1_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode1_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode1_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode1_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode1_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode1_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode1_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode1_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode1_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode1_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode1_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode1_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode1_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
  }
}
layer {
  name: "encode1_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode1_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode1_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode1_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode1_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode1_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode1_hidden->transform->13"
  type: "Convolution"
  bottom: "h_conted_t=13"
  top: "hidden->transform->13"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_ou
I1223 00:14:24.417563 25375 layer_factory.hpp:77] Creating layer encode1_
I1223 00:14:24.417573 25375 net.cpp:84] Creating Layer encode1_
I1223 00:14:24.417578 25375 net.cpp:380] encode1_ -> x
I1223 00:14:24.417585 25375 net.cpp:380] encode1_ -> cont
I1223 00:14:24.417626 25375 net.cpp:122] Setting up encode1_
I1223 00:14:24.417632 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.417636 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.417639 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:24.417642 25375 layer_factory.hpp:77] Creating layer encode1_x->transform
I1223 00:14:24.417652 25375 net.cpp:84] Creating Layer encode1_x->transform
I1223 00:14:24.417656 25375 net.cpp:406] encode1_x->transform <- x
I1223 00:14:24.417661 25375 net.cpp:380] encode1_x->transform -> x->transform
I1223 00:14:24.417848 25375 net.cpp:122] Setting up encode1_x->transform
I1223 00:14:24.417855 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:24.417858 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:24.417863 25375 layer_factory.hpp:77] Creating layer encode1_input->cell_hidden
I1223 00:14:24.417868 25375 net.cpp:84] Creating Layer encode1_input->cell_hidden
I1223 00:14:24.417872 25375 net.cpp:380] encode1_input->cell_hidden -> c_t=0
I1223 00:14:24.417878 25375 net.cpp:380] encode1_input->cell_hidden -> h_t=0
I1223 00:14:24.417909 25375 net.cpp:122] Setting up encode1_input->cell_hidden
I1223 00:14:24.417915 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.417919 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.417922 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:24.417924 25375 layer_factory.hpp:77] Creating layer encode1_W_xc_x_slice
I1223 00:14:24.417932 25375 net.cpp:84] Creating Layer encode1_W_xc_x_slice
I1223 00:14:24.417935 25375 net.cpp:406] encode1_W_xc_x_slice <- x->transform
I1223 00:14:24.417942 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=1
I1223 00:14:24.417966 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=2
I1223 00:14:24.417973 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=3
I1223 00:14:24.417979 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=4
I1223 00:14:24.417990 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=5
I1223 00:14:24.417996 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=6
I1223 00:14:24.418002 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=7
I1223 00:14:24.418009 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=8
I1223 00:14:24.418030 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=9
I1223 00:14:24.418036 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=10
I1223 00:14:24.418042 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=11
I1223 00:14:24.418049 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=12
I1223 00:14:24.418057 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=13
I1223 00:14:24.418063 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=14
I1223 00:14:24.418069 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=15
I1223 00:14:24.418076 25375 net.cpp:380] encode1_W_xc_x_slice -> x->transform->t=16
I1223 00:14:24.418264 25375 net.cpp:122] Setting up encode1_W_xc_x_slice
I1223 00:14:24.418270 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418273 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418277 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418282 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418299 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418303 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418306 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418310 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418314 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418318 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418321 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418325 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418329 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418332 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418335 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418354 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.418355 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:24.418359 25375 layer_factory.hpp:77] Creating layer encode1_cont_slice
I1223 00:14:24.418365 25375 net.cpp:84] Creating Layer encode1_cont_slice
I1223 00:14:24.418368 25375 net.cpp:406] encode1_cont_slice <- cont
I1223 00:14:24.418373 25375 net.cpp:380] encode1_cont_slice -> cont_t=1
I1223 00:14:24.418380 25375 net.cpp:380] encode1_cont_slice -> cont_t=2
I1223 00:14:24.418385 25375 net.cpp:380] encode1_cont_slice -> cont_t=3
I1223 00:14:24.418392 25375 net.cpp:380] encode1_cont_slice -> cont_t=4
I1223 00:14:24.418397 25375 net.cpp:380] encode1_cont_slice -> cont_t=5
I1223 00:14:24.418403 25375 net.cpp:380] encode1_cont_slice -> cont_t=6
I1223 00:14:24.418408 25375 net.cpp:380] encode1_cont_slice -> cont_t=7
I1223 00:14:24.418414 25375 net.cpp:380] encode1_cont_slice -> cont_t=8
I1223 00:14:24.418419 25375 net.cpp:380] encode1_cont_slice -> cont_t=9
I1223 00:14:24.418426 25375 net.cpp:380] encode1_cont_slice -> cont_t=10
I1223 00:14:24.418431 25375 net.cpp:380] encode1_cont_slice -> cont_t=11
I1223 00:14:24.418437 25375 net.cpp:380] encode1_cont_slice -> cont_t=12
I1223 00:14:24.418444 25375 net.cpp:380] encode1_cont_slice -> cont_t=13
I1223 00:14:24.418449 25375 net.cpp:380] encode1_cont_slice -> cont_t=14
I1223 00:14:24.418454 25375 net.cpp:380] encode1_cont_slice -> cont_t=15
I1223 00:14:24.418460 25375 net.cpp:380] encode1_cont_slice -> cont_t=16
I1223 00:14:24.418649 25375 net.cpp:122] Setting up encode1_cont_slice
I1223 00:14:24.418655 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418658 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418661 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418664 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418682 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418685 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418689 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418692 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418695 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418699 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418715 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418720 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418722 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418725 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418728 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418731 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418735 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:24.418736 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode1_cont_slice_0_split
I1223 00:14:24.418741 25375 net.cpp:84] Creating Layer cont_t=1_encode1_cont_slice_0_split
I1223 00:14:24.418745 25375 net.cpp:406] cont_t=1_encode1_cont_slice_0_split <- cont_t=1
I1223 00:14:24.418748 25375 net.cpp:380] cont_t=1_encode1_cont_slice_0_split -> cont_t=1_encode1_cont_slice_0_split_0
I1223 00:14:24.418754 25375 net.cpp:380] cont_t=1_encode1_cont_slice_0_split -> cont_t=1_encode1_cont_slice_0_split_1
I1223 00:14:24.418786 25375 net.cpp:122] Setting up cont_t=1_encode1_cont_slice_0_split
I1223 00:14:24.418790 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418793 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418797 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:24.418798 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode1_cont_slice_1_split
I1223 00:14:24.418803 25375 net.cpp:84] Creating Layer cont_t=2_encode1_cont_slice_1_split
I1223 00:14:24.418807 25375 net.cpp:406] cont_t=2_encode1_cont_slice_1_split <- cont_t=2
I1223 00:14:24.418812 25375 net.cpp:380] cont_t=2_encode1_cont_slice_1_split -> cont_t=2_encode1_cont_slice_1_split_0
I1223 00:14:24.418817 25375 net.cpp:380] cont_t=2_encode1_cont_slice_1_split -> cont_t=2_encode1_cont_slice_1_split_1
I1223 00:14:24.418874 25375 net.cpp:122] Setting up cont_t=2_encode1_cont_slice_1_split
I1223 00:14:24.418879 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418881 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418884 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:24.418886 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode1_cont_slice_2_split
I1223 00:14:24.418891 25375 net.cpp:84] Creating Layer cont_t=3_encode1_cont_slice_2_split
I1223 00:14:24.418895 25375 net.cpp:406] cont_t=3_encode1_cont_slice_2_split <- cont_t=3
I1223 00:14:24.418898 25375 net.cpp:380] cont_t=3_encode1_cont_slice_2_split -> cont_t=3_encode1_cont_slice_2_split_0
I1223 00:14:24.418903 25375 net.cpp:380] cont_t=3_encode1_cont_slice_2_split -> cont_t=3_encode1_cont_slice_2_split_1
I1223 00:14:24.418933 25375 net.cpp:122] Setting up cont_t=3_encode1_cont_slice_2_split
I1223 00:14:24.418938 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418942 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.418944 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:24.418947 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode1_cont_slice_3_split
I1223 00:14:24.418952 25375 net.cpp:84] Creating Layer cont_t=4_encode1_cont_slice_3_split
I1223 00:14:24.418956 25375 net.cpp:406] cont_t=4_encode1_cont_slice_3_split <- cont_t=4
I1223 00:14:24.418961 25375 net.cpp:380] cont_t=4_encode1_cont_slice_3_split -> cont_t=4_encode1_cont_slice_3_split_0
I1223 00:14:24.418967 25375 net.cpp:380] cont_t=4_encode1_cont_slice_3_split -> cont_t=4_encode1_cont_slice_3_split_1
I1223 00:14:24.418997 25375 net.cpp:122] Setting up cont_t=4_encode1_cont_slice_3_split
I1223 00:14:24.419003 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419005 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419008 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:24.419010 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode1_cont_slice_4_split
I1223 00:14:24.419015 25375 net.cpp:84] Creating Layer cont_t=5_encode1_cont_slice_4_split
I1223 00:14:24.419018 25375 net.cpp:406] cont_t=5_encode1_cont_slice_4_split <- cont_t=5
I1223 00:14:24.419023 25375 net.cpp:380] cont_t=5_encode1_cont_slice_4_split -> cont_t=5_encode1_cont_slice_4_split_0
I1223 00:14:24.419028 25375 net.cpp:380] cont_t=5_encode1_cont_slice_4_split -> cont_t=5_encode1_cont_slice_4_split_1
I1223 00:14:24.419056 25375 net.cpp:122] Setting up cont_t=5_encode1_cont_slice_4_split
I1223 00:14:24.419060 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419064 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419066 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:24.419068 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode1_cont_slice_5_split
I1223 00:14:24.419073 25375 net.cpp:84] Creating Layer cont_t=6_encode1_cont_slice_5_split
I1223 00:14:24.419076 25375 net.cpp:406] cont_t=6_encode1_cont_slice_5_split <- cont_t=6
I1223 00:14:24.419080 25375 net.cpp:380] cont_t=6_encode1_cont_slice_5_split -> cont_t=6_encode1_cont_slice_5_split_0
I1223 00:14:24.419085 25375 net.cpp:380] cont_t=6_encode1_cont_slice_5_split -> cont_t=6_encode1_cont_slice_5_split_1
I1223 00:14:24.419116 25375 net.cpp:122] Setting up cont_t=6_encode1_cont_slice_5_split
I1223 00:14:24.419121 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419126 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419127 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:24.419131 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode1_cont_slice_6_split
I1223 00:14:24.419133 25375 net.cpp:84] Creating Layer cont_t=7_encode1_cont_slice_6_split
I1223 00:14:24.419137 25375 net.cpp:406] cont_t=7_encode1_cont_slice_6_split <- cont_t=7
I1223 00:14:24.419142 25375 net.cpp:380] cont_t=7_encode1_cont_slice_6_split -> cont_t=7_encode1_cont_slice_6_split_0
I1223 00:14:24.419147 25375 net.cpp:380] cont_t=7_encode1_cont_slice_6_split -> cont_t=7_encode1_cont_slice_6_split_1
I1223 00:14:24.419174 25375 net.cpp:122] Setting up cont_t=7_encode1_cont_slice_6_split
I1223 00:14:24.419179 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419183 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419185 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:24.419188 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode1_cont_slice_7_split
I1223 00:14:24.419191 25375 net.cpp:84] Creating Layer cont_t=8_encode1_cont_slice_7_split
I1223 00:14:24.419194 25375 net.cpp:406] cont_t=8_encode1_cont_slice_7_split <- cont_t=8
I1223 00:14:24.419199 25375 net.cpp:380] cont_t=8_encode1_cont_slice_7_split -> cont_t=8_encode1_cont_slice_7_split_0
I1223 00:14:24.419204 25375 net.cpp:380] cont_t=8_encode1_cont_slice_7_split -> cont_t=8_encode1_cont_slice_7_split_1
I1223 00:14:24.419232 25375 net.cpp:122] Setting up cont_t=8_encode1_cont_slice_7_split
I1223 00:14:24.419237 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419241 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419243 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:24.419245 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode1_cont_slice_8_split
I1223 00:14:24.419250 25375 net.cpp:84] Creating Layer cont_t=9_encode1_cont_slice_8_split
I1223 00:14:24.419252 25375 net.cpp:406] cont_t=9_encode1_cont_slice_8_split <- cont_t=9
I1223 00:14:24.419256 25375 net.cpp:380] cont_t=9_encode1_cont_slice_8_split -> cont_t=9_encode1_cont_slice_8_split_0
I1223 00:14:24.419261 25375 net.cpp:380] cont_t=9_encode1_cont_slice_8_split -> cont_t=9_encode1_cont_slice_8_split_1
I1223 00:14:24.419291 25375 net.cpp:122] Setting up cont_t=9_encode1_cont_slice_8_split
I1223 00:14:24.419296 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419298 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419301 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:24.419303 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode1_cont_slice_9_split
I1223 00:14:24.419307 25375 net.cpp:84] Creating Layer cont_t=10_encode1_cont_slice_9_split
I1223 00:14:24.419311 25375 net.cpp:406] cont_t=10_encode1_cont_slice_9_split <- cont_t=10
I1223 00:14:24.419317 25375 net.cpp:380] cont_t=10_encode1_cont_slice_9_split -> cont_t=10_encode1_cont_slice_9_split_0
I1223 00:14:24.419322 25375 net.cpp:380] cont_t=10_encode1_cont_slice_9_split -> cont_t=10_encode1_cont_slice_9_split_1
I1223 00:14:24.419351 25375 net.cpp:122] Setting up cont_t=10_encode1_cont_slice_9_split
I1223 00:14:24.419356 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419359 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419363 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:24.419378 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode1_cont_slice_10_split
I1223 00:14:24.419381 25375 net.cpp:84] Creating Layer cont_t=11_encode1_cont_slice_10_split
I1223 00:14:24.419384 25375 net.cpp:406] cont_t=11_encode1_cont_slice_10_split <- cont_t=11
I1223 00:14:24.419402 25375 net.cpp:380] cont_t=11_encode1_cont_slice_10_split -> cont_t=11_encode1_cont_slice_10_split_0
I1223 00:14:24.419407 25375 net.cpp:380] cont_t=11_encode1_cont_slice_10_split -> cont_t=11_encode1_cont_slice_10_split_1
I1223 00:14:24.419435 25375 net.cpp:122] Setting up cont_t=11_encode1_cont_slice_10_split
I1223 00:14:24.419440 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419445 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419446 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:24.419450 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode1_cont_slice_11_split
I1223 00:14:24.419454 25375 net.cpp:84] Creating Layer cont_t=12_encode1_cont_slice_11_split
I1223 00:14:24.419457 25375 net.cpp:406] cont_t=12_encode1_cont_slice_11_split <- cont_t=12
I1223 00:14:24.419462 25375 net.cpp:380] cont_t=12_encode1_cont_slice_11_split -> cont_t=12_encode1_cont_slice_11_split_0
I1223 00:14:24.419467 25375 net.cpp:380] cont_t=12_encode1_cont_slice_11_split -> cont_t=12_encode1_cont_slice_11_split_1
I1223 00:14:24.419497 25375 net.cpp:122] Setting up cont_t=12_encode1_cont_slice_11_split
I1223 00:14:24.419502 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419505 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419507 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:24.419509 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode1_cont_slice_12_split
I1223 00:14:24.419513 25375 net.cpp:84] Creating Layer cont_t=13_encode1_cont_slice_12_split
I1223 00:14:24.419517 25375 net.cpp:406] cont_t=13_encode1_cont_slice_12_split <- cont_t=13
I1223 00:14:24.419520 25375 net.cpp:380] cont_t=13_encode1_cont_slice_12_split -> cont_t=13_encode1_cont_slice_12_split_0
I1223 00:14:24.419525 25375 net.cpp:380] cont_t=13_encode1_cont_slice_12_split -> cont_t=13_encode1_cont_slice_12_split_1
I1223 00:14:24.419553 25375 net.cpp:122] Setting up cont_t=13_encode1_cont_slice_12_split
I1223 00:14:24.419559 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419561 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419564 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:24.419567 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode1_cont_slice_13_split
I1223 00:14:24.419570 25375 net.cpp:84] Creating Layer cont_t=14_encode1_cont_slice_13_split
I1223 00:14:24.419574 25375 net.cpp:406] cont_t=14_encode1_cont_slice_13_split <- cont_t=14
I1223 00:14:24.419579 25375 net.cpp:380] cont_t=14_encode1_cont_slice_13_split -> cont_t=14_encode1_cont_slice_13_split_0
I1223 00:14:24.419584 25375 net.cpp:380] cont_t=14_encode1_cont_slice_13_split -> cont_t=14_encode1_cont_slice_13_split_1
I1223 00:14:24.419615 25375 net.cpp:122] Setting up cont_t=14_encode1_cont_slice_13_split
I1223 00:14:24.419620 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419625 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419628 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:24.419631 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode1_cont_slice_14_split
I1223 00:14:24.419634 25375 net.cpp:84] Creating Layer cont_t=15_encode1_cont_slice_14_split
I1223 00:14:24.419637 25375 net.cpp:406] cont_t=15_encode1_cont_slice_14_split <- cont_t=15
I1223 00:14:24.419641 25375 net.cpp:380] cont_t=15_encode1_cont_slice_14_split -> cont_t=15_encode1_cont_slice_14_split_0
I1223 00:14:24.419646 25375 net.cpp:380] cont_t=15_encode1_cont_slice_14_split -> cont_t=15_encode1_cont_slice_14_split_1
I1223 00:14:24.419677 25375 net.cpp:122] Setting up cont_t=15_encode1_cont_slice_14_split
I1223 00:14:24.419680 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419684 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419687 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:24.419689 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode1_cont_slice_15_split
I1223 00:14:24.419692 25375 net.cpp:84] Creating Layer cont_t=16_encode1_cont_slice_15_split
I1223 00:14:24.419695 25375 net.cpp:406] cont_t=16_encode1_cont_slice_15_split <- cont_t=16
I1223 00:14:24.419700 25375 net.cpp:380] cont_t=16_encode1_cont_slice_15_split -> cont_t=16_encode1_cont_slice_15_split_0
I1223 00:14:24.419706 25375 net.cpp:380] cont_t=16_encode1_cont_slice_15_split -> cont_t=16_encode1_cont_slice_15_split_1
I1223 00:14:24.419734 25375 net.cpp:122] Setting up cont_t=16_encode1_cont_slice_15_split
I1223 00:14:24.419739 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419742 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.419744 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:24.419747 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_c0
I1223 00:14:24.419752 25375 net.cpp:84] Creating Layer encode1_dummy_forward_c0
I1223 00:14:24.419755 25375 net.cpp:406] encode1_dummy_forward_c0 <- c_t=0
I1223 00:14:24.419759 25375 net.cpp:367] encode1_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:24.419778 25375 net.cpp:122] Setting up encode1_dummy_forward_c0
I1223 00:14:24.419783 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.419786 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:24.419791 25375 layer_factory.hpp:77] Creating layer c_t=0_encode1_dummy_forward_c0_0_split
I1223 00:14:24.419797 25375 net.cpp:84] Creating Layer c_t=0_encode1_dummy_forward_c0_0_split
I1223 00:14:24.419800 25375 net.cpp:406] c_t=0_encode1_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:24.419805 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_0
I1223 00:14:24.419811 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_1
I1223 00:14:24.419816 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_2
I1223 00:14:24.419821 25375 net.cpp:380] c_t=0_encode1_dummy_forward_c0_0_split -> c_t=0_encode1_dummy_forward_c0_0_split_3
I1223 00:14:24.419876 25375 net.cpp:122] Setting up c_t=0_encode1_dummy_forward_c0_0_split
I1223 00:14:24.419883 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.419888 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.419893 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.419896 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.419899 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:24.419901 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_h0
I1223 00:14:24.419906 25375 net.cpp:84] Creating Layer encode1_dummy_forward_h0
I1223 00:14:24.419910 25375 net.cpp:406] encode1_dummy_forward_h0 <- h_t=0
I1223 00:14:24.419916 25375 net.cpp:367] encode1_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:24.419937 25375 net.cpp:122] Setting up encode1_dummy_forward_h0
I1223 00:14:24.419944 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.419946 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:24.419952 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=0
I1223 00:14:24.419957 25375 net.cpp:84] Creating Layer encode1_h_conted_t=0
I1223 00:14:24.419961 25375 net.cpp:406] encode1_h_conted_t=0 <- h_t=0
I1223 00:14:24.419965 25375 net.cpp:406] encode1_h_conted_t=0 <- cont_t=1_encode1_cont_slice_0_split_0
I1223 00:14:24.419972 25375 net.cpp:380] encode1_h_conted_t=0 -> h_conted_t=0
I1223 00:14:24.420053 25375 net.cpp:122] Setting up encode1_h_conted_t=0
I1223 00:14:24.420059 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.420063 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:24.420065 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->0
I1223 00:14:24.420073 25375 net.cpp:84] Creating Layer encode1_hidden->transform->0
I1223 00:14:24.420078 25375 net.cpp:406] encode1_hidden->transform->0 <- h_conted_t=0
I1223 00:14:24.420084 25375 net.cpp:380] encode1_hidden->transform->0 -> hidden->transform->0
I1223 00:14:24.420590 25375 net.cpp:122] Setting up encode1_hidden->transform->0
I1223 00:14:24.420598 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.420601 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:24.420608 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=0
I1223 00:14:24.420615 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=0
I1223 00:14:24.420619 25375 net.cpp:406] encode1_hadamard->input_t=0 <- c_t=0_encode1_dummy_forward_c0_0_split_0
I1223 00:14:24.420626 25375 net.cpp:380] encode1_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:24.420732 25375 net.cpp:122] Setting up encode1_hadamard->input_t=0
I1223 00:14:24.420739 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.420742 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:24.420747 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=0
I1223 00:14:24.420753 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=0
I1223 00:14:24.420758 25375 net.cpp:406] encode1_hadamard->forget_t=0 <- c_t=0_encode1_dummy_forward_c0_0_split_1
I1223 00:14:24.420763 25375 net.cpp:380] encode1_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:24.420867 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=0
I1223 00:14:24.420873 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.420876 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:24.420881 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=0
I1223 00:14:24.420899 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=0
I1223 00:14:24.420903 25375 net.cpp:406] encode1_hadamard->output_t=0 <- c_t=0_encode1_dummy_forward_c0_0_split_2
I1223 00:14:24.420908 25375 net.cpp:380] encode1_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:24.421025 25375 net.cpp:122] Setting up encode1_hadamard->output_t=0
I1223 00:14:24.421033 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421036 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:24.421041 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=1
I1223 00:14:24.421046 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=1
I1223 00:14:24.421052 25375 net.cpp:380] encode1_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:24.421123 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=1
I1223 00:14:24.421131 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421134 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:24.421138 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=1
I1223 00:14:24.421144 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=1
I1223 00:14:24.421147 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:24.421151 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:24.421156 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:24.421160 25375 net.cpp:406] encode1_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:24.421165 25375 net.cpp:380] encode1_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:24.421188 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=1
I1223 00:14:24.421195 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.421198 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:24.421201 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_1
I1223 00:14:24.421206 25375 net.cpp:84] Creating Layer encode1_gate_input_1
I1223 00:14:24.421211 25375 net.cpp:406] encode1_gate_input_1 <- hidden->transform->0
I1223 00:14:24.421216 25375 net.cpp:406] encode1_gate_input_1 <- x->transform->t=1
I1223 00:14:24.421219 25375 net.cpp:406] encode1_gate_input_1 <- hadamard_t=1
I1223 00:14:24.421226 25375 net.cpp:380] encode1_gate_input_1 -> gate_input_1
I1223 00:14:24.421247 25375 net.cpp:122] Setting up encode1_gate_input_1
I1223 00:14:24.421253 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.421257 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:24.421259 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=1
I1223 00:14:24.421268 25375 net.cpp:84] Creating Layer encode1_unit_t=1
I1223 00:14:24.421272 25375 net.cpp:406] encode1_unit_t=1 <- c_t=0_encode1_dummy_forward_c0_0_split_3
I1223 00:14:24.421277 25375 net.cpp:406] encode1_unit_t=1 <- gate_input_1
I1223 00:14:24.421280 25375 net.cpp:406] encode1_unit_t=1 <- cont_t=1_encode1_cont_slice_0_split_1
I1223 00:14:24.421286 25375 net.cpp:380] encode1_unit_t=1 -> c_t=1
I1223 00:14:24.421293 25375 net.cpp:380] encode1_unit_t=1 -> h_t=1
I1223 00:14:24.421339 25375 net.cpp:122] Setting up encode1_unit_t=1
I1223 00:14:24.421345 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421350 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421352 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:24.421355 25375 layer_factory.hpp:77] Creating layer c_t=1_encode1_unit_t=1_0_split
I1223 00:14:24.421360 25375 net.cpp:84] Creating Layer c_t=1_encode1_unit_t=1_0_split
I1223 00:14:24.421363 25375 net.cpp:406] c_t=1_encode1_unit_t=1_0_split <- c_t=1
I1223 00:14:24.421370 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_0
I1223 00:14:24.421376 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_1
I1223 00:14:24.421383 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_2
I1223 00:14:24.421391 25375 net.cpp:380] c_t=1_encode1_unit_t=1_0_split -> c_t=1_encode1_unit_t=1_0_split_3
I1223 00:14:24.421443 25375 net.cpp:122] Setting up c_t=1_encode1_unit_t=1_0_split
I1223 00:14:24.421449 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421454 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421458 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421463 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421465 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:24.421468 25375 layer_factory.hpp:77] Creating layer h_t=1_encode1_unit_t=1_1_split
I1223 00:14:24.421473 25375 net.cpp:84] Creating Layer h_t=1_encode1_unit_t=1_1_split
I1223 00:14:24.421478 25375 net.cpp:406] h_t=1_encode1_unit_t=1_1_split <- h_t=1
I1223 00:14:24.421483 25375 net.cpp:380] h_t=1_encode1_unit_t=1_1_split -> h_t=1_encode1_unit_t=1_1_split_0
I1223 00:14:24.421489 25375 net.cpp:380] h_t=1_encode1_unit_t=1_1_split -> h_t=1_encode1_unit_t=1_1_split_1
I1223 00:14:24.421520 25375 net.cpp:122] Setting up h_t=1_encode1_unit_t=1_1_split
I1223 00:14:24.421526 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421531 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421533 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:24.421536 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=1
I1223 00:14:24.421541 25375 net.cpp:84] Creating Layer encode1_h_conted_t=1
I1223 00:14:24.421545 25375 net.cpp:406] encode1_h_conted_t=1 <- h_t=1_encode1_unit_t=1_1_split_0
I1223 00:14:24.421550 25375 net.cpp:406] encode1_h_conted_t=1 <- cont_t=2_encode1_cont_slice_1_split_0
I1223 00:14:24.421555 25375 net.cpp:380] encode1_h_conted_t=1 -> h_conted_t=1
I1223 00:14:24.421630 25375 net.cpp:122] Setting up encode1_h_conted_t=1
I1223 00:14:24.421638 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.421640 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:24.421643 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->1
I1223 00:14:24.421650 25375 net.cpp:84] Creating Layer encode1_hidden->transform->1
I1223 00:14:24.421654 25375 net.cpp:406] encode1_hidden->transform->1 <- h_conted_t=1
I1223 00:14:24.421663 25375 net.cpp:380] encode1_hidden->transform->1 -> hidden->transform->1
I1223 00:14:24.422166 25375 net.cpp:122] Setting up encode1_hidden->transform->1
I1223 00:14:24.422173 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.422176 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:24.422181 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.422186 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.422189 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=1
I1223 00:14:24.422195 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=1
I1223 00:14:24.422199 25375 net.cpp:406] encode1_hadamard->input_t=1 <- c_t=1_encode1_unit_t=1_0_split_0
I1223 00:14:24.422205 25375 net.cpp:380] encode1_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:24.422299 25375 net.cpp:122] Setting up encode1_hadamard->input_t=1
I1223 00:14:24.422307 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422309 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:24.422313 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.422317 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=1
I1223 00:14:24.422322 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=1
I1223 00:14:24.422325 25375 net.cpp:406] encode1_hadamard->forget_t=1 <- c_t=1_encode1_unit_t=1_0_split_1
I1223 00:14:24.422333 25375 net.cpp:380] encode1_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:24.422422 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=1
I1223 00:14:24.422430 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422432 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:24.422436 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.422439 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=1
I1223 00:14:24.422444 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=1
I1223 00:14:24.422447 25375 net.cpp:406] encode1_hadamard->output_t=1 <- c_t=1_encode1_unit_t=1_0_split_2
I1223 00:14:24.422453 25375 net.cpp:380] encode1_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:24.422540 25375 net.cpp:122] Setting up encode1_hadamard->output_t=1
I1223 00:14:24.422547 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422550 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:24.422554 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.422557 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=2
I1223 00:14:24.422562 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=2
I1223 00:14:24.422569 25375 net.cpp:380] encode1_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:24.422621 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=2
I1223 00:14:24.422627 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422631 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:24.422633 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=2
I1223 00:14:24.422641 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=2
I1223 00:14:24.422644 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:24.422649 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:24.422653 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:24.422658 25375 net.cpp:406] encode1_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:24.422663 25375 net.cpp:380] encode1_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:24.422685 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=2
I1223 00:14:24.422691 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.422695 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:24.422698 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_2
I1223 00:14:24.422705 25375 net.cpp:84] Creating Layer encode1_gate_input_2
I1223 00:14:24.422708 25375 net.cpp:406] encode1_gate_input_2 <- hidden->transform->1
I1223 00:14:24.422713 25375 net.cpp:406] encode1_gate_input_2 <- x->transform->t=2
I1223 00:14:24.422718 25375 net.cpp:406] encode1_gate_input_2 <- hadamard_t=2
I1223 00:14:24.422722 25375 net.cpp:380] encode1_gate_input_2 -> gate_input_2
I1223 00:14:24.422744 25375 net.cpp:122] Setting up encode1_gate_input_2
I1223 00:14:24.422750 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.422754 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:24.422756 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=2
I1223 00:14:24.422761 25375 net.cpp:84] Creating Layer encode1_unit_t=2
I1223 00:14:24.422766 25375 net.cpp:406] encode1_unit_t=2 <- c_t=1_encode1_unit_t=1_0_split_3
I1223 00:14:24.422770 25375 net.cpp:406] encode1_unit_t=2 <- gate_input_2
I1223 00:14:24.422775 25375 net.cpp:406] encode1_unit_t=2 <- cont_t=2_encode1_cont_slice_1_split_1
I1223 00:14:24.422782 25375 net.cpp:380] encode1_unit_t=2 -> c_t=2
I1223 00:14:24.422791 25375 net.cpp:380] encode1_unit_t=2 -> h_t=2
I1223 00:14:24.422835 25375 net.cpp:122] Setting up encode1_unit_t=2
I1223 00:14:24.422842 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422845 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422848 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:24.422852 25375 layer_factory.hpp:77] Creating layer c_t=2_encode1_unit_t=2_0_split
I1223 00:14:24.422857 25375 net.cpp:84] Creating Layer c_t=2_encode1_unit_t=2_0_split
I1223 00:14:24.422860 25375 net.cpp:406] c_t=2_encode1_unit_t=2_0_split <- c_t=2
I1223 00:14:24.422866 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_0
I1223 00:14:24.422873 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_1
I1223 00:14:24.422880 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_2
I1223 00:14:24.422888 25375 net.cpp:380] c_t=2_encode1_unit_t=2_0_split -> c_t=2_encode1_unit_t=2_0_split_3
I1223 00:14:24.422943 25375 net.cpp:122] Setting up c_t=2_encode1_unit_t=2_0_split
I1223 00:14:24.422950 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422955 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422957 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422962 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.422965 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:24.422967 25375 layer_factory.hpp:77] Creating layer h_t=2_encode1_unit_t=2_1_split
I1223 00:14:24.422971 25375 net.cpp:84] Creating Layer h_t=2_encode1_unit_t=2_1_split
I1223 00:14:24.422976 25375 net.cpp:406] h_t=2_encode1_unit_t=2_1_split <- h_t=2
I1223 00:14:24.422981 25375 net.cpp:380] h_t=2_encode1_unit_t=2_1_split -> h_t=2_encode1_unit_t=2_1_split_0
I1223 00:14:24.422987 25375 net.cpp:380] h_t=2_encode1_unit_t=2_1_split -> h_t=2_encode1_unit_t=2_1_split_1
I1223 00:14:24.423018 25375 net.cpp:122] Setting up h_t=2_encode1_unit_t=2_1_split
I1223 00:14:24.423025 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.423029 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.423032 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:24.423035 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=2
I1223 00:14:24.423040 25375 net.cpp:84] Creating Layer encode1_h_conted_t=2
I1223 00:14:24.423044 25375 net.cpp:406] encode1_h_conted_t=2 <- h_t=2_encode1_unit_t=2_1_split_0
I1223 00:14:24.423048 25375 net.cpp:406] encode1_h_conted_t=2 <- cont_t=3_encode1_cont_slice_2_split_0
I1223 00:14:24.423055 25375 net.cpp:380] encode1_h_conted_t=2 -> h_conted_t=2
I1223 00:14:24.423131 25375 net.cpp:122] Setting up encode1_h_conted_t=2
I1223 00:14:24.423137 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.423141 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:24.423143 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->2
I1223 00:14:24.423152 25375 net.cpp:84] Creating Layer encode1_hidden->transform->2
I1223 00:14:24.423156 25375 net.cpp:406] encode1_hidden->transform->2 <- h_conted_t=2
I1223 00:14:24.423162 25375 net.cpp:380] encode1_hidden->transform->2 -> hidden->transform->2
I1223 00:14:24.423660 25375 net.cpp:122] Setting up encode1_hidden->transform->2
I1223 00:14:24.423668 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.423671 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:24.423676 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.423679 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.423683 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=2
I1223 00:14:24.423689 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=2
I1223 00:14:24.423693 25375 net.cpp:406] encode1_hadamard->input_t=2 <- c_t=2_encode1_unit_t=2_0_split_0
I1223 00:14:24.423703 25375 net.cpp:380] encode1_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:24.423795 25375 net.cpp:122] Setting up encode1_hadamard->input_t=2
I1223 00:14:24.423802 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.423805 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:24.423808 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.423812 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=2
I1223 00:14:24.423818 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=2
I1223 00:14:24.423822 25375 net.cpp:406] encode1_hadamard->forget_t=2 <- c_t=2_encode1_unit_t=2_0_split_1
I1223 00:14:24.423828 25375 net.cpp:380] encode1_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:24.423916 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=2
I1223 00:14:24.423923 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.423926 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:24.423933 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.423936 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=2
I1223 00:14:24.423941 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=2
I1223 00:14:24.423944 25375 net.cpp:406] encode1_hadamard->output_t=2 <- c_t=2_encode1_unit_t=2_0_split_2
I1223 00:14:24.423950 25375 net.cpp:380] encode1_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:24.424036 25375 net.cpp:122] Setting up encode1_hadamard->output_t=2
I1223 00:14:24.424043 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424046 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:24.424051 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.424053 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=3
I1223 00:14:24.424058 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=3
I1223 00:14:24.424063 25375 net.cpp:380] encode1_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:24.424116 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=3
I1223 00:14:24.424124 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424126 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:24.424129 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=3
I1223 00:14:24.424134 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=3
I1223 00:14:24.424139 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:24.424144 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:24.424147 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:24.424151 25375 net.cpp:406] encode1_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:24.424159 25375 net.cpp:380] encode1_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:24.424182 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=3
I1223 00:14:24.424188 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.424191 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:24.424194 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_3
I1223 00:14:24.424199 25375 net.cpp:84] Creating Layer encode1_gate_input_3
I1223 00:14:24.424203 25375 net.cpp:406] encode1_gate_input_3 <- hidden->transform->2
I1223 00:14:24.424207 25375 net.cpp:406] encode1_gate_input_3 <- x->transform->t=3
I1223 00:14:24.424212 25375 net.cpp:406] encode1_gate_input_3 <- hadamard_t=3
I1223 00:14:24.424218 25375 net.cpp:380] encode1_gate_input_3 -> gate_input_3
I1223 00:14:24.424239 25375 net.cpp:122] Setting up encode1_gate_input_3
I1223 00:14:24.424245 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.424248 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:24.424252 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=3
I1223 00:14:24.424257 25375 net.cpp:84] Creating Layer encode1_unit_t=3
I1223 00:14:24.424259 25375 net.cpp:406] encode1_unit_t=3 <- c_t=2_encode1_unit_t=2_0_split_3
I1223 00:14:24.424264 25375 net.cpp:406] encode1_unit_t=3 <- gate_input_3
I1223 00:14:24.424268 25375 net.cpp:406] encode1_unit_t=3 <- cont_t=3_encode1_cont_slice_2_split_1
I1223 00:14:24.424273 25375 net.cpp:380] encode1_unit_t=3 -> c_t=3
I1223 00:14:24.424279 25375 net.cpp:380] encode1_unit_t=3 -> h_t=3
I1223 00:14:24.424324 25375 net.cpp:122] Setting up encode1_unit_t=3
I1223 00:14:24.424330 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424335 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424337 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:24.424340 25375 layer_factory.hpp:77] Creating layer c_t=3_encode1_unit_t=3_0_split
I1223 00:14:24.424346 25375 net.cpp:84] Creating Layer c_t=3_encode1_unit_t=3_0_split
I1223 00:14:24.424350 25375 net.cpp:406] c_t=3_encode1_unit_t=3_0_split <- c_t=3
I1223 00:14:24.424355 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_0
I1223 00:14:24.424362 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_1
I1223 00:14:24.424371 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_2
I1223 00:14:24.424376 25375 net.cpp:380] c_t=3_encode1_unit_t=3_0_split -> c_t=3_encode1_unit_t=3_0_split_3
I1223 00:14:24.424432 25375 net.cpp:122] Setting up c_t=3_encode1_unit_t=3_0_split
I1223 00:14:24.424439 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424443 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424448 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424451 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424454 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:24.424458 25375 layer_factory.hpp:77] Creating layer h_t=3_encode1_unit_t=3_1_split
I1223 00:14:24.424464 25375 net.cpp:84] Creating Layer h_t=3_encode1_unit_t=3_1_split
I1223 00:14:24.424469 25375 net.cpp:406] h_t=3_encode1_unit_t=3_1_split <- h_t=3
I1223 00:14:24.424474 25375 net.cpp:380] h_t=3_encode1_unit_t=3_1_split -> h_t=3_encode1_unit_t=3_1_split_0
I1223 00:14:24.424481 25375 net.cpp:380] h_t=3_encode1_unit_t=3_1_split -> h_t=3_encode1_unit_t=3_1_split_1
I1223 00:14:24.424513 25375 net.cpp:122] Setting up h_t=3_encode1_unit_t=3_1_split
I1223 00:14:24.424520 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424525 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424527 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:24.424530 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=3
I1223 00:14:24.424535 25375 net.cpp:84] Creating Layer encode1_h_conted_t=3
I1223 00:14:24.424538 25375 net.cpp:406] encode1_h_conted_t=3 <- h_t=3_encode1_unit_t=3_1_split_0
I1223 00:14:24.424543 25375 net.cpp:406] encode1_h_conted_t=3 <- cont_t=4_encode1_cont_slice_3_split_0
I1223 00:14:24.424548 25375 net.cpp:380] encode1_h_conted_t=3 -> h_conted_t=3
I1223 00:14:24.424623 25375 net.cpp:122] Setting up encode1_h_conted_t=3
I1223 00:14:24.424631 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.424634 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:24.424638 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->3
I1223 00:14:24.424645 25375 net.cpp:84] Creating Layer encode1_hidden->transform->3
I1223 00:14:24.424650 25375 net.cpp:406] encode1_hidden->transform->3 <- h_conted_t=3
I1223 00:14:24.424656 25375 net.cpp:380] encode1_hidden->transform->3 -> hidden->transform->3
I1223 00:14:24.425161 25375 net.cpp:122] Setting up encode1_hidden->transform->3
I1223 00:14:24.425169 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.425173 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:24.425176 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.425180 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.425184 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=3
I1223 00:14:24.425189 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=3
I1223 00:14:24.425194 25375 net.cpp:406] encode1_hadamard->input_t=3 <- c_t=3_encode1_unit_t=3_0_split_0
I1223 00:14:24.425200 25375 net.cpp:380] encode1_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:24.425298 25375 net.cpp:122] Setting up encode1_hadamard->input_t=3
I1223 00:14:24.425305 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425308 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:24.425312 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.425315 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=3
I1223 00:14:24.425320 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=3
I1223 00:14:24.425324 25375 net.cpp:406] encode1_hadamard->forget_t=3 <- c_t=3_encode1_unit_t=3_0_split_1
I1223 00:14:24.425330 25375 net.cpp:380] encode1_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:24.425422 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=3
I1223 00:14:24.425429 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425432 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:24.425436 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.425439 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=3
I1223 00:14:24.425446 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=3
I1223 00:14:24.425449 25375 net.cpp:406] encode1_hadamard->output_t=3 <- c_t=3_encode1_unit_t=3_0_split_2
I1223 00:14:24.425454 25375 net.cpp:380] encode1_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:24.425540 25375 net.cpp:122] Setting up encode1_hadamard->output_t=3
I1223 00:14:24.425549 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425551 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:24.425555 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.425559 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=4
I1223 00:14:24.425565 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=4
I1223 00:14:24.425570 25375 net.cpp:380] encode1_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:24.425629 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=4
I1223 00:14:24.425637 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425640 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:24.425643 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=4
I1223 00:14:24.425648 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=4
I1223 00:14:24.425652 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:24.425657 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:24.425660 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:24.425664 25375 net.cpp:406] encode1_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:24.425669 25375 net.cpp:380] encode1_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:24.425693 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=4
I1223 00:14:24.425698 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.425701 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:24.425704 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_4
I1223 00:14:24.425714 25375 net.cpp:84] Creating Layer encode1_gate_input_4
I1223 00:14:24.425717 25375 net.cpp:406] encode1_gate_input_4 <- hidden->transform->3
I1223 00:14:24.425721 25375 net.cpp:406] encode1_gate_input_4 <- x->transform->t=4
I1223 00:14:24.425726 25375 net.cpp:406] encode1_gate_input_4 <- hadamard_t=4
I1223 00:14:24.425731 25375 net.cpp:380] encode1_gate_input_4 -> gate_input_4
I1223 00:14:24.425757 25375 net.cpp:122] Setting up encode1_gate_input_4
I1223 00:14:24.425765 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.425767 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:24.425771 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=4
I1223 00:14:24.425776 25375 net.cpp:84] Creating Layer encode1_unit_t=4
I1223 00:14:24.425779 25375 net.cpp:406] encode1_unit_t=4 <- c_t=3_encode1_unit_t=3_0_split_3
I1223 00:14:24.425784 25375 net.cpp:406] encode1_unit_t=4 <- gate_input_4
I1223 00:14:24.425788 25375 net.cpp:406] encode1_unit_t=4 <- cont_t=4_encode1_cont_slice_3_split_1
I1223 00:14:24.425793 25375 net.cpp:380] encode1_unit_t=4 -> c_t=4
I1223 00:14:24.425799 25375 net.cpp:380] encode1_unit_t=4 -> h_t=4
I1223 00:14:24.425845 25375 net.cpp:122] Setting up encode1_unit_t=4
I1223 00:14:24.425851 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425856 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425859 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:24.425861 25375 layer_factory.hpp:77] Creating layer c_t=4_encode1_unit_t=4_0_split
I1223 00:14:24.425868 25375 net.cpp:84] Creating Layer c_t=4_encode1_unit_t=4_0_split
I1223 00:14:24.425873 25375 net.cpp:406] c_t=4_encode1_unit_t=4_0_split <- c_t=4
I1223 00:14:24.425878 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_0
I1223 00:14:24.425884 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_1
I1223 00:14:24.425890 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_2
I1223 00:14:24.425897 25375 net.cpp:380] c_t=4_encode1_unit_t=4_0_split -> c_t=4_encode1_unit_t=4_0_split_3
I1223 00:14:24.425953 25375 net.cpp:122] Setting up c_t=4_encode1_unit_t=4_0_split
I1223 00:14:24.425959 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425964 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425968 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425971 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.425974 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:24.425977 25375 layer_factory.hpp:77] Creating layer h_t=4_encode1_unit_t=4_1_split
I1223 00:14:24.425982 25375 net.cpp:84] Creating Layer h_t=4_encode1_unit_t=4_1_split
I1223 00:14:24.425985 25375 net.cpp:406] h_t=4_encode1_unit_t=4_1_split <- h_t=4
I1223 00:14:24.425992 25375 net.cpp:380] h_t=4_encode1_unit_t=4_1_split -> h_t=4_encode1_unit_t=4_1_split_0
I1223 00:14:24.425999 25375 net.cpp:380] h_t=4_encode1_unit_t=4_1_split -> h_t=4_encode1_unit_t=4_1_split_1
I1223 00:14:24.426031 25375 net.cpp:122] Setting up h_t=4_encode1_unit_t=4_1_split
I1223 00:14:24.426038 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.426043 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.426045 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:24.426048 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=4
I1223 00:14:24.426054 25375 net.cpp:84] Creating Layer encode1_h_conted_t=4
I1223 00:14:24.426059 25375 net.cpp:406] encode1_h_conted_t=4 <- h_t=4_encode1_unit_t=4_1_split_0
I1223 00:14:24.426064 25375 net.cpp:406] encode1_h_conted_t=4 <- cont_t=5_encode1_cont_slice_4_split_0
I1223 00:14:24.426069 25375 net.cpp:380] encode1_h_conted_t=4 -> h_conted_t=4
I1223 00:14:24.426152 25375 net.cpp:122] Setting up encode1_h_conted_t=4
I1223 00:14:24.426159 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.426162 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:24.426165 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->4
I1223 00:14:24.426173 25375 net.cpp:84] Creating Layer encode1_hidden->transform->4
I1223 00:14:24.426177 25375 net.cpp:406] encode1_hidden->transform->4 <- h_conted_t=4
I1223 00:14:24.426185 25375 net.cpp:380] encode1_hidden->transform->4 -> hidden->transform->4
I1223 00:14:24.426688 25375 net.cpp:122] Setting up encode1_hidden->transform->4
I1223 00:14:24.426695 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.426698 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:24.426702 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.426707 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.426710 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=4
I1223 00:14:24.426715 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=4
I1223 00:14:24.426719 25375 net.cpp:406] encode1_hadamard->input_t=4 <- c_t=4_encode1_unit_t=4_0_split_0
I1223 00:14:24.426725 25375 net.cpp:380] encode1_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:24.426818 25375 net.cpp:122] Setting up encode1_hadamard->input_t=4
I1223 00:14:24.426826 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.426829 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:24.426832 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.426836 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=4
I1223 00:14:24.426842 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=4
I1223 00:14:24.426846 25375 net.cpp:406] encode1_hadamard->forget_t=4 <- c_t=4_encode1_unit_t=4_0_split_1
I1223 00:14:24.426851 25375 net.cpp:380] encode1_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:24.426941 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=4
I1223 00:14:24.426949 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.426951 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:24.426955 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.426959 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=4
I1223 00:14:24.426964 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=4
I1223 00:14:24.426968 25375 net.cpp:406] encode1_hadamard->output_t=4 <- c_t=4_encode1_unit_t=4_0_split_2
I1223 00:14:24.426975 25375 net.cpp:380] encode1_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:24.427062 25375 net.cpp:122] Setting up encode1_hadamard->output_t=4
I1223 00:14:24.427069 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427073 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:24.427076 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.427080 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=5
I1223 00:14:24.427085 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=5
I1223 00:14:24.427090 25375 net.cpp:380] encode1_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:24.427152 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=5
I1223 00:14:24.427160 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427162 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:24.427165 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=5
I1223 00:14:24.427170 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=5
I1223 00:14:24.427175 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:24.427179 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:24.427183 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:24.427188 25375 net.cpp:406] encode1_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:24.427194 25375 net.cpp:380] encode1_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:24.427218 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=5
I1223 00:14:24.427224 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.427227 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:24.427230 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_5
I1223 00:14:24.427235 25375 net.cpp:84] Creating Layer encode1_gate_input_5
I1223 00:14:24.427239 25375 net.cpp:406] encode1_gate_input_5 <- hidden->transform->4
I1223 00:14:24.427243 25375 net.cpp:406] encode1_gate_input_5 <- x->transform->t=5
I1223 00:14:24.427248 25375 net.cpp:406] encode1_gate_input_5 <- hadamard_t=5
I1223 00:14:24.427254 25375 net.cpp:380] encode1_gate_input_5 -> gate_input_5
I1223 00:14:24.427275 25375 net.cpp:122] Setting up encode1_gate_input_5
I1223 00:14:24.427283 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.427286 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:24.427289 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=5
I1223 00:14:24.427294 25375 net.cpp:84] Creating Layer encode1_unit_t=5
I1223 00:14:24.427297 25375 net.cpp:406] encode1_unit_t=5 <- c_t=4_encode1_unit_t=4_0_split_3
I1223 00:14:24.427302 25375 net.cpp:406] encode1_unit_t=5 <- gate_input_5
I1223 00:14:24.427306 25375 net.cpp:406] encode1_unit_t=5 <- cont_t=5_encode1_cont_slice_4_split_1
I1223 00:14:24.427311 25375 net.cpp:380] encode1_unit_t=5 -> c_t=5
I1223 00:14:24.427320 25375 net.cpp:380] encode1_unit_t=5 -> h_t=5
I1223 00:14:24.427366 25375 net.cpp:122] Setting up encode1_unit_t=5
I1223 00:14:24.427372 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427376 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427379 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:24.427382 25375 layer_factory.hpp:77] Creating layer c_t=5_encode1_unit_t=5_0_split
I1223 00:14:24.427387 25375 net.cpp:84] Creating Layer c_t=5_encode1_unit_t=5_0_split
I1223 00:14:24.427390 25375 net.cpp:406] c_t=5_encode1_unit_t=5_0_split <- c_t=5
I1223 00:14:24.427397 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_0
I1223 00:14:24.427402 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_1
I1223 00:14:24.427410 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_2
I1223 00:14:24.427417 25375 net.cpp:380] c_t=5_encode1_unit_t=5_0_split -> c_t=5_encode1_unit_t=5_0_split_3
I1223 00:14:24.427472 25375 net.cpp:122] Setting up c_t=5_encode1_unit_t=5_0_split
I1223 00:14:24.427479 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427484 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427487 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427491 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427495 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:24.427496 25375 layer_factory.hpp:77] Creating layer h_t=5_encode1_unit_t=5_1_split
I1223 00:14:24.427502 25375 net.cpp:84] Creating Layer h_t=5_encode1_unit_t=5_1_split
I1223 00:14:24.427506 25375 net.cpp:406] h_t=5_encode1_unit_t=5_1_split <- h_t=5
I1223 00:14:24.427511 25375 net.cpp:380] h_t=5_encode1_unit_t=5_1_split -> h_t=5_encode1_unit_t=5_1_split_0
I1223 00:14:24.427517 25375 net.cpp:380] h_t=5_encode1_unit_t=5_1_split -> h_t=5_encode1_unit_t=5_1_split_1
I1223 00:14:24.427551 25375 net.cpp:122] Setting up h_t=5_encode1_unit_t=5_1_split
I1223 00:14:24.427556 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427561 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427563 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:24.427567 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=5
I1223 00:14:24.427572 25375 net.cpp:84] Creating Layer encode1_h_conted_t=5
I1223 00:14:24.427575 25375 net.cpp:406] encode1_h_conted_t=5 <- h_t=5_encode1_unit_t=5_1_split_0
I1223 00:14:24.427579 25375 net.cpp:406] encode1_h_conted_t=5 <- cont_t=6_encode1_cont_slice_5_split_0
I1223 00:14:24.427585 25375 net.cpp:380] encode1_h_conted_t=5 -> h_conted_t=5
I1223 00:14:24.427666 25375 net.cpp:122] Setting up encode1_h_conted_t=5
I1223 00:14:24.427672 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.427675 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:24.427680 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->5
I1223 00:14:24.427687 25375 net.cpp:84] Creating Layer encode1_hidden->transform->5
I1223 00:14:24.427691 25375 net.cpp:406] encode1_hidden->transform->5 <- h_conted_t=5
I1223 00:14:24.427698 25375 net.cpp:380] encode1_hidden->transform->5 -> hidden->transform->5
I1223 00:14:24.428205 25375 net.cpp:122] Setting up encode1_hidden->transform->5
I1223 00:14:24.428213 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.428216 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:24.428220 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.428225 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.428227 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=5
I1223 00:14:24.428233 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=5
I1223 00:14:24.428236 25375 net.cpp:406] encode1_hadamard->input_t=5 <- c_t=5_encode1_unit_t=5_0_split_0
I1223 00:14:24.428244 25375 net.cpp:380] encode1_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:24.428336 25375 net.cpp:122] Setting up encode1_hadamard->input_t=5
I1223 00:14:24.428344 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.428349 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:24.428351 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.428355 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=5
I1223 00:14:24.428360 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=5
I1223 00:14:24.428364 25375 net.cpp:406] encode1_hadamard->forget_t=5 <- c_t=5_encode1_unit_t=5_0_split_1
I1223 00:14:24.428370 25375 net.cpp:380] encode1_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:24.428462 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=5
I1223 00:14:24.428468 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.428472 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:24.428477 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.428479 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=5
I1223 00:14:24.428484 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=5
I1223 00:14:24.428488 25375 net.cpp:406] encode1_hadamard->output_t=5 <- c_t=5_encode1_unit_t=5_0_split_2
I1223 00:14:24.428494 25375 net.cpp:380] encode1_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:24.428581 25375 net.cpp:122] Setting up encode1_hadamard->output_t=5
I1223 00:14:24.428588 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.428591 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:24.428598 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.428602 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=6
I1223 00:14:24.428607 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=6
I1223 00:14:24.428612 25375 net.cpp:380] encode1_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:24.428670 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=6
I1223 00:14:24.428678 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.428680 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:24.428683 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=6
I1223 00:14:24.428689 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=6
I1223 00:14:24.428692 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:24.428697 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:24.428701 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:24.428705 25375 net.cpp:406] encode1_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:24.428710 25375 net.cpp:380] encode1_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:24.428735 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=6
I1223 00:14:24.428741 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.428745 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:24.428747 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_6
I1223 00:14:24.428753 25375 net.cpp:84] Creating Layer encode1_gate_input_6
I1223 00:14:24.428757 25375 net.cpp:406] encode1_gate_input_6 <- hidden->transform->5
I1223 00:14:24.428762 25375 net.cpp:406] encode1_gate_input_6 <- x->transform->t=6
I1223 00:14:24.428766 25375 net.cpp:406] encode1_gate_input_6 <- hadamard_t=6
I1223 00:14:24.428771 25375 net.cpp:380] encode1_gate_input_6 -> gate_input_6
I1223 00:14:24.428793 25375 net.cpp:122] Setting up encode1_gate_input_6
I1223 00:14:24.428800 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.428803 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:24.428807 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=6
I1223 00:14:24.428812 25375 net.cpp:84] Creating Layer encode1_unit_t=6
I1223 00:14:24.428814 25375 net.cpp:406] encode1_unit_t=6 <- c_t=5_encode1_unit_t=5_0_split_3
I1223 00:14:24.428819 25375 net.cpp:406] encode1_unit_t=6 <- gate_input_6
I1223 00:14:24.428823 25375 net.cpp:406] encode1_unit_t=6 <- cont_t=6_encode1_cont_slice_5_split_1
I1223 00:14:24.428828 25375 net.cpp:380] encode1_unit_t=6 -> c_t=6
I1223 00:14:24.428834 25375 net.cpp:380] encode1_unit_t=6 -> h_t=6
I1223 00:14:24.428880 25375 net.cpp:122] Setting up encode1_unit_t=6
I1223 00:14:24.428886 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.428890 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.428894 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:24.428896 25375 layer_factory.hpp:77] Creating layer c_t=6_encode1_unit_t=6_0_split
I1223 00:14:24.428902 25375 net.cpp:84] Creating Layer c_t=6_encode1_unit_t=6_0_split
I1223 00:14:24.428906 25375 net.cpp:406] c_t=6_encode1_unit_t=6_0_split <- c_t=6
I1223 00:14:24.428912 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_0
I1223 00:14:24.428920 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_1
I1223 00:14:24.428925 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_2
I1223 00:14:24.428931 25375 net.cpp:380] c_t=6_encode1_unit_t=6_0_split -> c_t=6_encode1_unit_t=6_0_split_3
I1223 00:14:24.428987 25375 net.cpp:122] Setting up c_t=6_encode1_unit_t=6_0_split
I1223 00:14:24.428993 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.428997 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429002 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429005 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429008 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:24.429011 25375 layer_factory.hpp:77] Creating layer h_t=6_encode1_unit_t=6_1_split
I1223 00:14:24.429015 25375 net.cpp:84] Creating Layer h_t=6_encode1_unit_t=6_1_split
I1223 00:14:24.429018 25375 net.cpp:406] h_t=6_encode1_unit_t=6_1_split <- h_t=6
I1223 00:14:24.429025 25375 net.cpp:380] h_t=6_encode1_unit_t=6_1_split -> h_t=6_encode1_unit_t=6_1_split_0
I1223 00:14:24.429031 25375 net.cpp:380] h_t=6_encode1_unit_t=6_1_split -> h_t=6_encode1_unit_t=6_1_split_1
I1223 00:14:24.429064 25375 net.cpp:122] Setting up h_t=6_encode1_unit_t=6_1_split
I1223 00:14:24.429075 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429080 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429082 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:24.429085 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=6
I1223 00:14:24.429090 25375 net.cpp:84] Creating Layer encode1_h_conted_t=6
I1223 00:14:24.429095 25375 net.cpp:406] encode1_h_conted_t=6 <- h_t=6_encode1_unit_t=6_1_split_0
I1223 00:14:24.429098 25375 net.cpp:406] encode1_h_conted_t=6 <- cont_t=7_encode1_cont_slice_6_split_0
I1223 00:14:24.429103 25375 net.cpp:380] encode1_h_conted_t=6 -> h_conted_t=6
I1223 00:14:24.429188 25375 net.cpp:122] Setting up encode1_h_conted_t=6
I1223 00:14:24.429195 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429198 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:24.429201 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->6
I1223 00:14:24.429209 25375 net.cpp:84] Creating Layer encode1_hidden->transform->6
I1223 00:14:24.429214 25375 net.cpp:406] encode1_hidden->transform->6 <- h_conted_t=6
I1223 00:14:24.429224 25375 net.cpp:380] encode1_hidden->transform->6 -> hidden->transform->6
I1223 00:14:24.429726 25375 net.cpp:122] Setting up encode1_hidden->transform->6
I1223 00:14:24.429733 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.429738 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:24.429740 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.429744 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.429749 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=6
I1223 00:14:24.429754 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=6
I1223 00:14:24.429757 25375 net.cpp:406] encode1_hadamard->input_t=6 <- c_t=6_encode1_unit_t=6_0_split_0
I1223 00:14:24.429762 25375 net.cpp:380] encode1_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:24.429853 25375 net.cpp:122] Setting up encode1_hadamard->input_t=6
I1223 00:14:24.429860 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429863 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:24.429867 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.429870 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=6
I1223 00:14:24.429877 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=6
I1223 00:14:24.429880 25375 net.cpp:406] encode1_hadamard->forget_t=6 <- c_t=6_encode1_unit_t=6_0_split_1
I1223 00:14:24.429885 25375 net.cpp:380] encode1_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:24.429977 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=6
I1223 00:14:24.429985 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.429987 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:24.429991 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.429994 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=6
I1223 00:14:24.430001 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=6
I1223 00:14:24.430004 25375 net.cpp:406] encode1_hadamard->output_t=6 <- c_t=6_encode1_unit_t=6_0_split_2
I1223 00:14:24.430011 25375 net.cpp:380] encode1_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:24.430099 25375 net.cpp:122] Setting up encode1_hadamard->output_t=6
I1223 00:14:24.430107 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430110 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:24.430114 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.430117 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=7
I1223 00:14:24.430122 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=7
I1223 00:14:24.430128 25375 net.cpp:380] encode1_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:24.430191 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=7
I1223 00:14:24.430198 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430202 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:24.430204 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=7
I1223 00:14:24.430209 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=7
I1223 00:14:24.430213 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:24.430218 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:24.430222 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:24.430227 25375 net.cpp:406] encode1_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:24.430233 25375 net.cpp:380] encode1_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:24.430258 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=7
I1223 00:14:24.430264 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.430268 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:24.430270 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_7
I1223 00:14:24.430275 25375 net.cpp:84] Creating Layer encode1_gate_input_7
I1223 00:14:24.430279 25375 net.cpp:406] encode1_gate_input_7 <- hidden->transform->6
I1223 00:14:24.430284 25375 net.cpp:406] encode1_gate_input_7 <- x->transform->t=7
I1223 00:14:24.430289 25375 net.cpp:406] encode1_gate_input_7 <- hadamard_t=7
I1223 00:14:24.430294 25375 net.cpp:380] encode1_gate_input_7 -> gate_input_7
I1223 00:14:24.430315 25375 net.cpp:122] Setting up encode1_gate_input_7
I1223 00:14:24.430322 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.430326 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:24.430330 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=7
I1223 00:14:24.430335 25375 net.cpp:84] Creating Layer encode1_unit_t=7
I1223 00:14:24.430337 25375 net.cpp:406] encode1_unit_t=7 <- c_t=6_encode1_unit_t=6_0_split_3
I1223 00:14:24.430342 25375 net.cpp:406] encode1_unit_t=7 <- gate_input_7
I1223 00:14:24.430346 25375 net.cpp:406] encode1_unit_t=7 <- cont_t=7_encode1_cont_slice_6_split_1
I1223 00:14:24.430351 25375 net.cpp:380] encode1_unit_t=7 -> c_t=7
I1223 00:14:24.430359 25375 net.cpp:380] encode1_unit_t=7 -> h_t=7
I1223 00:14:24.430405 25375 net.cpp:122] Setting up encode1_unit_t=7
I1223 00:14:24.430413 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430416 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430418 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:24.430423 25375 layer_factory.hpp:77] Creating layer c_t=7_encode1_unit_t=7_0_split
I1223 00:14:24.430426 25375 net.cpp:84] Creating Layer c_t=7_encode1_unit_t=7_0_split
I1223 00:14:24.430430 25375 net.cpp:406] c_t=7_encode1_unit_t=7_0_split <- c_t=7
I1223 00:14:24.430435 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_0
I1223 00:14:24.430443 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_1
I1223 00:14:24.430450 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_2
I1223 00:14:24.430457 25375 net.cpp:380] c_t=7_encode1_unit_t=7_0_split -> c_t=7_encode1_unit_t=7_0_split_3
I1223 00:14:24.430513 25375 net.cpp:122] Setting up c_t=7_encode1_unit_t=7_0_split
I1223 00:14:24.430521 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430524 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430528 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430532 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430536 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:24.430538 25375 layer_factory.hpp:77] Creating layer h_t=7_encode1_unit_t=7_1_split
I1223 00:14:24.430544 25375 net.cpp:84] Creating Layer h_t=7_encode1_unit_t=7_1_split
I1223 00:14:24.430548 25375 net.cpp:406] h_t=7_encode1_unit_t=7_1_split <- h_t=7
I1223 00:14:24.430553 25375 net.cpp:380] h_t=7_encode1_unit_t=7_1_split -> h_t=7_encode1_unit_t=7_1_split_0
I1223 00:14:24.430560 25375 net.cpp:380] h_t=7_encode1_unit_t=7_1_split -> h_t=7_encode1_unit_t=7_1_split_1
I1223 00:14:24.430595 25375 net.cpp:122] Setting up h_t=7_encode1_unit_t=7_1_split
I1223 00:14:24.430601 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430606 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430609 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:24.430613 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=7
I1223 00:14:24.430618 25375 net.cpp:84] Creating Layer encode1_h_conted_t=7
I1223 00:14:24.430621 25375 net.cpp:406] encode1_h_conted_t=7 <- h_t=7_encode1_unit_t=7_1_split_0
I1223 00:14:24.430625 25375 net.cpp:406] encode1_h_conted_t=7 <- cont_t=8_encode1_cont_slice_7_split_0
I1223 00:14:24.430630 25375 net.cpp:380] encode1_h_conted_t=7 -> h_conted_t=7
I1223 00:14:24.430711 25375 net.cpp:122] Setting up encode1_h_conted_t=7
I1223 00:14:24.430717 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.430721 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:24.430723 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->7
I1223 00:14:24.430732 25375 net.cpp:84] Creating Layer encode1_hidden->transform->7
I1223 00:14:24.430737 25375 net.cpp:406] encode1_hidden->transform->7 <- h_conted_t=7
I1223 00:14:24.430742 25375 net.cpp:380] encode1_hidden->transform->7 -> hidden->transform->7
I1223 00:14:24.431246 25375 net.cpp:122] Setting up encode1_hidden->transform->7
I1223 00:14:24.431253 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.431257 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:24.431260 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.431264 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.431267 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=7
I1223 00:14:24.431274 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=7
I1223 00:14:24.431278 25375 net.cpp:406] encode1_hadamard->input_t=7 <- c_t=7_encode1_unit_t=7_0_split_0
I1223 00:14:24.431284 25375 net.cpp:380] encode1_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:24.431376 25375 net.cpp:122] Setting up encode1_hadamard->input_t=7
I1223 00:14:24.431385 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.431387 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:24.431391 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.431394 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=7
I1223 00:14:24.431401 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=7
I1223 00:14:24.431406 25375 net.cpp:406] encode1_hadamard->forget_t=7 <- c_t=7_encode1_unit_t=7_0_split_1
I1223 00:14:24.431411 25375 net.cpp:380] encode1_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:24.431501 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=7
I1223 00:14:24.431509 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.431512 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:24.431515 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.431519 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=7
I1223 00:14:24.431525 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=7
I1223 00:14:24.431529 25375 net.cpp:406] encode1_hadamard->output_t=7 <- c_t=7_encode1_unit_t=7_0_split_2
I1223 00:14:24.431533 25375 net.cpp:380] encode1_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:24.431620 25375 net.cpp:122] Setting up encode1_hadamard->output_t=7
I1223 00:14:24.431627 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.431632 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:24.431634 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.431638 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=8
I1223 00:14:24.431644 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=8
I1223 00:14:24.431649 25375 net.cpp:380] encode1_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:24.431726 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=8
I1223 00:14:24.431733 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.431736 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:24.431740 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=8
I1223 00:14:24.431746 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=8
I1223 00:14:24.431748 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:24.431753 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:24.431758 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:24.431762 25375 net.cpp:406] encode1_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:24.431767 25375 net.cpp:380] encode1_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:24.431790 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=8
I1223 00:14:24.431797 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.431799 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:24.431802 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_8
I1223 00:14:24.431808 25375 net.cpp:84] Creating Layer encode1_gate_input_8
I1223 00:14:24.431813 25375 net.cpp:406] encode1_gate_input_8 <- hidden->transform->7
I1223 00:14:24.431816 25375 net.cpp:406] encode1_gate_input_8 <- x->transform->t=8
I1223 00:14:24.431821 25375 net.cpp:406] encode1_gate_input_8 <- hadamard_t=8
I1223 00:14:24.431828 25375 net.cpp:380] encode1_gate_input_8 -> gate_input_8
I1223 00:14:24.431849 25375 net.cpp:122] Setting up encode1_gate_input_8
I1223 00:14:24.431854 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.431857 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:24.431860 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=8
I1223 00:14:24.431867 25375 net.cpp:84] Creating Layer encode1_unit_t=8
I1223 00:14:24.431871 25375 net.cpp:406] encode1_unit_t=8 <- c_t=7_encode1_unit_t=7_0_split_3
I1223 00:14:24.431875 25375 net.cpp:406] encode1_unit_t=8 <- gate_input_8
I1223 00:14:24.431879 25375 net.cpp:406] encode1_unit_t=8 <- cont_t=8_encode1_cont_slice_7_split_1
I1223 00:14:24.431885 25375 net.cpp:380] encode1_unit_t=8 -> c_t=8
I1223 00:14:24.431891 25375 net.cpp:380] encode1_unit_t=8 -> h_t=8
I1223 00:14:24.431936 25375 net.cpp:122] Setting up encode1_unit_t=8
I1223 00:14:24.431942 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.431946 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.431949 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:24.431952 25375 layer_factory.hpp:77] Creating layer c_t=8_encode1_unit_t=8_0_split
I1223 00:14:24.431957 25375 net.cpp:84] Creating Layer c_t=8_encode1_unit_t=8_0_split
I1223 00:14:24.431960 25375 net.cpp:406] c_t=8_encode1_unit_t=8_0_split <- c_t=8
I1223 00:14:24.431967 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_0
I1223 00:14:24.431975 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_1
I1223 00:14:24.431983 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_2
I1223 00:14:24.431990 25375 net.cpp:380] c_t=8_encode1_unit_t=8_0_split -> c_t=8_encode1_unit_t=8_0_split_3
I1223 00:14:24.432045 25375 net.cpp:122] Setting up c_t=8_encode1_unit_t=8_0_split
I1223 00:14:24.432051 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432056 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432060 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432065 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432066 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:24.432070 25375 layer_factory.hpp:77] Creating layer h_t=8_encode1_unit_t=8_1_split
I1223 00:14:24.432075 25375 net.cpp:84] Creating Layer h_t=8_encode1_unit_t=8_1_split
I1223 00:14:24.432077 25375 net.cpp:406] h_t=8_encode1_unit_t=8_1_split <- h_t=8
I1223 00:14:24.432082 25375 net.cpp:380] h_t=8_encode1_unit_t=8_1_split -> h_t=8_encode1_unit_t=8_1_split_0
I1223 00:14:24.432090 25375 net.cpp:380] h_t=8_encode1_unit_t=8_1_split -> h_t=8_encode1_unit_t=8_1_split_1
I1223 00:14:24.432121 25375 net.cpp:122] Setting up h_t=8_encode1_unit_t=8_1_split
I1223 00:14:24.432127 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432132 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432135 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:24.432138 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=8
I1223 00:14:24.432144 25375 net.cpp:84] Creating Layer encode1_h_conted_t=8
I1223 00:14:24.432147 25375 net.cpp:406] encode1_h_conted_t=8 <- h_t=8_encode1_unit_t=8_1_split_0
I1223 00:14:24.432152 25375 net.cpp:406] encode1_h_conted_t=8 <- cont_t=9_encode1_cont_slice_8_split_0
I1223 00:14:24.432157 25375 net.cpp:380] encode1_h_conted_t=8 -> h_conted_t=8
I1223 00:14:24.432243 25375 net.cpp:122] Setting up encode1_h_conted_t=8
I1223 00:14:24.432250 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432253 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:24.432256 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->8
I1223 00:14:24.432265 25375 net.cpp:84] Creating Layer encode1_hidden->transform->8
I1223 00:14:24.432268 25375 net.cpp:406] encode1_hidden->transform->8 <- h_conted_t=8
I1223 00:14:24.432276 25375 net.cpp:380] encode1_hidden->transform->8 -> hidden->transform->8
I1223 00:14:24.432780 25375 net.cpp:122] Setting up encode1_hidden->transform->8
I1223 00:14:24.432786 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.432790 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:24.432793 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.432797 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.432801 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=8
I1223 00:14:24.432807 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=8
I1223 00:14:24.432811 25375 net.cpp:406] encode1_hadamard->input_t=8 <- c_t=8_encode1_unit_t=8_0_split_0
I1223 00:14:24.432818 25375 net.cpp:380] encode1_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:24.432909 25375 net.cpp:122] Setting up encode1_hadamard->input_t=8
I1223 00:14:24.432915 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.432919 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:24.432922 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.432925 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=8
I1223 00:14:24.432931 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=8
I1223 00:14:24.432935 25375 net.cpp:406] encode1_hadamard->forget_t=8 <- c_t=8_encode1_unit_t=8_0_split_1
I1223 00:14:24.432942 25375 net.cpp:380] encode1_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:24.433032 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=8
I1223 00:14:24.433038 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433043 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:24.433045 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.433048 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=8
I1223 00:14:24.433055 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=8
I1223 00:14:24.433059 25375 net.cpp:406] encode1_hadamard->output_t=8 <- c_t=8_encode1_unit_t=8_0_split_2
I1223 00:14:24.433064 25375 net.cpp:380] encode1_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:24.433159 25375 net.cpp:122] Setting up encode1_hadamard->output_t=8
I1223 00:14:24.433167 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433171 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:24.433174 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.433177 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=9
I1223 00:14:24.433182 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=9
I1223 00:14:24.433187 25375 net.cpp:380] encode1_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:24.433269 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=9
I1223 00:14:24.433275 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433279 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:24.433281 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=9
I1223 00:14:24.433287 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=9
I1223 00:14:24.433291 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:24.433295 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:24.433300 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:24.433305 25375 net.cpp:406] encode1_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:24.433310 25375 net.cpp:380] encode1_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:24.433333 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=9
I1223 00:14:24.433339 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.433342 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:24.433346 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_9
I1223 00:14:24.433352 25375 net.cpp:84] Creating Layer encode1_gate_input_9
I1223 00:14:24.433357 25375 net.cpp:406] encode1_gate_input_9 <- hidden->transform->8
I1223 00:14:24.433362 25375 net.cpp:406] encode1_gate_input_9 <- x->transform->t=9
I1223 00:14:24.433365 25375 net.cpp:406] encode1_gate_input_9 <- hadamard_t=9
I1223 00:14:24.433370 25375 net.cpp:380] encode1_gate_input_9 -> gate_input_9
I1223 00:14:24.433393 25375 net.cpp:122] Setting up encode1_gate_input_9
I1223 00:14:24.433399 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.433403 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:24.433405 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=9
I1223 00:14:24.433410 25375 net.cpp:84] Creating Layer encode1_unit_t=9
I1223 00:14:24.433414 25375 net.cpp:406] encode1_unit_t=9 <- c_t=8_encode1_unit_t=8_0_split_3
I1223 00:14:24.433418 25375 net.cpp:406] encode1_unit_t=9 <- gate_input_9
I1223 00:14:24.433423 25375 net.cpp:406] encode1_unit_t=9 <- cont_t=9_encode1_cont_slice_8_split_1
I1223 00:14:24.433428 25375 net.cpp:380] encode1_unit_t=9 -> c_t=9
I1223 00:14:24.433434 25375 net.cpp:380] encode1_unit_t=9 -> h_t=9
I1223 00:14:24.433480 25375 net.cpp:122] Setting up encode1_unit_t=9
I1223 00:14:24.433486 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433490 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433493 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:24.433496 25375 layer_factory.hpp:77] Creating layer c_t=9_encode1_unit_t=9_0_split
I1223 00:14:24.433502 25375 net.cpp:84] Creating Layer c_t=9_encode1_unit_t=9_0_split
I1223 00:14:24.433506 25375 net.cpp:406] c_t=9_encode1_unit_t=9_0_split <- c_t=9
I1223 00:14:24.433512 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_0
I1223 00:14:24.433519 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_1
I1223 00:14:24.433526 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_2
I1223 00:14:24.433532 25375 net.cpp:380] c_t=9_encode1_unit_t=9_0_split -> c_t=9_encode1_unit_t=9_0_split_3
I1223 00:14:24.433588 25375 net.cpp:122] Setting up c_t=9_encode1_unit_t=9_0_split
I1223 00:14:24.433594 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433599 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433604 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433607 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433610 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:24.433614 25375 layer_factory.hpp:77] Creating layer h_t=9_encode1_unit_t=9_1_split
I1223 00:14:24.433617 25375 net.cpp:84] Creating Layer h_t=9_encode1_unit_t=9_1_split
I1223 00:14:24.433621 25375 net.cpp:406] h_t=9_encode1_unit_t=9_1_split <- h_t=9
I1223 00:14:24.433627 25375 net.cpp:380] h_t=9_encode1_unit_t=9_1_split -> h_t=9_encode1_unit_t=9_1_split_0
I1223 00:14:24.433634 25375 net.cpp:380] h_t=9_encode1_unit_t=9_1_split -> h_t=9_encode1_unit_t=9_1_split_1
I1223 00:14:24.433665 25375 net.cpp:122] Setting up h_t=9_encode1_unit_t=9_1_split
I1223 00:14:24.433671 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433676 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.433678 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:24.433681 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=9
I1223 00:14:24.433688 25375 net.cpp:84] Creating Layer encode1_h_conted_t=9
I1223 00:14:24.433692 25375 net.cpp:406] encode1_h_conted_t=9 <- h_t=9_encode1_unit_t=9_1_split_0
I1223 00:14:24.433696 25375 net.cpp:406] encode1_h_conted_t=9 <- cont_t=10_encode1_cont_slice_9_split_0
I1223 00:14:24.433702 25375 net.cpp:380] encode1_h_conted_t=9 -> h_conted_t=9
I1223 00:14:24.434541 25375 net.cpp:122] Setting up encode1_h_conted_t=9
I1223 00:14:24.434551 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.434554 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:24.434558 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->9
I1223 00:14:24.434568 25375 net.cpp:84] Creating Layer encode1_hidden->transform->9
I1223 00:14:24.434572 25375 net.cpp:406] encode1_hidden->transform->9 <- h_conted_t=9
I1223 00:14:24.434579 25375 net.cpp:380] encode1_hidden->transform->9 -> hidden->transform->9
I1223 00:14:24.435097 25375 net.cpp:122] Setting up encode1_hidden->transform->9
I1223 00:14:24.435106 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.435109 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:24.435112 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.435117 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.435120 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=9
I1223 00:14:24.435127 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=9
I1223 00:14:24.435132 25375 net.cpp:406] encode1_hadamard->input_t=9 <- c_t=9_encode1_unit_t=9_0_split_0
I1223 00:14:24.435140 25375 net.cpp:380] encode1_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:24.435235 25375 net.cpp:122] Setting up encode1_hadamard->input_t=9
I1223 00:14:24.435242 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435245 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:24.435250 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.435252 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=9
I1223 00:14:24.435259 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=9
I1223 00:14:24.435262 25375 net.cpp:406] encode1_hadamard->forget_t=9 <- c_t=9_encode1_unit_t=9_0_split_1
I1223 00:14:24.435269 25375 net.cpp:380] encode1_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:24.435362 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=9
I1223 00:14:24.435369 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435372 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:24.435376 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.435379 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=9
I1223 00:14:24.435384 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=9
I1223 00:14:24.435387 25375 net.cpp:406] encode1_hadamard->output_t=9 <- c_t=9_encode1_unit_t=9_0_split_2
I1223 00:14:24.435394 25375 net.cpp:380] encode1_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:24.435482 25375 net.cpp:122] Setting up encode1_hadamard->output_t=9
I1223 00:14:24.435489 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435492 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:24.435497 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.435499 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=10
I1223 00:14:24.435513 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=10
I1223 00:14:24.435519 25375 net.cpp:380] encode1_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:24.435571 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=10
I1223 00:14:24.435577 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435581 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:24.435585 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=10
I1223 00:14:24.435590 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=10
I1223 00:14:24.435593 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:24.435598 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:24.435602 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:24.435607 25375 net.cpp:406] encode1_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:24.435612 25375 net.cpp:380] encode1_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:24.435636 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=10
I1223 00:14:24.435642 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.435645 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:24.435647 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_10
I1223 00:14:24.435654 25375 net.cpp:84] Creating Layer encode1_gate_input_10
I1223 00:14:24.435658 25375 net.cpp:406] encode1_gate_input_10 <- hidden->transform->9
I1223 00:14:24.435663 25375 net.cpp:406] encode1_gate_input_10 <- x->transform->t=10
I1223 00:14:24.435667 25375 net.cpp:406] encode1_gate_input_10 <- hadamard_t=10
I1223 00:14:24.435673 25375 net.cpp:380] encode1_gate_input_10 -> gate_input_10
I1223 00:14:24.435694 25375 net.cpp:122] Setting up encode1_gate_input_10
I1223 00:14:24.435700 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.435703 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:24.435706 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=10
I1223 00:14:24.435711 25375 net.cpp:84] Creating Layer encode1_unit_t=10
I1223 00:14:24.435715 25375 net.cpp:406] encode1_unit_t=10 <- c_t=9_encode1_unit_t=9_0_split_3
I1223 00:14:24.435719 25375 net.cpp:406] encode1_unit_t=10 <- gate_input_10
I1223 00:14:24.435724 25375 net.cpp:406] encode1_unit_t=10 <- cont_t=10_encode1_cont_slice_9_split_1
I1223 00:14:24.435730 25375 net.cpp:380] encode1_unit_t=10 -> c_t=10
I1223 00:14:24.435737 25375 net.cpp:380] encode1_unit_t=10 -> h_t=10
I1223 00:14:24.435786 25375 net.cpp:122] Setting up encode1_unit_t=10
I1223 00:14:24.435791 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435796 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435799 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:24.435801 25375 layer_factory.hpp:77] Creating layer c_t=10_encode1_unit_t=10_0_split
I1223 00:14:24.435806 25375 net.cpp:84] Creating Layer c_t=10_encode1_unit_t=10_0_split
I1223 00:14:24.435811 25375 net.cpp:406] c_t=10_encode1_unit_t=10_0_split <- c_t=10
I1223 00:14:24.435817 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_0
I1223 00:14:24.435823 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_1
I1223 00:14:24.435830 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_2
I1223 00:14:24.435837 25375 net.cpp:380] c_t=10_encode1_unit_t=10_0_split -> c_t=10_encode1_unit_t=10_0_split_3
I1223 00:14:24.435894 25375 net.cpp:122] Setting up c_t=10_encode1_unit_t=10_0_split
I1223 00:14:24.435900 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435904 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435909 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435912 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435915 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:24.435919 25375 layer_factory.hpp:77] Creating layer h_t=10_encode1_unit_t=10_1_split
I1223 00:14:24.435922 25375 net.cpp:84] Creating Layer h_t=10_encode1_unit_t=10_1_split
I1223 00:14:24.435926 25375 net.cpp:406] h_t=10_encode1_unit_t=10_1_split <- h_t=10
I1223 00:14:24.435932 25375 net.cpp:380] h_t=10_encode1_unit_t=10_1_split -> h_t=10_encode1_unit_t=10_1_split_0
I1223 00:14:24.435940 25375 net.cpp:380] h_t=10_encode1_unit_t=10_1_split -> h_t=10_encode1_unit_t=10_1_split_1
I1223 00:14:24.435971 25375 net.cpp:122] Setting up h_t=10_encode1_unit_t=10_1_split
I1223 00:14:24.435977 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435981 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.435984 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:24.435987 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=10
I1223 00:14:24.435992 25375 net.cpp:84] Creating Layer encode1_h_conted_t=10
I1223 00:14:24.435997 25375 net.cpp:406] encode1_h_conted_t=10 <- h_t=10_encode1_unit_t=10_1_split_0
I1223 00:14:24.436000 25375 net.cpp:406] encode1_h_conted_t=10 <- cont_t=11_encode1_cont_slice_10_split_0
I1223 00:14:24.436009 25375 net.cpp:380] encode1_h_conted_t=10 -> h_conted_t=10
I1223 00:14:24.436085 25375 net.cpp:122] Setting up encode1_h_conted_t=10
I1223 00:14:24.436092 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.436095 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:24.436098 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->10
I1223 00:14:24.436107 25375 net.cpp:84] Creating Layer encode1_hidden->transform->10
I1223 00:14:24.436111 25375 net.cpp:406] encode1_hidden->transform->10 <- h_conted_t=10
I1223 00:14:24.436118 25375 net.cpp:380] encode1_hidden->transform->10 -> hidden->transform->10
I1223 00:14:24.436621 25375 net.cpp:122] Setting up encode1_hidden->transform->10
I1223 00:14:24.436630 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.436632 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:24.436636 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.436640 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.436643 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=10
I1223 00:14:24.436650 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=10
I1223 00:14:24.436655 25375 net.cpp:406] encode1_hadamard->input_t=10 <- c_t=10_encode1_unit_t=10_0_split_0
I1223 00:14:24.436661 25375 net.cpp:380] encode1_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:24.436754 25375 net.cpp:122] Setting up encode1_hadamard->input_t=10
I1223 00:14:24.436760 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.436764 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:24.436767 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.436771 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=10
I1223 00:14:24.436777 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=10
I1223 00:14:24.436780 25375 net.cpp:406] encode1_hadamard->forget_t=10 <- c_t=10_encode1_unit_t=10_0_split_1
I1223 00:14:24.436787 25375 net.cpp:380] encode1_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:24.436878 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=10
I1223 00:14:24.436885 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.436888 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:24.436892 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.436895 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=10
I1223 00:14:24.436902 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=10
I1223 00:14:24.436905 25375 net.cpp:406] encode1_hadamard->output_t=10 <- c_t=10_encode1_unit_t=10_0_split_2
I1223 00:14:24.436910 25375 net.cpp:380] encode1_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:24.437000 25375 net.cpp:122] Setting up encode1_hadamard->output_t=10
I1223 00:14:24.437007 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437011 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:24.437013 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.437017 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=11
I1223 00:14:24.437022 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=11
I1223 00:14:24.437026 25375 net.cpp:380] encode1_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:24.437084 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=11
I1223 00:14:24.437093 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437095 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:24.437098 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=11
I1223 00:14:24.437104 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=11
I1223 00:14:24.437108 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:24.437113 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:24.437117 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:24.437120 25375 net.cpp:406] encode1_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:24.437126 25375 net.cpp:380] encode1_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:24.437152 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=11
I1223 00:14:24.437160 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.437162 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:24.437165 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_11
I1223 00:14:24.437172 25375 net.cpp:84] Creating Layer encode1_gate_input_11
I1223 00:14:24.437176 25375 net.cpp:406] encode1_gate_input_11 <- hidden->transform->10
I1223 00:14:24.437180 25375 net.cpp:406] encode1_gate_input_11 <- x->transform->t=11
I1223 00:14:24.437186 25375 net.cpp:406] encode1_gate_input_11 <- hadamard_t=11
I1223 00:14:24.437191 25375 net.cpp:380] encode1_gate_input_11 -> gate_input_11
I1223 00:14:24.437213 25375 net.cpp:122] Setting up encode1_gate_input_11
I1223 00:14:24.437219 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.437222 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:24.437225 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=11
I1223 00:14:24.437230 25375 net.cpp:84] Creating Layer encode1_unit_t=11
I1223 00:14:24.437233 25375 net.cpp:406] encode1_unit_t=11 <- c_t=10_encode1_unit_t=10_0_split_3
I1223 00:14:24.437238 25375 net.cpp:406] encode1_unit_t=11 <- gate_input_11
I1223 00:14:24.437242 25375 net.cpp:406] encode1_unit_t=11 <- cont_t=11_encode1_cont_slice_10_split_1
I1223 00:14:24.437247 25375 net.cpp:380] encode1_unit_t=11 -> c_t=11
I1223 00:14:24.437254 25375 net.cpp:380] encode1_unit_t=11 -> h_t=11
I1223 00:14:24.437299 25375 net.cpp:122] Setting up encode1_unit_t=11
I1223 00:14:24.437306 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437310 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437314 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:24.437316 25375 layer_factory.hpp:77] Creating layer c_t=11_encode1_unit_t=11_0_split
I1223 00:14:24.437322 25375 net.cpp:84] Creating Layer c_t=11_encode1_unit_t=11_0_split
I1223 00:14:24.437326 25375 net.cpp:406] c_t=11_encode1_unit_t=11_0_split <- c_t=11
I1223 00:14:24.437332 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_0
I1223 00:14:24.437340 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_1
I1223 00:14:24.437346 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_2
I1223 00:14:24.437352 25375 net.cpp:380] c_t=11_encode1_unit_t=11_0_split -> c_t=11_encode1_unit_t=11_0_split_3
I1223 00:14:24.437408 25375 net.cpp:122] Setting up c_t=11_encode1_unit_t=11_0_split
I1223 00:14:24.437415 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437419 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437423 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437427 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437430 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:24.437433 25375 layer_factory.hpp:77] Creating layer h_t=11_encode1_unit_t=11_1_split
I1223 00:14:24.437438 25375 net.cpp:84] Creating Layer h_t=11_encode1_unit_t=11_1_split
I1223 00:14:24.437441 25375 net.cpp:406] h_t=11_encode1_unit_t=11_1_split <- h_t=11
I1223 00:14:24.437448 25375 net.cpp:380] h_t=11_encode1_unit_t=11_1_split -> h_t=11_encode1_unit_t=11_1_split_0
I1223 00:14:24.437454 25375 net.cpp:380] h_t=11_encode1_unit_t=11_1_split -> h_t=11_encode1_unit_t=11_1_split_1
I1223 00:14:24.437486 25375 net.cpp:122] Setting up h_t=11_encode1_unit_t=11_1_split
I1223 00:14:24.437492 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437497 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437500 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:24.437503 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=11
I1223 00:14:24.437507 25375 net.cpp:84] Creating Layer encode1_h_conted_t=11
I1223 00:14:24.437511 25375 net.cpp:406] encode1_h_conted_t=11 <- h_t=11_encode1_unit_t=11_1_split_0
I1223 00:14:24.437516 25375 net.cpp:406] encode1_h_conted_t=11 <- cont_t=12_encode1_cont_slice_11_split_0
I1223 00:14:24.437521 25375 net.cpp:380] encode1_h_conted_t=11 -> h_conted_t=11
I1223 00:14:24.437597 25375 net.cpp:122] Setting up encode1_h_conted_t=11
I1223 00:14:24.437604 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.437608 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:24.437610 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->11
I1223 00:14:24.437618 25375 net.cpp:84] Creating Layer encode1_hidden->transform->11
I1223 00:14:24.437621 25375 net.cpp:406] encode1_hidden->transform->11 <- h_conted_t=11
I1223 00:14:24.437629 25375 net.cpp:380] encode1_hidden->transform->11 -> hidden->transform->11
I1223 00:14:24.438135 25375 net.cpp:122] Setting up encode1_hidden->transform->11
I1223 00:14:24.438143 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.438146 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:24.438150 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.438154 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.438158 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=11
I1223 00:14:24.438163 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=11
I1223 00:14:24.438168 25375 net.cpp:406] encode1_hadamard->input_t=11 <- c_t=11_encode1_unit_t=11_0_split_0
I1223 00:14:24.438174 25375 net.cpp:380] encode1_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:24.438266 25375 net.cpp:122] Setting up encode1_hadamard->input_t=11
I1223 00:14:24.438274 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438278 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:24.438282 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.438284 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=11
I1223 00:14:24.438290 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=11
I1223 00:14:24.438293 25375 net.cpp:406] encode1_hadamard->forget_t=11 <- c_t=11_encode1_unit_t=11_0_split_1
I1223 00:14:24.438300 25375 net.cpp:380] encode1_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:24.438392 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=11
I1223 00:14:24.438400 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438402 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:24.438405 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.438410 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=11
I1223 00:14:24.438415 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=11
I1223 00:14:24.438417 25375 net.cpp:406] encode1_hadamard->output_t=11 <- c_t=11_encode1_unit_t=11_0_split_2
I1223 00:14:24.438424 25375 net.cpp:380] encode1_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:24.438513 25375 net.cpp:122] Setting up encode1_hadamard->output_t=11
I1223 00:14:24.438520 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438524 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:24.438527 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.438530 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=12
I1223 00:14:24.438536 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=12
I1223 00:14:24.438541 25375 net.cpp:380] encode1_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:24.438593 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=12
I1223 00:14:24.438599 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438603 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:24.438606 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=12
I1223 00:14:24.438612 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=12
I1223 00:14:24.438616 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:24.438621 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:24.438627 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:24.438630 25375 net.cpp:406] encode1_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:24.438635 25375 net.cpp:380] encode1_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:24.438657 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=12
I1223 00:14:24.438664 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.438668 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:24.438670 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_12
I1223 00:14:24.438675 25375 net.cpp:84] Creating Layer encode1_gate_input_12
I1223 00:14:24.438679 25375 net.cpp:406] encode1_gate_input_12 <- hidden->transform->11
I1223 00:14:24.438684 25375 net.cpp:406] encode1_gate_input_12 <- x->transform->t=12
I1223 00:14:24.438689 25375 net.cpp:406] encode1_gate_input_12 <- hadamard_t=12
I1223 00:14:24.438694 25375 net.cpp:380] encode1_gate_input_12 -> gate_input_12
I1223 00:14:24.438726 25375 net.cpp:122] Setting up encode1_gate_input_12
I1223 00:14:24.438733 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.438736 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:24.438740 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=12
I1223 00:14:24.438745 25375 net.cpp:84] Creating Layer encode1_unit_t=12
I1223 00:14:24.438748 25375 net.cpp:406] encode1_unit_t=12 <- c_t=11_encode1_unit_t=11_0_split_3
I1223 00:14:24.438753 25375 net.cpp:406] encode1_unit_t=12 <- gate_input_12
I1223 00:14:24.438757 25375 net.cpp:406] encode1_unit_t=12 <- cont_t=12_encode1_cont_slice_11_split_1
I1223 00:14:24.438762 25375 net.cpp:380] encode1_unit_t=12 -> c_t=12
I1223 00:14:24.438769 25375 net.cpp:380] encode1_unit_t=12 -> h_t=12
I1223 00:14:24.438813 25375 net.cpp:122] Setting up encode1_unit_t=12
I1223 00:14:24.438820 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438824 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438827 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:24.438830 25375 layer_factory.hpp:77] Creating layer c_t=12_encode1_unit_t=12_0_split
I1223 00:14:24.438835 25375 net.cpp:84] Creating Layer c_t=12_encode1_unit_t=12_0_split
I1223 00:14:24.438839 25375 net.cpp:406] c_t=12_encode1_unit_t=12_0_split <- c_t=12
I1223 00:14:24.438844 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_0
I1223 00:14:24.438851 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_1
I1223 00:14:24.438859 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_2
I1223 00:14:24.438865 25375 net.cpp:380] c_t=12_encode1_unit_t=12_0_split -> c_t=12_encode1_unit_t=12_0_split_3
I1223 00:14:24.438921 25375 net.cpp:122] Setting up c_t=12_encode1_unit_t=12_0_split
I1223 00:14:24.438928 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438932 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438936 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438941 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.438943 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:24.438946 25375 layer_factory.hpp:77] Creating layer h_t=12_encode1_unit_t=12_1_split
I1223 00:14:24.438951 25375 net.cpp:84] Creating Layer h_t=12_encode1_unit_t=12_1_split
I1223 00:14:24.438956 25375 net.cpp:406] h_t=12_encode1_unit_t=12_1_split <- h_t=12
I1223 00:14:24.438961 25375 net.cpp:380] h_t=12_encode1_unit_t=12_1_split -> h_t=12_encode1_unit_t=12_1_split_0
I1223 00:14:24.438967 25375 net.cpp:380] h_t=12_encode1_unit_t=12_1_split -> h_t=12_encode1_unit_t=12_1_split_1
I1223 00:14:24.439002 25375 net.cpp:122] Setting up h_t=12_encode1_unit_t=12_1_split
I1223 00:14:24.439007 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.439012 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.439015 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:24.439018 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=12
I1223 00:14:24.439023 25375 net.cpp:84] Creating Layer encode1_h_conted_t=12
I1223 00:14:24.439028 25375 net.cpp:406] encode1_h_conted_t=12 <- h_t=12_encode1_unit_t=12_1_split_0
I1223 00:14:24.439033 25375 net.cpp:406] encode1_h_conted_t=12 <- cont_t=13_encode1_cont_slice_12_split_0
I1223 00:14:24.439038 25375 net.cpp:380] encode1_h_conted_t=12 -> h_conted_t=12
I1223 00:14:24.439116 25375 net.cpp:122] Setting up encode1_h_conted_t=12
I1223 00:14:24.439123 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.439126 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:24.439129 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->12
I1223 00:14:24.439139 25375 net.cpp:84] Creating Layer encode1_hidden->transform->12
I1223 00:14:24.439143 25375 net.cpp:406] encode1_hidden->transform->12 <- h_conted_t=12
I1223 00:14:24.439149 25375 net.cpp:380] encode1_hidden->transform->12 -> hidden->transform->12
I1223 00:14:24.439654 25375 net.cpp:122] Setting up encode1_hidden->transform->12
I1223 00:14:24.439662 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.439666 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:24.439669 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.439679 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.439685 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=12
I1223 00:14:24.439692 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=12
I1223 00:14:24.439697 25375 net.cpp:406] encode1_hadamard->input_t=12 <- c_t=12_encode1_unit_t=12_0_split_0
I1223 00:14:24.439702 25375 net.cpp:380] encode1_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:24.439796 25375 net.cpp:122] Setting up encode1_hadamard->input_t=12
I1223 00:14:24.439805 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.439807 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:24.439811 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.439815 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=12
I1223 00:14:24.439821 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=12
I1223 00:14:24.439824 25375 net.cpp:406] encode1_hadamard->forget_t=12 <- c_t=12_encode1_unit_t=12_0_split_1
I1223 00:14:24.439829 25375 net.cpp:380] encode1_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:24.439921 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=12
I1223 00:14:24.439929 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.439931 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:24.439934 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.439937 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=12
I1223 00:14:24.439942 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=12
I1223 00:14:24.439946 25375 net.cpp:406] encode1_hadamard->output_t=12 <- c_t=12_encode1_unit_t=12_0_split_2
I1223 00:14:24.439951 25375 net.cpp:380] encode1_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:24.440039 25375 net.cpp:122] Setting up encode1_hadamard->output_t=12
I1223 00:14:24.440047 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440049 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:24.440053 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.440057 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=13
I1223 00:14:24.440062 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=13
I1223 00:14:24.440068 25375 net.cpp:380] encode1_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:24.440119 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=13
I1223 00:14:24.440126 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440129 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:24.440132 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=13
I1223 00:14:24.440138 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=13
I1223 00:14:24.440141 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:24.440146 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:24.440151 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:24.440155 25375 net.cpp:406] encode1_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:24.440161 25375 net.cpp:380] encode1_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:24.440186 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=13
I1223 00:14:24.440192 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.440196 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:24.440198 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_13
I1223 00:14:24.440203 25375 net.cpp:84] Creating Layer encode1_gate_input_13
I1223 00:14:24.440207 25375 net.cpp:406] encode1_gate_input_13 <- hidden->transform->12
I1223 00:14:24.440212 25375 net.cpp:406] encode1_gate_input_13 <- x->transform->t=13
I1223 00:14:24.440217 25375 net.cpp:406] encode1_gate_input_13 <- hadamard_t=13
I1223 00:14:24.440222 25375 net.cpp:380] encode1_gate_input_13 -> gate_input_13
I1223 00:14:24.440244 25375 net.cpp:122] Setting up encode1_gate_input_13
I1223 00:14:24.440254 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.440258 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:24.440260 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=13
I1223 00:14:24.440266 25375 net.cpp:84] Creating Layer encode1_unit_t=13
I1223 00:14:24.440269 25375 net.cpp:406] encode1_unit_t=13 <- c_t=12_encode1_unit_t=12_0_split_3
I1223 00:14:24.440274 25375 net.cpp:406] encode1_unit_t=13 <- gate_input_13
I1223 00:14:24.440279 25375 net.cpp:406] encode1_unit_t=13 <- cont_t=13_encode1_cont_slice_12_split_1
I1223 00:14:24.440284 25375 net.cpp:380] encode1_unit_t=13 -> c_t=13
I1223 00:14:24.440290 25375 net.cpp:380] encode1_unit_t=13 -> h_t=13
I1223 00:14:24.440338 25375 net.cpp:122] Setting up encode1_unit_t=13
I1223 00:14:24.440346 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440351 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440352 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:24.440356 25375 layer_factory.hpp:77] Creating layer c_t=13_encode1_unit_t=13_0_split
I1223 00:14:24.440361 25375 net.cpp:84] Creating Layer c_t=13_encode1_unit_t=13_0_split
I1223 00:14:24.440366 25375 net.cpp:406] c_t=13_encode1_unit_t=13_0_split <- c_t=13
I1223 00:14:24.440371 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_0
I1223 00:14:24.440377 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_1
I1223 00:14:24.440384 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_2
I1223 00:14:24.440392 25375 net.cpp:380] c_t=13_encode1_unit_t=13_0_split -> c_t=13_encode1_unit_t=13_0_split_3
I1223 00:14:24.440450 25375 net.cpp:122] Setting up c_t=13_encode1_unit_t=13_0_split
I1223 00:14:24.440456 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440460 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440465 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440469 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440471 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:24.440474 25375 layer_factory.hpp:77] Creating layer h_t=13_encode1_unit_t=13_1_split
I1223 00:14:24.440480 25375 net.cpp:84] Creating Layer h_t=13_encode1_unit_t=13_1_split
I1223 00:14:24.440484 25375 net.cpp:406] h_t=13_encode1_unit_t=13_1_split <- h_t=13
I1223 00:14:24.440488 25375 net.cpp:380] h_t=13_encode1_unit_t=13_1_split -> h_t=13_encode1_unit_t=13_1_split_0
I1223 00:14:24.440495 25375 net.cpp:380] h_t=13_encode1_unit_t=13_1_split -> h_t=13_encode1_unit_t=13_1_split_1
I1223 00:14:24.440529 25375 net.cpp:122] Setting up h_t=13_encode1_unit_t=13_1_split
I1223 00:14:24.440536 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440539 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440542 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:24.440546 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=13
I1223 00:14:24.440551 25375 net.cpp:84] Creating Layer encode1_h_conted_t=13
I1223 00:14:24.440553 25375 net.cpp:406] encode1_h_conted_t=13 <- h_t=13_encode1_unit_t=13_1_split_0
I1223 00:14:24.440558 25375 net.cpp:406] encode1_h_conted_t=13 <- cont_t=14_encode1_cont_slice_13_split_0
I1223 00:14:24.440563 25375 net.cpp:380] encode1_h_conted_t=13 -> h_conted_t=13
I1223 00:14:24.440639 25375 net.cpp:122] Setting up encode1_h_conted_t=13
I1223 00:14:24.440645 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.440649 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:24.440652 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->13
I1223 00:14:24.440660 25375 net.cpp:84] Creating Layer encode1_hidden->transform->13
I1223 00:14:24.440665 25375 net.cpp:406] encode1_hidden->transform->13 <- h_conted_t=13
I1223 00:14:24.440671 25375 net.cpp:380] encode1_hidden->transform->13 -> hidden->transform->13
I1223 00:14:24.441181 25375 net.cpp:122] Setting up encode1_hidden->transform->13
I1223 00:14:24.441190 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.441193 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:24.441197 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.441201 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.441205 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=13
I1223 00:14:24.441210 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=13
I1223 00:14:24.441213 25375 net.cpp:406] encode1_hadamard->input_t=13 <- c_t=13_encode1_unit_t=13_0_split_0
I1223 00:14:24.441221 25375 net.cpp:380] encode1_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:24.441315 25375 net.cpp:122] Setting up encode1_hadamard->input_t=13
I1223 00:14:24.441323 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441325 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:24.441329 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.441334 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=13
I1223 00:14:24.441339 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=13
I1223 00:14:24.441342 25375 net.cpp:406] encode1_hadamard->forget_t=13 <- c_t=13_encode1_unit_t=13_0_split_1
I1223 00:14:24.441349 25375 net.cpp:380] encode1_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:24.441442 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=13
I1223 00:14:24.441449 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441453 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:24.441457 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.441460 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=13
I1223 00:14:24.441467 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=13
I1223 00:14:24.441470 25375 net.cpp:406] encode1_hadamard->output_t=13 <- c_t=13_encode1_unit_t=13_0_split_2
I1223 00:14:24.441476 25375 net.cpp:380] encode1_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:24.441565 25375 net.cpp:122] Setting up encode1_hadamard->output_t=13
I1223 00:14:24.441572 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441576 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:24.441579 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.441583 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=14
I1223 00:14:24.441589 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=14
I1223 00:14:24.441594 25375 net.cpp:380] encode1_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:24.441648 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=14
I1223 00:14:24.441654 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441658 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:24.441660 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=14
I1223 00:14:24.441666 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=14
I1223 00:14:24.441670 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:24.441674 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:24.441679 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:24.441682 25375 net.cpp:406] encode1_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:24.441687 25375 net.cpp:380] encode1_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:24.441710 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=14
I1223 00:14:24.441716 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.441720 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:24.441722 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_14
I1223 00:14:24.441730 25375 net.cpp:84] Creating Layer encode1_gate_input_14
I1223 00:14:24.441733 25375 net.cpp:406] encode1_gate_input_14 <- hidden->transform->13
I1223 00:14:24.441738 25375 net.cpp:406] encode1_gate_input_14 <- x->transform->t=14
I1223 00:14:24.441742 25375 net.cpp:406] encode1_gate_input_14 <- hadamard_t=14
I1223 00:14:24.441748 25375 net.cpp:380] encode1_gate_input_14 -> gate_input_14
I1223 00:14:24.441771 25375 net.cpp:122] Setting up encode1_gate_input_14
I1223 00:14:24.441776 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.441779 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:24.441782 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=14
I1223 00:14:24.441788 25375 net.cpp:84] Creating Layer encode1_unit_t=14
I1223 00:14:24.441792 25375 net.cpp:406] encode1_unit_t=14 <- c_t=13_encode1_unit_t=13_0_split_3
I1223 00:14:24.441797 25375 net.cpp:406] encode1_unit_t=14 <- gate_input_14
I1223 00:14:24.441802 25375 net.cpp:406] encode1_unit_t=14 <- cont_t=14_encode1_cont_slice_13_split_1
I1223 00:14:24.441807 25375 net.cpp:380] encode1_unit_t=14 -> c_t=14
I1223 00:14:24.441813 25375 net.cpp:380] encode1_unit_t=14 -> h_t=14
I1223 00:14:24.441861 25375 net.cpp:122] Setting up encode1_unit_t=14
I1223 00:14:24.441869 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441872 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441875 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:24.441879 25375 layer_factory.hpp:77] Creating layer c_t=14_encode1_unit_t=14_0_split
I1223 00:14:24.441884 25375 net.cpp:84] Creating Layer c_t=14_encode1_unit_t=14_0_split
I1223 00:14:24.441886 25375 net.cpp:406] c_t=14_encode1_unit_t=14_0_split <- c_t=14
I1223 00:14:24.441893 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_0
I1223 00:14:24.441902 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_1
I1223 00:14:24.441910 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_2
I1223 00:14:24.441916 25375 net.cpp:380] c_t=14_encode1_unit_t=14_0_split -> c_t=14_encode1_unit_t=14_0_split_3
I1223 00:14:24.441974 25375 net.cpp:122] Setting up c_t=14_encode1_unit_t=14_0_split
I1223 00:14:24.441980 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441985 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441989 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441993 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.441996 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:24.441998 25375 layer_factory.hpp:77] Creating layer h_t=14_encode1_unit_t=14_1_split
I1223 00:14:24.442003 25375 net.cpp:84] Creating Layer h_t=14_encode1_unit_t=14_1_split
I1223 00:14:24.442006 25375 net.cpp:406] h_t=14_encode1_unit_t=14_1_split <- h_t=14
I1223 00:14:24.442011 25375 net.cpp:380] h_t=14_encode1_unit_t=14_1_split -> h_t=14_encode1_unit_t=14_1_split_0
I1223 00:14:24.442018 25375 net.cpp:380] h_t=14_encode1_unit_t=14_1_split -> h_t=14_encode1_unit_t=14_1_split_1
I1223 00:14:24.442051 25375 net.cpp:122] Setting up h_t=14_encode1_unit_t=14_1_split
I1223 00:14:24.442059 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.442062 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.442065 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:24.442067 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=14
I1223 00:14:24.442075 25375 net.cpp:84] Creating Layer encode1_h_conted_t=14
I1223 00:14:24.442078 25375 net.cpp:406] encode1_h_conted_t=14 <- h_t=14_encode1_unit_t=14_1_split_0
I1223 00:14:24.442082 25375 net.cpp:406] encode1_h_conted_t=14 <- cont_t=15_encode1_cont_slice_14_split_0
I1223 00:14:24.442087 25375 net.cpp:380] encode1_h_conted_t=14 -> h_conted_t=14
I1223 00:14:24.442903 25375 net.cpp:122] Setting up encode1_h_conted_t=14
I1223 00:14:24.442914 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.442917 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:24.442921 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->14
I1223 00:14:24.442931 25375 net.cpp:84] Creating Layer encode1_hidden->transform->14
I1223 00:14:24.442937 25375 net.cpp:406] encode1_hidden->transform->14 <- h_conted_t=14
I1223 00:14:24.442945 25375 net.cpp:380] encode1_hidden->transform->14 -> hidden->transform->14
I1223 00:14:24.443473 25375 net.cpp:122] Setting up encode1_hidden->transform->14
I1223 00:14:24.443481 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.443485 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:24.443488 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.443492 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.443496 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=14
I1223 00:14:24.443503 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=14
I1223 00:14:24.443508 25375 net.cpp:406] encode1_hadamard->input_t=14 <- c_t=14_encode1_unit_t=14_0_split_0
I1223 00:14:24.443514 25375 net.cpp:380] encode1_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:24.443617 25375 net.cpp:122] Setting up encode1_hadamard->input_t=14
I1223 00:14:24.443624 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.443627 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:24.443631 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.443635 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=14
I1223 00:14:24.443641 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=14
I1223 00:14:24.443646 25375 net.cpp:406] encode1_hadamard->forget_t=14 <- c_t=14_encode1_unit_t=14_0_split_1
I1223 00:14:24.443651 25375 net.cpp:380] encode1_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:24.443747 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=14
I1223 00:14:24.443754 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.443758 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:24.443761 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.443765 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=14
I1223 00:14:24.443771 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=14
I1223 00:14:24.443775 25375 net.cpp:406] encode1_hadamard->output_t=14 <- c_t=14_encode1_unit_t=14_0_split_2
I1223 00:14:24.443781 25375 net.cpp:380] encode1_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:24.443871 25375 net.cpp:122] Setting up encode1_hadamard->output_t=14
I1223 00:14:24.443877 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.443881 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:24.443884 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.443888 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=15
I1223 00:14:24.443898 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=15
I1223 00:14:24.443904 25375 net.cpp:380] encode1_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:24.443959 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=15
I1223 00:14:24.443966 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.443969 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:24.443972 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=15
I1223 00:14:24.443979 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=15
I1223 00:14:24.443982 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:24.443987 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:24.443991 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:24.443996 25375 net.cpp:406] encode1_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:24.444001 25375 net.cpp:380] encode1_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:24.444027 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=15
I1223 00:14:24.444033 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.444036 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:24.444041 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_15
I1223 00:14:24.444046 25375 net.cpp:84] Creating Layer encode1_gate_input_15
I1223 00:14:24.444049 25375 net.cpp:406] encode1_gate_input_15 <- hidden->transform->14
I1223 00:14:24.444053 25375 net.cpp:406] encode1_gate_input_15 <- x->transform->t=15
I1223 00:14:24.444058 25375 net.cpp:406] encode1_gate_input_15 <- hadamard_t=15
I1223 00:14:24.444064 25375 net.cpp:380] encode1_gate_input_15 -> gate_input_15
I1223 00:14:24.444087 25375 net.cpp:122] Setting up encode1_gate_input_15
I1223 00:14:24.444092 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.444097 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:24.444099 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=15
I1223 00:14:24.444105 25375 net.cpp:84] Creating Layer encode1_unit_t=15
I1223 00:14:24.444109 25375 net.cpp:406] encode1_unit_t=15 <- c_t=14_encode1_unit_t=14_0_split_3
I1223 00:14:24.444114 25375 net.cpp:406] encode1_unit_t=15 <- gate_input_15
I1223 00:14:24.444118 25375 net.cpp:406] encode1_unit_t=15 <- cont_t=15_encode1_cont_slice_14_split_1
I1223 00:14:24.444123 25375 net.cpp:380] encode1_unit_t=15 -> c_t=15
I1223 00:14:24.444130 25375 net.cpp:380] encode1_unit_t=15 -> h_t=15
I1223 00:14:24.444177 25375 net.cpp:122] Setting up encode1_unit_t=15
I1223 00:14:24.444183 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444188 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444190 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:24.444195 25375 layer_factory.hpp:77] Creating layer c_t=15_encode1_unit_t=15_0_split
I1223 00:14:24.444200 25375 net.cpp:84] Creating Layer c_t=15_encode1_unit_t=15_0_split
I1223 00:14:24.444203 25375 net.cpp:406] c_t=15_encode1_unit_t=15_0_split <- c_t=15
I1223 00:14:24.444209 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_0
I1223 00:14:24.444217 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_1
I1223 00:14:24.444223 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_2
I1223 00:14:24.444231 25375 net.cpp:380] c_t=15_encode1_unit_t=15_0_split -> c_t=15_encode1_unit_t=15_0_split_3
I1223 00:14:24.444286 25375 net.cpp:122] Setting up c_t=15_encode1_unit_t=15_0_split
I1223 00:14:24.444293 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444298 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444301 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444305 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444308 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:24.444311 25375 layer_factory.hpp:77] Creating layer h_t=15_encode1_unit_t=15_1_split
I1223 00:14:24.444315 25375 net.cpp:84] Creating Layer h_t=15_encode1_unit_t=15_1_split
I1223 00:14:24.444319 25375 net.cpp:406] h_t=15_encode1_unit_t=15_1_split <- h_t=15
I1223 00:14:24.444324 25375 net.cpp:380] h_t=15_encode1_unit_t=15_1_split -> h_t=15_encode1_unit_t=15_1_split_0
I1223 00:14:24.444332 25375 net.cpp:380] h_t=15_encode1_unit_t=15_1_split -> h_t=15_encode1_unit_t=15_1_split_1
I1223 00:14:24.444363 25375 net.cpp:122] Setting up h_t=15_encode1_unit_t=15_1_split
I1223 00:14:24.444370 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444375 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444377 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:24.444380 25375 layer_factory.hpp:77] Creating layer encode1_h_conted_t=15
I1223 00:14:24.444386 25375 net.cpp:84] Creating Layer encode1_h_conted_t=15
I1223 00:14:24.444391 25375 net.cpp:406] encode1_h_conted_t=15 <- h_t=15_encode1_unit_t=15_1_split_0
I1223 00:14:24.444394 25375 net.cpp:406] encode1_h_conted_t=15 <- cont_t=16_encode1_cont_slice_15_split_0
I1223 00:14:24.444401 25375 net.cpp:380] encode1_h_conted_t=15 -> h_conted_t=15
I1223 00:14:24.444476 25375 net.cpp:122] Setting up encode1_h_conted_t=15
I1223 00:14:24.444483 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.444486 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:24.444489 25375 layer_factory.hpp:77] Creating layer encode1_hidden->transform->15
I1223 00:14:24.444499 25375 net.cpp:84] Creating Layer encode1_hidden->transform->15
I1223 00:14:24.444504 25375 net.cpp:406] encode1_hidden->transform->15 <- h_conted_t=15
I1223 00:14:24.444510 25375 net.cpp:380] encode1_hidden->transform->15 -> hidden->transform->15
I1223 00:14:24.445020 25375 net.cpp:122] Setting up encode1_hidden->transform->15
I1223 00:14:24.445029 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.445031 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:24.445035 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode1_hidden->transform->0', param index 0
I1223 00:14:24.445039 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode1_hidden->transform->0', param index 1
I1223 00:14:24.445042 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->input_t=15
I1223 00:14:24.445050 25375 net.cpp:84] Creating Layer encode1_hadamard->input_t=15
I1223 00:14:24.445055 25375 net.cpp:406] encode1_hadamard->input_t=15 <- c_t=15_encode1_unit_t=15_0_split_0
I1223 00:14:24.445060 25375 net.cpp:380] encode1_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:24.445160 25375 net.cpp:122] Setting up encode1_hadamard->input_t=15
I1223 00:14:24.445168 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445171 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:24.445174 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode1_hadamard->input_t=0', param index 0
I1223 00:14:24.445178 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->forget_t=15
I1223 00:14:24.445184 25375 net.cpp:84] Creating Layer encode1_hadamard->forget_t=15
I1223 00:14:24.445188 25375 net.cpp:406] encode1_hadamard->forget_t=15 <- c_t=15_encode1_unit_t=15_0_split_1
I1223 00:14:24.445194 25375 net.cpp:380] encode1_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:24.445288 25375 net.cpp:122] Setting up encode1_hadamard->forget_t=15
I1223 00:14:24.445296 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445299 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:24.445302 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode1_hadamard->forget_t=0', param index 0
I1223 00:14:24.445307 25375 layer_factory.hpp:77] Creating layer encode1_hadamard->output_t=15
I1223 00:14:24.445312 25375 net.cpp:84] Creating Layer encode1_hadamard->output_t=15
I1223 00:14:24.445317 25375 net.cpp:406] encode1_hadamard->output_t=15 <- c_t=15_encode1_unit_t=15_0_split_2
I1223 00:14:24.445322 25375 net.cpp:380] encode1_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:24.445410 25375 net.cpp:122] Setting up encode1_hadamard->output_t=15
I1223 00:14:24.445417 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445421 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:24.445425 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode1_hadamard->output_t=0', param index 0
I1223 00:14:24.445427 25375 layer_factory.hpp:77] Creating layer encode1_hadamard_gat_t=16
I1223 00:14:24.445435 25375 net.cpp:84] Creating Layer encode1_hadamard_gat_t=16
I1223 00:14:24.445439 25375 net.cpp:380] encode1_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:24.445493 25375 net.cpp:122] Setting up encode1_hadamard_gat_t=16
I1223 00:14:24.445500 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445503 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:24.445507 25375 layer_factory.hpp:77] Creating layer encode1_concat_hadamard_t=16
I1223 00:14:24.445513 25375 net.cpp:84] Creating Layer encode1_concat_hadamard_t=16
I1223 00:14:24.445515 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:24.445520 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:24.445524 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:24.445528 25375 net.cpp:406] encode1_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:24.445535 25375 net.cpp:380] encode1_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:24.445560 25375 net.cpp:122] Setting up encode1_concat_hadamard_t=16
I1223 00:14:24.445566 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.445569 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:24.445572 25375 layer_factory.hpp:77] Creating layer encode1_gate_input_16
I1223 00:14:24.445577 25375 net.cpp:84] Creating Layer encode1_gate_input_16
I1223 00:14:24.445581 25375 net.cpp:406] encode1_gate_input_16 <- hidden->transform->15
I1223 00:14:24.445586 25375 net.cpp:406] encode1_gate_input_16 <- x->transform->t=16
I1223 00:14:24.445590 25375 net.cpp:406] encode1_gate_input_16 <- hadamard_t=16
I1223 00:14:24.445597 25375 net.cpp:380] encode1_gate_input_16 -> gate_input_16
I1223 00:14:24.445621 25375 net.cpp:122] Setting up encode1_gate_input_16
I1223 00:14:24.445628 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.445631 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:24.445634 25375 layer_factory.hpp:77] Creating layer encode1_unit_t=16
I1223 00:14:24.445639 25375 net.cpp:84] Creating Layer encode1_unit_t=16
I1223 00:14:24.445643 25375 net.cpp:406] encode1_unit_t=16 <- c_t=15_encode1_unit_t=15_0_split_3
I1223 00:14:24.445647 25375 net.cpp:406] encode1_unit_t=16 <- gate_input_16
I1223 00:14:24.445652 25375 net.cpp:406] encode1_unit_t=16 <- cont_t=16_encode1_cont_slice_15_split_1
I1223 00:14:24.445657 25375 net.cpp:380] encode1_unit_t=16 -> c_t=16
I1223 00:14:24.445663 25375 net.cpp:380] encode1_unit_t=16 -> h_t=16
I1223 00:14:24.445713 25375 net.cpp:122] Setting up encode1_unit_t=16
I1223 00:14:24.445720 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445725 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445727 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:24.445730 25375 layer_factory.hpp:77] Creating layer h_t=16_encode1_unit_t=16_1_split
I1223 00:14:24.445736 25375 net.cpp:84] Creating Layer h_t=16_encode1_unit_t=16_1_split
I1223 00:14:24.445741 25375 net.cpp:406] h_t=16_encode1_unit_t=16_1_split <- h_t=16
I1223 00:14:24.445746 25375 net.cpp:380] h_t=16_encode1_unit_t=16_1_split -> h_t=16_encode1_unit_t=16_1_split_0
I1223 00:14:24.445752 25375 net.cpp:380] h_t=16_encode1_unit_t=16_1_split -> h_t=16_encode1_unit_t=16_1_split_1
I1223 00:14:24.445787 25375 net.cpp:122] Setting up h_t=16_encode1_unit_t=16_1_split
I1223 00:14:24.445794 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445798 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445801 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:24.445804 25375 layer_factory.hpp:77] Creating layer encode1_h_concat
I1223 00:14:24.445812 25375 net.cpp:84] Creating Layer encode1_h_concat
I1223 00:14:24.445816 25375 net.cpp:406] encode1_h_concat <- h_t=1_encode1_unit_t=1_1_split_1
I1223 00:14:24.445821 25375 net.cpp:406] encode1_h_concat <- h_t=2_encode1_unit_t=2_1_split_1
I1223 00:14:24.445824 25375 net.cpp:406] encode1_h_concat <- h_t=3_encode1_unit_t=3_1_split_1
I1223 00:14:24.445829 25375 net.cpp:406] encode1_h_concat <- h_t=4_encode1_unit_t=4_1_split_1
I1223 00:14:24.445832 25375 net.cpp:406] encode1_h_concat <- h_t=5_encode1_unit_t=5_1_split_1
I1223 00:14:24.445837 25375 net.cpp:406] encode1_h_concat <- h_t=6_encode1_unit_t=6_1_split_1
I1223 00:14:24.445840 25375 net.cpp:406] encode1_h_concat <- h_t=7_encode1_unit_t=7_1_split_1
I1223 00:14:24.445844 25375 net.cpp:406] encode1_h_concat <- h_t=8_encode1_unit_t=8_1_split_1
I1223 00:14:24.445848 25375 net.cpp:406] encode1_h_concat <- h_t=9_encode1_unit_t=9_1_split_1
I1223 00:14:24.445852 25375 net.cpp:406] encode1_h_concat <- h_t=10_encode1_unit_t=10_1_split_1
I1223 00:14:24.445855 25375 net.cpp:406] encode1_h_concat <- h_t=11_encode1_unit_t=11_1_split_1
I1223 00:14:24.445859 25375 net.cpp:406] encode1_h_concat <- h_t=12_encode1_unit_t=12_1_split_1
I1223 00:14:24.445863 25375 net.cpp:406] encode1_h_concat <- h_t=13_encode1_unit_t=13_1_split_1
I1223 00:14:24.445866 25375 net.cpp:406] encode1_h_concat <- h_t=14_encode1_unit_t=14_1_split_1
I1223 00:14:24.445869 25375 net.cpp:406] encode1_h_concat <- h_t=15_encode1_unit_t=15_1_split_1
I1223 00:14:24.445873 25375 net.cpp:406] encode1_h_concat <- h_t=16_encode1_unit_t=16_1_split_0
I1223 00:14:24.445880 25375 net.cpp:380] encode1_h_concat -> h
I1223 00:14:24.445904 25375 net.cpp:122] Setting up encode1_h_concat
I1223 00:14:24.445910 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.445914 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:24.445917 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_h
I1223 00:14:24.445924 25375 net.cpp:84] Creating Layer encode1_dummy_forward_h
I1223 00:14:24.445927 25375 net.cpp:406] encode1_dummy_forward_h <- h_t=16_encode1_unit_t=16_1_split_1
I1223 00:14:24.445932 25375 net.cpp:380] encode1_dummy_forward_h -> h_t=T
I1223 00:14:24.445968 25375 net.cpp:122] Setting up encode1_dummy_forward_h
I1223 00:14:24.445974 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.445977 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:24.445984 25375 layer_factory.hpp:77] Creating layer encode1_dummy_forward_c
I1223 00:14:24.445991 25375 net.cpp:84] Creating Layer encode1_dummy_forward_c
I1223 00:14:24.445994 25375 net.cpp:406] encode1_dummy_forward_c <- c_t=16
I1223 00:14:24.445999 25375 net.cpp:380] encode1_dummy_forward_c -> c_t=T
I1223 00:14:24.446034 25375 net.cpp:122] Setting up encode1_dummy_forward_c
I1223 00:14:24.446040 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.446043 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:24.446048 25375 layer_factory.hpp:77] Creating layer encode1_h_t=T_pseudoloss
I1223 00:14:24.446053 25375 net.cpp:84] Creating Layer encode1_h_t=T_pseudoloss
I1223 00:14:24.446058 25375 net.cpp:406] encode1_h_t=T_pseudoloss <- h_t=T
I1223 00:14:24.446061 25375 net.cpp:380] encode1_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:24.446130 25375 net.cpp:122] Setting up encode1_h_t=T_pseudoloss
I1223 00:14:24.446136 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.446139 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.446147 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:24.446151 25375 layer_factory.hpp:77] Creating layer encode1_c_t=T_pseudoloss
I1223 00:14:24.446157 25375 net.cpp:84] Creating Layer encode1_c_t=T_pseudoloss
I1223 00:14:24.446162 25375 net.cpp:406] encode1_c_t=T_pseudoloss <- c_t=T
I1223 00:14:24.446167 25375 net.cpp:380] encode1_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:24.446233 25375 net.cpp:122] Setting up encode1_c_t=T_pseudoloss
I1223 00:14:24.446238 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.446241 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.446245 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:24.446249 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:24.446254 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:24.446257 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:24.446262 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:24.447352 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:24.447365 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.447367 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.447372 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:24.447376 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:24.447381 25375 net.cpp:198] encode1_c_t=T_pseudoloss needs backward computation.
I1223 00:14:24.447383 25375 net.cpp:198] encode1_h_t=T_pseudoloss needs backward computation.
I1223 00:14:24.447386 25375 net.cpp:198] encode1_dummy_forward_c needs backward computation.
I1223 00:14:24.447389 25375 net.cpp:198] encode1_dummy_forward_h needs backward computation.
I1223 00:14:24.447392 25375 net.cpp:198] encode1_h_concat needs backward computation.
I1223 00:14:24.447402 25375 net.cpp:198] h_t=16_encode1_unit_t=16_1_split needs backward computation.
I1223 00:14:24.447405 25375 net.cpp:198] encode1_unit_t=16 needs backward computation.
I1223 00:14:24.447412 25375 net.cpp:198] encode1_gate_input_16 needs backward computation.
I1223 00:14:24.447417 25375 net.cpp:198] encode1_concat_hadamard_t=16 needs backward computation.
I1223 00:14:24.447420 25375 net.cpp:200] encode1_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:24.447424 25375 net.cpp:198] encode1_hadamard->output_t=15 needs backward computation.
I1223 00:14:24.447427 25375 net.cpp:198] encode1_hadamard->forget_t=15 needs backward computation.
I1223 00:14:24.447432 25375 net.cpp:198] encode1_hadamard->input_t=15 needs backward computation.
I1223 00:14:24.447434 25375 net.cpp:198] encode1_hidden->transform->15 needs backward computation.
I1223 00:14:24.447438 25375 net.cpp:198] encode1_h_conted_t=15 needs backward computation.
I1223 00:14:24.447443 25375 net.cpp:198] h_t=15_encode1_unit_t=15_1_split needs backward computation.
I1223 00:14:24.447445 25375 net.cpp:198] c_t=15_encode1_unit_t=15_0_split needs backward computation.
I1223 00:14:24.447449 25375 net.cpp:198] encode1_unit_t=15 needs backward computation.
I1223 00:14:24.447453 25375 net.cpp:198] encode1_gate_input_15 needs backward computation.
I1223 00:14:24.447458 25375 net.cpp:198] encode1_concat_hadamard_t=15 needs backward computation.
I1223 00:14:24.447463 25375 net.cpp:200] encode1_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:24.447465 25375 net.cpp:198] encode1_hadamard->output_t=14 needs backward computation.
I1223 00:14:24.447469 25375 net.cpp:198] encode1_hadamard->forget_t=14 needs backward computation.
I1223 00:14:24.447473 25375 net.cpp:198] encode1_hadamard->input_t=14 needs backward computation.
I1223 00:14:24.447476 25375 net.cpp:198] encode1_hidden->transform->14 needs backward computation.
I1223 00:14:24.447481 25375 net.cpp:198] encode1_h_conted_t=14 needs backward computation.
I1223 00:14:24.447485 25375 net.cpp:198] h_t=14_encode1_unit_t=14_1_split needs backward computation.
I1223 00:14:24.447489 25375 net.cpp:198] c_t=14_encode1_unit_t=14_0_split needs backward computation.
I1223 00:14:24.447494 25375 net.cpp:198] encode1_unit_t=14 needs backward computation.
I1223 00:14:24.447497 25375 net.cpp:198] encode1_gate_input_14 needs backward computation.
I1223 00:14:24.447502 25375 net.cpp:198] encode1_concat_hadamard_t=14 needs backward computation.
I1223 00:14:24.447507 25375 net.cpp:200] encode1_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:24.447510 25375 net.cpp:198] encode1_hadamard->output_t=13 needs backward computation.
I1223 00:14:24.447515 25375 net.cpp:198] encode1_hadamard->forget_t=13 needs backward computation.
I1223 00:14:24.447517 25375 net.cpp:198] encode1_hadamard->input_t=13 needs backward computation.
I1223 00:14:24.447521 25375 net.cpp:198] encode1_hidden->transform->13 needs backward computation.
I1223 00:14:24.447525 25375 net.cpp:198] encode1_h_conted_t=13 needs backward computation.
I1223 00:14:24.447530 25375 net.cpp:198] h_t=13_encode1_unit_t=13_1_split needs backward computation.
I1223 00:14:24.447532 25375 net.cpp:198] c_t=13_encode1_unit_t=13_0_split needs backward computation.
I1223 00:14:24.447535 25375 net.cpp:198] encode1_unit_t=13 needs backward computation.
I1223 00:14:24.447540 25375 net.cpp:198] encode1_gate_input_13 needs backward computation.
I1223 00:14:24.447546 25375 net.cpp:198] encode1_concat_hadamard_t=13 needs backward computation.
I1223 00:14:24.447551 25375 net.cpp:200] encode1_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:24.447556 25375 net.cpp:198] encode1_hadamard->output_t=12 needs backward computation.
I1223 00:14:24.447559 25375 net.cpp:198] encode1_hadamard->forget_t=12 needs backward computation.
I1223 00:14:24.447562 25375 net.cpp:198] encode1_hadamard->input_t=12 needs backward computation.
I1223 00:14:24.447566 25375 net.cpp:198] encode1_hidden->transform->12 needs backward computation.
I1223 00:14:24.447569 25375 net.cpp:198] encode1_h_conted_t=12 needs backward computation.
I1223 00:14:24.447574 25375 net.cpp:198] h_t=12_encode1_unit_t=12_1_split needs backward computation.
I1223 00:14:24.447577 25375 net.cpp:198] c_t=12_encode1_unit_t=12_0_split needs backward computation.
I1223 00:14:24.447582 25375 net.cpp:198] encode1_unit_t=12 needs backward computation.
I1223 00:14:24.447587 25375 net.cpp:198] encode1_gate_input_12 needs backward computation.
I1223 00:14:24.447590 25375 net.cpp:198] encode1_concat_hadamard_t=12 needs backward computation.
I1223 00:14:24.447597 25375 net.cpp:200] encode1_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:24.447599 25375 net.cpp:198] encode1_hadamard->output_t=11 needs backward computation.
I1223 00:14:24.447603 25375 net.cpp:198] encode1_hadamard->forget_t=11 needs backward computation.
I1223 00:14:24.447607 25375 net.cpp:198] encode1_hadamard->input_t=11 needs backward computation.
I1223 00:14:24.447610 25375 net.cpp:198] encode1_hidden->transform->11 needs backward computation.
I1223 00:14:24.447614 25375 net.cpp:198] encode1_h_conted_t=11 needs backward computation.
I1223 00:14:24.447618 25375 net.cpp:198] h_t=11_encode1_unit_t=11_1_split needs backward computation.
I1223 00:14:24.447623 25375 net.cpp:198] c_t=11_encode1_unit_t=11_0_split needs backward computation.
I1223 00:14:24.447626 25375 net.cpp:198] encode1_unit_t=11 needs backward computation.
I1223 00:14:24.447630 25375 net.cpp:198] encode1_gate_input_11 needs backward computation.
I1223 00:14:24.447636 25375 net.cpp:198] encode1_concat_hadamard_t=11 needs backward computation.
I1223 00:14:24.447641 25375 net.cpp:200] encode1_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:24.447644 25375 net.cpp:198] encode1_hadamard->output_t=10 needs backward computation.
I1223 00:14:24.447649 25375 net.cpp:198] encode1_hadamard->forget_t=10 needs backward computation.
I1223 00:14:24.447651 25375 net.cpp:198] encode1_hadamard->input_t=10 needs backward computation.
I1223 00:14:24.447655 25375 net.cpp:198] encode1_hidden->transform->10 needs backward computation.
I1223 00:14:24.447659 25375 net.cpp:198] encode1_h_conted_t=10 needs backward computation.
I1223 00:14:24.447662 25375 net.cpp:198] h_t=10_encode1_unit_t=10_1_split needs backward computation.
I1223 00:14:24.447666 25375 net.cpp:198] c_t=10_encode1_unit_t=10_0_split needs backward computation.
I1223 00:14:24.447670 25375 net.cpp:198] encode1_unit_t=10 needs backward computation.
I1223 00:14:24.447675 25375 net.cpp:198] encode1_gate_input_10 needs backward computation.
I1223 00:14:24.447679 25375 net.cpp:198] encode1_concat_hadamard_t=10 needs backward computation.
I1223 00:14:24.447685 25375 net.cpp:200] encode1_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:24.447688 25375 net.cpp:198] encode1_hadamard->output_t=9 needs backward computation.
I1223 00:14:24.447692 25375 net.cpp:198] encode1_hadamard->forget_t=9 needs backward computation.
I1223 00:14:24.447696 25375 net.cpp:198] encode1_hadamard->input_t=9 needs backward computation.
I1223 00:14:24.447700 25375 net.cpp:198] encode1_hidden->transform->9 needs backward computation.
I1223 00:14:24.447705 25375 net.cpp:198] encode1_h_conted_t=9 needs backward computation.
I1223 00:14:24.447708 25375 net.cpp:198] h_t=9_encode1_unit_t=9_1_split needs backward computation.
I1223 00:14:24.447712 25375 net.cpp:198] c_t=9_encode1_unit_t=9_0_split needs backward computation.
I1223 00:14:24.447716 25375 net.cpp:198] encode1_unit_t=9 needs backward computation.
I1223 00:14:24.447722 25375 net.cpp:198] encode1_gate_input_9 needs backward computation.
I1223 00:14:24.447727 25375 net.cpp:198] encode1_concat_hadamard_t=9 needs backward computation.
I1223 00:14:24.447733 25375 net.cpp:200] encode1_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:24.447736 25375 net.cpp:198] encode1_hadamard->output_t=8 needs backward computation.
I1223 00:14:24.447741 25375 net.cpp:198] encode1_hadamard->forget_t=8 needs backward computation.
I1223 00:14:24.447744 25375 net.cpp:198] encode1_hadamard->input_t=8 needs backward computation.
I1223 00:14:24.447748 25375 net.cpp:198] encode1_hidden->transform->8 needs backward computation.
I1223 00:14:24.447752 25375 net.cpp:198] encode1_h_conted_t=8 needs backward computation.
I1223 00:14:24.447757 25375 net.cpp:198] h_t=8_encode1_unit_t=8_1_split needs backward computation.
I1223 00:14:24.447760 25375 net.cpp:198] c_t=8_encode1_unit_t=8_0_split needs backward computation.
I1223 00:14:24.447763 25375 net.cpp:198] encode1_unit_t=8 needs backward computation.
I1223 00:14:24.447768 25375 net.cpp:198] encode1_gate_input_8 needs backward computation.
I1223 00:14:24.447773 25375 net.cpp:198] encode1_concat_hadamard_t=8 needs backward computation.
I1223 00:14:24.447779 25375 net.cpp:200] encode1_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:24.447782 25375 net.cpp:198] encode1_hadamard->output_t=7 needs backward computation.
I1223 00:14:24.447787 25375 net.cpp:198] encode1_hadamard->forget_t=7 needs backward computation.
I1223 00:14:24.447789 25375 net.cpp:198] encode1_hadamard->input_t=7 needs backward computation.
I1223 00:14:24.447793 25375 net.cpp:198] encode1_hidden->transform->7 needs backward computation.
I1223 00:14:24.447798 25375 net.cpp:198] encode1_h_conted_t=7 needs backward computation.
I1223 00:14:24.447803 25375 net.cpp:198] h_t=7_encode1_unit_t=7_1_split needs backward computation.
I1223 00:14:24.447808 25375 net.cpp:198] c_t=7_encode1_unit_t=7_0_split needs backward computation.
I1223 00:14:24.447811 25375 net.cpp:198] encode1_unit_t=7 needs backward computation.
I1223 00:14:24.447816 25375 net.cpp:198] encode1_gate_input_7 needs backward computation.
I1223 00:14:24.447821 25375 net.cpp:198] encode1_concat_hadamard_t=7 needs backward computation.
I1223 00:14:24.447827 25375 net.cpp:200] encode1_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:24.447831 25375 net.cpp:198] encode1_hadamard->output_t=6 needs backward computation.
I1223 00:14:24.447835 25375 net.cpp:198] encode1_hadamard->forget_t=6 needs backward computation.
I1223 00:14:24.447839 25375 net.cpp:198] encode1_hadamard->input_t=6 needs backward computation.
I1223 00:14:24.447844 25375 net.cpp:198] encode1_hidden->transform->6 needs backward computation.
I1223 00:14:24.447846 25375 net.cpp:198] encode1_h_conted_t=6 needs backward computation.
I1223 00:14:24.447851 25375 net.cpp:198] h_t=6_encode1_unit_t=6_1_split needs backward computation.
I1223 00:14:24.447854 25375 net.cpp:198] c_t=6_encode1_unit_t=6_0_split needs backward computation.
I1223 00:14:24.447859 25375 net.cpp:198] encode1_unit_t=6 needs backward computation.
I1223 00:14:24.447863 25375 net.cpp:198] encode1_gate_input_6 needs backward computation.
I1223 00:14:24.447868 25375 net.cpp:198] encode1_concat_hadamard_t=6 needs backward computation.
I1223 00:14:24.447873 25375 net.cpp:200] encode1_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:24.447876 25375 net.cpp:198] encode1_hadamard->output_t=5 needs backward computation.
I1223 00:14:24.447881 25375 net.cpp:198] encode1_hadamard->forget_t=5 needs backward computation.
I1223 00:14:24.447885 25375 net.cpp:198] encode1_hadamard->input_t=5 needs backward computation.
I1223 00:14:24.447890 25375 net.cpp:198] encode1_hidden->transform->5 needs backward computation.
I1223 00:14:24.447893 25375 net.cpp:198] encode1_h_conted_t=5 needs backward computation.
I1223 00:14:24.447897 25375 net.cpp:198] h_t=5_encode1_unit_t=5_1_split needs backward computation.
I1223 00:14:24.447901 25375 net.cpp:198] c_t=5_encode1_unit_t=5_0_split needs backward computation.
I1223 00:14:24.447904 25375 net.cpp:198] encode1_unit_t=5 needs backward computation.
I1223 00:14:24.447909 25375 net.cpp:198] encode1_gate_input_5 needs backward computation.
I1223 00:14:24.447914 25375 net.cpp:198] encode1_concat_hadamard_t=5 needs backward computation.
I1223 00:14:24.447919 25375 net.cpp:200] encode1_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:24.447922 25375 net.cpp:198] encode1_hadamard->output_t=4 needs backward computation.
I1223 00:14:24.447926 25375 net.cpp:198] encode1_hadamard->forget_t=4 needs backward computation.
I1223 00:14:24.447930 25375 net.cpp:198] encode1_hadamard->input_t=4 needs backward computation.
I1223 00:14:24.447933 25375 net.cpp:198] encode1_hidden->transform->4 needs backward computation.
I1223 00:14:24.447937 25375 net.cpp:198] encode1_h_conted_t=4 needs backward computation.
I1223 00:14:24.447942 25375 net.cpp:198] h_t=4_encode1_unit_t=4_1_split needs backward computation.
I1223 00:14:24.447945 25375 net.cpp:198] c_t=4_encode1_unit_t=4_0_split needs backward computation.
I1223 00:14:24.447948 25375 net.cpp:198] encode1_unit_t=4 needs backward computation.
I1223 00:14:24.447953 25375 net.cpp:198] encode1_gate_input_4 needs backward computation.
I1223 00:14:24.447958 25375 net.cpp:198] encode1_concat_hadamard_t=4 needs backward computation.
I1223 00:14:24.447964 25375 net.cpp:200] encode1_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:24.447968 25375 net.cpp:198] encode1_hadamard->output_t=3 needs backward computation.
I1223 00:14:24.447973 25375 net.cpp:198] encode1_hadamard->forget_t=3 needs backward computation.
I1223 00:14:24.447976 25375 net.cpp:198] encode1_hadamard->input_t=3 needs backward computation.
I1223 00:14:24.447980 25375 net.cpp:198] encode1_hidden->transform->3 needs backward computation.
I1223 00:14:24.447984 25375 net.cpp:198] encode1_h_conted_t=3 needs backward computation.
I1223 00:14:24.447988 25375 net.cpp:198] h_t=3_encode1_unit_t=3_1_split needs backward computation.
I1223 00:14:24.447991 25375 net.cpp:198] c_t=3_encode1_unit_t=3_0_split needs backward computation.
I1223 00:14:24.447995 25375 net.cpp:198] encode1_unit_t=3 needs backward computation.
I1223 00:14:24.448000 25375 net.cpp:198] encode1_gate_input_3 needs backward computation.
I1223 00:14:24.448004 25375 net.cpp:198] encode1_concat_hadamard_t=3 needs backward computation.
I1223 00:14:24.448009 25375 net.cpp:200] encode1_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:24.448014 25375 net.cpp:198] encode1_hadamard->output_t=2 needs backward computation.
I1223 00:14:24.448016 25375 net.cpp:198] encode1_hadamard->forget_t=2 needs backward computation.
I1223 00:14:24.448020 25375 net.cpp:198] encode1_hadamard->input_t=2 needs backward computation.
I1223 00:14:24.448024 25375 net.cpp:198] encode1_hidden->transform->2 needs backward computation.
I1223 00:14:24.448027 25375 net.cpp:198] encode1_h_conted_t=2 needs backward computation.
I1223 00:14:24.448032 25375 net.cpp:198] h_t=2_encode1_unit_t=2_1_split needs backward computation.
I1223 00:14:24.448036 25375 net.cpp:198] c_t=2_encode1_unit_t=2_0_split needs backward computation.
I1223 00:14:24.448040 25375 net.cpp:198] encode1_unit_t=2 needs backward computation.
I1223 00:14:24.448045 25375 net.cpp:198] encode1_gate_input_2 needs backward computation.
I1223 00:14:24.448050 25375 net.cpp:198] encode1_concat_hadamard_t=2 needs backward computation.
I1223 00:14:24.448055 25375 net.cpp:200] encode1_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:24.448058 25375 net.cpp:198] encode1_hadamard->output_t=1 needs backward computation.
I1223 00:14:24.448062 25375 net.cpp:198] encode1_hadamard->forget_t=1 needs backward computation.
I1223 00:14:24.448066 25375 net.cpp:198] encode1_hadamard->input_t=1 needs backward computation.
I1223 00:14:24.448070 25375 net.cpp:198] encode1_hidden->transform->1 needs backward computation.
I1223 00:14:24.448073 25375 net.cpp:198] encode1_h_conted_t=1 needs backward computation.
I1223 00:14:24.448078 25375 net.cpp:198] h_t=1_encode1_unit_t=1_1_split needs backward computation.
I1223 00:14:24.448081 25375 net.cpp:198] c_t=1_encode1_unit_t=1_0_split needs backward computation.
I1223 00:14:24.448086 25375 net.cpp:198] encode1_unit_t=1 needs backward computation.
I1223 00:14:24.448091 25375 net.cpp:198] encode1_gate_input_1 needs backward computation.
I1223 00:14:24.448096 25375 net.cpp:198] encode1_concat_hadamard_t=1 needs backward computation.
I1223 00:14:24.448101 25375 net.cpp:200] encode1_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:24.448106 25375 net.cpp:198] encode1_hadamard->output_t=0 needs backward computation.
I1223 00:14:24.448109 25375 net.cpp:198] encode1_hadamard->forget_t=0 needs backward computation.
I1223 00:14:24.448112 25375 net.cpp:198] encode1_hadamard->input_t=0 needs backward computation.
I1223 00:14:24.448117 25375 net.cpp:198] encode1_hidden->transform->0 needs backward computation.
I1223 00:14:24.448120 25375 net.cpp:198] encode1_h_conted_t=0 needs backward computation.
I1223 00:14:24.448125 25375 net.cpp:198] encode1_dummy_forward_h0 needs backward computation.
I1223 00:14:24.448129 25375 net.cpp:198] c_t=0_encode1_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:24.448133 25375 net.cpp:198] encode1_dummy_forward_c0 needs backward computation.
I1223 00:14:24.448137 25375 net.cpp:200] cont_t=16_encode1_cont_slice_15_split does not need backward computation.
I1223 00:14:24.448143 25375 net.cpp:200] cont_t=15_encode1_cont_slice_14_split does not need backward computation.
I1223 00:14:24.448146 25375 net.cpp:200] cont_t=14_encode1_cont_slice_13_split does not need backward computation.
I1223 00:14:24.448149 25375 net.cpp:200] cont_t=13_encode1_cont_slice_12_split does not need backward computation.
I1223 00:14:24.448153 25375 net.cpp:200] cont_t=12_encode1_cont_slice_11_split does not need backward computation.
I1223 00:14:24.448158 25375 net.cpp:200] cont_t=11_encode1_cont_slice_10_split does not need backward computation.
I1223 00:14:24.448163 25375 net.cpp:200] cont_t=10_encode1_cont_slice_9_split does not need backward computation.
I1223 00:14:24.448166 25375 net.cpp:200] cont_t=9_encode1_cont_slice_8_split does not need backward computation.
I1223 00:14:24.448170 25375 net.cpp:200] cont_t=8_encode1_cont_slice_7_split does not need backward computation.
I1223 00:14:24.448174 25375 net.cpp:200] cont_t=7_encode1_cont_slice_6_split does not need backward computation.
I1223 00:14:24.448179 25375 net.cpp:200] cont_t=6_encode1_cont_slice_5_split does not need backward computation.
I1223 00:14:24.448182 25375 net.cpp:200] cont_t=5_encode1_cont_slice_4_split does not need backward computation.
I1223 00:14:24.448186 25375 net.cpp:200] cont_t=4_encode1_cont_slice_3_split does not need backward computation.
I1223 00:14:24.448190 25375 net.cpp:200] cont_t=3_encode1_cont_slice_2_split does not need backward computation.
I1223 00:14:24.448194 25375 net.cpp:200] cont_t=2_encode1_cont_slice_1_split does not need backward computation.
I1223 00:14:24.448199 25375 net.cpp:200] cont_t=1_encode1_cont_slice_0_split does not need backward computation.
I1223 00:14:24.448206 25375 net.cpp:200] encode1_cont_slice does not need backward computation.
I1223 00:14:24.448211 25375 net.cpp:198] encode1_W_xc_x_slice needs backward computation.
I1223 00:14:24.448215 25375 net.cpp:200] encode1_input->cell_hidden does not need backward computation.
I1223 00:14:24.448218 25375 net.cpp:198] encode1_x->transform needs backward computation.
I1223 00:14:24.448221 25375 net.cpp:200] encode1_ does not need backward computation.
I1223 00:14:24.448225 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:24.448228 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:24.448232 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:24.449215 25375 net.cpp:255] Network initialization done.
I1223 00:14:24.449625 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:24.449630 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:24.449635 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:24.449637 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:24.449640 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:24.449643 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:24.449645 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:24.449648 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:24.449651 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:24.449654 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:24.450340 25375 net.cpp:122] Setting up encode1
I1223 00:14:24.450351 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.450356 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.450361 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.450363 25375 net.cpp:137] Memory required for data: 4282253696
I1223 00:14:24.450378 25375 layer_factory.hpp:77] Creating layer encode2
I1223 00:14:24.450392 25375 net.cpp:84] Creating Layer encode2
I1223 00:14:24.450398 25375 net.cpp:406] encode2 <- conv6-reshape_reshape-data_0_split_1
I1223 00:14:24.450404 25375 net.cpp:406] encode2 <- reshape-cm_reshape-cm_0_split_1
I1223 00:14:24.450409 25375 net.cpp:406] encode2 <- dummy_dummy_0_split_2
I1223 00:14:24.450413 25375 net.cpp:406] encode2 <- dummy_dummy_0_split_3
I1223 00:14:24.450422 25375 net.cpp:380] encode2 -> encode2
I1223 00:14:24.450433 25375 net.cpp:380] encode2 -> encode2_h
I1223 00:14:24.450441 25375 net.cpp:380] encode2 -> encode2_c
I1223 00:14:24.450453 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:24.451894 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode2_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode2_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode2_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode2_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode2_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode2_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode2_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode2_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode2_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode2_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode2_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode2_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode2_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode2_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode2_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode2_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 2
  }
}
layer {
  name: "encode2_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode2_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode2_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode2_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode2_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode2_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode2_hidden->transfor
I1223 00:14:24.452849 25375 layer_factory.hpp:77] Creating layer encode2_
I1223 00:14:24.452859 25375 net.cpp:84] Creating Layer encode2_
I1223 00:14:24.452864 25375 net.cpp:380] encode2_ -> x
I1223 00:14:24.452872 25375 net.cpp:380] encode2_ -> cont
I1223 00:14:24.452936 25375 net.cpp:122] Setting up encode2_
I1223 00:14:24.452944 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.452949 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.452951 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:24.452955 25375 layer_factory.hpp:77] Creating layer encode2_x->transform
I1223 00:14:24.452963 25375 net.cpp:84] Creating Layer encode2_x->transform
I1223 00:14:24.452968 25375 net.cpp:406] encode2_x->transform <- x
I1223 00:14:24.452975 25375 net.cpp:380] encode2_x->transform -> x->transform
I1223 00:14:24.453269 25375 net.cpp:122] Setting up encode2_x->transform
I1223 00:14:24.453277 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:24.453281 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:24.453286 25375 layer_factory.hpp:77] Creating layer encode2_input->cell_hidden
I1223 00:14:24.453292 25375 net.cpp:84] Creating Layer encode2_input->cell_hidden
I1223 00:14:24.453297 25375 net.cpp:380] encode2_input->cell_hidden -> c_t=0
I1223 00:14:24.453305 25375 net.cpp:380] encode2_input->cell_hidden -> h_t=0
I1223 00:14:24.453342 25375 net.cpp:122] Setting up encode2_input->cell_hidden
I1223 00:14:24.453349 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.453353 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.453357 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:24.453359 25375 layer_factory.hpp:77] Creating layer encode2_W_xc_x_slice
I1223 00:14:24.453366 25375 net.cpp:84] Creating Layer encode2_W_xc_x_slice
I1223 00:14:24.453369 25375 net.cpp:406] encode2_W_xc_x_slice <- x->transform
I1223 00:14:24.453377 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=1
I1223 00:14:24.453384 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=2
I1223 00:14:24.453392 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=3
I1223 00:14:24.453399 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=4
I1223 00:14:24.453408 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=5
I1223 00:14:24.453418 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=6
I1223 00:14:24.453424 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=7
I1223 00:14:24.453431 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=8
I1223 00:14:24.453439 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=9
I1223 00:14:24.453447 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=10
I1223 00:14:24.453454 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=11
I1223 00:14:24.453462 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=12
I1223 00:14:24.453471 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=13
I1223 00:14:24.453480 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=14
I1223 00:14:24.453488 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=15
I1223 00:14:24.453496 25375 net.cpp:380] encode2_W_xc_x_slice -> x->transform->t=16
I1223 00:14:24.453692 25375 net.cpp:122] Setting up encode2_W_xc_x_slice
I1223 00:14:24.453699 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453704 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453708 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453712 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453716 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453721 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453724 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453728 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453732 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453737 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453740 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453745 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453749 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453752 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453757 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453761 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.453763 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:24.453766 25375 layer_factory.hpp:77] Creating layer encode2_cont_slice
I1223 00:14:24.453773 25375 net.cpp:84] Creating Layer encode2_cont_slice
I1223 00:14:24.453776 25375 net.cpp:406] encode2_cont_slice <- cont
I1223 00:14:24.453783 25375 net.cpp:380] encode2_cont_slice -> cont_t=1
I1223 00:14:24.453789 25375 net.cpp:380] encode2_cont_slice -> cont_t=2
I1223 00:14:24.453796 25375 net.cpp:380] encode2_cont_slice -> cont_t=3
I1223 00:14:24.453804 25375 net.cpp:380] encode2_cont_slice -> cont_t=4
I1223 00:14:24.453811 25375 net.cpp:380] encode2_cont_slice -> cont_t=5
I1223 00:14:24.453819 25375 net.cpp:380] encode2_cont_slice -> cont_t=6
I1223 00:14:24.453825 25375 net.cpp:380] encode2_cont_slice -> cont_t=7
I1223 00:14:24.453832 25375 net.cpp:380] encode2_cont_slice -> cont_t=8
I1223 00:14:24.453840 25375 net.cpp:380] encode2_cont_slice -> cont_t=9
I1223 00:14:24.453846 25375 net.cpp:380] encode2_cont_slice -> cont_t=10
I1223 00:14:24.453855 25375 net.cpp:380] encode2_cont_slice -> cont_t=11
I1223 00:14:24.453861 25375 net.cpp:380] encode2_cont_slice -> cont_t=12
I1223 00:14:24.453869 25375 net.cpp:380] encode2_cont_slice -> cont_t=13
I1223 00:14:24.453876 25375 net.cpp:380] encode2_cont_slice -> cont_t=14
I1223 00:14:24.453881 25375 net.cpp:380] encode2_cont_slice -> cont_t=15
I1223 00:14:24.453888 25375 net.cpp:380] encode2_cont_slice -> cont_t=16
I1223 00:14:24.454098 25375 net.cpp:122] Setting up encode2_cont_slice
I1223 00:14:24.454104 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454108 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454113 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454116 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454119 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454123 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454126 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454130 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454133 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454138 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454140 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454144 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454149 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454151 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454155 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454159 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454161 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:24.454164 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode2_cont_slice_0_split
I1223 00:14:24.454171 25375 net.cpp:84] Creating Layer cont_t=1_encode2_cont_slice_0_split
I1223 00:14:24.454175 25375 net.cpp:406] cont_t=1_encode2_cont_slice_0_split <- cont_t=1
I1223 00:14:24.454180 25375 net.cpp:380] cont_t=1_encode2_cont_slice_0_split -> cont_t=1_encode2_cont_slice_0_split_0
I1223 00:14:24.454186 25375 net.cpp:380] cont_t=1_encode2_cont_slice_0_split -> cont_t=1_encode2_cont_slice_0_split_1
I1223 00:14:24.454221 25375 net.cpp:122] Setting up cont_t=1_encode2_cont_slice_0_split
I1223 00:14:24.454227 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454231 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454233 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:24.454236 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode2_cont_slice_1_split
I1223 00:14:24.454242 25375 net.cpp:84] Creating Layer cont_t=2_encode2_cont_slice_1_split
I1223 00:14:24.454246 25375 net.cpp:406] cont_t=2_encode2_cont_slice_1_split <- cont_t=2
I1223 00:14:24.454250 25375 net.cpp:380] cont_t=2_encode2_cont_slice_1_split -> cont_t=2_encode2_cont_slice_1_split_0
I1223 00:14:24.454258 25375 net.cpp:380] cont_t=2_encode2_cont_slice_1_split -> cont_t=2_encode2_cont_slice_1_split_1
I1223 00:14:24.454293 25375 net.cpp:122] Setting up cont_t=2_encode2_cont_slice_1_split
I1223 00:14:24.454298 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454303 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454305 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:24.454308 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode2_cont_slice_2_split
I1223 00:14:24.454313 25375 net.cpp:84] Creating Layer cont_t=3_encode2_cont_slice_2_split
I1223 00:14:24.454316 25375 net.cpp:406] cont_t=3_encode2_cont_slice_2_split <- cont_t=3
I1223 00:14:24.454321 25375 net.cpp:380] cont_t=3_encode2_cont_slice_2_split -> cont_t=3_encode2_cont_slice_2_split_0
I1223 00:14:24.454329 25375 net.cpp:380] cont_t=3_encode2_cont_slice_2_split -> cont_t=3_encode2_cont_slice_2_split_1
I1223 00:14:24.454362 25375 net.cpp:122] Setting up cont_t=3_encode2_cont_slice_2_split
I1223 00:14:24.454368 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454372 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454375 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:24.454377 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode2_cont_slice_3_split
I1223 00:14:24.454383 25375 net.cpp:84] Creating Layer cont_t=4_encode2_cont_slice_3_split
I1223 00:14:24.454387 25375 net.cpp:406] cont_t=4_encode2_cont_slice_3_split <- cont_t=4
I1223 00:14:24.454392 25375 net.cpp:380] cont_t=4_encode2_cont_slice_3_split -> cont_t=4_encode2_cont_slice_3_split_0
I1223 00:14:24.454401 25375 net.cpp:380] cont_t=4_encode2_cont_slice_3_split -> cont_t=4_encode2_cont_slice_3_split_1
I1223 00:14:24.454432 25375 net.cpp:122] Setting up cont_t=4_encode2_cont_slice_3_split
I1223 00:14:24.454438 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454442 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454445 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:24.454447 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode2_cont_slice_4_split
I1223 00:14:24.454453 25375 net.cpp:84] Creating Layer cont_t=5_encode2_cont_slice_4_split
I1223 00:14:24.454457 25375 net.cpp:406] cont_t=5_encode2_cont_slice_4_split <- cont_t=5
I1223 00:14:24.454461 25375 net.cpp:380] cont_t=5_encode2_cont_slice_4_split -> cont_t=5_encode2_cont_slice_4_split_0
I1223 00:14:24.454468 25375 net.cpp:380] cont_t=5_encode2_cont_slice_4_split -> cont_t=5_encode2_cont_slice_4_split_1
I1223 00:14:24.454500 25375 net.cpp:122] Setting up cont_t=5_encode2_cont_slice_4_split
I1223 00:14:24.454506 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454510 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454512 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:24.454515 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode2_cont_slice_5_split
I1223 00:14:24.454521 25375 net.cpp:84] Creating Layer cont_t=6_encode2_cont_slice_5_split
I1223 00:14:24.454524 25375 net.cpp:406] cont_t=6_encode2_cont_slice_5_split <- cont_t=6
I1223 00:14:24.454530 25375 net.cpp:380] cont_t=6_encode2_cont_slice_5_split -> cont_t=6_encode2_cont_slice_5_split_0
I1223 00:14:24.454535 25375 net.cpp:380] cont_t=6_encode2_cont_slice_5_split -> cont_t=6_encode2_cont_slice_5_split_1
I1223 00:14:24.454568 25375 net.cpp:122] Setting up cont_t=6_encode2_cont_slice_5_split
I1223 00:14:24.454574 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454577 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454581 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:24.454583 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode2_cont_slice_6_split
I1223 00:14:24.454587 25375 net.cpp:84] Creating Layer cont_t=7_encode2_cont_slice_6_split
I1223 00:14:24.454591 25375 net.cpp:406] cont_t=7_encode2_cont_slice_6_split <- cont_t=7
I1223 00:14:24.454596 25375 net.cpp:380] cont_t=7_encode2_cont_slice_6_split -> cont_t=7_encode2_cont_slice_6_split_0
I1223 00:14:24.454602 25375 net.cpp:380] cont_t=7_encode2_cont_slice_6_split -> cont_t=7_encode2_cont_slice_6_split_1
I1223 00:14:24.454634 25375 net.cpp:122] Setting up cont_t=7_encode2_cont_slice_6_split
I1223 00:14:24.454640 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454643 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454646 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:24.454649 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode2_cont_slice_7_split
I1223 00:14:24.454653 25375 net.cpp:84] Creating Layer cont_t=8_encode2_cont_slice_7_split
I1223 00:14:24.454656 25375 net.cpp:406] cont_t=8_encode2_cont_slice_7_split <- cont_t=8
I1223 00:14:24.454663 25375 net.cpp:380] cont_t=8_encode2_cont_slice_7_split -> cont_t=8_encode2_cont_slice_7_split_0
I1223 00:14:24.454669 25375 net.cpp:380] cont_t=8_encode2_cont_slice_7_split -> cont_t=8_encode2_cont_slice_7_split_1
I1223 00:14:24.454701 25375 net.cpp:122] Setting up cont_t=8_encode2_cont_slice_7_split
I1223 00:14:24.454707 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454711 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454713 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:24.454716 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode2_cont_slice_8_split
I1223 00:14:24.454720 25375 net.cpp:84] Creating Layer cont_t=9_encode2_cont_slice_8_split
I1223 00:14:24.454725 25375 net.cpp:406] cont_t=9_encode2_cont_slice_8_split <- cont_t=9
I1223 00:14:24.454730 25375 net.cpp:380] cont_t=9_encode2_cont_slice_8_split -> cont_t=9_encode2_cont_slice_8_split_0
I1223 00:14:24.454735 25375 net.cpp:380] cont_t=9_encode2_cont_slice_8_split -> cont_t=9_encode2_cont_slice_8_split_1
I1223 00:14:24.454767 25375 net.cpp:122] Setting up cont_t=9_encode2_cont_slice_8_split
I1223 00:14:24.454774 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454777 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454780 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:24.454783 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode2_cont_slice_9_split
I1223 00:14:24.454787 25375 net.cpp:84] Creating Layer cont_t=10_encode2_cont_slice_9_split
I1223 00:14:24.454790 25375 net.cpp:406] cont_t=10_encode2_cont_slice_9_split <- cont_t=10
I1223 00:14:24.454797 25375 net.cpp:380] cont_t=10_encode2_cont_slice_9_split -> cont_t=10_encode2_cont_slice_9_split_0
I1223 00:14:24.454802 25375 net.cpp:380] cont_t=10_encode2_cont_slice_9_split -> cont_t=10_encode2_cont_slice_9_split_1
I1223 00:14:24.454835 25375 net.cpp:122] Setting up cont_t=10_encode2_cont_slice_9_split
I1223 00:14:24.454841 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454845 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454847 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:24.454850 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode2_cont_slice_10_split
I1223 00:14:24.454855 25375 net.cpp:84] Creating Layer cont_t=11_encode2_cont_slice_10_split
I1223 00:14:24.454859 25375 net.cpp:406] cont_t=11_encode2_cont_slice_10_split <- cont_t=11
I1223 00:14:24.454864 25375 net.cpp:380] cont_t=11_encode2_cont_slice_10_split -> cont_t=11_encode2_cont_slice_10_split_0
I1223 00:14:24.454869 25375 net.cpp:380] cont_t=11_encode2_cont_slice_10_split -> cont_t=11_encode2_cont_slice_10_split_1
I1223 00:14:24.454902 25375 net.cpp:122] Setting up cont_t=11_encode2_cont_slice_10_split
I1223 00:14:24.454907 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454911 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454915 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:24.454917 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode2_cont_slice_11_split
I1223 00:14:24.454926 25375 net.cpp:84] Creating Layer cont_t=12_encode2_cont_slice_11_split
I1223 00:14:24.454929 25375 net.cpp:406] cont_t=12_encode2_cont_slice_11_split <- cont_t=12
I1223 00:14:24.454934 25375 net.cpp:380] cont_t=12_encode2_cont_slice_11_split -> cont_t=12_encode2_cont_slice_11_split_0
I1223 00:14:24.454941 25375 net.cpp:380] cont_t=12_encode2_cont_slice_11_split -> cont_t=12_encode2_cont_slice_11_split_1
I1223 00:14:24.454973 25375 net.cpp:122] Setting up cont_t=12_encode2_cont_slice_11_split
I1223 00:14:24.454978 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454983 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.454985 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:24.454988 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode2_cont_slice_12_split
I1223 00:14:24.454993 25375 net.cpp:84] Creating Layer cont_t=13_encode2_cont_slice_12_split
I1223 00:14:24.454995 25375 net.cpp:406] cont_t=13_encode2_cont_slice_12_split <- cont_t=13
I1223 00:14:24.455000 25375 net.cpp:380] cont_t=13_encode2_cont_slice_12_split -> cont_t=13_encode2_cont_slice_12_split_0
I1223 00:14:24.455006 25375 net.cpp:380] cont_t=13_encode2_cont_slice_12_split -> cont_t=13_encode2_cont_slice_12_split_1
I1223 00:14:24.455039 25375 net.cpp:122] Setting up cont_t=13_encode2_cont_slice_12_split
I1223 00:14:24.455044 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455047 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455050 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:24.455054 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode2_cont_slice_13_split
I1223 00:14:24.455058 25375 net.cpp:84] Creating Layer cont_t=14_encode2_cont_slice_13_split
I1223 00:14:24.455061 25375 net.cpp:406] cont_t=14_encode2_cont_slice_13_split <- cont_t=14
I1223 00:14:24.455067 25375 net.cpp:380] cont_t=14_encode2_cont_slice_13_split -> cont_t=14_encode2_cont_slice_13_split_0
I1223 00:14:24.455073 25375 net.cpp:380] cont_t=14_encode2_cont_slice_13_split -> cont_t=14_encode2_cont_slice_13_split_1
I1223 00:14:24.455108 25375 net.cpp:122] Setting up cont_t=14_encode2_cont_slice_13_split
I1223 00:14:24.455114 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455119 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455122 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:24.455126 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode2_cont_slice_14_split
I1223 00:14:24.455129 25375 net.cpp:84] Creating Layer cont_t=15_encode2_cont_slice_14_split
I1223 00:14:24.455133 25375 net.cpp:406] cont_t=15_encode2_cont_slice_14_split <- cont_t=15
I1223 00:14:24.455137 25375 net.cpp:380] cont_t=15_encode2_cont_slice_14_split -> cont_t=15_encode2_cont_slice_14_split_0
I1223 00:14:24.455143 25375 net.cpp:380] cont_t=15_encode2_cont_slice_14_split -> cont_t=15_encode2_cont_slice_14_split_1
I1223 00:14:24.455176 25375 net.cpp:122] Setting up cont_t=15_encode2_cont_slice_14_split
I1223 00:14:24.455183 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455186 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455188 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:24.455191 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode2_cont_slice_15_split
I1223 00:14:24.455195 25375 net.cpp:84] Creating Layer cont_t=16_encode2_cont_slice_15_split
I1223 00:14:24.455199 25375 net.cpp:406] cont_t=16_encode2_cont_slice_15_split <- cont_t=16
I1223 00:14:24.455205 25375 net.cpp:380] cont_t=16_encode2_cont_slice_15_split -> cont_t=16_encode2_cont_slice_15_split_0
I1223 00:14:24.455211 25375 net.cpp:380] cont_t=16_encode2_cont_slice_15_split -> cont_t=16_encode2_cont_slice_15_split_1
I1223 00:14:24.455241 25375 net.cpp:122] Setting up cont_t=16_encode2_cont_slice_15_split
I1223 00:14:24.455247 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455251 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.455255 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:24.455256 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_c0
I1223 00:14:24.455263 25375 net.cpp:84] Creating Layer encode2_dummy_forward_c0
I1223 00:14:24.455267 25375 net.cpp:406] encode2_dummy_forward_c0 <- c_t=0
I1223 00:14:24.455271 25375 net.cpp:367] encode2_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:24.455292 25375 net.cpp:122] Setting up encode2_dummy_forward_c0
I1223 00:14:24.455298 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.455302 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:24.455308 25375 layer_factory.hpp:77] Creating layer c_t=0_encode2_dummy_forward_c0_0_split
I1223 00:14:24.455314 25375 net.cpp:84] Creating Layer c_t=0_encode2_dummy_forward_c0_0_split
I1223 00:14:24.455317 25375 net.cpp:406] c_t=0_encode2_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:24.455323 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_0
I1223 00:14:24.455329 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_1
I1223 00:14:24.455337 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_2
I1223 00:14:24.455343 25375 net.cpp:380] c_t=0_encode2_dummy_forward_c0_0_split -> c_t=0_encode2_dummy_forward_c0_0_split_3
I1223 00:14:24.455411 25375 net.cpp:122] Setting up c_t=0_encode2_dummy_forward_c0_0_split
I1223 00:14:24.455417 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.455422 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.455426 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.455430 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.455433 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:24.455436 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_h0
I1223 00:14:24.455440 25375 net.cpp:84] Creating Layer encode2_dummy_forward_h0
I1223 00:14:24.455444 25375 net.cpp:406] encode2_dummy_forward_h0 <- h_t=0
I1223 00:14:24.455451 25375 net.cpp:367] encode2_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:24.455472 25375 net.cpp:122] Setting up encode2_dummy_forward_h0
I1223 00:14:24.455477 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.455482 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:24.455487 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=0
I1223 00:14:24.455492 25375 net.cpp:84] Creating Layer encode2_h_conted_t=0
I1223 00:14:24.455495 25375 net.cpp:406] encode2_h_conted_t=0 <- h_t=0
I1223 00:14:24.455499 25375 net.cpp:406] encode2_h_conted_t=0 <- cont_t=1_encode2_cont_slice_0_split_0
I1223 00:14:24.455507 25375 net.cpp:380] encode2_h_conted_t=0 -> h_conted_t=0
I1223 00:14:24.455588 25375 net.cpp:122] Setting up encode2_h_conted_t=0
I1223 00:14:24.455595 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.455598 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:24.455601 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->0
I1223 00:14:24.455610 25375 net.cpp:84] Creating Layer encode2_hidden->transform->0
I1223 00:14:24.455615 25375 net.cpp:406] encode2_hidden->transform->0 <- h_conted_t=0
I1223 00:14:24.455622 25375 net.cpp:380] encode2_hidden->transform->0 -> hidden->transform->0
I1223 00:14:24.456137 25375 net.cpp:122] Setting up encode2_hidden->transform->0
I1223 00:14:24.456146 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.456148 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:24.456156 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=0
I1223 00:14:24.456162 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=0
I1223 00:14:24.456166 25375 net.cpp:406] encode2_hadamard->input_t=0 <- c_t=0_encode2_dummy_forward_c0_0_split_0
I1223 00:14:24.456173 25375 net.cpp:380] encode2_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:24.456274 25375 net.cpp:122] Setting up encode2_hadamard->input_t=0
I1223 00:14:24.456281 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456284 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:24.456288 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=0
I1223 00:14:24.456295 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=0
I1223 00:14:24.456298 25375 net.cpp:406] encode2_hadamard->forget_t=0 <- c_t=0_encode2_dummy_forward_c0_0_split_1
I1223 00:14:24.456305 25375 net.cpp:380] encode2_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:24.456395 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=0
I1223 00:14:24.456403 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456406 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:24.456410 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=0
I1223 00:14:24.456416 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=0
I1223 00:14:24.456420 25375 net.cpp:406] encode2_hadamard->output_t=0 <- c_t=0_encode2_dummy_forward_c0_0_split_2
I1223 00:14:24.456425 25375 net.cpp:380] encode2_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:24.456517 25375 net.cpp:122] Setting up encode2_hadamard->output_t=0
I1223 00:14:24.456524 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456527 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:24.456532 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=1
I1223 00:14:24.456539 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=1
I1223 00:14:24.456543 25375 net.cpp:380] encode2_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:24.456601 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=1
I1223 00:14:24.456607 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456610 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:24.456614 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=1
I1223 00:14:24.456619 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=1
I1223 00:14:24.456624 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:24.456627 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:24.456631 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:24.456636 25375 net.cpp:406] encode2_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:24.456641 25375 net.cpp:380] encode2_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:24.456665 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=1
I1223 00:14:24.456672 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.456676 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:24.456678 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_1
I1223 00:14:24.456684 25375 net.cpp:84] Creating Layer encode2_gate_input_1
I1223 00:14:24.456687 25375 net.cpp:406] encode2_gate_input_1 <- hidden->transform->0
I1223 00:14:24.456692 25375 net.cpp:406] encode2_gate_input_1 <- x->transform->t=1
I1223 00:14:24.456696 25375 net.cpp:406] encode2_gate_input_1 <- hadamard_t=1
I1223 00:14:24.456702 25375 net.cpp:380] encode2_gate_input_1 -> gate_input_1
I1223 00:14:24.456724 25375 net.cpp:122] Setting up encode2_gate_input_1
I1223 00:14:24.456730 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.456733 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:24.456737 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=1
I1223 00:14:24.456744 25375 net.cpp:84] Creating Layer encode2_unit_t=1
I1223 00:14:24.456748 25375 net.cpp:406] encode2_unit_t=1 <- c_t=0_encode2_dummy_forward_c0_0_split_3
I1223 00:14:24.456753 25375 net.cpp:406] encode2_unit_t=1 <- gate_input_1
I1223 00:14:24.456758 25375 net.cpp:406] encode2_unit_t=1 <- cont_t=1_encode2_cont_slice_0_split_1
I1223 00:14:24.456763 25375 net.cpp:380] encode2_unit_t=1 -> c_t=1
I1223 00:14:24.456769 25375 net.cpp:380] encode2_unit_t=1 -> h_t=1
I1223 00:14:24.456817 25375 net.cpp:122] Setting up encode2_unit_t=1
I1223 00:14:24.456823 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456827 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456830 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:24.456833 25375 layer_factory.hpp:77] Creating layer c_t=1_encode2_unit_t=1_0_split
I1223 00:14:24.456838 25375 net.cpp:84] Creating Layer c_t=1_encode2_unit_t=1_0_split
I1223 00:14:24.456843 25375 net.cpp:406] c_t=1_encode2_unit_t=1_0_split <- c_t=1
I1223 00:14:24.456849 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_0
I1223 00:14:24.456856 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_1
I1223 00:14:24.456866 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_2
I1223 00:14:24.456871 25375 net.cpp:380] c_t=1_encode2_unit_t=1_0_split -> c_t=1_encode2_unit_t=1_0_split_3
I1223 00:14:24.456929 25375 net.cpp:122] Setting up c_t=1_encode2_unit_t=1_0_split
I1223 00:14:24.456935 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456939 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456943 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456948 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.456950 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:24.456954 25375 layer_factory.hpp:77] Creating layer h_t=1_encode2_unit_t=1_1_split
I1223 00:14:24.456959 25375 net.cpp:84] Creating Layer h_t=1_encode2_unit_t=1_1_split
I1223 00:14:24.456962 25375 net.cpp:406] h_t=1_encode2_unit_t=1_1_split <- h_t=1
I1223 00:14:24.456969 25375 net.cpp:380] h_t=1_encode2_unit_t=1_1_split -> h_t=1_encode2_unit_t=1_1_split_0
I1223 00:14:24.456974 25375 net.cpp:380] h_t=1_encode2_unit_t=1_1_split -> h_t=1_encode2_unit_t=1_1_split_1
I1223 00:14:24.457007 25375 net.cpp:122] Setting up h_t=1_encode2_unit_t=1_1_split
I1223 00:14:24.457015 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.457018 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.457020 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:24.457023 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=1
I1223 00:14:24.457029 25375 net.cpp:84] Creating Layer encode2_h_conted_t=1
I1223 00:14:24.457032 25375 net.cpp:406] encode2_h_conted_t=1 <- h_t=1_encode2_unit_t=1_1_split_0
I1223 00:14:24.457037 25375 net.cpp:406] encode2_h_conted_t=1 <- cont_t=2_encode2_cont_slice_1_split_0
I1223 00:14:24.457042 25375 net.cpp:380] encode2_h_conted_t=1 -> h_conted_t=1
I1223 00:14:24.457128 25375 net.cpp:122] Setting up encode2_h_conted_t=1
I1223 00:14:24.457134 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.457137 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:24.457140 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->1
I1223 00:14:24.457152 25375 net.cpp:84] Creating Layer encode2_hidden->transform->1
I1223 00:14:24.457159 25375 net.cpp:406] encode2_hidden->transform->1 <- h_conted_t=1
I1223 00:14:24.457165 25375 net.cpp:380] encode2_hidden->transform->1 -> hidden->transform->1
I1223 00:14:24.457675 25375 net.cpp:122] Setting up encode2_hidden->transform->1
I1223 00:14:24.457684 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.457686 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:24.457691 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.457695 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.457700 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=1
I1223 00:14:24.457706 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=1
I1223 00:14:24.457710 25375 net.cpp:406] encode2_hadamard->input_t=1 <- c_t=1_encode2_unit_t=1_0_split_0
I1223 00:14:24.457715 25375 net.cpp:380] encode2_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:24.457805 25375 net.cpp:122] Setting up encode2_hadamard->input_t=1
I1223 00:14:24.457813 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.457816 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:24.457819 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.457823 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=1
I1223 00:14:24.457828 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=1
I1223 00:14:24.457831 25375 net.cpp:406] encode2_hadamard->forget_t=1 <- c_t=1_encode2_unit_t=1_0_split_1
I1223 00:14:24.457839 25375 net.cpp:380] encode2_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:24.457934 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=1
I1223 00:14:24.457942 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.457945 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:24.457948 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.457952 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=1
I1223 00:14:24.457958 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=1
I1223 00:14:24.457962 25375 net.cpp:406] encode2_hadamard->output_t=1 <- c_t=1_encode2_unit_t=1_0_split_2
I1223 00:14:24.457967 25375 net.cpp:380] encode2_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:24.458058 25375 net.cpp:122] Setting up encode2_hadamard->output_t=1
I1223 00:14:24.458065 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458068 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:24.458071 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.458076 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=2
I1223 00:14:24.458081 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=2
I1223 00:14:24.458086 25375 net.cpp:380] encode2_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:24.458139 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=2
I1223 00:14:24.458147 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458149 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:24.458153 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=2
I1223 00:14:24.458159 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=2
I1223 00:14:24.458163 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:24.458168 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:24.458173 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:24.458176 25375 net.cpp:406] encode2_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:24.458181 25375 net.cpp:380] encode2_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:24.458204 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=2
I1223 00:14:24.458211 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.458214 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:24.458217 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_2
I1223 00:14:24.458223 25375 net.cpp:84] Creating Layer encode2_gate_input_2
I1223 00:14:24.458227 25375 net.cpp:406] encode2_gate_input_2 <- hidden->transform->1
I1223 00:14:24.458232 25375 net.cpp:406] encode2_gate_input_2 <- x->transform->t=2
I1223 00:14:24.458236 25375 net.cpp:406] encode2_gate_input_2 <- hadamard_t=2
I1223 00:14:24.458241 25375 net.cpp:380] encode2_gate_input_2 -> gate_input_2
I1223 00:14:24.458267 25375 net.cpp:122] Setting up encode2_gate_input_2
I1223 00:14:24.458273 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.458276 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:24.458279 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=2
I1223 00:14:24.458284 25375 net.cpp:84] Creating Layer encode2_unit_t=2
I1223 00:14:24.458288 25375 net.cpp:406] encode2_unit_t=2 <- c_t=1_encode2_unit_t=1_0_split_3
I1223 00:14:24.458294 25375 net.cpp:406] encode2_unit_t=2 <- gate_input_2
I1223 00:14:24.458298 25375 net.cpp:406] encode2_unit_t=2 <- cont_t=2_encode2_cont_slice_1_split_1
I1223 00:14:24.458303 25375 net.cpp:380] encode2_unit_t=2 -> c_t=2
I1223 00:14:24.458310 25375 net.cpp:380] encode2_unit_t=2 -> h_t=2
I1223 00:14:24.458359 25375 net.cpp:122] Setting up encode2_unit_t=2
I1223 00:14:24.458364 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458369 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458371 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:24.458374 25375 layer_factory.hpp:77] Creating layer c_t=2_encode2_unit_t=2_0_split
I1223 00:14:24.458379 25375 net.cpp:84] Creating Layer c_t=2_encode2_unit_t=2_0_split
I1223 00:14:24.458382 25375 net.cpp:406] c_t=2_encode2_unit_t=2_0_split <- c_t=2
I1223 00:14:24.458389 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_0
I1223 00:14:24.458396 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_1
I1223 00:14:24.458403 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_2
I1223 00:14:24.458412 25375 net.cpp:380] c_t=2_encode2_unit_t=2_0_split -> c_t=2_encode2_unit_t=2_0_split_3
I1223 00:14:24.458470 25375 net.cpp:122] Setting up c_t=2_encode2_unit_t=2_0_split
I1223 00:14:24.458477 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458482 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458485 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458489 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458492 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:24.458495 25375 layer_factory.hpp:77] Creating layer h_t=2_encode2_unit_t=2_1_split
I1223 00:14:24.458500 25375 net.cpp:84] Creating Layer h_t=2_encode2_unit_t=2_1_split
I1223 00:14:24.458503 25375 net.cpp:406] h_t=2_encode2_unit_t=2_1_split <- h_t=2
I1223 00:14:24.458508 25375 net.cpp:380] h_t=2_encode2_unit_t=2_1_split -> h_t=2_encode2_unit_t=2_1_split_0
I1223 00:14:24.458515 25375 net.cpp:380] h_t=2_encode2_unit_t=2_1_split -> h_t=2_encode2_unit_t=2_1_split_1
I1223 00:14:24.458549 25375 net.cpp:122] Setting up h_t=2_encode2_unit_t=2_1_split
I1223 00:14:24.458554 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458559 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458561 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:24.458564 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=2
I1223 00:14:24.458570 25375 net.cpp:84] Creating Layer encode2_h_conted_t=2
I1223 00:14:24.458573 25375 net.cpp:406] encode2_h_conted_t=2 <- h_t=2_encode2_unit_t=2_1_split_0
I1223 00:14:24.458578 25375 net.cpp:406] encode2_h_conted_t=2 <- cont_t=3_encode2_cont_slice_2_split_0
I1223 00:14:24.458585 25375 net.cpp:380] encode2_h_conted_t=2 -> h_conted_t=2
I1223 00:14:24.458663 25375 net.cpp:122] Setting up encode2_h_conted_t=2
I1223 00:14:24.458670 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.458673 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:24.458676 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->2
I1223 00:14:24.458684 25375 net.cpp:84] Creating Layer encode2_hidden->transform->2
I1223 00:14:24.458688 25375 net.cpp:406] encode2_hidden->transform->2 <- h_conted_t=2
I1223 00:14:24.458695 25375 net.cpp:380] encode2_hidden->transform->2 -> hidden->transform->2
I1223 00:14:24.459194 25375 net.cpp:122] Setting up encode2_hidden->transform->2
I1223 00:14:24.459203 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.459205 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:24.459209 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.459213 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.459216 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=2
I1223 00:14:24.459223 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=2
I1223 00:14:24.459225 25375 net.cpp:406] encode2_hadamard->input_t=2 <- c_t=2_encode2_unit_t=2_0_split_0
I1223 00:14:24.459233 25375 net.cpp:380] encode2_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:24.459331 25375 net.cpp:122] Setting up encode2_hadamard->input_t=2
I1223 00:14:24.459339 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.459342 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:24.459345 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.459349 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=2
I1223 00:14:24.459354 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=2
I1223 00:14:24.459358 25375 net.cpp:406] encode2_hadamard->forget_t=2 <- c_t=2_encode2_unit_t=2_0_split_1
I1223 00:14:24.459364 25375 net.cpp:380] encode2_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:24.459462 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=2
I1223 00:14:24.459470 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.459473 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:24.459478 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.459482 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=2
I1223 00:14:24.459489 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=2
I1223 00:14:24.459492 25375 net.cpp:406] encode2_hadamard->output_t=2 <- c_t=2_encode2_unit_t=2_0_split_2
I1223 00:14:24.459498 25375 net.cpp:380] encode2_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:24.459583 25375 net.cpp:122] Setting up encode2_hadamard->output_t=2
I1223 00:14:24.459589 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.459592 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:24.459596 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.459599 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=3
I1223 00:14:24.459606 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=3
I1223 00:14:24.459610 25375 net.cpp:380] encode2_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:24.459667 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=3
I1223 00:14:24.459674 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.459677 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:24.459681 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=3
I1223 00:14:24.459686 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=3
I1223 00:14:24.459689 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:24.459694 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:24.459698 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:24.459702 25375 net.cpp:406] encode2_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:24.459707 25375 net.cpp:380] encode2_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:24.459733 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=3
I1223 00:14:24.459739 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.459743 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:24.459745 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_3
I1223 00:14:24.459751 25375 net.cpp:84] Creating Layer encode2_gate_input_3
I1223 00:14:24.459754 25375 net.cpp:406] encode2_gate_input_3 <- hidden->transform->2
I1223 00:14:24.459759 25375 net.cpp:406] encode2_gate_input_3 <- x->transform->t=3
I1223 00:14:24.459764 25375 net.cpp:406] encode2_gate_input_3 <- hadamard_t=3
I1223 00:14:24.459770 25375 net.cpp:380] encode2_gate_input_3 -> gate_input_3
I1223 00:14:24.459791 25375 net.cpp:122] Setting up encode2_gate_input_3
I1223 00:14:24.459798 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.459801 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:24.459805 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=3
I1223 00:14:24.459810 25375 net.cpp:84] Creating Layer encode2_unit_t=3
I1223 00:14:24.459815 25375 net.cpp:406] encode2_unit_t=3 <- c_t=2_encode2_unit_t=2_0_split_3
I1223 00:14:24.459818 25375 net.cpp:406] encode2_unit_t=3 <- gate_input_3
I1223 00:14:24.459823 25375 net.cpp:406] encode2_unit_t=3 <- cont_t=3_encode2_cont_slice_2_split_1
I1223 00:14:24.459828 25375 net.cpp:380] encode2_unit_t=3 -> c_t=3
I1223 00:14:24.459834 25375 net.cpp:380] encode2_unit_t=3 -> h_t=3
I1223 00:14:24.459882 25375 net.cpp:122] Setting up encode2_unit_t=3
I1223 00:14:24.459888 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.459892 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.459895 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:24.459898 25375 layer_factory.hpp:77] Creating layer c_t=3_encode2_unit_t=3_0_split
I1223 00:14:24.459903 25375 net.cpp:84] Creating Layer c_t=3_encode2_unit_t=3_0_split
I1223 00:14:24.459906 25375 net.cpp:406] c_t=3_encode2_unit_t=3_0_split <- c_t=3
I1223 00:14:24.459916 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_0
I1223 00:14:24.459925 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_1
I1223 00:14:24.459933 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_2
I1223 00:14:24.459941 25375 net.cpp:380] c_t=3_encode2_unit_t=3_0_split -> c_t=3_encode2_unit_t=3_0_split_3
I1223 00:14:24.460000 25375 net.cpp:122] Setting up c_t=3_encode2_unit_t=3_0_split
I1223 00:14:24.460005 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460011 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460014 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460018 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460021 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:24.460024 25375 layer_factory.hpp:77] Creating layer h_t=3_encode2_unit_t=3_1_split
I1223 00:14:24.460028 25375 net.cpp:84] Creating Layer h_t=3_encode2_unit_t=3_1_split
I1223 00:14:24.460031 25375 net.cpp:406] h_t=3_encode2_unit_t=3_1_split <- h_t=3
I1223 00:14:24.460036 25375 net.cpp:380] h_t=3_encode2_unit_t=3_1_split -> h_t=3_encode2_unit_t=3_1_split_0
I1223 00:14:24.460043 25375 net.cpp:380] h_t=3_encode2_unit_t=3_1_split -> h_t=3_encode2_unit_t=3_1_split_1
I1223 00:14:24.460077 25375 net.cpp:122] Setting up h_t=3_encode2_unit_t=3_1_split
I1223 00:14:24.460083 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460088 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460090 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:24.460093 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=3
I1223 00:14:24.460099 25375 net.cpp:84] Creating Layer encode2_h_conted_t=3
I1223 00:14:24.460103 25375 net.cpp:406] encode2_h_conted_t=3 <- h_t=3_encode2_unit_t=3_1_split_0
I1223 00:14:24.460108 25375 net.cpp:406] encode2_h_conted_t=3 <- cont_t=4_encode2_cont_slice_3_split_0
I1223 00:14:24.460113 25375 net.cpp:380] encode2_h_conted_t=3 -> h_conted_t=3
I1223 00:14:24.460191 25375 net.cpp:122] Setting up encode2_h_conted_t=3
I1223 00:14:24.460197 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460201 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:24.460203 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->3
I1223 00:14:24.460212 25375 net.cpp:84] Creating Layer encode2_hidden->transform->3
I1223 00:14:24.460217 25375 net.cpp:406] encode2_hidden->transform->3 <- h_conted_t=3
I1223 00:14:24.460224 25375 net.cpp:380] encode2_hidden->transform->3 -> hidden->transform->3
I1223 00:14:24.460728 25375 net.cpp:122] Setting up encode2_hidden->transform->3
I1223 00:14:24.460736 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.460739 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:24.460743 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.460747 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.460750 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=3
I1223 00:14:24.460757 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=3
I1223 00:14:24.460762 25375 net.cpp:406] encode2_hadamard->input_t=3 <- c_t=3_encode2_unit_t=3_0_split_0
I1223 00:14:24.460768 25375 net.cpp:380] encode2_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:24.460865 25375 net.cpp:122] Setting up encode2_hadamard->input_t=3
I1223 00:14:24.460871 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.460875 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:24.460878 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.460882 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=3
I1223 00:14:24.460888 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=3
I1223 00:14:24.460892 25375 net.cpp:406] encode2_hadamard->forget_t=3 <- c_t=3_encode2_unit_t=3_0_split_1
I1223 00:14:24.460899 25375 net.cpp:380] encode2_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:24.460989 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=3
I1223 00:14:24.460996 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461000 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:24.461004 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.461007 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=3
I1223 00:14:24.461014 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=3
I1223 00:14:24.461017 25375 net.cpp:406] encode2_hadamard->output_t=3 <- c_t=3_encode2_unit_t=3_0_split_2
I1223 00:14:24.461022 25375 net.cpp:380] encode2_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:24.461127 25375 net.cpp:122] Setting up encode2_hadamard->output_t=3
I1223 00:14:24.461134 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461138 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:24.461141 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.461144 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=4
I1223 00:14:24.461151 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=4
I1223 00:14:24.461156 25375 net.cpp:380] encode2_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:24.461212 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=4
I1223 00:14:24.461218 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461221 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:24.461225 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=4
I1223 00:14:24.461230 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=4
I1223 00:14:24.461235 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:24.461238 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:24.461243 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:24.461247 25375 net.cpp:406] encode2_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:24.461252 25375 net.cpp:380] encode2_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:24.461277 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=4
I1223 00:14:24.461283 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.461287 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:24.461289 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_4
I1223 00:14:24.461297 25375 net.cpp:84] Creating Layer encode2_gate_input_4
I1223 00:14:24.461302 25375 net.cpp:406] encode2_gate_input_4 <- hidden->transform->3
I1223 00:14:24.461308 25375 net.cpp:406] encode2_gate_input_4 <- x->transform->t=4
I1223 00:14:24.461311 25375 net.cpp:406] encode2_gate_input_4 <- hadamard_t=4
I1223 00:14:24.461316 25375 net.cpp:380] encode2_gate_input_4 -> gate_input_4
I1223 00:14:24.461344 25375 net.cpp:122] Setting up encode2_gate_input_4
I1223 00:14:24.461351 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.461354 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:24.461359 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=4
I1223 00:14:24.461364 25375 net.cpp:84] Creating Layer encode2_unit_t=4
I1223 00:14:24.461367 25375 net.cpp:406] encode2_unit_t=4 <- c_t=3_encode2_unit_t=3_0_split_3
I1223 00:14:24.461371 25375 net.cpp:406] encode2_unit_t=4 <- gate_input_4
I1223 00:14:24.461375 25375 net.cpp:406] encode2_unit_t=4 <- cont_t=4_encode2_cont_slice_3_split_1
I1223 00:14:24.461381 25375 net.cpp:380] encode2_unit_t=4 -> c_t=4
I1223 00:14:24.461387 25375 net.cpp:380] encode2_unit_t=4 -> h_t=4
I1223 00:14:24.461437 25375 net.cpp:122] Setting up encode2_unit_t=4
I1223 00:14:24.461443 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461448 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461452 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:24.461454 25375 layer_factory.hpp:77] Creating layer c_t=4_encode2_unit_t=4_0_split
I1223 00:14:24.461459 25375 net.cpp:84] Creating Layer c_t=4_encode2_unit_t=4_0_split
I1223 00:14:24.461463 25375 net.cpp:406] c_t=4_encode2_unit_t=4_0_split <- c_t=4
I1223 00:14:24.461468 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_0
I1223 00:14:24.461475 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_1
I1223 00:14:24.461484 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_2
I1223 00:14:24.461491 25375 net.cpp:380] c_t=4_encode2_unit_t=4_0_split -> c_t=4_encode2_unit_t=4_0_split_3
I1223 00:14:24.461554 25375 net.cpp:122] Setting up c_t=4_encode2_unit_t=4_0_split
I1223 00:14:24.461560 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461565 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461568 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461572 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461575 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:24.461578 25375 layer_factory.hpp:77] Creating layer h_t=4_encode2_unit_t=4_1_split
I1223 00:14:24.461585 25375 net.cpp:84] Creating Layer h_t=4_encode2_unit_t=4_1_split
I1223 00:14:24.461587 25375 net.cpp:406] h_t=4_encode2_unit_t=4_1_split <- h_t=4
I1223 00:14:24.461592 25375 net.cpp:380] h_t=4_encode2_unit_t=4_1_split -> h_t=4_encode2_unit_t=4_1_split_0
I1223 00:14:24.461598 25375 net.cpp:380] h_t=4_encode2_unit_t=4_1_split -> h_t=4_encode2_unit_t=4_1_split_1
I1223 00:14:24.461632 25375 net.cpp:122] Setting up h_t=4_encode2_unit_t=4_1_split
I1223 00:14:24.461638 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461643 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461645 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:24.461649 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=4
I1223 00:14:24.461655 25375 net.cpp:84] Creating Layer encode2_h_conted_t=4
I1223 00:14:24.461658 25375 net.cpp:406] encode2_h_conted_t=4 <- h_t=4_encode2_unit_t=4_1_split_0
I1223 00:14:24.461663 25375 net.cpp:406] encode2_h_conted_t=4 <- cont_t=5_encode2_cont_slice_4_split_0
I1223 00:14:24.461669 25375 net.cpp:380] encode2_h_conted_t=4 -> h_conted_t=4
I1223 00:14:24.461752 25375 net.cpp:122] Setting up encode2_h_conted_t=4
I1223 00:14:24.461758 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.461761 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:24.461766 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->4
I1223 00:14:24.461774 25375 net.cpp:84] Creating Layer encode2_hidden->transform->4
I1223 00:14:24.461778 25375 net.cpp:406] encode2_hidden->transform->4 <- h_conted_t=4
I1223 00:14:24.461784 25375 net.cpp:380] encode2_hidden->transform->4 -> hidden->transform->4
I1223 00:14:24.462291 25375 net.cpp:122] Setting up encode2_hidden->transform->4
I1223 00:14:24.462298 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.462301 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:24.462306 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.462309 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.462312 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=4
I1223 00:14:24.462318 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=4
I1223 00:14:24.462321 25375 net.cpp:406] encode2_hadamard->input_t=4 <- c_t=4_encode2_unit_t=4_0_split_0
I1223 00:14:24.462328 25375 net.cpp:380] encode2_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:24.462419 25375 net.cpp:122] Setting up encode2_hadamard->input_t=4
I1223 00:14:24.462425 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.462429 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:24.462432 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.462435 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=4
I1223 00:14:24.462442 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=4
I1223 00:14:24.462445 25375 net.cpp:406] encode2_hadamard->forget_t=4 <- c_t=4_encode2_unit_t=4_0_split_1
I1223 00:14:24.462451 25375 net.cpp:380] encode2_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:24.462544 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=4
I1223 00:14:24.462551 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.462554 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:24.462558 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.462561 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=4
I1223 00:14:24.462568 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=4
I1223 00:14:24.462570 25375 net.cpp:406] encode2_hadamard->output_t=4 <- c_t=4_encode2_unit_t=4_0_split_2
I1223 00:14:24.462577 25375 net.cpp:380] encode2_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:24.462669 25375 net.cpp:122] Setting up encode2_hadamard->output_t=4
I1223 00:14:24.462677 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.462680 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:24.462684 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.462688 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=5
I1223 00:14:24.462693 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=5
I1223 00:14:24.462698 25375 net.cpp:380] encode2_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:24.462754 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=5
I1223 00:14:24.462761 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.462764 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:24.462767 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=5
I1223 00:14:24.462772 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=5
I1223 00:14:24.462776 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:24.462781 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:24.462785 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:24.462790 25375 net.cpp:406] encode2_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:24.462796 25375 net.cpp:380] encode2_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:24.462821 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=5
I1223 00:14:24.462827 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.462831 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:24.462833 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_5
I1223 00:14:24.462838 25375 net.cpp:84] Creating Layer encode2_gate_input_5
I1223 00:14:24.462842 25375 net.cpp:406] encode2_gate_input_5 <- hidden->transform->4
I1223 00:14:24.462847 25375 net.cpp:406] encode2_gate_input_5 <- x->transform->t=5
I1223 00:14:24.462852 25375 net.cpp:406] encode2_gate_input_5 <- hadamard_t=5
I1223 00:14:24.462857 25375 net.cpp:380] encode2_gate_input_5 -> gate_input_5
I1223 00:14:24.462879 25375 net.cpp:122] Setting up encode2_gate_input_5
I1223 00:14:24.462888 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.462890 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:24.462893 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=5
I1223 00:14:24.462898 25375 net.cpp:84] Creating Layer encode2_unit_t=5
I1223 00:14:24.462903 25375 net.cpp:406] encode2_unit_t=5 <- c_t=4_encode2_unit_t=4_0_split_3
I1223 00:14:24.462906 25375 net.cpp:406] encode2_unit_t=5 <- gate_input_5
I1223 00:14:24.462910 25375 net.cpp:406] encode2_unit_t=5 <- cont_t=5_encode2_cont_slice_4_split_1
I1223 00:14:24.462915 25375 net.cpp:380] encode2_unit_t=5 -> c_t=5
I1223 00:14:24.462924 25375 net.cpp:380] encode2_unit_t=5 -> h_t=5
I1223 00:14:24.462972 25375 net.cpp:122] Setting up encode2_unit_t=5
I1223 00:14:24.462980 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.462983 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.462986 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:24.462990 25375 layer_factory.hpp:77] Creating layer c_t=5_encode2_unit_t=5_0_split
I1223 00:14:24.462994 25375 net.cpp:84] Creating Layer c_t=5_encode2_unit_t=5_0_split
I1223 00:14:24.462997 25375 net.cpp:406] c_t=5_encode2_unit_t=5_0_split <- c_t=5
I1223 00:14:24.463003 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_0
I1223 00:14:24.463011 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_1
I1223 00:14:24.463017 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_2
I1223 00:14:24.463024 25375 net.cpp:380] c_t=5_encode2_unit_t=5_0_split -> c_t=5_encode2_unit_t=5_0_split_3
I1223 00:14:24.463083 25375 net.cpp:122] Setting up c_t=5_encode2_unit_t=5_0_split
I1223 00:14:24.463088 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463093 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463098 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463101 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463104 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:24.463107 25375 layer_factory.hpp:77] Creating layer h_t=5_encode2_unit_t=5_1_split
I1223 00:14:24.463115 25375 net.cpp:84] Creating Layer h_t=5_encode2_unit_t=5_1_split
I1223 00:14:24.463120 25375 net.cpp:406] h_t=5_encode2_unit_t=5_1_split <- h_t=5
I1223 00:14:24.463125 25375 net.cpp:380] h_t=5_encode2_unit_t=5_1_split -> h_t=5_encode2_unit_t=5_1_split_0
I1223 00:14:24.463132 25375 net.cpp:380] h_t=5_encode2_unit_t=5_1_split -> h_t=5_encode2_unit_t=5_1_split_1
I1223 00:14:24.463165 25375 net.cpp:122] Setting up h_t=5_encode2_unit_t=5_1_split
I1223 00:14:24.463172 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463176 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463179 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:24.463182 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=5
I1223 00:14:24.463187 25375 net.cpp:84] Creating Layer encode2_h_conted_t=5
I1223 00:14:24.463191 25375 net.cpp:406] encode2_h_conted_t=5 <- h_t=5_encode2_unit_t=5_1_split_0
I1223 00:14:24.463196 25375 net.cpp:406] encode2_h_conted_t=5 <- cont_t=6_encode2_cont_slice_5_split_0
I1223 00:14:24.463201 25375 net.cpp:380] encode2_h_conted_t=5 -> h_conted_t=5
I1223 00:14:24.463284 25375 net.cpp:122] Setting up encode2_h_conted_t=5
I1223 00:14:24.463291 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463294 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:24.463297 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->5
I1223 00:14:24.463306 25375 net.cpp:84] Creating Layer encode2_hidden->transform->5
I1223 00:14:24.463311 25375 net.cpp:406] encode2_hidden->transform->5 <- h_conted_t=5
I1223 00:14:24.463317 25375 net.cpp:380] encode2_hidden->transform->5 -> hidden->transform->5
I1223 00:14:24.463820 25375 net.cpp:122] Setting up encode2_hidden->transform->5
I1223 00:14:24.463827 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.463831 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:24.463835 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.463840 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.463842 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=5
I1223 00:14:24.463848 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=5
I1223 00:14:24.463852 25375 net.cpp:406] encode2_hadamard->input_t=5 <- c_t=5_encode2_unit_t=5_0_split_0
I1223 00:14:24.463857 25375 net.cpp:380] encode2_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:24.463954 25375 net.cpp:122] Setting up encode2_hadamard->input_t=5
I1223 00:14:24.463961 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.463964 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:24.463968 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.463971 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=5
I1223 00:14:24.463977 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=5
I1223 00:14:24.463981 25375 net.cpp:406] encode2_hadamard->forget_t=5 <- c_t=5_encode2_unit_t=5_0_split_1
I1223 00:14:24.463989 25375 net.cpp:380] encode2_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:24.464082 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=5
I1223 00:14:24.464090 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464093 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:24.464097 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.464100 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=5
I1223 00:14:24.464105 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=5
I1223 00:14:24.464109 25375 net.cpp:406] encode2_hadamard->output_t=5 <- c_t=5_encode2_unit_t=5_0_split_2
I1223 00:14:24.464115 25375 net.cpp:380] encode2_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:24.464201 25375 net.cpp:122] Setting up encode2_hadamard->output_t=5
I1223 00:14:24.464208 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464211 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:24.464217 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.464222 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=6
I1223 00:14:24.464229 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=6
I1223 00:14:24.464234 25375 net.cpp:380] encode2_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:24.464292 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=6
I1223 00:14:24.464298 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464301 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:24.464304 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=6
I1223 00:14:24.464310 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=6
I1223 00:14:24.464313 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:24.464318 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:24.464323 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:24.464326 25375 net.cpp:406] encode2_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:24.464332 25375 net.cpp:380] encode2_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:24.464355 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=6
I1223 00:14:24.464362 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.464365 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:24.464367 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_6
I1223 00:14:24.464375 25375 net.cpp:84] Creating Layer encode2_gate_input_6
I1223 00:14:24.464378 25375 net.cpp:406] encode2_gate_input_6 <- hidden->transform->5
I1223 00:14:24.464382 25375 net.cpp:406] encode2_gate_input_6 <- x->transform->t=6
I1223 00:14:24.464386 25375 net.cpp:406] encode2_gate_input_6 <- hadamard_t=6
I1223 00:14:24.464393 25375 net.cpp:380] encode2_gate_input_6 -> gate_input_6
I1223 00:14:24.464416 25375 net.cpp:122] Setting up encode2_gate_input_6
I1223 00:14:24.464422 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.464424 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:24.464428 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=6
I1223 00:14:24.464434 25375 net.cpp:84] Creating Layer encode2_unit_t=6
I1223 00:14:24.464438 25375 net.cpp:406] encode2_unit_t=6 <- c_t=5_encode2_unit_t=5_0_split_3
I1223 00:14:24.464442 25375 net.cpp:406] encode2_unit_t=6 <- gate_input_6
I1223 00:14:24.464447 25375 net.cpp:406] encode2_unit_t=6 <- cont_t=6_encode2_cont_slice_5_split_1
I1223 00:14:24.464452 25375 net.cpp:380] encode2_unit_t=6 -> c_t=6
I1223 00:14:24.464458 25375 net.cpp:380] encode2_unit_t=6 -> h_t=6
I1223 00:14:24.464506 25375 net.cpp:122] Setting up encode2_unit_t=6
I1223 00:14:24.464514 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464519 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464521 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:24.464524 25375 layer_factory.hpp:77] Creating layer c_t=6_encode2_unit_t=6_0_split
I1223 00:14:24.464529 25375 net.cpp:84] Creating Layer c_t=6_encode2_unit_t=6_0_split
I1223 00:14:24.464532 25375 net.cpp:406] c_t=6_encode2_unit_t=6_0_split <- c_t=6
I1223 00:14:24.464540 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_0
I1223 00:14:24.464546 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_1
I1223 00:14:24.464553 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_2
I1223 00:14:24.464560 25375 net.cpp:380] c_t=6_encode2_unit_t=6_0_split -> c_t=6_encode2_unit_t=6_0_split_3
I1223 00:14:24.464617 25375 net.cpp:122] Setting up c_t=6_encode2_unit_t=6_0_split
I1223 00:14:24.464623 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464628 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464632 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464635 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464638 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:24.464642 25375 layer_factory.hpp:77] Creating layer h_t=6_encode2_unit_t=6_1_split
I1223 00:14:24.464646 25375 net.cpp:84] Creating Layer h_t=6_encode2_unit_t=6_1_split
I1223 00:14:24.464649 25375 net.cpp:406] h_t=6_encode2_unit_t=6_1_split <- h_t=6
I1223 00:14:24.464654 25375 net.cpp:380] h_t=6_encode2_unit_t=6_1_split -> h_t=6_encode2_unit_t=6_1_split_0
I1223 00:14:24.464660 25375 net.cpp:380] h_t=6_encode2_unit_t=6_1_split -> h_t=6_encode2_unit_t=6_1_split_1
I1223 00:14:24.464694 25375 net.cpp:122] Setting up h_t=6_encode2_unit_t=6_1_split
I1223 00:14:24.464700 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464704 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464707 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:24.464710 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=6
I1223 00:14:24.464716 25375 net.cpp:84] Creating Layer encode2_h_conted_t=6
I1223 00:14:24.464720 25375 net.cpp:406] encode2_h_conted_t=6 <- h_t=6_encode2_unit_t=6_1_split_0
I1223 00:14:24.464725 25375 net.cpp:406] encode2_h_conted_t=6 <- cont_t=7_encode2_cont_slice_6_split_0
I1223 00:14:24.464730 25375 net.cpp:380] encode2_h_conted_t=6 -> h_conted_t=6
I1223 00:14:24.464813 25375 net.cpp:122] Setting up encode2_h_conted_t=6
I1223 00:14:24.464820 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.464823 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:24.464826 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->6
I1223 00:14:24.464835 25375 net.cpp:84] Creating Layer encode2_hidden->transform->6
I1223 00:14:24.464840 25375 net.cpp:406] encode2_hidden->transform->6 <- h_conted_t=6
I1223 00:14:24.464848 25375 net.cpp:380] encode2_hidden->transform->6 -> hidden->transform->6
I1223 00:14:24.465360 25375 net.cpp:122] Setting up encode2_hidden->transform->6
I1223 00:14:24.465369 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.465373 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:24.465376 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.465380 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.465384 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=6
I1223 00:14:24.465390 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=6
I1223 00:14:24.465395 25375 net.cpp:406] encode2_hadamard->input_t=6 <- c_t=6_encode2_unit_t=6_0_split_0
I1223 00:14:24.465402 25375 net.cpp:380] encode2_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:24.465498 25375 net.cpp:122] Setting up encode2_hadamard->input_t=6
I1223 00:14:24.465507 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.465509 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:24.465513 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.465517 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=6
I1223 00:14:24.465523 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=6
I1223 00:14:24.465526 25375 net.cpp:406] encode2_hadamard->forget_t=6 <- c_t=6_encode2_unit_t=6_0_split_1
I1223 00:14:24.465533 25375 net.cpp:380] encode2_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:24.465620 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=6
I1223 00:14:24.465627 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.465631 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:24.465634 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.465637 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=6
I1223 00:14:24.465643 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=6
I1223 00:14:24.465647 25375 net.cpp:406] encode2_hadamard->output_t=6 <- c_t=6_encode2_unit_t=6_0_split_2
I1223 00:14:24.465653 25375 net.cpp:380] encode2_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:24.465744 25375 net.cpp:122] Setting up encode2_hadamard->output_t=6
I1223 00:14:24.465751 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.465754 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:24.465759 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.465761 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=7
I1223 00:14:24.465767 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=7
I1223 00:14:24.465772 25375 net.cpp:380] encode2_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:24.466588 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=7
I1223 00:14:24.466598 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.466601 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:24.466605 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=7
I1223 00:14:24.466614 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=7
I1223 00:14:24.466617 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:24.466622 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:24.466627 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:24.466631 25375 net.cpp:406] encode2_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:24.466636 25375 net.cpp:380] encode2_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:24.466667 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=7
I1223 00:14:24.466675 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.466677 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:24.466681 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_7
I1223 00:14:24.466686 25375 net.cpp:84] Creating Layer encode2_gate_input_7
I1223 00:14:24.466689 25375 net.cpp:406] encode2_gate_input_7 <- hidden->transform->6
I1223 00:14:24.466693 25375 net.cpp:406] encode2_gate_input_7 <- x->transform->t=7
I1223 00:14:24.466697 25375 net.cpp:406] encode2_gate_input_7 <- hadamard_t=7
I1223 00:14:24.466704 25375 net.cpp:380] encode2_gate_input_7 -> gate_input_7
I1223 00:14:24.466728 25375 net.cpp:122] Setting up encode2_gate_input_7
I1223 00:14:24.466734 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.466737 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:24.466740 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=7
I1223 00:14:24.466745 25375 net.cpp:84] Creating Layer encode2_unit_t=7
I1223 00:14:24.466749 25375 net.cpp:406] encode2_unit_t=7 <- c_t=6_encode2_unit_t=6_0_split_3
I1223 00:14:24.466754 25375 net.cpp:406] encode2_unit_t=7 <- gate_input_7
I1223 00:14:24.466758 25375 net.cpp:406] encode2_unit_t=7 <- cont_t=7_encode2_cont_slice_6_split_1
I1223 00:14:24.466764 25375 net.cpp:380] encode2_unit_t=7 -> c_t=7
I1223 00:14:24.466771 25375 net.cpp:380] encode2_unit_t=7 -> h_t=7
I1223 00:14:24.466820 25375 net.cpp:122] Setting up encode2_unit_t=7
I1223 00:14:24.466826 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.466831 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.466835 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:24.466837 25375 layer_factory.hpp:77] Creating layer c_t=7_encode2_unit_t=7_0_split
I1223 00:14:24.466845 25375 net.cpp:84] Creating Layer c_t=7_encode2_unit_t=7_0_split
I1223 00:14:24.466847 25375 net.cpp:406] c_t=7_encode2_unit_t=7_0_split <- c_t=7
I1223 00:14:24.466855 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_0
I1223 00:14:24.466861 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_1
I1223 00:14:24.466867 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_2
I1223 00:14:24.466874 25375 net.cpp:380] c_t=7_encode2_unit_t=7_0_split -> c_t=7_encode2_unit_t=7_0_split_3
I1223 00:14:24.466934 25375 net.cpp:122] Setting up c_t=7_encode2_unit_t=7_0_split
I1223 00:14:24.466940 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.466944 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.466949 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.466953 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.466956 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:24.466958 25375 layer_factory.hpp:77] Creating layer h_t=7_encode2_unit_t=7_1_split
I1223 00:14:24.466965 25375 net.cpp:84] Creating Layer h_t=7_encode2_unit_t=7_1_split
I1223 00:14:24.466969 25375 net.cpp:406] h_t=7_encode2_unit_t=7_1_split <- h_t=7
I1223 00:14:24.466974 25375 net.cpp:380] h_t=7_encode2_unit_t=7_1_split -> h_t=7_encode2_unit_t=7_1_split_0
I1223 00:14:24.466980 25375 net.cpp:380] h_t=7_encode2_unit_t=7_1_split -> h_t=7_encode2_unit_t=7_1_split_1
I1223 00:14:24.467015 25375 net.cpp:122] Setting up h_t=7_encode2_unit_t=7_1_split
I1223 00:14:24.467022 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.467026 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.467030 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:24.467032 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=7
I1223 00:14:24.467038 25375 net.cpp:84] Creating Layer encode2_h_conted_t=7
I1223 00:14:24.467041 25375 net.cpp:406] encode2_h_conted_t=7 <- h_t=7_encode2_unit_t=7_1_split_0
I1223 00:14:24.467046 25375 net.cpp:406] encode2_h_conted_t=7 <- cont_t=8_encode2_cont_slice_7_split_0
I1223 00:14:24.467053 25375 net.cpp:380] encode2_h_conted_t=7 -> h_conted_t=7
I1223 00:14:24.467131 25375 net.cpp:122] Setting up encode2_h_conted_t=7
I1223 00:14:24.467137 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.467140 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:24.467144 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->7
I1223 00:14:24.467154 25375 net.cpp:84] Creating Layer encode2_hidden->transform->7
I1223 00:14:24.467159 25375 net.cpp:406] encode2_hidden->transform->7 <- h_conted_t=7
I1223 00:14:24.467165 25375 net.cpp:380] encode2_hidden->transform->7 -> hidden->transform->7
I1223 00:14:24.467679 25375 net.cpp:122] Setting up encode2_hidden->transform->7
I1223 00:14:24.467685 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.467689 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:24.467692 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.467697 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.467700 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=7
I1223 00:14:24.467707 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=7
I1223 00:14:24.467711 25375 net.cpp:406] encode2_hadamard->input_t=7 <- c_t=7_encode2_unit_t=7_0_split_0
I1223 00:14:24.467717 25375 net.cpp:380] encode2_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:24.467808 25375 net.cpp:122] Setting up encode2_hadamard->input_t=7
I1223 00:14:24.467815 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.467818 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:24.467821 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.467825 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=7
I1223 00:14:24.467830 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=7
I1223 00:14:24.467834 25375 net.cpp:406] encode2_hadamard->forget_t=7 <- c_t=7_encode2_unit_t=7_0_split_1
I1223 00:14:24.467842 25375 net.cpp:380] encode2_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:24.467939 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=7
I1223 00:14:24.467947 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.467949 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:24.467953 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.467957 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=7
I1223 00:14:24.467963 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=7
I1223 00:14:24.467967 25375 net.cpp:406] encode2_hadamard->output_t=7 <- c_t=7_encode2_unit_t=7_0_split_2
I1223 00:14:24.467972 25375 net.cpp:380] encode2_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:24.468065 25375 net.cpp:122] Setting up encode2_hadamard->output_t=7
I1223 00:14:24.468071 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468075 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:24.468078 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.468081 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=8
I1223 00:14:24.468091 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=8
I1223 00:14:24.468096 25375 net.cpp:380] encode2_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:24.468148 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=8
I1223 00:14:24.468154 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468158 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:24.468160 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=8
I1223 00:14:24.468168 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=8
I1223 00:14:24.468171 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:24.468176 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:24.468180 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:24.468184 25375 net.cpp:406] encode2_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:24.468189 25375 net.cpp:380] encode2_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:24.468214 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=8
I1223 00:14:24.468220 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.468225 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:24.468227 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_8
I1223 00:14:24.468233 25375 net.cpp:84] Creating Layer encode2_gate_input_8
I1223 00:14:24.468237 25375 net.cpp:406] encode2_gate_input_8 <- hidden->transform->7
I1223 00:14:24.468242 25375 net.cpp:406] encode2_gate_input_8 <- x->transform->t=8
I1223 00:14:24.468246 25375 net.cpp:406] encode2_gate_input_8 <- hadamard_t=8
I1223 00:14:24.468253 25375 net.cpp:380] encode2_gate_input_8 -> gate_input_8
I1223 00:14:24.468276 25375 net.cpp:122] Setting up encode2_gate_input_8
I1223 00:14:24.468282 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.468286 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:24.468288 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=8
I1223 00:14:24.468294 25375 net.cpp:84] Creating Layer encode2_unit_t=8
I1223 00:14:24.468298 25375 net.cpp:406] encode2_unit_t=8 <- c_t=7_encode2_unit_t=7_0_split_3
I1223 00:14:24.468302 25375 net.cpp:406] encode2_unit_t=8 <- gate_input_8
I1223 00:14:24.468307 25375 net.cpp:406] encode2_unit_t=8 <- cont_t=8_encode2_cont_slice_7_split_1
I1223 00:14:24.468312 25375 net.cpp:380] encode2_unit_t=8 -> c_t=8
I1223 00:14:24.468318 25375 net.cpp:380] encode2_unit_t=8 -> h_t=8
I1223 00:14:24.468367 25375 net.cpp:122] Setting up encode2_unit_t=8
I1223 00:14:24.468374 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468377 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468380 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:24.468384 25375 layer_factory.hpp:77] Creating layer c_t=8_encode2_unit_t=8_0_split
I1223 00:14:24.468389 25375 net.cpp:84] Creating Layer c_t=8_encode2_unit_t=8_0_split
I1223 00:14:24.468391 25375 net.cpp:406] c_t=8_encode2_unit_t=8_0_split <- c_t=8
I1223 00:14:24.468400 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_0
I1223 00:14:24.468407 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_1
I1223 00:14:24.468415 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_2
I1223 00:14:24.468422 25375 net.cpp:380] c_t=8_encode2_unit_t=8_0_split -> c_t=8_encode2_unit_t=8_0_split_3
I1223 00:14:24.468482 25375 net.cpp:122] Setting up c_t=8_encode2_unit_t=8_0_split
I1223 00:14:24.468487 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468492 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468495 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468500 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468503 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:24.468506 25375 layer_factory.hpp:77] Creating layer h_t=8_encode2_unit_t=8_1_split
I1223 00:14:24.468510 25375 net.cpp:84] Creating Layer h_t=8_encode2_unit_t=8_1_split
I1223 00:14:24.468514 25375 net.cpp:406] h_t=8_encode2_unit_t=8_1_split <- h_t=8
I1223 00:14:24.468519 25375 net.cpp:380] h_t=8_encode2_unit_t=8_1_split -> h_t=8_encode2_unit_t=8_1_split_0
I1223 00:14:24.468525 25375 net.cpp:380] h_t=8_encode2_unit_t=8_1_split -> h_t=8_encode2_unit_t=8_1_split_1
I1223 00:14:24.468559 25375 net.cpp:122] Setting up h_t=8_encode2_unit_t=8_1_split
I1223 00:14:24.468565 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468569 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468572 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:24.468575 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=8
I1223 00:14:24.468581 25375 net.cpp:84] Creating Layer encode2_h_conted_t=8
I1223 00:14:24.468585 25375 net.cpp:406] encode2_h_conted_t=8 <- h_t=8_encode2_unit_t=8_1_split_0
I1223 00:14:24.468590 25375 net.cpp:406] encode2_h_conted_t=8 <- cont_t=9_encode2_cont_slice_8_split_0
I1223 00:14:24.468595 25375 net.cpp:380] encode2_h_conted_t=8 -> h_conted_t=8
I1223 00:14:24.468672 25375 net.cpp:122] Setting up encode2_h_conted_t=8
I1223 00:14:24.468678 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.468681 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:24.468684 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->8
I1223 00:14:24.468693 25375 net.cpp:84] Creating Layer encode2_hidden->transform->8
I1223 00:14:24.468698 25375 net.cpp:406] encode2_hidden->transform->8 <- h_conted_t=8
I1223 00:14:24.468705 25375 net.cpp:380] encode2_hidden->transform->8 -> hidden->transform->8
I1223 00:14:24.469219 25375 net.cpp:122] Setting up encode2_hidden->transform->8
I1223 00:14:24.469229 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.469233 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:24.469236 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.469240 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.469244 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=8
I1223 00:14:24.469250 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=8
I1223 00:14:24.469254 25375 net.cpp:406] encode2_hadamard->input_t=8 <- c_t=8_encode2_unit_t=8_0_split_0
I1223 00:14:24.469261 25375 net.cpp:380] encode2_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:24.469359 25375 net.cpp:122] Setting up encode2_hadamard->input_t=8
I1223 00:14:24.469367 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.469369 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:24.469373 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.469377 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=8
I1223 00:14:24.469384 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=8
I1223 00:14:24.469388 25375 net.cpp:406] encode2_hadamard->forget_t=8 <- c_t=8_encode2_unit_t=8_0_split_1
I1223 00:14:24.469394 25375 net.cpp:380] encode2_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:24.469491 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=8
I1223 00:14:24.469497 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.469501 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:24.469504 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.469508 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=8
I1223 00:14:24.469514 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=8
I1223 00:14:24.469518 25375 net.cpp:406] encode2_hadamard->output_t=8 <- c_t=8_encode2_unit_t=8_0_split_2
I1223 00:14:24.469523 25375 net.cpp:380] encode2_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:24.469610 25375 net.cpp:122] Setting up encode2_hadamard->output_t=8
I1223 00:14:24.469617 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.469620 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:24.469624 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.469627 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=9
I1223 00:14:24.469635 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=9
I1223 00:14:24.469640 25375 net.cpp:380] encode2_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:24.469693 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=9
I1223 00:14:24.469699 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.469703 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:24.469705 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=9
I1223 00:14:24.469712 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=9
I1223 00:14:24.469715 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:24.469720 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:24.469724 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:24.469728 25375 net.cpp:406] encode2_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:24.469733 25375 net.cpp:380] encode2_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:24.469758 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=9
I1223 00:14:24.469764 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.469768 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:24.469770 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_9
I1223 00:14:24.469776 25375 net.cpp:84] Creating Layer encode2_gate_input_9
I1223 00:14:24.469779 25375 net.cpp:406] encode2_gate_input_9 <- hidden->transform->8
I1223 00:14:24.469784 25375 net.cpp:406] encode2_gate_input_9 <- x->transform->t=9
I1223 00:14:24.469789 25375 net.cpp:406] encode2_gate_input_9 <- hadamard_t=9
I1223 00:14:24.469796 25375 net.cpp:380] encode2_gate_input_9 -> gate_input_9
I1223 00:14:24.469820 25375 net.cpp:122] Setting up encode2_gate_input_9
I1223 00:14:24.469825 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.469828 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:24.469831 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=9
I1223 00:14:24.469838 25375 net.cpp:84] Creating Layer encode2_unit_t=9
I1223 00:14:24.469841 25375 net.cpp:406] encode2_unit_t=9 <- c_t=8_encode2_unit_t=8_0_split_3
I1223 00:14:24.469846 25375 net.cpp:406] encode2_unit_t=9 <- gate_input_9
I1223 00:14:24.469851 25375 net.cpp:406] encode2_unit_t=9 <- cont_t=9_encode2_cont_slice_8_split_1
I1223 00:14:24.469856 25375 net.cpp:380] encode2_unit_t=9 -> c_t=9
I1223 00:14:24.469862 25375 net.cpp:380] encode2_unit_t=9 -> h_t=9
I1223 00:14:24.469911 25375 net.cpp:122] Setting up encode2_unit_t=9
I1223 00:14:24.469918 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.469921 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.469924 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:24.469928 25375 layer_factory.hpp:77] Creating layer c_t=9_encode2_unit_t=9_0_split
I1223 00:14:24.469933 25375 net.cpp:84] Creating Layer c_t=9_encode2_unit_t=9_0_split
I1223 00:14:24.469936 25375 net.cpp:406] c_t=9_encode2_unit_t=9_0_split <- c_t=9
I1223 00:14:24.469944 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_0
I1223 00:14:24.469951 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_1
I1223 00:14:24.469960 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_2
I1223 00:14:24.469966 25375 net.cpp:380] c_t=9_encode2_unit_t=9_0_split -> c_t=9_encode2_unit_t=9_0_split_3
I1223 00:14:24.470026 25375 net.cpp:122] Setting up c_t=9_encode2_unit_t=9_0_split
I1223 00:14:24.470032 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470036 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470041 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470044 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470047 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:24.470051 25375 layer_factory.hpp:77] Creating layer h_t=9_encode2_unit_t=9_1_split
I1223 00:14:24.470054 25375 net.cpp:84] Creating Layer h_t=9_encode2_unit_t=9_1_split
I1223 00:14:24.470057 25375 net.cpp:406] h_t=9_encode2_unit_t=9_1_split <- h_t=9
I1223 00:14:24.470063 25375 net.cpp:380] h_t=9_encode2_unit_t=9_1_split -> h_t=9_encode2_unit_t=9_1_split_0
I1223 00:14:24.470069 25375 net.cpp:380] h_t=9_encode2_unit_t=9_1_split -> h_t=9_encode2_unit_t=9_1_split_1
I1223 00:14:24.470103 25375 net.cpp:122] Setting up h_t=9_encode2_unit_t=9_1_split
I1223 00:14:24.470108 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470113 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470116 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:24.470119 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=9
I1223 00:14:24.470125 25375 net.cpp:84] Creating Layer encode2_h_conted_t=9
I1223 00:14:24.470129 25375 net.cpp:406] encode2_h_conted_t=9 <- h_t=9_encode2_unit_t=9_1_split_0
I1223 00:14:24.470134 25375 net.cpp:406] encode2_h_conted_t=9 <- cont_t=10_encode2_cont_slice_9_split_0
I1223 00:14:24.470139 25375 net.cpp:380] encode2_h_conted_t=9 -> h_conted_t=9
I1223 00:14:24.470216 25375 net.cpp:122] Setting up encode2_h_conted_t=9
I1223 00:14:24.470223 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470227 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:24.470229 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->9
I1223 00:14:24.470239 25375 net.cpp:84] Creating Layer encode2_hidden->transform->9
I1223 00:14:24.470244 25375 net.cpp:406] encode2_hidden->transform->9 <- h_conted_t=9
I1223 00:14:24.470252 25375 net.cpp:380] encode2_hidden->transform->9 -> hidden->transform->9
I1223 00:14:24.470763 25375 net.cpp:122] Setting up encode2_hidden->transform->9
I1223 00:14:24.470770 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.470774 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:24.470778 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.470782 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.470785 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=9
I1223 00:14:24.470793 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=9
I1223 00:14:24.470796 25375 net.cpp:406] encode2_hadamard->input_t=9 <- c_t=9_encode2_unit_t=9_0_split_0
I1223 00:14:24.470803 25375 net.cpp:380] encode2_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:24.470901 25375 net.cpp:122] Setting up encode2_hadamard->input_t=9
I1223 00:14:24.470907 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.470911 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:24.470914 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.470917 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=9
I1223 00:14:24.470924 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=9
I1223 00:14:24.470928 25375 net.cpp:406] encode2_hadamard->forget_t=9 <- c_t=9_encode2_unit_t=9_0_split_1
I1223 00:14:24.470933 25375 net.cpp:380] encode2_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:24.471024 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=9
I1223 00:14:24.471030 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471034 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:24.471037 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.471040 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=9
I1223 00:14:24.471046 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=9
I1223 00:14:24.471050 25375 net.cpp:406] encode2_hadamard->output_t=9 <- c_t=9_encode2_unit_t=9_0_split_2
I1223 00:14:24.471055 25375 net.cpp:380] encode2_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:24.471148 25375 net.cpp:122] Setting up encode2_hadamard->output_t=9
I1223 00:14:24.471154 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471158 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:24.471161 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.471164 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=10
I1223 00:14:24.471174 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=10
I1223 00:14:24.471179 25375 net.cpp:380] encode2_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:24.471231 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=10
I1223 00:14:24.471238 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471241 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:24.471246 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=10
I1223 00:14:24.471251 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=10
I1223 00:14:24.471254 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:24.471259 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:24.471264 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:24.471268 25375 net.cpp:406] encode2_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:24.471273 25375 net.cpp:380] encode2_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:24.471297 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=10
I1223 00:14:24.471303 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.471307 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:24.471309 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_10
I1223 00:14:24.471315 25375 net.cpp:84] Creating Layer encode2_gate_input_10
I1223 00:14:24.471319 25375 net.cpp:406] encode2_gate_input_10 <- hidden->transform->9
I1223 00:14:24.471324 25375 net.cpp:406] encode2_gate_input_10 <- x->transform->t=10
I1223 00:14:24.471328 25375 net.cpp:406] encode2_gate_input_10 <- hadamard_t=10
I1223 00:14:24.471333 25375 net.cpp:380] encode2_gate_input_10 -> gate_input_10
I1223 00:14:24.471355 25375 net.cpp:122] Setting up encode2_gate_input_10
I1223 00:14:24.471361 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.471364 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:24.471367 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=10
I1223 00:14:24.471372 25375 net.cpp:84] Creating Layer encode2_unit_t=10
I1223 00:14:24.471376 25375 net.cpp:406] encode2_unit_t=10 <- c_t=9_encode2_unit_t=9_0_split_3
I1223 00:14:24.471380 25375 net.cpp:406] encode2_unit_t=10 <- gate_input_10
I1223 00:14:24.471385 25375 net.cpp:406] encode2_unit_t=10 <- cont_t=10_encode2_cont_slice_9_split_1
I1223 00:14:24.471391 25375 net.cpp:380] encode2_unit_t=10 -> c_t=10
I1223 00:14:24.471398 25375 net.cpp:380] encode2_unit_t=10 -> h_t=10
I1223 00:14:24.471449 25375 net.cpp:122] Setting up encode2_unit_t=10
I1223 00:14:24.471457 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471462 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471463 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:24.471467 25375 layer_factory.hpp:77] Creating layer c_t=10_encode2_unit_t=10_0_split
I1223 00:14:24.471472 25375 net.cpp:84] Creating Layer c_t=10_encode2_unit_t=10_0_split
I1223 00:14:24.471475 25375 net.cpp:406] c_t=10_encode2_unit_t=10_0_split <- c_t=10
I1223 00:14:24.471482 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_0
I1223 00:14:24.471489 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_1
I1223 00:14:24.471496 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_2
I1223 00:14:24.471503 25375 net.cpp:380] c_t=10_encode2_unit_t=10_0_split -> c_t=10_encode2_unit_t=10_0_split_3
I1223 00:14:24.471561 25375 net.cpp:122] Setting up c_t=10_encode2_unit_t=10_0_split
I1223 00:14:24.471568 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471572 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471576 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471580 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471583 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:24.471586 25375 layer_factory.hpp:77] Creating layer h_t=10_encode2_unit_t=10_1_split
I1223 00:14:24.471591 25375 net.cpp:84] Creating Layer h_t=10_encode2_unit_t=10_1_split
I1223 00:14:24.471595 25375 net.cpp:406] h_t=10_encode2_unit_t=10_1_split <- h_t=10
I1223 00:14:24.471601 25375 net.cpp:380] h_t=10_encode2_unit_t=10_1_split -> h_t=10_encode2_unit_t=10_1_split_0
I1223 00:14:24.471608 25375 net.cpp:380] h_t=10_encode2_unit_t=10_1_split -> h_t=10_encode2_unit_t=10_1_split_1
I1223 00:14:24.471642 25375 net.cpp:122] Setting up h_t=10_encode2_unit_t=10_1_split
I1223 00:14:24.471649 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471653 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471657 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:24.471659 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=10
I1223 00:14:24.471664 25375 net.cpp:84] Creating Layer encode2_h_conted_t=10
I1223 00:14:24.471668 25375 net.cpp:406] encode2_h_conted_t=10 <- h_t=10_encode2_unit_t=10_1_split_0
I1223 00:14:24.471673 25375 net.cpp:406] encode2_h_conted_t=10 <- cont_t=11_encode2_cont_slice_10_split_0
I1223 00:14:24.471679 25375 net.cpp:380] encode2_h_conted_t=10 -> h_conted_t=10
I1223 00:14:24.471755 25375 net.cpp:122] Setting up encode2_h_conted_t=10
I1223 00:14:24.471761 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.471765 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:24.471767 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->10
I1223 00:14:24.471776 25375 net.cpp:84] Creating Layer encode2_hidden->transform->10
I1223 00:14:24.471781 25375 net.cpp:406] encode2_hidden->transform->10 <- h_conted_t=10
I1223 00:14:24.471787 25375 net.cpp:380] encode2_hidden->transform->10 -> hidden->transform->10
I1223 00:14:24.472295 25375 net.cpp:122] Setting up encode2_hidden->transform->10
I1223 00:14:24.472302 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.472306 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:24.472309 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.472314 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.472317 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=10
I1223 00:14:24.472324 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=10
I1223 00:14:24.472328 25375 net.cpp:406] encode2_hadamard->input_t=10 <- c_t=10_encode2_unit_t=10_0_split_0
I1223 00:14:24.472335 25375 net.cpp:380] encode2_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:24.472424 25375 net.cpp:122] Setting up encode2_hadamard->input_t=10
I1223 00:14:24.472431 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.472434 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:24.472439 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.472441 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=10
I1223 00:14:24.472448 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=10
I1223 00:14:24.472452 25375 net.cpp:406] encode2_hadamard->forget_t=10 <- c_t=10_encode2_unit_t=10_0_split_1
I1223 00:14:24.472460 25375 net.cpp:380] encode2_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:24.472553 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=10
I1223 00:14:24.472560 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.472563 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:24.472568 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.472570 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=10
I1223 00:14:24.472576 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=10
I1223 00:14:24.472580 25375 net.cpp:406] encode2_hadamard->output_t=10 <- c_t=10_encode2_unit_t=10_0_split_2
I1223 00:14:24.472585 25375 net.cpp:380] encode2_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:24.472676 25375 net.cpp:122] Setting up encode2_hadamard->output_t=10
I1223 00:14:24.472683 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.472687 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:24.472690 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.472693 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=11
I1223 00:14:24.472702 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=11
I1223 00:14:24.472707 25375 net.cpp:380] encode2_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:24.472759 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=11
I1223 00:14:24.472766 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.472769 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:24.472772 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=11
I1223 00:14:24.472777 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=11
I1223 00:14:24.472781 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:24.472786 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:24.472790 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:24.472795 25375 net.cpp:406] encode2_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:24.472800 25375 net.cpp:380] encode2_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:24.472823 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=11
I1223 00:14:24.472831 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.472833 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:24.472836 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_11
I1223 00:14:24.472841 25375 net.cpp:84] Creating Layer encode2_gate_input_11
I1223 00:14:24.472846 25375 net.cpp:406] encode2_gate_input_11 <- hidden->transform->10
I1223 00:14:24.472849 25375 net.cpp:406] encode2_gate_input_11 <- x->transform->t=11
I1223 00:14:24.472853 25375 net.cpp:406] encode2_gate_input_11 <- hadamard_t=11
I1223 00:14:24.472859 25375 net.cpp:380] encode2_gate_input_11 -> gate_input_11
I1223 00:14:24.472882 25375 net.cpp:122] Setting up encode2_gate_input_11
I1223 00:14:24.472888 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.472892 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:24.472894 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=11
I1223 00:14:24.472901 25375 net.cpp:84] Creating Layer encode2_unit_t=11
I1223 00:14:24.472905 25375 net.cpp:406] encode2_unit_t=11 <- c_t=10_encode2_unit_t=10_0_split_3
I1223 00:14:24.472910 25375 net.cpp:406] encode2_unit_t=11 <- gate_input_11
I1223 00:14:24.472914 25375 net.cpp:406] encode2_unit_t=11 <- cont_t=11_encode2_cont_slice_10_split_1
I1223 00:14:24.472919 25375 net.cpp:380] encode2_unit_t=11 -> c_t=11
I1223 00:14:24.472926 25375 net.cpp:380] encode2_unit_t=11 -> h_t=11
I1223 00:14:24.472973 25375 net.cpp:122] Setting up encode2_unit_t=11
I1223 00:14:24.472980 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.472985 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.472986 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:24.472990 25375 layer_factory.hpp:77] Creating layer c_t=11_encode2_unit_t=11_0_split
I1223 00:14:24.472995 25375 net.cpp:84] Creating Layer c_t=11_encode2_unit_t=11_0_split
I1223 00:14:24.473000 25375 net.cpp:406] c_t=11_encode2_unit_t=11_0_split <- c_t=11
I1223 00:14:24.473008 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_0
I1223 00:14:24.473016 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_1
I1223 00:14:24.473022 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_2
I1223 00:14:24.473029 25375 net.cpp:380] c_t=11_encode2_unit_t=11_0_split -> c_t=11_encode2_unit_t=11_0_split_3
I1223 00:14:24.473091 25375 net.cpp:122] Setting up c_t=11_encode2_unit_t=11_0_split
I1223 00:14:24.473098 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473103 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473106 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473110 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473114 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:24.473116 25375 layer_factory.hpp:77] Creating layer h_t=11_encode2_unit_t=11_1_split
I1223 00:14:24.473120 25375 net.cpp:84] Creating Layer h_t=11_encode2_unit_t=11_1_split
I1223 00:14:24.473124 25375 net.cpp:406] h_t=11_encode2_unit_t=11_1_split <- h_t=11
I1223 00:14:24.473130 25375 net.cpp:380] h_t=11_encode2_unit_t=11_1_split -> h_t=11_encode2_unit_t=11_1_split_0
I1223 00:14:24.473137 25375 net.cpp:380] h_t=11_encode2_unit_t=11_1_split -> h_t=11_encode2_unit_t=11_1_split_1
I1223 00:14:24.473170 25375 net.cpp:122] Setting up h_t=11_encode2_unit_t=11_1_split
I1223 00:14:24.473177 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473181 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473183 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:24.473186 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=11
I1223 00:14:24.473193 25375 net.cpp:84] Creating Layer encode2_h_conted_t=11
I1223 00:14:24.473197 25375 net.cpp:406] encode2_h_conted_t=11 <- h_t=11_encode2_unit_t=11_1_split_0
I1223 00:14:24.473201 25375 net.cpp:406] encode2_h_conted_t=11 <- cont_t=12_encode2_cont_slice_11_split_0
I1223 00:14:24.473207 25375 net.cpp:380] encode2_h_conted_t=11 -> h_conted_t=11
I1223 00:14:24.473284 25375 net.cpp:122] Setting up encode2_h_conted_t=11
I1223 00:14:24.473289 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473292 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:24.473295 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->11
I1223 00:14:24.473304 25375 net.cpp:84] Creating Layer encode2_hidden->transform->11
I1223 00:14:24.473309 25375 net.cpp:406] encode2_hidden->transform->11 <- h_conted_t=11
I1223 00:14:24.473317 25375 net.cpp:380] encode2_hidden->transform->11 -> hidden->transform->11
I1223 00:14:24.473827 25375 net.cpp:122] Setting up encode2_hidden->transform->11
I1223 00:14:24.473834 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.473839 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:24.473841 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.473846 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.473850 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=11
I1223 00:14:24.473855 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=11
I1223 00:14:24.473858 25375 net.cpp:406] encode2_hadamard->input_t=11 <- c_t=11_encode2_unit_t=11_0_split_0
I1223 00:14:24.473865 25375 net.cpp:380] encode2_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:24.473960 25375 net.cpp:122] Setting up encode2_hadamard->input_t=11
I1223 00:14:24.473968 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.473970 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:24.473974 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.473978 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=11
I1223 00:14:24.473984 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=11
I1223 00:14:24.473986 25375 net.cpp:406] encode2_hadamard->forget_t=11 <- c_t=11_encode2_unit_t=11_0_split_1
I1223 00:14:24.473994 25375 net.cpp:380] encode2_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:24.474086 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=11
I1223 00:14:24.474092 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.474095 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:24.474099 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.474103 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=11
I1223 00:14:24.474109 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=11
I1223 00:14:24.474112 25375 net.cpp:406] encode2_hadamard->output_t=11 <- c_t=11_encode2_unit_t=11_0_split_2
I1223 00:14:24.474119 25375 net.cpp:380] encode2_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:24.474210 25375 net.cpp:122] Setting up encode2_hadamard->output_t=11
I1223 00:14:24.474217 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.474220 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:24.474225 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.474227 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=12
I1223 00:14:24.474232 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=12
I1223 00:14:24.474238 25375 net.cpp:380] encode2_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:24.475003 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=12
I1223 00:14:24.475013 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475018 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:24.475020 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=12
I1223 00:14:24.475028 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=12
I1223 00:14:24.475033 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:24.475037 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:24.475042 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:24.475046 25375 net.cpp:406] encode2_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:24.475052 25375 net.cpp:380] encode2_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:24.475082 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=12
I1223 00:14:24.475090 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.475092 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:24.475095 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_12
I1223 00:14:24.475114 25375 net.cpp:84] Creating Layer encode2_gate_input_12
I1223 00:14:24.475118 25375 net.cpp:406] encode2_gate_input_12 <- hidden->transform->11
I1223 00:14:24.475136 25375 net.cpp:406] encode2_gate_input_12 <- x->transform->t=12
I1223 00:14:24.475141 25375 net.cpp:406] encode2_gate_input_12 <- hadamard_t=12
I1223 00:14:24.475159 25375 net.cpp:380] encode2_gate_input_12 -> gate_input_12
I1223 00:14:24.475191 25375 net.cpp:122] Setting up encode2_gate_input_12
I1223 00:14:24.475199 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.475203 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:24.475205 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=12
I1223 00:14:24.475210 25375 net.cpp:84] Creating Layer encode2_unit_t=12
I1223 00:14:24.475227 25375 net.cpp:406] encode2_unit_t=12 <- c_t=11_encode2_unit_t=11_0_split_3
I1223 00:14:24.475231 25375 net.cpp:406] encode2_unit_t=12 <- gate_input_12
I1223 00:14:24.475250 25375 net.cpp:406] encode2_unit_t=12 <- cont_t=12_encode2_cont_slice_11_split_1
I1223 00:14:24.475255 25375 net.cpp:380] encode2_unit_t=12 -> c_t=12
I1223 00:14:24.475275 25375 net.cpp:380] encode2_unit_t=12 -> h_t=12
I1223 00:14:24.475323 25375 net.cpp:122] Setting up encode2_unit_t=12
I1223 00:14:24.475342 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475347 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475349 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:24.475353 25375 layer_factory.hpp:77] Creating layer c_t=12_encode2_unit_t=12_0_split
I1223 00:14:24.475358 25375 net.cpp:84] Creating Layer c_t=12_encode2_unit_t=12_0_split
I1223 00:14:24.475374 25375 net.cpp:406] c_t=12_encode2_unit_t=12_0_split <- c_t=12
I1223 00:14:24.475380 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_0
I1223 00:14:24.475388 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_1
I1223 00:14:24.475397 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_2
I1223 00:14:24.475404 25375 net.cpp:380] c_t=12_encode2_unit_t=12_0_split -> c_t=12_encode2_unit_t=12_0_split_3
I1223 00:14:24.475492 25375 net.cpp:122] Setting up c_t=12_encode2_unit_t=12_0_split
I1223 00:14:24.475497 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475502 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475505 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475509 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475527 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:24.475528 25375 layer_factory.hpp:77] Creating layer h_t=12_encode2_unit_t=12_1_split
I1223 00:14:24.475548 25375 net.cpp:84] Creating Layer h_t=12_encode2_unit_t=12_1_split
I1223 00:14:24.475551 25375 net.cpp:406] h_t=12_encode2_unit_t=12_1_split <- h_t=12
I1223 00:14:24.475556 25375 net.cpp:380] h_t=12_encode2_unit_t=12_1_split -> h_t=12_encode2_unit_t=12_1_split_0
I1223 00:14:24.475564 25375 net.cpp:380] h_t=12_encode2_unit_t=12_1_split -> h_t=12_encode2_unit_t=12_1_split_1
I1223 00:14:24.475599 25375 net.cpp:122] Setting up h_t=12_encode2_unit_t=12_1_split
I1223 00:14:24.475618 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475623 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475626 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:24.475628 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=12
I1223 00:14:24.475636 25375 net.cpp:84] Creating Layer encode2_h_conted_t=12
I1223 00:14:24.475652 25375 net.cpp:406] encode2_h_conted_t=12 <- h_t=12_encode2_unit_t=12_1_split_0
I1223 00:14:24.475657 25375 net.cpp:406] encode2_h_conted_t=12 <- cont_t=13_encode2_cont_slice_12_split_0
I1223 00:14:24.475662 25375 net.cpp:380] encode2_h_conted_t=12 -> h_conted_t=12
I1223 00:14:24.475756 25375 net.cpp:122] Setting up encode2_h_conted_t=12
I1223 00:14:24.475764 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.475766 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:24.475769 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->12
I1223 00:14:24.475780 25375 net.cpp:84] Creating Layer encode2_hidden->transform->12
I1223 00:14:24.475785 25375 net.cpp:406] encode2_hidden->transform->12 <- h_conted_t=12
I1223 00:14:24.475792 25375 net.cpp:380] encode2_hidden->transform->12 -> hidden->transform->12
I1223 00:14:24.476320 25375 net.cpp:122] Setting up encode2_hidden->transform->12
I1223 00:14:24.476327 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.476330 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:24.476335 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.476343 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.476349 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=12
I1223 00:14:24.476356 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=12
I1223 00:14:24.476359 25375 net.cpp:406] encode2_hadamard->input_t=12 <- c_t=12_encode2_unit_t=12_0_split_0
I1223 00:14:24.476366 25375 net.cpp:380] encode2_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:24.476466 25375 net.cpp:122] Setting up encode2_hadamard->input_t=12
I1223 00:14:24.476474 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.476476 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:24.476480 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.476483 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=12
I1223 00:14:24.476490 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=12
I1223 00:14:24.476493 25375 net.cpp:406] encode2_hadamard->forget_t=12 <- c_t=12_encode2_unit_t=12_0_split_1
I1223 00:14:24.476500 25375 net.cpp:380] encode2_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:24.476605 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=12
I1223 00:14:24.476611 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.476615 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:24.476619 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.476621 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=12
I1223 00:14:24.476641 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=12
I1223 00:14:24.476644 25375 net.cpp:406] encode2_hadamard->output_t=12 <- c_t=12_encode2_unit_t=12_0_split_2
I1223 00:14:24.476650 25375 net.cpp:380] encode2_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:24.476766 25375 net.cpp:122] Setting up encode2_hadamard->output_t=12
I1223 00:14:24.476773 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.476776 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:24.476780 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.476783 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=13
I1223 00:14:24.476804 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=13
I1223 00:14:24.476809 25375 net.cpp:380] encode2_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:24.476876 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=13
I1223 00:14:24.476882 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.476886 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:24.476888 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=13
I1223 00:14:24.476907 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=13
I1223 00:14:24.476912 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:24.476915 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:24.476920 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:24.476923 25375 net.cpp:406] encode2_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:24.476943 25375 net.cpp:380] encode2_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:24.476965 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=13
I1223 00:14:24.476972 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.476975 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:24.476979 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_13
I1223 00:14:24.476984 25375 net.cpp:84] Creating Layer encode2_gate_input_13
I1223 00:14:24.476989 25375 net.cpp:406] encode2_gate_input_13 <- hidden->transform->12
I1223 00:14:24.476994 25375 net.cpp:406] encode2_gate_input_13 <- x->transform->t=13
I1223 00:14:24.476999 25375 net.cpp:406] encode2_gate_input_13 <- hadamard_t=13
I1223 00:14:24.477005 25375 net.cpp:380] encode2_gate_input_13 -> gate_input_13
I1223 00:14:24.477025 25375 net.cpp:122] Setting up encode2_gate_input_13
I1223 00:14:24.477031 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.477035 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:24.477037 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=13
I1223 00:14:24.477044 25375 net.cpp:84] Creating Layer encode2_unit_t=13
I1223 00:14:24.477047 25375 net.cpp:406] encode2_unit_t=13 <- c_t=12_encode2_unit_t=12_0_split_3
I1223 00:14:24.477052 25375 net.cpp:406] encode2_unit_t=13 <- gate_input_13
I1223 00:14:24.477056 25375 net.cpp:406] encode2_unit_t=13 <- cont_t=13_encode2_cont_slice_12_split_1
I1223 00:14:24.477061 25375 net.cpp:380] encode2_unit_t=13 -> c_t=13
I1223 00:14:24.477072 25375 net.cpp:380] encode2_unit_t=13 -> h_t=13
I1223 00:14:24.477120 25375 net.cpp:122] Setting up encode2_unit_t=13
I1223 00:14:24.477126 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477131 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477133 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:24.477138 25375 layer_factory.hpp:77] Creating layer c_t=13_encode2_unit_t=13_0_split
I1223 00:14:24.477143 25375 net.cpp:84] Creating Layer c_t=13_encode2_unit_t=13_0_split
I1223 00:14:24.477145 25375 net.cpp:406] c_t=13_encode2_unit_t=13_0_split <- c_t=13
I1223 00:14:24.477151 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_0
I1223 00:14:24.477160 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_1
I1223 00:14:24.477169 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_2
I1223 00:14:24.477175 25375 net.cpp:380] c_t=13_encode2_unit_t=13_0_split -> c_t=13_encode2_unit_t=13_0_split_3
I1223 00:14:24.477232 25375 net.cpp:122] Setting up c_t=13_encode2_unit_t=13_0_split
I1223 00:14:24.477238 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477242 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477246 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477250 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477253 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:24.477257 25375 layer_factory.hpp:77] Creating layer h_t=13_encode2_unit_t=13_1_split
I1223 00:14:24.477260 25375 net.cpp:84] Creating Layer h_t=13_encode2_unit_t=13_1_split
I1223 00:14:24.477264 25375 net.cpp:406] h_t=13_encode2_unit_t=13_1_split <- h_t=13
I1223 00:14:24.477269 25375 net.cpp:380] h_t=13_encode2_unit_t=13_1_split -> h_t=13_encode2_unit_t=13_1_split_0
I1223 00:14:24.477275 25375 net.cpp:380] h_t=13_encode2_unit_t=13_1_split -> h_t=13_encode2_unit_t=13_1_split_1
I1223 00:14:24.477310 25375 net.cpp:122] Setting up h_t=13_encode2_unit_t=13_1_split
I1223 00:14:24.477316 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477321 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477324 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:24.477326 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=13
I1223 00:14:24.477334 25375 net.cpp:84] Creating Layer encode2_h_conted_t=13
I1223 00:14:24.477337 25375 net.cpp:406] encode2_h_conted_t=13 <- h_t=13_encode2_unit_t=13_1_split_0
I1223 00:14:24.477341 25375 net.cpp:406] encode2_h_conted_t=13 <- cont_t=14_encode2_cont_slice_13_split_0
I1223 00:14:24.477346 25375 net.cpp:380] encode2_h_conted_t=13 -> h_conted_t=13
I1223 00:14:24.477437 25375 net.cpp:122] Setting up encode2_h_conted_t=13
I1223 00:14:24.477443 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.477447 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:24.477463 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->13
I1223 00:14:24.477471 25375 net.cpp:84] Creating Layer encode2_hidden->transform->13
I1223 00:14:24.477476 25375 net.cpp:406] encode2_hidden->transform->13 <- h_conted_t=13
I1223 00:14:24.477483 25375 net.cpp:380] encode2_hidden->transform->13 -> hidden->transform->13
I1223 00:14:24.477994 25375 net.cpp:122] Setting up encode2_hidden->transform->13
I1223 00:14:24.478003 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.478006 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:24.478009 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.478013 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.478018 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=13
I1223 00:14:24.478024 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=13
I1223 00:14:24.478027 25375 net.cpp:406] encode2_hadamard->input_t=13 <- c_t=13_encode2_unit_t=13_0_split_0
I1223 00:14:24.478034 25375 net.cpp:380] encode2_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:24.478129 25375 net.cpp:122] Setting up encode2_hadamard->input_t=13
I1223 00:14:24.478137 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478140 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:24.478144 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.478147 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=13
I1223 00:14:24.478154 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=13
I1223 00:14:24.478157 25375 net.cpp:406] encode2_hadamard->forget_t=13 <- c_t=13_encode2_unit_t=13_0_split_1
I1223 00:14:24.478163 25375 net.cpp:380] encode2_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:24.478269 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=13
I1223 00:14:24.478276 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478279 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:24.478282 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.478286 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=13
I1223 00:14:24.478291 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=13
I1223 00:14:24.478307 25375 net.cpp:406] encode2_hadamard->output_t=13 <- c_t=13_encode2_unit_t=13_0_split_2
I1223 00:14:24.478312 25375 net.cpp:380] encode2_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:24.478430 25375 net.cpp:122] Setting up encode2_hadamard->output_t=13
I1223 00:14:24.478436 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478440 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:24.478443 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.478446 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=14
I1223 00:14:24.478452 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=14
I1223 00:14:24.478457 25375 net.cpp:380] encode2_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:24.478523 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=14
I1223 00:14:24.478543 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478546 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:24.478549 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=14
I1223 00:14:24.478554 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=14
I1223 00:14:24.478559 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:24.478564 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:24.478567 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:24.478571 25375 net.cpp:406] encode2_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:24.478592 25375 net.cpp:380] encode2_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:24.478619 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=14
I1223 00:14:24.478626 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.478628 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:24.478631 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_14
I1223 00:14:24.478636 25375 net.cpp:84] Creating Layer encode2_gate_input_14
I1223 00:14:24.478654 25375 net.cpp:406] encode2_gate_input_14 <- hidden->transform->13
I1223 00:14:24.478659 25375 net.cpp:406] encode2_gate_input_14 <- x->transform->t=14
I1223 00:14:24.478677 25375 net.cpp:406] encode2_gate_input_14 <- hadamard_t=14
I1223 00:14:24.478682 25375 net.cpp:380] encode2_gate_input_14 -> gate_input_14
I1223 00:14:24.478704 25375 net.cpp:122] Setting up encode2_gate_input_14
I1223 00:14:24.478711 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.478714 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:24.478718 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=14
I1223 00:14:24.478724 25375 net.cpp:84] Creating Layer encode2_unit_t=14
I1223 00:14:24.478727 25375 net.cpp:406] encode2_unit_t=14 <- c_t=13_encode2_unit_t=13_0_split_3
I1223 00:14:24.478731 25375 net.cpp:406] encode2_unit_t=14 <- gate_input_14
I1223 00:14:24.478736 25375 net.cpp:406] encode2_unit_t=14 <- cont_t=14_encode2_cont_slice_13_split_1
I1223 00:14:24.478741 25375 net.cpp:380] encode2_unit_t=14 -> c_t=14
I1223 00:14:24.478747 25375 net.cpp:380] encode2_unit_t=14 -> h_t=14
I1223 00:14:24.478808 25375 net.cpp:122] Setting up encode2_unit_t=14
I1223 00:14:24.478816 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478821 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478822 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:24.478826 25375 layer_factory.hpp:77] Creating layer c_t=14_encode2_unit_t=14_0_split
I1223 00:14:24.478830 25375 net.cpp:84] Creating Layer c_t=14_encode2_unit_t=14_0_split
I1223 00:14:24.478847 25375 net.cpp:406] c_t=14_encode2_unit_t=14_0_split <- c_t=14
I1223 00:14:24.478854 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_0
I1223 00:14:24.478862 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_1
I1223 00:14:24.478870 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_2
I1223 00:14:24.478878 25375 net.cpp:380] c_t=14_encode2_unit_t=14_0_split -> c_t=14_encode2_unit_t=14_0_split_3
I1223 00:14:24.478935 25375 net.cpp:122] Setting up c_t=14_encode2_unit_t=14_0_split
I1223 00:14:24.478942 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478946 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478965 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478968 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.478971 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:24.478974 25375 layer_factory.hpp:77] Creating layer h_t=14_encode2_unit_t=14_1_split
I1223 00:14:24.478981 25375 net.cpp:84] Creating Layer h_t=14_encode2_unit_t=14_1_split
I1223 00:14:24.478983 25375 net.cpp:406] h_t=14_encode2_unit_t=14_1_split <- h_t=14
I1223 00:14:24.478988 25375 net.cpp:380] h_t=14_encode2_unit_t=14_1_split -> h_t=14_encode2_unit_t=14_1_split_0
I1223 00:14:24.478996 25375 net.cpp:380] h_t=14_encode2_unit_t=14_1_split -> h_t=14_encode2_unit_t=14_1_split_1
I1223 00:14:24.479028 25375 net.cpp:122] Setting up h_t=14_encode2_unit_t=14_1_split
I1223 00:14:24.479034 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.479038 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.479041 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:24.479044 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=14
I1223 00:14:24.479049 25375 net.cpp:84] Creating Layer encode2_h_conted_t=14
I1223 00:14:24.479053 25375 net.cpp:406] encode2_h_conted_t=14 <- h_t=14_encode2_unit_t=14_1_split_0
I1223 00:14:24.479058 25375 net.cpp:406] encode2_h_conted_t=14 <- cont_t=15_encode2_cont_slice_14_split_0
I1223 00:14:24.479063 25375 net.cpp:380] encode2_h_conted_t=14 -> h_conted_t=14
I1223 00:14:24.479138 25375 net.cpp:122] Setting up encode2_h_conted_t=14
I1223 00:14:24.479146 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.479148 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:24.479151 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->14
I1223 00:14:24.479161 25375 net.cpp:84] Creating Layer encode2_hidden->transform->14
I1223 00:14:24.479166 25375 net.cpp:406] encode2_hidden->transform->14 <- h_conted_t=14
I1223 00:14:24.479172 25375 net.cpp:380] encode2_hidden->transform->14 -> hidden->transform->14
I1223 00:14:24.479684 25375 net.cpp:122] Setting up encode2_hidden->transform->14
I1223 00:14:24.479692 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.479696 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:24.479713 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.479717 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.479720 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=14
I1223 00:14:24.479725 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=14
I1223 00:14:24.479730 25375 net.cpp:406] encode2_hadamard->input_t=14 <- c_t=14_encode2_unit_t=14_0_split_0
I1223 00:14:24.479737 25375 net.cpp:380] encode2_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:24.479848 25375 net.cpp:122] Setting up encode2_hadamard->input_t=14
I1223 00:14:24.479856 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.479858 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:24.479862 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.479866 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=14
I1223 00:14:24.479871 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=14
I1223 00:14:24.479874 25375 net.cpp:406] encode2_hadamard->forget_t=14 <- c_t=14_encode2_unit_t=14_0_split_1
I1223 00:14:24.479882 25375 net.cpp:380] encode2_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:24.480001 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=14
I1223 00:14:24.480007 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480011 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:24.480015 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.480017 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=14
I1223 00:14:24.480036 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=14
I1223 00:14:24.480041 25375 net.cpp:406] encode2_hadamard->output_t=14 <- c_t=14_encode2_unit_t=14_0_split_2
I1223 00:14:24.480058 25375 net.cpp:380] encode2_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:24.480162 25375 net.cpp:122] Setting up encode2_hadamard->output_t=14
I1223 00:14:24.480170 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480172 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:24.480176 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.480180 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=15
I1223 00:14:24.480187 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=15
I1223 00:14:24.480192 25375 net.cpp:380] encode2_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:24.480257 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=15
I1223 00:14:24.480263 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480267 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:24.480284 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=15
I1223 00:14:24.480291 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=15
I1223 00:14:24.480295 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:24.480299 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:24.480304 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:24.480309 25375 net.cpp:406] encode2_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:24.480326 25375 net.cpp:380] encode2_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:24.480350 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=15
I1223 00:14:24.480356 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.480360 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:24.480362 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_15
I1223 00:14:24.480368 25375 net.cpp:84] Creating Layer encode2_gate_input_15
I1223 00:14:24.480373 25375 net.cpp:406] encode2_gate_input_15 <- hidden->transform->14
I1223 00:14:24.480377 25375 net.cpp:406] encode2_gate_input_15 <- x->transform->t=15
I1223 00:14:24.480381 25375 net.cpp:406] encode2_gate_input_15 <- hadamard_t=15
I1223 00:14:24.480387 25375 net.cpp:380] encode2_gate_input_15 -> gate_input_15
I1223 00:14:24.480409 25375 net.cpp:122] Setting up encode2_gate_input_15
I1223 00:14:24.480415 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.480418 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:24.480422 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=15
I1223 00:14:24.480442 25375 net.cpp:84] Creating Layer encode2_unit_t=15
I1223 00:14:24.480445 25375 net.cpp:406] encode2_unit_t=15 <- c_t=14_encode2_unit_t=14_0_split_3
I1223 00:14:24.480463 25375 net.cpp:406] encode2_unit_t=15 <- gate_input_15
I1223 00:14:24.480468 25375 net.cpp:406] encode2_unit_t=15 <- cont_t=15_encode2_cont_slice_14_split_1
I1223 00:14:24.480473 25375 net.cpp:380] encode2_unit_t=15 -> c_t=15
I1223 00:14:24.480479 25375 net.cpp:380] encode2_unit_t=15 -> h_t=15
I1223 00:14:24.480526 25375 net.cpp:122] Setting up encode2_unit_t=15
I1223 00:14:24.480545 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480551 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480552 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:24.480556 25375 layer_factory.hpp:77] Creating layer c_t=15_encode2_unit_t=15_0_split
I1223 00:14:24.480561 25375 net.cpp:84] Creating Layer c_t=15_encode2_unit_t=15_0_split
I1223 00:14:24.480564 25375 net.cpp:406] c_t=15_encode2_unit_t=15_0_split <- c_t=15
I1223 00:14:24.480571 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_0
I1223 00:14:24.480592 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_1
I1223 00:14:24.480600 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_2
I1223 00:14:24.480607 25375 net.cpp:380] c_t=15_encode2_unit_t=15_0_split -> c_t=15_encode2_unit_t=15_0_split_3
I1223 00:14:24.480676 25375 net.cpp:122] Setting up c_t=15_encode2_unit_t=15_0_split
I1223 00:14:24.480682 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480686 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480691 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480695 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480697 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:24.480700 25375 layer_factory.hpp:77] Creating layer h_t=15_encode2_unit_t=15_1_split
I1223 00:14:24.480705 25375 net.cpp:84] Creating Layer h_t=15_encode2_unit_t=15_1_split
I1223 00:14:24.480708 25375 net.cpp:406] h_t=15_encode2_unit_t=15_1_split <- h_t=15
I1223 00:14:24.480713 25375 net.cpp:380] h_t=15_encode2_unit_t=15_1_split -> h_t=15_encode2_unit_t=15_1_split_0
I1223 00:14:24.480720 25375 net.cpp:380] h_t=15_encode2_unit_t=15_1_split -> h_t=15_encode2_unit_t=15_1_split_1
I1223 00:14:24.480767 25375 net.cpp:122] Setting up h_t=15_encode2_unit_t=15_1_split
I1223 00:14:24.480773 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480777 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480780 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:24.480783 25375 layer_factory.hpp:77] Creating layer encode2_h_conted_t=15
I1223 00:14:24.480789 25375 net.cpp:84] Creating Layer encode2_h_conted_t=15
I1223 00:14:24.480793 25375 net.cpp:406] encode2_h_conted_t=15 <- h_t=15_encode2_unit_t=15_1_split_0
I1223 00:14:24.480798 25375 net.cpp:406] encode2_h_conted_t=15 <- cont_t=16_encode2_cont_slice_15_split_0
I1223 00:14:24.480803 25375 net.cpp:380] encode2_h_conted_t=15 -> h_conted_t=15
I1223 00:14:24.480892 25375 net.cpp:122] Setting up encode2_h_conted_t=15
I1223 00:14:24.480900 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.480902 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:24.480906 25375 layer_factory.hpp:77] Creating layer encode2_hidden->transform->15
I1223 00:14:24.480914 25375 net.cpp:84] Creating Layer encode2_hidden->transform->15
I1223 00:14:24.480919 25375 net.cpp:406] encode2_hidden->transform->15 <- h_conted_t=15
I1223 00:14:24.480926 25375 net.cpp:380] encode2_hidden->transform->15 -> hidden->transform->15
I1223 00:14:24.481467 25375 net.cpp:122] Setting up encode2_hidden->transform->15
I1223 00:14:24.481475 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.481479 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:24.481482 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode2_hidden->transform->0', param index 0
I1223 00:14:24.481500 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode2_hidden->transform->0', param index 1
I1223 00:14:24.481503 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->input_t=15
I1223 00:14:24.481509 25375 net.cpp:84] Creating Layer encode2_hadamard->input_t=15
I1223 00:14:24.481513 25375 net.cpp:406] encode2_hadamard->input_t=15 <- c_t=15_encode2_unit_t=15_0_split_0
I1223 00:14:24.481520 25375 net.cpp:380] encode2_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:24.481631 25375 net.cpp:122] Setting up encode2_hadamard->input_t=15
I1223 00:14:24.481637 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.481640 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:24.481644 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode2_hadamard->input_t=0', param index 0
I1223 00:14:24.481660 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->forget_t=15
I1223 00:14:24.481667 25375 net.cpp:84] Creating Layer encode2_hadamard->forget_t=15
I1223 00:14:24.481670 25375 net.cpp:406] encode2_hadamard->forget_t=15 <- c_t=15_encode2_unit_t=15_0_split_1
I1223 00:14:24.481676 25375 net.cpp:380] encode2_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:24.481784 25375 net.cpp:122] Setting up encode2_hadamard->forget_t=15
I1223 00:14:24.481791 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.481794 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:24.481798 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode2_hadamard->forget_t=0', param index 0
I1223 00:14:24.481801 25375 layer_factory.hpp:77] Creating layer encode2_hadamard->output_t=15
I1223 00:14:24.481819 25375 net.cpp:84] Creating Layer encode2_hadamard->output_t=15
I1223 00:14:24.481822 25375 net.cpp:406] encode2_hadamard->output_t=15 <- c_t=15_encode2_unit_t=15_0_split_2
I1223 00:14:24.481828 25375 net.cpp:380] encode2_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:24.481919 25375 net.cpp:122] Setting up encode2_hadamard->output_t=15
I1223 00:14:24.481925 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.481928 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:24.481932 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode2_hadamard->output_t=0', param index 0
I1223 00:14:24.481935 25375 layer_factory.hpp:77] Creating layer encode2_hadamard_gat_t=16
I1223 00:14:24.481940 25375 net.cpp:84] Creating Layer encode2_hadamard_gat_t=16
I1223 00:14:24.481945 25375 net.cpp:380] encode2_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:24.482013 25375 net.cpp:122] Setting up encode2_hadamard_gat_t=16
I1223 00:14:24.482020 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.482023 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:24.482026 25375 layer_factory.hpp:77] Creating layer encode2_concat_hadamard_t=16
I1223 00:14:24.482033 25375 net.cpp:84] Creating Layer encode2_concat_hadamard_t=16
I1223 00:14:24.482035 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:24.482040 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:24.482044 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:24.482049 25375 net.cpp:406] encode2_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:24.482056 25375 net.cpp:380] encode2_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:24.482079 25375 net.cpp:122] Setting up encode2_concat_hadamard_t=16
I1223 00:14:24.482087 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.482090 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:24.482094 25375 layer_factory.hpp:77] Creating layer encode2_gate_input_16
I1223 00:14:24.482098 25375 net.cpp:84] Creating Layer encode2_gate_input_16
I1223 00:14:24.482102 25375 net.cpp:406] encode2_gate_input_16 <- hidden->transform->15
I1223 00:14:24.482106 25375 net.cpp:406] encode2_gate_input_16 <- x->transform->t=16
I1223 00:14:24.482110 25375 net.cpp:406] encode2_gate_input_16 <- hadamard_t=16
I1223 00:14:24.482115 25375 net.cpp:380] encode2_gate_input_16 -> gate_input_16
I1223 00:14:24.482138 25375 net.cpp:122] Setting up encode2_gate_input_16
I1223 00:14:24.482144 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.482147 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:24.482151 25375 layer_factory.hpp:77] Creating layer encode2_unit_t=16
I1223 00:14:24.482156 25375 net.cpp:84] Creating Layer encode2_unit_t=16
I1223 00:14:24.482161 25375 net.cpp:406] encode2_unit_t=16 <- c_t=15_encode2_unit_t=15_0_split_3
I1223 00:14:24.482165 25375 net.cpp:406] encode2_unit_t=16 <- gate_input_16
I1223 00:14:24.482169 25375 net.cpp:406] encode2_unit_t=16 <- cont_t=16_encode2_cont_slice_15_split_1
I1223 00:14:24.482174 25375 net.cpp:380] encode2_unit_t=16 -> c_t=16
I1223 00:14:24.482182 25375 net.cpp:380] encode2_unit_t=16 -> h_t=16
I1223 00:14:24.482242 25375 net.cpp:122] Setting up encode2_unit_t=16
I1223 00:14:24.482249 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.482254 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.482256 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:24.482272 25375 layer_factory.hpp:77] Creating layer h_t=16_encode2_unit_t=16_1_split
I1223 00:14:24.482277 25375 net.cpp:84] Creating Layer h_t=16_encode2_unit_t=16_1_split
I1223 00:14:24.482280 25375 net.cpp:406] h_t=16_encode2_unit_t=16_1_split <- h_t=16
I1223 00:14:24.482287 25375 net.cpp:380] h_t=16_encode2_unit_t=16_1_split -> h_t=16_encode2_unit_t=16_1_split_0
I1223 00:14:24.482295 25375 net.cpp:380] h_t=16_encode2_unit_t=16_1_split -> h_t=16_encode2_unit_t=16_1_split_1
I1223 00:14:24.482343 25375 net.cpp:122] Setting up h_t=16_encode2_unit_t=16_1_split
I1223 00:14:24.482349 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.482354 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.482357 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:24.482359 25375 layer_factory.hpp:77] Creating layer encode2_h_concat
I1223 00:14:24.482380 25375 net.cpp:84] Creating Layer encode2_h_concat
I1223 00:14:24.482384 25375 net.cpp:406] encode2_h_concat <- h_t=1_encode2_unit_t=1_1_split_1
I1223 00:14:24.482389 25375 net.cpp:406] encode2_h_concat <- h_t=2_encode2_unit_t=2_1_split_1
I1223 00:14:24.482393 25375 net.cpp:406] encode2_h_concat <- h_t=3_encode2_unit_t=3_1_split_1
I1223 00:14:24.482396 25375 net.cpp:406] encode2_h_concat <- h_t=4_encode2_unit_t=4_1_split_1
I1223 00:14:24.482400 25375 net.cpp:406] encode2_h_concat <- h_t=5_encode2_unit_t=5_1_split_1
I1223 00:14:24.482404 25375 net.cpp:406] encode2_h_concat <- h_t=6_encode2_unit_t=6_1_split_1
I1223 00:14:24.482409 25375 net.cpp:406] encode2_h_concat <- h_t=7_encode2_unit_t=7_1_split_1
I1223 00:14:24.482411 25375 net.cpp:406] encode2_h_concat <- h_t=8_encode2_unit_t=8_1_split_1
I1223 00:14:24.482414 25375 net.cpp:406] encode2_h_concat <- h_t=9_encode2_unit_t=9_1_split_1
I1223 00:14:24.482419 25375 net.cpp:406] encode2_h_concat <- h_t=10_encode2_unit_t=10_1_split_1
I1223 00:14:24.482422 25375 net.cpp:406] encode2_h_concat <- h_t=11_encode2_unit_t=11_1_split_1
I1223 00:14:24.482425 25375 net.cpp:406] encode2_h_concat <- h_t=12_encode2_unit_t=12_1_split_1
I1223 00:14:24.482429 25375 net.cpp:406] encode2_h_concat <- h_t=13_encode2_unit_t=13_1_split_1
I1223 00:14:24.482432 25375 net.cpp:406] encode2_h_concat <- h_t=14_encode2_unit_t=14_1_split_1
I1223 00:14:24.482436 25375 net.cpp:406] encode2_h_concat <- h_t=15_encode2_unit_t=15_1_split_1
I1223 00:14:24.482439 25375 net.cpp:406] encode2_h_concat <- h_t=16_encode2_unit_t=16_1_split_0
I1223 00:14:24.482445 25375 net.cpp:380] encode2_h_concat -> h
I1223 00:14:24.482470 25375 net.cpp:122] Setting up encode2_h_concat
I1223 00:14:24.482475 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.482491 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:24.482496 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_h
I1223 00:14:24.482499 25375 net.cpp:84] Creating Layer encode2_dummy_forward_h
I1223 00:14:24.482503 25375 net.cpp:406] encode2_dummy_forward_h <- h_t=16_encode2_unit_t=16_1_split_1
I1223 00:14:24.482509 25375 net.cpp:380] encode2_dummy_forward_h -> h_t=T
I1223 00:14:24.482560 25375 net.cpp:122] Setting up encode2_dummy_forward_h
I1223 00:14:24.482566 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.482569 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:24.482575 25375 layer_factory.hpp:77] Creating layer encode2_dummy_forward_c
I1223 00:14:24.482581 25375 net.cpp:84] Creating Layer encode2_dummy_forward_c
I1223 00:14:24.482584 25375 net.cpp:406] encode2_dummy_forward_c <- c_t=16
I1223 00:14:24.482590 25375 net.cpp:380] encode2_dummy_forward_c -> c_t=T
I1223 00:14:24.482627 25375 net.cpp:122] Setting up encode2_dummy_forward_c
I1223 00:14:24.482633 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.482650 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:24.482655 25375 layer_factory.hpp:77] Creating layer encode2_h_t=T_pseudoloss
I1223 00:14:24.482659 25375 net.cpp:84] Creating Layer encode2_h_t=T_pseudoloss
I1223 00:14:24.482663 25375 net.cpp:406] encode2_h_t=T_pseudoloss <- h_t=T
I1223 00:14:24.482667 25375 net.cpp:380] encode2_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:24.482748 25375 net.cpp:122] Setting up encode2_h_t=T_pseudoloss
I1223 00:14:24.482753 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.482756 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.482766 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:24.482769 25375 layer_factory.hpp:77] Creating layer encode2_c_t=T_pseudoloss
I1223 00:14:24.482774 25375 net.cpp:84] Creating Layer encode2_c_t=T_pseudoloss
I1223 00:14:24.482777 25375 net.cpp:406] encode2_c_t=T_pseudoloss <- c_t=T
I1223 00:14:24.482784 25375 net.cpp:380] encode2_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:24.482864 25375 net.cpp:122] Setting up encode2_c_t=T_pseudoloss
I1223 00:14:24.482870 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.482873 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.482877 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:24.482880 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:24.482885 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:24.482903 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:24.482908 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:24.484004 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:24.484014 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.484019 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.484022 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:24.484040 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:24.484043 25375 net.cpp:198] encode2_c_t=T_pseudoloss needs backward computation.
I1223 00:14:24.484047 25375 net.cpp:198] encode2_h_t=T_pseudoloss needs backward computation.
I1223 00:14:24.484050 25375 net.cpp:198] encode2_dummy_forward_c needs backward computation.
I1223 00:14:24.484053 25375 net.cpp:198] encode2_dummy_forward_h needs backward computation.
I1223 00:14:24.484056 25375 net.cpp:198] encode2_h_concat needs backward computation.
I1223 00:14:24.484063 25375 net.cpp:198] h_t=16_encode2_unit_t=16_1_split needs backward computation.
I1223 00:14:24.484067 25375 net.cpp:198] encode2_unit_t=16 needs backward computation.
I1223 00:14:24.484072 25375 net.cpp:198] encode2_gate_input_16 needs backward computation.
I1223 00:14:24.484077 25375 net.cpp:198] encode2_concat_hadamard_t=16 needs backward computation.
I1223 00:14:24.484082 25375 net.cpp:200] encode2_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:24.484086 25375 net.cpp:198] encode2_hadamard->output_t=15 needs backward computation.
I1223 00:14:24.484088 25375 net.cpp:198] encode2_hadamard->forget_t=15 needs backward computation.
I1223 00:14:24.484091 25375 net.cpp:198] encode2_hadamard->input_t=15 needs backward computation.
I1223 00:14:24.484096 25375 net.cpp:198] encode2_hidden->transform->15 needs backward computation.
I1223 00:14:24.484098 25375 net.cpp:198] encode2_h_conted_t=15 needs backward computation.
I1223 00:14:24.484102 25375 net.cpp:198] h_t=15_encode2_unit_t=15_1_split needs backward computation.
I1223 00:14:24.484107 25375 net.cpp:198] c_t=15_encode2_unit_t=15_0_split needs backward computation.
I1223 00:14:24.484109 25375 net.cpp:198] encode2_unit_t=15 needs backward computation.
I1223 00:14:24.484113 25375 net.cpp:198] encode2_gate_input_15 needs backward computation.
I1223 00:14:24.484118 25375 net.cpp:198] encode2_concat_hadamard_t=15 needs backward computation.
I1223 00:14:24.484122 25375 net.cpp:200] encode2_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:24.484127 25375 net.cpp:198] encode2_hadamard->output_t=14 needs backward computation.
I1223 00:14:24.484129 25375 net.cpp:198] encode2_hadamard->forget_t=14 needs backward computation.
I1223 00:14:24.484133 25375 net.cpp:198] encode2_hadamard->input_t=14 needs backward computation.
I1223 00:14:24.484135 25375 net.cpp:198] encode2_hidden->transform->14 needs backward computation.
I1223 00:14:24.484139 25375 net.cpp:198] encode2_h_conted_t=14 needs backward computation.
I1223 00:14:24.484144 25375 net.cpp:198] h_t=14_encode2_unit_t=14_1_split needs backward computation.
I1223 00:14:24.484148 25375 net.cpp:198] c_t=14_encode2_unit_t=14_0_split needs backward computation.
I1223 00:14:24.484151 25375 net.cpp:198] encode2_unit_t=14 needs backward computation.
I1223 00:14:24.484156 25375 net.cpp:198] encode2_gate_input_14 needs backward computation.
I1223 00:14:24.484160 25375 net.cpp:198] encode2_concat_hadamard_t=14 needs backward computation.
I1223 00:14:24.484165 25375 net.cpp:200] encode2_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:24.484169 25375 net.cpp:198] encode2_hadamard->output_t=13 needs backward computation.
I1223 00:14:24.484171 25375 net.cpp:198] encode2_hadamard->forget_t=13 needs backward computation.
I1223 00:14:24.484175 25375 net.cpp:198] encode2_hadamard->input_t=13 needs backward computation.
I1223 00:14:24.484179 25375 net.cpp:198] encode2_hidden->transform->13 needs backward computation.
I1223 00:14:24.484181 25375 net.cpp:198] encode2_h_conted_t=13 needs backward computation.
I1223 00:14:24.484185 25375 net.cpp:198] h_t=13_encode2_unit_t=13_1_split needs backward computation.
I1223 00:14:24.484189 25375 net.cpp:198] c_t=13_encode2_unit_t=13_0_split needs backward computation.
I1223 00:14:24.484192 25375 net.cpp:198] encode2_unit_t=13 needs backward computation.
I1223 00:14:24.484196 25375 net.cpp:198] encode2_gate_input_13 needs backward computation.
I1223 00:14:24.484201 25375 net.cpp:198] encode2_concat_hadamard_t=13 needs backward computation.
I1223 00:14:24.484205 25375 net.cpp:200] encode2_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:24.484210 25375 net.cpp:198] encode2_hadamard->output_t=12 needs backward computation.
I1223 00:14:24.484212 25375 net.cpp:198] encode2_hadamard->forget_t=12 needs backward computation.
I1223 00:14:24.484217 25375 net.cpp:198] encode2_hadamard->input_t=12 needs backward computation.
I1223 00:14:24.484221 25375 net.cpp:198] encode2_hidden->transform->12 needs backward computation.
I1223 00:14:24.484225 25375 net.cpp:198] encode2_h_conted_t=12 needs backward computation.
I1223 00:14:24.484230 25375 net.cpp:198] h_t=12_encode2_unit_t=12_1_split needs backward computation.
I1223 00:14:24.484233 25375 net.cpp:198] c_t=12_encode2_unit_t=12_0_split needs backward computation.
I1223 00:14:24.484236 25375 net.cpp:198] encode2_unit_t=12 needs backward computation.
I1223 00:14:24.484241 25375 net.cpp:198] encode2_gate_input_12 needs backward computation.
I1223 00:14:24.484244 25375 net.cpp:198] encode2_concat_hadamard_t=12 needs backward computation.
I1223 00:14:24.484249 25375 net.cpp:200] encode2_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:24.484252 25375 net.cpp:198] encode2_hadamard->output_t=11 needs backward computation.
I1223 00:14:24.484256 25375 net.cpp:198] encode2_hadamard->forget_t=11 needs backward computation.
I1223 00:14:24.484258 25375 net.cpp:198] encode2_hadamard->input_t=11 needs backward computation.
I1223 00:14:24.484262 25375 net.cpp:198] encode2_hidden->transform->11 needs backward computation.
I1223 00:14:24.484266 25375 net.cpp:198] encode2_h_conted_t=11 needs backward computation.
I1223 00:14:24.484269 25375 net.cpp:198] h_t=11_encode2_unit_t=11_1_split needs backward computation.
I1223 00:14:24.484273 25375 net.cpp:198] c_t=11_encode2_unit_t=11_0_split needs backward computation.
I1223 00:14:24.484277 25375 net.cpp:198] encode2_unit_t=11 needs backward computation.
I1223 00:14:24.484280 25375 net.cpp:198] encode2_gate_input_11 needs backward computation.
I1223 00:14:24.484285 25375 net.cpp:198] encode2_concat_hadamard_t=11 needs backward computation.
I1223 00:14:24.484292 25375 net.cpp:200] encode2_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:24.484294 25375 net.cpp:198] encode2_hadamard->output_t=10 needs backward computation.
I1223 00:14:24.484298 25375 net.cpp:198] encode2_hadamard->forget_t=10 needs backward computation.
I1223 00:14:24.484302 25375 net.cpp:198] encode2_hadamard->input_t=10 needs backward computation.
I1223 00:14:24.484305 25375 net.cpp:198] encode2_hidden->transform->10 needs backward computation.
I1223 00:14:24.484308 25375 net.cpp:198] encode2_h_conted_t=10 needs backward computation.
I1223 00:14:24.484313 25375 net.cpp:198] h_t=10_encode2_unit_t=10_1_split needs backward computation.
I1223 00:14:24.484316 25375 net.cpp:198] c_t=10_encode2_unit_t=10_0_split needs backward computation.
I1223 00:14:24.484319 25375 net.cpp:198] encode2_unit_t=10 needs backward computation.
I1223 00:14:24.484324 25375 net.cpp:198] encode2_gate_input_10 needs backward computation.
I1223 00:14:24.484328 25375 net.cpp:198] encode2_concat_hadamard_t=10 needs backward computation.
I1223 00:14:24.484334 25375 net.cpp:200] encode2_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:24.484338 25375 net.cpp:198] encode2_hadamard->output_t=9 needs backward computation.
I1223 00:14:24.484340 25375 net.cpp:198] encode2_hadamard->forget_t=9 needs backward computation.
I1223 00:14:24.484344 25375 net.cpp:198] encode2_hadamard->input_t=9 needs backward computation.
I1223 00:14:24.484349 25375 net.cpp:198] encode2_hidden->transform->9 needs backward computation.
I1223 00:14:24.484352 25375 net.cpp:198] encode2_h_conted_t=9 needs backward computation.
I1223 00:14:24.484356 25375 net.cpp:198] h_t=9_encode2_unit_t=9_1_split needs backward computation.
I1223 00:14:24.484360 25375 net.cpp:198] c_t=9_encode2_unit_t=9_0_split needs backward computation.
I1223 00:14:24.484364 25375 net.cpp:198] encode2_unit_t=9 needs backward computation.
I1223 00:14:24.484369 25375 net.cpp:198] encode2_gate_input_9 needs backward computation.
I1223 00:14:24.484375 25375 net.cpp:198] encode2_concat_hadamard_t=9 needs backward computation.
I1223 00:14:24.484380 25375 net.cpp:200] encode2_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:24.484383 25375 net.cpp:198] encode2_hadamard->output_t=8 needs backward computation.
I1223 00:14:24.484386 25375 net.cpp:198] encode2_hadamard->forget_t=8 needs backward computation.
I1223 00:14:24.484390 25375 net.cpp:198] encode2_hadamard->input_t=8 needs backward computation.
I1223 00:14:24.484395 25375 net.cpp:198] encode2_hidden->transform->8 needs backward computation.
I1223 00:14:24.484397 25375 net.cpp:198] encode2_h_conted_t=8 needs backward computation.
I1223 00:14:24.484402 25375 net.cpp:198] h_t=8_encode2_unit_t=8_1_split needs backward computation.
I1223 00:14:24.484406 25375 net.cpp:198] c_t=8_encode2_unit_t=8_0_split needs backward computation.
I1223 00:14:24.484410 25375 net.cpp:198] encode2_unit_t=8 needs backward computation.
I1223 00:14:24.484416 25375 net.cpp:198] encode2_gate_input_8 needs backward computation.
I1223 00:14:24.484419 25375 net.cpp:198] encode2_concat_hadamard_t=8 needs backward computation.
I1223 00:14:24.484426 25375 net.cpp:200] encode2_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:24.484428 25375 net.cpp:198] encode2_hadamard->output_t=7 needs backward computation.
I1223 00:14:24.484432 25375 net.cpp:198] encode2_hadamard->forget_t=7 needs backward computation.
I1223 00:14:24.484436 25375 net.cpp:198] encode2_hadamard->input_t=7 needs backward computation.
I1223 00:14:24.484439 25375 net.cpp:198] encode2_hidden->transform->7 needs backward computation.
I1223 00:14:24.484443 25375 net.cpp:198] encode2_h_conted_t=7 needs backward computation.
I1223 00:14:24.484447 25375 net.cpp:198] h_t=7_encode2_unit_t=7_1_split needs backward computation.
I1223 00:14:24.484454 25375 net.cpp:198] c_t=7_encode2_unit_t=7_0_split needs backward computation.
I1223 00:14:24.484458 25375 net.cpp:198] encode2_unit_t=7 needs backward computation.
I1223 00:14:24.484463 25375 net.cpp:198] encode2_gate_input_7 needs backward computation.
I1223 00:14:24.484467 25375 net.cpp:198] encode2_concat_hadamard_t=7 needs backward computation.
I1223 00:14:24.484472 25375 net.cpp:200] encode2_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:24.484475 25375 net.cpp:198] encode2_hadamard->output_t=6 needs backward computation.
I1223 00:14:24.484479 25375 net.cpp:198] encode2_hadamard->forget_t=6 needs backward computation.
I1223 00:14:24.484483 25375 net.cpp:198] encode2_hadamard->input_t=6 needs backward computation.
I1223 00:14:24.484488 25375 net.cpp:198] encode2_hidden->transform->6 needs backward computation.
I1223 00:14:24.484491 25375 net.cpp:198] encode2_h_conted_t=6 needs backward computation.
I1223 00:14:24.484496 25375 net.cpp:198] h_t=6_encode2_unit_t=6_1_split needs backward computation.
I1223 00:14:24.484500 25375 net.cpp:198] c_t=6_encode2_unit_t=6_0_split needs backward computation.
I1223 00:14:24.484503 25375 net.cpp:198] encode2_unit_t=6 needs backward computation.
I1223 00:14:24.484508 25375 net.cpp:198] encode2_gate_input_6 needs backward computation.
I1223 00:14:24.484513 25375 net.cpp:198] encode2_concat_hadamard_t=6 needs backward computation.
I1223 00:14:24.484519 25375 net.cpp:200] encode2_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:24.484522 25375 net.cpp:198] encode2_hadamard->output_t=5 needs backward computation.
I1223 00:14:24.484525 25375 net.cpp:198] encode2_hadamard->forget_t=5 needs backward computation.
I1223 00:14:24.484529 25375 net.cpp:198] encode2_hadamard->input_t=5 needs backward computation.
I1223 00:14:24.484534 25375 net.cpp:198] encode2_hidden->transform->5 needs backward computation.
I1223 00:14:24.484537 25375 net.cpp:198] encode2_h_conted_t=5 needs backward computation.
I1223 00:14:24.484541 25375 net.cpp:198] h_t=5_encode2_unit_t=5_1_split needs backward computation.
I1223 00:14:24.484546 25375 net.cpp:198] c_t=5_encode2_unit_t=5_0_split needs backward computation.
I1223 00:14:24.484549 25375 net.cpp:198] encode2_unit_t=5 needs backward computation.
I1223 00:14:24.484555 25375 net.cpp:198] encode2_gate_input_5 needs backward computation.
I1223 00:14:24.484560 25375 net.cpp:198] encode2_concat_hadamard_t=5 needs backward computation.
I1223 00:14:24.484565 25375 net.cpp:200] encode2_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:24.484568 25375 net.cpp:198] encode2_hadamard->output_t=4 needs backward computation.
I1223 00:14:24.484571 25375 net.cpp:198] encode2_hadamard->forget_t=4 needs backward computation.
I1223 00:14:24.484575 25375 net.cpp:198] encode2_hadamard->input_t=4 needs backward computation.
I1223 00:14:24.484580 25375 net.cpp:198] encode2_hidden->transform->4 needs backward computation.
I1223 00:14:24.484582 25375 net.cpp:198] encode2_h_conted_t=4 needs backward computation.
I1223 00:14:24.484586 25375 net.cpp:198] h_t=4_encode2_unit_t=4_1_split needs backward computation.
I1223 00:14:24.484589 25375 net.cpp:198] c_t=4_encode2_unit_t=4_0_split needs backward computation.
I1223 00:14:24.484593 25375 net.cpp:198] encode2_unit_t=4 needs backward computation.
I1223 00:14:24.484598 25375 net.cpp:198] encode2_gate_input_4 needs backward computation.
I1223 00:14:24.484602 25375 net.cpp:198] encode2_concat_hadamard_t=4 needs backward computation.
I1223 00:14:24.484608 25375 net.cpp:200] encode2_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:24.484612 25375 net.cpp:198] encode2_hadamard->output_t=3 needs backward computation.
I1223 00:14:24.484616 25375 net.cpp:198] encode2_hadamard->forget_t=3 needs backward computation.
I1223 00:14:24.484619 25375 net.cpp:198] encode2_hadamard->input_t=3 needs backward computation.
I1223 00:14:24.484622 25375 net.cpp:198] encode2_hidden->transform->3 needs backward computation.
I1223 00:14:24.484627 25375 net.cpp:198] encode2_h_conted_t=3 needs backward computation.
I1223 00:14:24.484630 25375 net.cpp:198] h_t=3_encode2_unit_t=3_1_split needs backward computation.
I1223 00:14:24.484634 25375 net.cpp:198] c_t=3_encode2_unit_t=3_0_split needs backward computation.
I1223 00:14:24.484637 25375 net.cpp:198] encode2_unit_t=3 needs backward computation.
I1223 00:14:24.484642 25375 net.cpp:198] encode2_gate_input_3 needs backward computation.
I1223 00:14:24.484647 25375 net.cpp:198] encode2_concat_hadamard_t=3 needs backward computation.
I1223 00:14:24.484652 25375 net.cpp:200] encode2_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:24.484654 25375 net.cpp:198] encode2_hadamard->output_t=2 needs backward computation.
I1223 00:14:24.484658 25375 net.cpp:198] encode2_hadamard->forget_t=2 needs backward computation.
I1223 00:14:24.484663 25375 net.cpp:198] encode2_hadamard->input_t=2 needs backward computation.
I1223 00:14:24.484665 25375 net.cpp:198] encode2_hidden->transform->2 needs backward computation.
I1223 00:14:24.484669 25375 net.cpp:198] encode2_h_conted_t=2 needs backward computation.
I1223 00:14:24.484673 25375 net.cpp:198] h_t=2_encode2_unit_t=2_1_split needs backward computation.
I1223 00:14:24.484678 25375 net.cpp:198] c_t=2_encode2_unit_t=2_0_split needs backward computation.
I1223 00:14:24.484680 25375 net.cpp:198] encode2_unit_t=2 needs backward computation.
I1223 00:14:24.484685 25375 net.cpp:198] encode2_gate_input_2 needs backward computation.
I1223 00:14:24.484691 25375 net.cpp:198] encode2_concat_hadamard_t=2 needs backward computation.
I1223 00:14:24.484696 25375 net.cpp:200] encode2_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:24.484699 25375 net.cpp:198] encode2_hadamard->output_t=1 needs backward computation.
I1223 00:14:24.484702 25375 net.cpp:198] encode2_hadamard->forget_t=1 needs backward computation.
I1223 00:14:24.484706 25375 net.cpp:198] encode2_hadamard->input_t=1 needs backward computation.
I1223 00:14:24.484710 25375 net.cpp:198] encode2_hidden->transform->1 needs backward computation.
I1223 00:14:24.484714 25375 net.cpp:198] encode2_h_conted_t=1 needs backward computation.
I1223 00:14:24.484719 25375 net.cpp:198] h_t=1_encode2_unit_t=1_1_split needs backward computation.
I1223 00:14:24.484722 25375 net.cpp:198] c_t=1_encode2_unit_t=1_0_split needs backward computation.
I1223 00:14:24.484725 25375 net.cpp:198] encode2_unit_t=1 needs backward computation.
I1223 00:14:24.484730 25375 net.cpp:198] encode2_gate_input_1 needs backward computation.
I1223 00:14:24.484735 25375 net.cpp:198] encode2_concat_hadamard_t=1 needs backward computation.
I1223 00:14:24.484740 25375 net.cpp:200] encode2_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:24.484743 25375 net.cpp:198] encode2_hadamard->output_t=0 needs backward computation.
I1223 00:14:24.484747 25375 net.cpp:198] encode2_hadamard->forget_t=0 needs backward computation.
I1223 00:14:24.484750 25375 net.cpp:198] encode2_hadamard->input_t=0 needs backward computation.
I1223 00:14:24.484755 25375 net.cpp:198] encode2_hidden->transform->0 needs backward computation.
I1223 00:14:24.484758 25375 net.cpp:198] encode2_h_conted_t=0 needs backward computation.
I1223 00:14:24.484762 25375 net.cpp:198] encode2_dummy_forward_h0 needs backward computation.
I1223 00:14:24.484766 25375 net.cpp:198] c_t=0_encode2_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:24.484769 25375 net.cpp:198] encode2_dummy_forward_c0 needs backward computation.
I1223 00:14:24.484773 25375 net.cpp:200] cont_t=16_encode2_cont_slice_15_split does not need backward computation.
I1223 00:14:24.484778 25375 net.cpp:200] cont_t=15_encode2_cont_slice_14_split does not need backward computation.
I1223 00:14:24.484782 25375 net.cpp:200] cont_t=14_encode2_cont_slice_13_split does not need backward computation.
I1223 00:14:24.484787 25375 net.cpp:200] cont_t=13_encode2_cont_slice_12_split does not need backward computation.
I1223 00:14:24.484791 25375 net.cpp:200] cont_t=12_encode2_cont_slice_11_split does not need backward computation.
I1223 00:14:24.484796 25375 net.cpp:200] cont_t=11_encode2_cont_slice_10_split does not need backward computation.
I1223 00:14:24.484799 25375 net.cpp:200] cont_t=10_encode2_cont_slice_9_split does not need backward computation.
I1223 00:14:24.484803 25375 net.cpp:200] cont_t=9_encode2_cont_slice_8_split does not need backward computation.
I1223 00:14:24.484807 25375 net.cpp:200] cont_t=8_encode2_cont_slice_7_split does not need backward computation.
I1223 00:14:24.484812 25375 net.cpp:200] cont_t=7_encode2_cont_slice_6_split does not need backward computation.
I1223 00:14:24.484815 25375 net.cpp:200] cont_t=6_encode2_cont_slice_5_split does not need backward computation.
I1223 00:14:24.484819 25375 net.cpp:200] cont_t=5_encode2_cont_slice_4_split does not need backward computation.
I1223 00:14:24.484823 25375 net.cpp:200] cont_t=4_encode2_cont_slice_3_split does not need backward computation.
I1223 00:14:24.484827 25375 net.cpp:200] cont_t=3_encode2_cont_slice_2_split does not need backward computation.
I1223 00:14:24.484830 25375 net.cpp:200] cont_t=2_encode2_cont_slice_1_split does not need backward computation.
I1223 00:14:24.484835 25375 net.cpp:200] cont_t=1_encode2_cont_slice_0_split does not need backward computation.
I1223 00:14:24.484843 25375 net.cpp:200] encode2_cont_slice does not need backward computation.
I1223 00:14:24.484846 25375 net.cpp:198] encode2_W_xc_x_slice needs backward computation.
I1223 00:14:24.484850 25375 net.cpp:200] encode2_input->cell_hidden does not need backward computation.
I1223 00:14:24.484853 25375 net.cpp:198] encode2_x->transform needs backward computation.
I1223 00:14:24.484858 25375 net.cpp:200] encode2_ does not need backward computation.
I1223 00:14:24.484859 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:24.484863 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:24.484869 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:24.485791 25375 net.cpp:255] Network initialization done.
I1223 00:14:24.486196 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:24.486203 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:24.486207 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:24.486210 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:24.486212 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:24.486215 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:24.486218 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:24.486222 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:24.486223 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:24.486227 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:24.486908 25375 net.cpp:122] Setting up encode2
I1223 00:14:24.486918 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.486922 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.486927 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.486930 25375 net.cpp:137] Memory required for data: 4284612992
I1223 00:14:24.486959 25375 layer_factory.hpp:77] Creating layer encode3
I1223 00:14:24.486970 25375 net.cpp:84] Creating Layer encode3
I1223 00:14:24.486976 25375 net.cpp:406] encode3 <- conv6-reshape_reshape-data_0_split_2
I1223 00:14:24.486982 25375 net.cpp:406] encode3 <- reshape-cm_reshape-cm_0_split_2
I1223 00:14:24.486987 25375 net.cpp:406] encode3 <- dummy_dummy_0_split_4
I1223 00:14:24.486991 25375 net.cpp:406] encode3 <- dummy_dummy_0_split_5
I1223 00:14:24.486997 25375 net.cpp:380] encode3 -> encode3
I1223 00:14:24.487010 25375 net.cpp:380] encode3 -> encode3_h
I1223 00:14:24.487018 25375 net.cpp:380] encode3 -> encode3_c
I1223 00:14:24.487028 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:24.488497 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode3_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode3_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode3_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode3_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode3_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode3_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode3_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode3_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode3_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode3_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode3_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode3_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode3_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode3_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode3_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode3_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode3_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode3_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 4
  }
}
layer {
  name: "encode3_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode3_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode3_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode3_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode3_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode3_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode3_hidden->transfor
I1223 00:14:24.489452 25375 layer_factory.hpp:77] Creating layer encode3_
I1223 00:14:24.489464 25375 net.cpp:84] Creating Layer encode3_
I1223 00:14:24.489468 25375 net.cpp:380] encode3_ -> x
I1223 00:14:24.489476 25375 net.cpp:380] encode3_ -> cont
I1223 00:14:24.489532 25375 net.cpp:122] Setting up encode3_
I1223 00:14:24.489540 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.489544 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.489547 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:24.489552 25375 layer_factory.hpp:77] Creating layer encode3_x->transform
I1223 00:14:24.489559 25375 net.cpp:84] Creating Layer encode3_x->transform
I1223 00:14:24.489563 25375 net.cpp:406] encode3_x->transform <- x
I1223 00:14:24.489569 25375 net.cpp:380] encode3_x->transform -> x->transform
I1223 00:14:24.489850 25375 net.cpp:122] Setting up encode3_x->transform
I1223 00:14:24.489858 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:24.489861 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:24.489867 25375 layer_factory.hpp:77] Creating layer encode3_input->cell_hidden
I1223 00:14:24.489873 25375 net.cpp:84] Creating Layer encode3_input->cell_hidden
I1223 00:14:24.489877 25375 net.cpp:380] encode3_input->cell_hidden -> c_t=0
I1223 00:14:24.489884 25375 net.cpp:380] encode3_input->cell_hidden -> h_t=0
I1223 00:14:24.489923 25375 net.cpp:122] Setting up encode3_input->cell_hidden
I1223 00:14:24.489930 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.489935 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.489938 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:24.489940 25375 layer_factory.hpp:77] Creating layer encode3_W_xc_x_slice
I1223 00:14:24.489948 25375 net.cpp:84] Creating Layer encode3_W_xc_x_slice
I1223 00:14:24.489951 25375 net.cpp:406] encode3_W_xc_x_slice <- x->transform
I1223 00:14:24.489958 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=1
I1223 00:14:24.489982 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=2
I1223 00:14:24.489991 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=3
I1223 00:14:24.490000 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=4
I1223 00:14:24.490007 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=5
I1223 00:14:24.490015 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=6
I1223 00:14:24.490023 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=7
I1223 00:14:24.490031 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=8
I1223 00:14:24.490038 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=9
I1223 00:14:24.490058 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=10
I1223 00:14:24.490067 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=11
I1223 00:14:24.490074 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=12
I1223 00:14:24.490083 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=13
I1223 00:14:24.490092 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=14
I1223 00:14:24.490100 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=15
I1223 00:14:24.490108 25375 net.cpp:380] encode3_W_xc_x_slice -> x->transform->t=16
I1223 00:14:24.490319 25375 net.cpp:122] Setting up encode3_W_xc_x_slice
I1223 00:14:24.490326 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490331 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490335 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490339 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490356 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490360 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490377 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490381 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490386 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490391 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490393 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490397 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490401 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490406 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490409 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490413 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.490417 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:24.490419 25375 layer_factory.hpp:77] Creating layer encode3_cont_slice
I1223 00:14:24.490425 25375 net.cpp:84] Creating Layer encode3_cont_slice
I1223 00:14:24.490429 25375 net.cpp:406] encode3_cont_slice <- cont
I1223 00:14:24.490435 25375 net.cpp:380] encode3_cont_slice -> cont_t=1
I1223 00:14:24.490442 25375 net.cpp:380] encode3_cont_slice -> cont_t=2
I1223 00:14:24.490449 25375 net.cpp:380] encode3_cont_slice -> cont_t=3
I1223 00:14:24.490456 25375 net.cpp:380] encode3_cont_slice -> cont_t=4
I1223 00:14:24.490464 25375 net.cpp:380] encode3_cont_slice -> cont_t=5
I1223 00:14:24.490471 25375 net.cpp:380] encode3_cont_slice -> cont_t=6
I1223 00:14:24.490478 25375 net.cpp:380] encode3_cont_slice -> cont_t=7
I1223 00:14:24.490483 25375 net.cpp:380] encode3_cont_slice -> cont_t=8
I1223 00:14:24.490489 25375 net.cpp:380] encode3_cont_slice -> cont_t=9
I1223 00:14:24.490497 25375 net.cpp:380] encode3_cont_slice -> cont_t=10
I1223 00:14:24.490504 25375 net.cpp:380] encode3_cont_slice -> cont_t=11
I1223 00:14:24.490512 25375 net.cpp:380] encode3_cont_slice -> cont_t=12
I1223 00:14:24.490520 25375 net.cpp:380] encode3_cont_slice -> cont_t=13
I1223 00:14:24.490527 25375 net.cpp:380] encode3_cont_slice -> cont_t=14
I1223 00:14:24.490533 25375 net.cpp:380] encode3_cont_slice -> cont_t=15
I1223 00:14:24.490540 25375 net.cpp:380] encode3_cont_slice -> cont_t=16
I1223 00:14:24.490769 25375 net.cpp:122] Setting up encode3_cont_slice
I1223 00:14:24.490775 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490779 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490783 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490787 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490803 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490808 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490810 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490814 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490818 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490821 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490824 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490842 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490846 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490850 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490854 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490857 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490860 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:24.490864 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode3_cont_slice_0_split
I1223 00:14:24.490869 25375 net.cpp:84] Creating Layer cont_t=1_encode3_cont_slice_0_split
I1223 00:14:24.490871 25375 net.cpp:406] cont_t=1_encode3_cont_slice_0_split <- cont_t=1
I1223 00:14:24.490876 25375 net.cpp:380] cont_t=1_encode3_cont_slice_0_split -> cont_t=1_encode3_cont_slice_0_split_0
I1223 00:14:24.490886 25375 net.cpp:380] cont_t=1_encode3_cont_slice_0_split -> cont_t=1_encode3_cont_slice_0_split_1
I1223 00:14:24.490922 25375 net.cpp:122] Setting up cont_t=1_encode3_cont_slice_0_split
I1223 00:14:24.490928 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490932 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.490936 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:24.490938 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode3_cont_slice_1_split
I1223 00:14:24.490943 25375 net.cpp:84] Creating Layer cont_t=2_encode3_cont_slice_1_split
I1223 00:14:24.490947 25375 net.cpp:406] cont_t=2_encode3_cont_slice_1_split <- cont_t=2
I1223 00:14:24.490952 25375 net.cpp:380] cont_t=2_encode3_cont_slice_1_split -> cont_t=2_encode3_cont_slice_1_split_0
I1223 00:14:24.490973 25375 net.cpp:380] cont_t=2_encode3_cont_slice_1_split -> cont_t=2_encode3_cont_slice_1_split_1
I1223 00:14:24.491021 25375 net.cpp:122] Setting up cont_t=2_encode3_cont_slice_1_split
I1223 00:14:24.491027 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491031 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491034 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:24.491037 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode3_cont_slice_2_split
I1223 00:14:24.491042 25375 net.cpp:84] Creating Layer cont_t=3_encode3_cont_slice_2_split
I1223 00:14:24.491046 25375 net.cpp:406] cont_t=3_encode3_cont_slice_2_split <- cont_t=3
I1223 00:14:24.491063 25375 net.cpp:380] cont_t=3_encode3_cont_slice_2_split -> cont_t=3_encode3_cont_slice_2_split_0
I1223 00:14:24.491070 25375 net.cpp:380] cont_t=3_encode3_cont_slice_2_split -> cont_t=3_encode3_cont_slice_2_split_1
I1223 00:14:24.491133 25375 net.cpp:122] Setting up cont_t=3_encode3_cont_slice_2_split
I1223 00:14:24.491139 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491142 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491145 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:24.491148 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode3_cont_slice_3_split
I1223 00:14:24.491168 25375 net.cpp:84] Creating Layer cont_t=4_encode3_cont_slice_3_split
I1223 00:14:24.491171 25375 net.cpp:406] cont_t=4_encode3_cont_slice_3_split <- cont_t=4
I1223 00:14:24.491178 25375 net.cpp:380] cont_t=4_encode3_cont_slice_3_split -> cont_t=4_encode3_cont_slice_3_split_0
I1223 00:14:24.491184 25375 net.cpp:380] cont_t=4_encode3_cont_slice_3_split -> cont_t=4_encode3_cont_slice_3_split_1
I1223 00:14:24.491230 25375 net.cpp:122] Setting up cont_t=4_encode3_cont_slice_3_split
I1223 00:14:24.491237 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491241 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491245 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:24.491247 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode3_cont_slice_4_split
I1223 00:14:24.491251 25375 net.cpp:84] Creating Layer cont_t=5_encode3_cont_slice_4_split
I1223 00:14:24.491255 25375 net.cpp:406] cont_t=5_encode3_cont_slice_4_split <- cont_t=5
I1223 00:14:24.491261 25375 net.cpp:380] cont_t=5_encode3_cont_slice_4_split -> cont_t=5_encode3_cont_slice_4_split_0
I1223 00:14:24.491267 25375 net.cpp:380] cont_t=5_encode3_cont_slice_4_split -> cont_t=5_encode3_cont_slice_4_split_1
I1223 00:14:24.491328 25375 net.cpp:122] Setting up cont_t=5_encode3_cont_slice_4_split
I1223 00:14:24.491333 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491349 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491353 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:24.491354 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode3_cont_slice_5_split
I1223 00:14:24.491374 25375 net.cpp:84] Creating Layer cont_t=6_encode3_cont_slice_5_split
I1223 00:14:24.491377 25375 net.cpp:406] cont_t=6_encode3_cont_slice_5_split <- cont_t=6
I1223 00:14:24.491395 25375 net.cpp:380] cont_t=6_encode3_cont_slice_5_split -> cont_t=6_encode3_cont_slice_5_split_0
I1223 00:14:24.491400 25375 net.cpp:380] cont_t=6_encode3_cont_slice_5_split -> cont_t=6_encode3_cont_slice_5_split_1
I1223 00:14:24.491434 25375 net.cpp:122] Setting up cont_t=6_encode3_cont_slice_5_split
I1223 00:14:24.491441 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491444 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491447 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:24.491451 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode3_cont_slice_6_split
I1223 00:14:24.491454 25375 net.cpp:84] Creating Layer cont_t=7_encode3_cont_slice_6_split
I1223 00:14:24.491457 25375 net.cpp:406] cont_t=7_encode3_cont_slice_6_split <- cont_t=7
I1223 00:14:24.491462 25375 net.cpp:380] cont_t=7_encode3_cont_slice_6_split -> cont_t=7_encode3_cont_slice_6_split_0
I1223 00:14:24.491468 25375 net.cpp:380] cont_t=7_encode3_cont_slice_6_split -> cont_t=7_encode3_cont_slice_6_split_1
I1223 00:14:24.491502 25375 net.cpp:122] Setting up cont_t=7_encode3_cont_slice_6_split
I1223 00:14:24.491508 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491511 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491513 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:24.491518 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode3_cont_slice_7_split
I1223 00:14:24.491523 25375 net.cpp:84] Creating Layer cont_t=8_encode3_cont_slice_7_split
I1223 00:14:24.491525 25375 net.cpp:406] cont_t=8_encode3_cont_slice_7_split <- cont_t=8
I1223 00:14:24.491530 25375 net.cpp:380] cont_t=8_encode3_cont_slice_7_split -> cont_t=8_encode3_cont_slice_7_split_0
I1223 00:14:24.491536 25375 net.cpp:380] cont_t=8_encode3_cont_slice_7_split -> cont_t=8_encode3_cont_slice_7_split_1
I1223 00:14:24.491570 25375 net.cpp:122] Setting up cont_t=8_encode3_cont_slice_7_split
I1223 00:14:24.491576 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491580 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491582 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:24.491585 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode3_cont_slice_8_split
I1223 00:14:24.491590 25375 net.cpp:84] Creating Layer cont_t=9_encode3_cont_slice_8_split
I1223 00:14:24.491592 25375 net.cpp:406] cont_t=9_encode3_cont_slice_8_split <- cont_t=9
I1223 00:14:24.491597 25375 net.cpp:380] cont_t=9_encode3_cont_slice_8_split -> cont_t=9_encode3_cont_slice_8_split_0
I1223 00:14:24.491603 25375 net.cpp:380] cont_t=9_encode3_cont_slice_8_split -> cont_t=9_encode3_cont_slice_8_split_1
I1223 00:14:24.491637 25375 net.cpp:122] Setting up cont_t=9_encode3_cont_slice_8_split
I1223 00:14:24.491642 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491660 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491663 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:24.491667 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode3_cont_slice_9_split
I1223 00:14:24.491670 25375 net.cpp:84] Creating Layer cont_t=10_encode3_cont_slice_9_split
I1223 00:14:24.491673 25375 net.cpp:406] cont_t=10_encode3_cont_slice_9_split <- cont_t=10
I1223 00:14:24.491679 25375 net.cpp:380] cont_t=10_encode3_cont_slice_9_split -> cont_t=10_encode3_cont_slice_9_split_0
I1223 00:14:24.491686 25375 net.cpp:380] cont_t=10_encode3_cont_slice_9_split -> cont_t=10_encode3_cont_slice_9_split_1
I1223 00:14:24.491734 25375 net.cpp:122] Setting up cont_t=10_encode3_cont_slice_9_split
I1223 00:14:24.491740 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491744 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491747 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:24.491750 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode3_cont_slice_10_split
I1223 00:14:24.491755 25375 net.cpp:84] Creating Layer cont_t=11_encode3_cont_slice_10_split
I1223 00:14:24.491757 25375 net.cpp:406] cont_t=11_encode3_cont_slice_10_split <- cont_t=11
I1223 00:14:24.491762 25375 net.cpp:380] cont_t=11_encode3_cont_slice_10_split -> cont_t=11_encode3_cont_slice_10_split_0
I1223 00:14:24.491768 25375 net.cpp:380] cont_t=11_encode3_cont_slice_10_split -> cont_t=11_encode3_cont_slice_10_split_1
I1223 00:14:24.491802 25375 net.cpp:122] Setting up cont_t=11_encode3_cont_slice_10_split
I1223 00:14:24.491808 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491811 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491814 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:24.491817 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode3_cont_slice_11_split
I1223 00:14:24.491827 25375 net.cpp:84] Creating Layer cont_t=12_encode3_cont_slice_11_split
I1223 00:14:24.491832 25375 net.cpp:406] cont_t=12_encode3_cont_slice_11_split <- cont_t=12
I1223 00:14:24.491837 25375 net.cpp:380] cont_t=12_encode3_cont_slice_11_split -> cont_t=12_encode3_cont_slice_11_split_0
I1223 00:14:24.491842 25375 net.cpp:380] cont_t=12_encode3_cont_slice_11_split -> cont_t=12_encode3_cont_slice_11_split_1
I1223 00:14:24.491876 25375 net.cpp:122] Setting up cont_t=12_encode3_cont_slice_11_split
I1223 00:14:24.491883 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491886 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491889 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:24.491892 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode3_cont_slice_12_split
I1223 00:14:24.491896 25375 net.cpp:84] Creating Layer cont_t=13_encode3_cont_slice_12_split
I1223 00:14:24.491899 25375 net.cpp:406] cont_t=13_encode3_cont_slice_12_split <- cont_t=13
I1223 00:14:24.491904 25375 net.cpp:380] cont_t=13_encode3_cont_slice_12_split -> cont_t=13_encode3_cont_slice_12_split_0
I1223 00:14:24.491910 25375 net.cpp:380] cont_t=13_encode3_cont_slice_12_split -> cont_t=13_encode3_cont_slice_12_split_1
I1223 00:14:24.491943 25375 net.cpp:122] Setting up cont_t=13_encode3_cont_slice_12_split
I1223 00:14:24.491950 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491955 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.491956 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:24.491960 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode3_cont_slice_13_split
I1223 00:14:24.491964 25375 net.cpp:84] Creating Layer cont_t=14_encode3_cont_slice_13_split
I1223 00:14:24.491968 25375 net.cpp:406] cont_t=14_encode3_cont_slice_13_split <- cont_t=14
I1223 00:14:24.491972 25375 net.cpp:380] cont_t=14_encode3_cont_slice_13_split -> cont_t=14_encode3_cont_slice_13_split_0
I1223 00:14:24.491978 25375 net.cpp:380] cont_t=14_encode3_cont_slice_13_split -> cont_t=14_encode3_cont_slice_13_split_1
I1223 00:14:24.492014 25375 net.cpp:122] Setting up cont_t=14_encode3_cont_slice_13_split
I1223 00:14:24.492020 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.492027 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.492028 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:24.492031 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode3_cont_slice_14_split
I1223 00:14:24.492036 25375 net.cpp:84] Creating Layer cont_t=15_encode3_cont_slice_14_split
I1223 00:14:24.492039 25375 net.cpp:406] cont_t=15_encode3_cont_slice_14_split <- cont_t=15
I1223 00:14:24.492044 25375 net.cpp:380] cont_t=15_encode3_cont_slice_14_split -> cont_t=15_encode3_cont_slice_14_split_0
I1223 00:14:24.492050 25375 net.cpp:380] cont_t=15_encode3_cont_slice_14_split -> cont_t=15_encode3_cont_slice_14_split_1
I1223 00:14:24.492084 25375 net.cpp:122] Setting up cont_t=15_encode3_cont_slice_14_split
I1223 00:14:24.492090 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.492094 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.492097 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:24.492100 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode3_cont_slice_15_split
I1223 00:14:24.492105 25375 net.cpp:84] Creating Layer cont_t=16_encode3_cont_slice_15_split
I1223 00:14:24.492107 25375 net.cpp:406] cont_t=16_encode3_cont_slice_15_split <- cont_t=16
I1223 00:14:24.492113 25375 net.cpp:380] cont_t=16_encode3_cont_slice_15_split -> cont_t=16_encode3_cont_slice_15_split_0
I1223 00:14:24.492121 25375 net.cpp:380] cont_t=16_encode3_cont_slice_15_split -> cont_t=16_encode3_cont_slice_15_split_1
I1223 00:14:24.492154 25375 net.cpp:122] Setting up cont_t=16_encode3_cont_slice_15_split
I1223 00:14:24.492161 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.492163 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.492166 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:24.492169 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_c0
I1223 00:14:24.492177 25375 net.cpp:84] Creating Layer encode3_dummy_forward_c0
I1223 00:14:24.492180 25375 net.cpp:406] encode3_dummy_forward_c0 <- c_t=0
I1223 00:14:24.492185 25375 net.cpp:367] encode3_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:24.492208 25375 net.cpp:122] Setting up encode3_dummy_forward_c0
I1223 00:14:24.492213 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.492216 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:24.492223 25375 layer_factory.hpp:77] Creating layer c_t=0_encode3_dummy_forward_c0_0_split
I1223 00:14:24.492229 25375 net.cpp:84] Creating Layer c_t=0_encode3_dummy_forward_c0_0_split
I1223 00:14:24.492233 25375 net.cpp:406] c_t=0_encode3_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:24.492238 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_0
I1223 00:14:24.492244 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_1
I1223 00:14:24.492250 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_2
I1223 00:14:24.492256 25375 net.cpp:380] c_t=0_encode3_dummy_forward_c0_0_split -> c_t=0_encode3_dummy_forward_c0_0_split_3
I1223 00:14:24.492321 25375 net.cpp:122] Setting up c_t=0_encode3_dummy_forward_c0_0_split
I1223 00:14:24.492328 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.492333 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.492337 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.492341 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.492344 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:24.492347 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_h0
I1223 00:14:24.492352 25375 net.cpp:84] Creating Layer encode3_dummy_forward_h0
I1223 00:14:24.492354 25375 net.cpp:406] encode3_dummy_forward_h0 <- h_t=0
I1223 00:14:24.492362 25375 net.cpp:367] encode3_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:24.492383 25375 net.cpp:122] Setting up encode3_dummy_forward_h0
I1223 00:14:24.492388 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.492391 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:24.492398 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=0
I1223 00:14:24.492403 25375 net.cpp:84] Creating Layer encode3_h_conted_t=0
I1223 00:14:24.492406 25375 net.cpp:406] encode3_h_conted_t=0 <- h_t=0
I1223 00:14:24.492411 25375 net.cpp:406] encode3_h_conted_t=0 <- cont_t=1_encode3_cont_slice_0_split_0
I1223 00:14:24.492419 25375 net.cpp:380] encode3_h_conted_t=0 -> h_conted_t=0
I1223 00:14:24.492514 25375 net.cpp:122] Setting up encode3_h_conted_t=0
I1223 00:14:24.492522 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.492524 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:24.492527 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->0
I1223 00:14:24.492537 25375 net.cpp:84] Creating Layer encode3_hidden->transform->0
I1223 00:14:24.492540 25375 net.cpp:406] encode3_hidden->transform->0 <- h_conted_t=0
I1223 00:14:24.492547 25375 net.cpp:380] encode3_hidden->transform->0 -> hidden->transform->0
I1223 00:14:24.493090 25375 net.cpp:122] Setting up encode3_hidden->transform->0
I1223 00:14:24.493099 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.493103 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:24.493122 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=0
I1223 00:14:24.493129 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=0
I1223 00:14:24.493134 25375 net.cpp:406] encode3_hadamard->input_t=0 <- c_t=0_encode3_dummy_forward_c0_0_split_0
I1223 00:14:24.493140 25375 net.cpp:380] encode3_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:24.493247 25375 net.cpp:122] Setting up encode3_hadamard->input_t=0
I1223 00:14:24.493255 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.493258 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:24.493276 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=0
I1223 00:14:24.493281 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=0
I1223 00:14:24.493285 25375 net.cpp:406] encode3_hadamard->forget_t=0 <- c_t=0_encode3_dummy_forward_c0_0_split_1
I1223 00:14:24.493291 25375 net.cpp:380] encode3_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:24.493399 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=0
I1223 00:14:24.493407 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.493409 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:24.493413 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=0
I1223 00:14:24.493433 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=0
I1223 00:14:24.493438 25375 net.cpp:406] encode3_hadamard->output_t=0 <- c_t=0_encode3_dummy_forward_c0_0_split_2
I1223 00:14:24.493444 25375 net.cpp:380] encode3_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:24.493544 25375 net.cpp:122] Setting up encode3_hadamard->output_t=0
I1223 00:14:24.493551 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.493554 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:24.493558 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=1
I1223 00:14:24.493566 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=1
I1223 00:14:24.493569 25375 net.cpp:380] encode3_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:24.493654 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=1
I1223 00:14:24.493661 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.493665 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:24.493667 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=1
I1223 00:14:24.493674 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=1
I1223 00:14:24.493677 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:24.493681 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:24.493700 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:24.493703 25375 net.cpp:406] encode3_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:24.493711 25375 net.cpp:380] encode3_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:24.493737 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=1
I1223 00:14:24.493743 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.493746 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:24.493764 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_1
I1223 00:14:24.493769 25375 net.cpp:84] Creating Layer encode3_gate_input_1
I1223 00:14:24.493773 25375 net.cpp:406] encode3_gate_input_1 <- hidden->transform->0
I1223 00:14:24.493777 25375 net.cpp:406] encode3_gate_input_1 <- x->transform->t=1
I1223 00:14:24.493782 25375 net.cpp:406] encode3_gate_input_1 <- hadamard_t=1
I1223 00:14:24.493788 25375 net.cpp:380] encode3_gate_input_1 -> gate_input_1
I1223 00:14:24.493824 25375 net.cpp:122] Setting up encode3_gate_input_1
I1223 00:14:24.493830 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.493834 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:24.493836 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=1
I1223 00:14:24.493844 25375 net.cpp:84] Creating Layer encode3_unit_t=1
I1223 00:14:24.493849 25375 net.cpp:406] encode3_unit_t=1 <- c_t=0_encode3_dummy_forward_c0_0_split_3
I1223 00:14:24.493854 25375 net.cpp:406] encode3_unit_t=1 <- gate_input_1
I1223 00:14:24.493857 25375 net.cpp:406] encode3_unit_t=1 <- cont_t=1_encode3_cont_slice_0_split_1
I1223 00:14:24.493862 25375 net.cpp:380] encode3_unit_t=1 -> c_t=1
I1223 00:14:24.493870 25375 net.cpp:380] encode3_unit_t=1 -> h_t=1
I1223 00:14:24.493932 25375 net.cpp:122] Setting up encode3_unit_t=1
I1223 00:14:24.493938 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.493942 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.493945 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:24.493963 25375 layer_factory.hpp:77] Creating layer c_t=1_encode3_unit_t=1_0_split
I1223 00:14:24.493968 25375 net.cpp:84] Creating Layer c_t=1_encode3_unit_t=1_0_split
I1223 00:14:24.493970 25375 net.cpp:406] c_t=1_encode3_unit_t=1_0_split <- c_t=1
I1223 00:14:24.493976 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_0
I1223 00:14:24.493984 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_1
I1223 00:14:24.493990 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_2
I1223 00:14:24.493999 25375 net.cpp:380] c_t=1_encode3_unit_t=1_0_split -> c_t=1_encode3_unit_t=1_0_split_3
I1223 00:14:24.494072 25375 net.cpp:122] Setting up c_t=1_encode3_unit_t=1_0_split
I1223 00:14:24.494079 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.494083 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.494087 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.494091 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.494094 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:24.494112 25375 layer_factory.hpp:77] Creating layer h_t=1_encode3_unit_t=1_1_split
I1223 00:14:24.494115 25375 net.cpp:84] Creating Layer h_t=1_encode3_unit_t=1_1_split
I1223 00:14:24.494118 25375 net.cpp:406] h_t=1_encode3_unit_t=1_1_split <- h_t=1
I1223 00:14:24.494124 25375 net.cpp:380] h_t=1_encode3_unit_t=1_1_split -> h_t=1_encode3_unit_t=1_1_split_0
I1223 00:14:24.494130 25375 net.cpp:380] h_t=1_encode3_unit_t=1_1_split -> h_t=1_encode3_unit_t=1_1_split_1
I1223 00:14:24.494179 25375 net.cpp:122] Setting up h_t=1_encode3_unit_t=1_1_split
I1223 00:14:24.494184 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.494189 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.494191 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:24.494194 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=1
I1223 00:14:24.494199 25375 net.cpp:84] Creating Layer encode3_h_conted_t=1
I1223 00:14:24.494216 25375 net.cpp:406] encode3_h_conted_t=1 <- h_t=1_encode3_unit_t=1_1_split_0
I1223 00:14:24.494220 25375 net.cpp:406] encode3_h_conted_t=1 <- cont_t=2_encode3_cont_slice_1_split_0
I1223 00:14:24.494230 25375 net.cpp:380] encode3_h_conted_t=1 -> h_conted_t=1
I1223 00:14:24.494323 25375 net.cpp:122] Setting up encode3_h_conted_t=1
I1223 00:14:24.494330 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.494333 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:24.494336 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->1
I1223 00:14:24.494345 25375 net.cpp:84] Creating Layer encode3_hidden->transform->1
I1223 00:14:24.494350 25375 net.cpp:406] encode3_hidden->transform->1 <- h_conted_t=1
I1223 00:14:24.494357 25375 net.cpp:380] encode3_hidden->transform->1 -> hidden->transform->1
I1223 00:14:24.494886 25375 net.cpp:122] Setting up encode3_hidden->transform->1
I1223 00:14:24.494894 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.494897 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:24.494902 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.494906 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.494910 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=1
I1223 00:14:24.494930 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=1
I1223 00:14:24.494935 25375 net.cpp:406] encode3_hadamard->input_t=1 <- c_t=1_encode3_unit_t=1_0_split_0
I1223 00:14:24.494940 25375 net.cpp:380] encode3_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:24.495046 25375 net.cpp:122] Setting up encode3_hadamard->input_t=1
I1223 00:14:24.495054 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495057 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:24.495060 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.495077 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=1
I1223 00:14:24.495082 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=1
I1223 00:14:24.495086 25375 net.cpp:406] encode3_hadamard->forget_t=1 <- c_t=1_encode3_unit_t=1_0_split_1
I1223 00:14:24.495092 25375 net.cpp:380] encode3_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:24.495194 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=1
I1223 00:14:24.495203 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495206 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:24.495209 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.495213 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=1
I1223 00:14:24.495230 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=1
I1223 00:14:24.495234 25375 net.cpp:406] encode3_hadamard->output_t=1 <- c_t=1_encode3_unit_t=1_0_split_2
I1223 00:14:24.495240 25375 net.cpp:380] encode3_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:24.495337 25375 net.cpp:122] Setting up encode3_hadamard->output_t=1
I1223 00:14:24.495344 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495347 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:24.495350 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.495353 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=2
I1223 00:14:24.495359 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=2
I1223 00:14:24.495364 25375 net.cpp:380] encode3_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:24.495434 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=2
I1223 00:14:24.495440 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495443 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:24.495460 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=2
I1223 00:14:24.495467 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=2
I1223 00:14:24.495471 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:24.495476 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:24.495481 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:24.495484 25375 net.cpp:406] encode3_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:24.495504 25375 net.cpp:380] encode3_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:24.495528 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=2
I1223 00:14:24.495534 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.495537 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:24.495540 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_2
I1223 00:14:24.495545 25375 net.cpp:84] Creating Layer encode3_gate_input_2
I1223 00:14:24.495549 25375 net.cpp:406] encode3_gate_input_2 <- hidden->transform->1
I1223 00:14:24.495553 25375 net.cpp:406] encode3_gate_input_2 <- x->transform->t=2
I1223 00:14:24.495558 25375 net.cpp:406] encode3_gate_input_2 <- hadamard_t=2
I1223 00:14:24.495564 25375 net.cpp:380] encode3_gate_input_2 -> gate_input_2
I1223 00:14:24.495589 25375 net.cpp:122] Setting up encode3_gate_input_2
I1223 00:14:24.495594 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.495597 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:24.495600 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=2
I1223 00:14:24.495618 25375 net.cpp:84] Creating Layer encode3_unit_t=2
I1223 00:14:24.495622 25375 net.cpp:406] encode3_unit_t=2 <- c_t=1_encode3_unit_t=1_0_split_3
I1223 00:14:24.495626 25375 net.cpp:406] encode3_unit_t=2 <- gate_input_2
I1223 00:14:24.495631 25375 net.cpp:406] encode3_unit_t=2 <- cont_t=2_encode3_cont_slice_1_split_1
I1223 00:14:24.495637 25375 net.cpp:380] encode3_unit_t=2 -> c_t=2
I1223 00:14:24.495657 25375 net.cpp:380] encode3_unit_t=2 -> h_t=2
I1223 00:14:24.495707 25375 net.cpp:122] Setting up encode3_unit_t=2
I1223 00:14:24.495726 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495730 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495733 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:24.495736 25375 layer_factory.hpp:77] Creating layer c_t=2_encode3_unit_t=2_0_split
I1223 00:14:24.495740 25375 net.cpp:84] Creating Layer c_t=2_encode3_unit_t=2_0_split
I1223 00:14:24.495744 25375 net.cpp:406] c_t=2_encode3_unit_t=2_0_split <- c_t=2
I1223 00:14:24.495749 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_0
I1223 00:14:24.495770 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_1
I1223 00:14:24.495779 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_2
I1223 00:14:24.495784 25375 net.cpp:380] c_t=2_encode3_unit_t=2_0_split -> c_t=2_encode3_unit_t=2_0_split_3
I1223 00:14:24.495859 25375 net.cpp:122] Setting up c_t=2_encode3_unit_t=2_0_split
I1223 00:14:24.495867 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495872 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495875 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495879 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495882 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:24.495885 25375 layer_factory.hpp:77] Creating layer h_t=2_encode3_unit_t=2_1_split
I1223 00:14:24.495890 25375 net.cpp:84] Creating Layer h_t=2_encode3_unit_t=2_1_split
I1223 00:14:24.495894 25375 net.cpp:406] h_t=2_encode3_unit_t=2_1_split <- h_t=2
I1223 00:14:24.495899 25375 net.cpp:380] h_t=2_encode3_unit_t=2_1_split -> h_t=2_encode3_unit_t=2_1_split_0
I1223 00:14:24.495906 25375 net.cpp:380] h_t=2_encode3_unit_t=2_1_split -> h_t=2_encode3_unit_t=2_1_split_1
I1223 00:14:24.495954 25375 net.cpp:122] Setting up h_t=2_encode3_unit_t=2_1_split
I1223 00:14:24.495960 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495965 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.495968 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:24.495971 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=2
I1223 00:14:24.495990 25375 net.cpp:84] Creating Layer encode3_h_conted_t=2
I1223 00:14:24.495992 25375 net.cpp:406] encode3_h_conted_t=2 <- h_t=2_encode3_unit_t=2_1_split_0
I1223 00:14:24.496011 25375 net.cpp:406] encode3_h_conted_t=2 <- cont_t=3_encode3_cont_slice_2_split_0
I1223 00:14:24.496017 25375 net.cpp:380] encode3_h_conted_t=2 -> h_conted_t=2
I1223 00:14:24.496112 25375 net.cpp:122] Setting up encode3_h_conted_t=2
I1223 00:14:24.496119 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.496122 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:24.496124 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->2
I1223 00:14:24.496134 25375 net.cpp:84] Creating Layer encode3_hidden->transform->2
I1223 00:14:24.496137 25375 net.cpp:406] encode3_hidden->transform->2 <- h_conted_t=2
I1223 00:14:24.496145 25375 net.cpp:380] encode3_hidden->transform->2 -> hidden->transform->2
I1223 00:14:24.496677 25375 net.cpp:122] Setting up encode3_hidden->transform->2
I1223 00:14:24.496685 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.496688 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:24.496692 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.496696 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.496701 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=2
I1223 00:14:24.496706 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=2
I1223 00:14:24.496709 25375 net.cpp:406] encode3_hadamard->input_t=2 <- c_t=2_encode3_unit_t=2_0_split_0
I1223 00:14:24.496716 25375 net.cpp:380] encode3_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:24.496840 25375 net.cpp:122] Setting up encode3_hadamard->input_t=2
I1223 00:14:24.496847 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.496850 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:24.496855 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.496857 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=2
I1223 00:14:24.496862 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=2
I1223 00:14:24.496879 25375 net.cpp:406] encode3_hadamard->forget_t=2 <- c_t=2_encode3_unit_t=2_0_split_1
I1223 00:14:24.496899 25375 net.cpp:380] encode3_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:24.497001 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=2
I1223 00:14:24.497009 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497011 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:24.497018 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.497023 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=2
I1223 00:14:24.497041 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=2
I1223 00:14:24.497045 25375 net.cpp:406] encode3_hadamard->output_t=2 <- c_t=2_encode3_unit_t=2_0_split_2
I1223 00:14:24.497052 25375 net.cpp:380] encode3_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:24.497166 25375 net.cpp:122] Setting up encode3_hadamard->output_t=2
I1223 00:14:24.497174 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497177 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:24.497181 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.497184 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=3
I1223 00:14:24.497203 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=3
I1223 00:14:24.497210 25375 net.cpp:380] encode3_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:24.497279 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=3
I1223 00:14:24.497287 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497289 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:24.497292 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=3
I1223 00:14:24.497313 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=3
I1223 00:14:24.497316 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:24.497321 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:24.497325 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:24.497329 25375 net.cpp:406] encode3_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:24.497334 25375 net.cpp:380] encode3_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:24.497359 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=3
I1223 00:14:24.497365 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.497368 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:24.497371 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_3
I1223 00:14:24.497377 25375 net.cpp:84] Creating Layer encode3_gate_input_3
I1223 00:14:24.497381 25375 net.cpp:406] encode3_gate_input_3 <- hidden->transform->2
I1223 00:14:24.497386 25375 net.cpp:406] encode3_gate_input_3 <- x->transform->t=3
I1223 00:14:24.497391 25375 net.cpp:406] encode3_gate_input_3 <- hadamard_t=3
I1223 00:14:24.497396 25375 net.cpp:380] encode3_gate_input_3 -> gate_input_3
I1223 00:14:24.497421 25375 net.cpp:122] Setting up encode3_gate_input_3
I1223 00:14:24.497426 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.497429 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:24.497432 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=3
I1223 00:14:24.497437 25375 net.cpp:84] Creating Layer encode3_unit_t=3
I1223 00:14:24.497440 25375 net.cpp:406] encode3_unit_t=3 <- c_t=2_encode3_unit_t=2_0_split_3
I1223 00:14:24.497445 25375 net.cpp:406] encode3_unit_t=3 <- gate_input_3
I1223 00:14:24.497449 25375 net.cpp:406] encode3_unit_t=3 <- cont_t=3_encode3_cont_slice_2_split_1
I1223 00:14:24.497455 25375 net.cpp:380] encode3_unit_t=3 -> c_t=3
I1223 00:14:24.497462 25375 net.cpp:380] encode3_unit_t=3 -> h_t=3
I1223 00:14:24.497510 25375 net.cpp:122] Setting up encode3_unit_t=3
I1223 00:14:24.497530 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497535 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497537 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:24.497540 25375 layer_factory.hpp:77] Creating layer c_t=3_encode3_unit_t=3_0_split
I1223 00:14:24.497545 25375 net.cpp:84] Creating Layer c_t=3_encode3_unit_t=3_0_split
I1223 00:14:24.497548 25375 net.cpp:406] c_t=3_encode3_unit_t=3_0_split <- c_t=3
I1223 00:14:24.497568 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_0
I1223 00:14:24.497575 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_1
I1223 00:14:24.497581 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_2
I1223 00:14:24.497589 25375 net.cpp:380] c_t=3_encode3_unit_t=3_0_split -> c_t=3_encode3_unit_t=3_0_split_3
I1223 00:14:24.497663 25375 net.cpp:122] Setting up c_t=3_encode3_unit_t=3_0_split
I1223 00:14:24.497669 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497674 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497678 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497683 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497684 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:24.497687 25375 layer_factory.hpp:77] Creating layer h_t=3_encode3_unit_t=3_1_split
I1223 00:14:24.497692 25375 net.cpp:84] Creating Layer h_t=3_encode3_unit_t=3_1_split
I1223 00:14:24.497695 25375 net.cpp:406] h_t=3_encode3_unit_t=3_1_split <- h_t=3
I1223 00:14:24.497700 25375 net.cpp:380] h_t=3_encode3_unit_t=3_1_split -> h_t=3_encode3_unit_t=3_1_split_0
I1223 00:14:24.497706 25375 net.cpp:380] h_t=3_encode3_unit_t=3_1_split -> h_t=3_encode3_unit_t=3_1_split_1
I1223 00:14:24.497756 25375 net.cpp:122] Setting up h_t=3_encode3_unit_t=3_1_split
I1223 00:14:24.497762 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497766 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497769 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:24.497772 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=3
I1223 00:14:24.497777 25375 net.cpp:84] Creating Layer encode3_h_conted_t=3
I1223 00:14:24.497781 25375 net.cpp:406] encode3_h_conted_t=3 <- h_t=3_encode3_unit_t=3_1_split_0
I1223 00:14:24.497786 25375 net.cpp:406] encode3_h_conted_t=3 <- cont_t=4_encode3_cont_slice_3_split_0
I1223 00:14:24.497792 25375 net.cpp:380] encode3_h_conted_t=3 -> h_conted_t=3
I1223 00:14:24.497886 25375 net.cpp:122] Setting up encode3_h_conted_t=3
I1223 00:14:24.497894 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.497896 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:24.497900 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->3
I1223 00:14:24.497910 25375 net.cpp:84] Creating Layer encode3_hidden->transform->3
I1223 00:14:24.497915 25375 net.cpp:406] encode3_hidden->transform->3 <- h_conted_t=3
I1223 00:14:24.497936 25375 net.cpp:380] encode3_hidden->transform->3 -> hidden->transform->3
I1223 00:14:24.498456 25375 net.cpp:122] Setting up encode3_hidden->transform->3
I1223 00:14:24.498463 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.498466 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:24.498483 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.498488 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.498492 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=3
I1223 00:14:24.498497 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=3
I1223 00:14:24.498500 25375 net.cpp:406] encode3_hadamard->input_t=3 <- c_t=3_encode3_unit_t=3_0_split_0
I1223 00:14:24.498507 25375 net.cpp:380] encode3_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:24.498625 25375 net.cpp:122] Setting up encode3_hadamard->input_t=3
I1223 00:14:24.498632 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.498636 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:24.498639 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.498642 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=3
I1223 00:14:24.498647 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=3
I1223 00:14:24.498651 25375 net.cpp:406] encode3_hadamard->forget_t=3 <- c_t=3_encode3_unit_t=3_0_split_1
I1223 00:14:24.498657 25375 net.cpp:380] encode3_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:24.498773 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=3
I1223 00:14:24.498780 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.498783 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:24.498787 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.498790 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=3
I1223 00:14:24.498808 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=3
I1223 00:14:24.498811 25375 net.cpp:406] encode3_hadamard->output_t=3 <- c_t=3_encode3_unit_t=3_0_split_2
I1223 00:14:24.498818 25375 net.cpp:380] encode3_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:24.498946 25375 net.cpp:122] Setting up encode3_hadamard->output_t=3
I1223 00:14:24.498955 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.498957 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:24.498961 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.498965 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=4
I1223 00:14:24.498970 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=4
I1223 00:14:24.498975 25375 net.cpp:380] encode3_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:24.499034 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=4
I1223 00:14:24.499042 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499044 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:24.499047 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=4
I1223 00:14:24.499054 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=4
I1223 00:14:24.499058 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:24.499063 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:24.499068 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:24.499071 25375 net.cpp:406] encode3_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:24.499076 25375 net.cpp:380] encode3_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:24.499114 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=4
I1223 00:14:24.499120 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.499124 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:24.499126 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_4
I1223 00:14:24.499135 25375 net.cpp:84] Creating Layer encode3_gate_input_4
I1223 00:14:24.499140 25375 net.cpp:406] encode3_gate_input_4 <- hidden->transform->3
I1223 00:14:24.499145 25375 net.cpp:406] encode3_gate_input_4 <- x->transform->t=4
I1223 00:14:24.499148 25375 net.cpp:406] encode3_gate_input_4 <- hadamard_t=4
I1223 00:14:24.499153 25375 net.cpp:380] encode3_gate_input_4 -> gate_input_4
I1223 00:14:24.499181 25375 net.cpp:122] Setting up encode3_gate_input_4
I1223 00:14:24.499188 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.499191 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:24.499194 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=4
I1223 00:14:24.499199 25375 net.cpp:84] Creating Layer encode3_unit_t=4
I1223 00:14:24.499217 25375 net.cpp:406] encode3_unit_t=4 <- c_t=3_encode3_unit_t=3_0_split_3
I1223 00:14:24.499222 25375 net.cpp:406] encode3_unit_t=4 <- gate_input_4
I1223 00:14:24.499238 25375 net.cpp:406] encode3_unit_t=4 <- cont_t=4_encode3_cont_slice_3_split_1
I1223 00:14:24.499243 25375 net.cpp:380] encode3_unit_t=4 -> c_t=4
I1223 00:14:24.499250 25375 net.cpp:380] encode3_unit_t=4 -> h_t=4
I1223 00:14:24.499299 25375 net.cpp:122] Setting up encode3_unit_t=4
I1223 00:14:24.499305 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499323 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499326 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:24.499330 25375 layer_factory.hpp:77] Creating layer c_t=4_encode3_unit_t=4_0_split
I1223 00:14:24.499336 25375 net.cpp:84] Creating Layer c_t=4_encode3_unit_t=4_0_split
I1223 00:14:24.499339 25375 net.cpp:406] c_t=4_encode3_unit_t=4_0_split <- c_t=4
I1223 00:14:24.499344 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_0
I1223 00:14:24.499364 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_1
I1223 00:14:24.499372 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_2
I1223 00:14:24.499377 25375 net.cpp:380] c_t=4_encode3_unit_t=4_0_split -> c_t=4_encode3_unit_t=4_0_split_3
I1223 00:14:24.499449 25375 net.cpp:122] Setting up c_t=4_encode3_unit_t=4_0_split
I1223 00:14:24.499457 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499476 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499480 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499485 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499487 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:24.499490 25375 layer_factory.hpp:77] Creating layer h_t=4_encode3_unit_t=4_1_split
I1223 00:14:24.499495 25375 net.cpp:84] Creating Layer h_t=4_encode3_unit_t=4_1_split
I1223 00:14:24.499498 25375 net.cpp:406] h_t=4_encode3_unit_t=4_1_split <- h_t=4
I1223 00:14:24.499503 25375 net.cpp:380] h_t=4_encode3_unit_t=4_1_split -> h_t=4_encode3_unit_t=4_1_split_0
I1223 00:14:24.499511 25375 net.cpp:380] h_t=4_encode3_unit_t=4_1_split -> h_t=4_encode3_unit_t=4_1_split_1
I1223 00:14:24.499544 25375 net.cpp:122] Setting up h_t=4_encode3_unit_t=4_1_split
I1223 00:14:24.499550 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499554 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499557 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:24.499560 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=4
I1223 00:14:24.499567 25375 net.cpp:84] Creating Layer encode3_h_conted_t=4
I1223 00:14:24.499570 25375 net.cpp:406] encode3_h_conted_t=4 <- h_t=4_encode3_unit_t=4_1_split_0
I1223 00:14:24.499575 25375 net.cpp:406] encode3_h_conted_t=4 <- cont_t=5_encode3_cont_slice_4_split_0
I1223 00:14:24.499581 25375 net.cpp:380] encode3_h_conted_t=4 -> h_conted_t=4
I1223 00:14:24.499701 25375 net.cpp:122] Setting up encode3_h_conted_t=4
I1223 00:14:24.499708 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.499711 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:24.499727 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->4
I1223 00:14:24.499737 25375 net.cpp:84] Creating Layer encode3_hidden->transform->4
I1223 00:14:24.499742 25375 net.cpp:406] encode3_hidden->transform->4 <- h_conted_t=4
I1223 00:14:24.499749 25375 net.cpp:380] encode3_hidden->transform->4 -> hidden->transform->4
I1223 00:14:24.501062 25375 net.cpp:122] Setting up encode3_hidden->transform->4
I1223 00:14:24.501080 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.501085 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:24.501088 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.501092 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.501096 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=4
I1223 00:14:24.501116 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=4
I1223 00:14:24.501121 25375 net.cpp:406] encode3_hadamard->input_t=4 <- c_t=4_encode3_unit_t=4_0_split_0
I1223 00:14:24.501127 25375 net.cpp:380] encode3_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:24.501245 25375 net.cpp:122] Setting up encode3_hadamard->input_t=4
I1223 00:14:24.501252 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.501255 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:24.501258 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.501276 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=4
I1223 00:14:24.501286 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=4
I1223 00:14:24.501291 25375 net.cpp:406] encode3_hadamard->forget_t=4 <- c_t=4_encode3_unit_t=4_0_split_1
I1223 00:14:24.501296 25375 net.cpp:380] encode3_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:24.501402 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=4
I1223 00:14:24.501410 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.501412 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:24.501416 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.501420 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=4
I1223 00:14:24.501440 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=4
I1223 00:14:24.501442 25375 net.cpp:406] encode3_hadamard->output_t=4 <- c_t=4_encode3_unit_t=4_0_split_2
I1223 00:14:24.501449 25375 net.cpp:380] encode3_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:24.501565 25375 net.cpp:122] Setting up encode3_hadamard->output_t=4
I1223 00:14:24.501571 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.501574 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:24.501576 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.501579 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=5
I1223 00:14:24.501583 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=5
I1223 00:14:24.501603 25375 net.cpp:380] encode3_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:24.501663 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=5
I1223 00:14:24.501668 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.501672 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:24.501673 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=5
I1223 00:14:24.501679 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=5
I1223 00:14:24.501682 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:24.501700 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:24.501704 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:24.501708 25375 net.cpp:406] encode3_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:24.501713 25375 net.cpp:380] encode3_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:24.501734 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=5
I1223 00:14:24.501751 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.501754 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:24.501756 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_5
I1223 00:14:24.501761 25375 net.cpp:84] Creating Layer encode3_gate_input_5
I1223 00:14:24.501765 25375 net.cpp:406] encode3_gate_input_5 <- hidden->transform->4
I1223 00:14:24.501783 25375 net.cpp:406] encode3_gate_input_5 <- x->transform->t=5
I1223 00:14:24.501786 25375 net.cpp:406] encode3_gate_input_5 <- hadamard_t=5
I1223 00:14:24.501791 25375 net.cpp:380] encode3_gate_input_5 -> gate_input_5
I1223 00:14:24.501826 25375 net.cpp:122] Setting up encode3_gate_input_5
I1223 00:14:24.501830 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.501832 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:24.501835 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=5
I1223 00:14:24.501839 25375 net.cpp:84] Creating Layer encode3_unit_t=5
I1223 00:14:24.501842 25375 net.cpp:406] encode3_unit_t=5 <- c_t=4_encode3_unit_t=4_0_split_3
I1223 00:14:24.501845 25375 net.cpp:406] encode3_unit_t=5 <- gate_input_5
I1223 00:14:24.501849 25375 net.cpp:406] encode3_unit_t=5 <- cont_t=5_encode3_cont_slice_4_split_1
I1223 00:14:24.501854 25375 net.cpp:380] encode3_unit_t=5 -> c_t=5
I1223 00:14:24.501859 25375 net.cpp:380] encode3_unit_t=5 -> h_t=5
I1223 00:14:24.501901 25375 net.cpp:122] Setting up encode3_unit_t=5
I1223 00:14:24.501906 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.501909 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.501911 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:24.501914 25375 layer_factory.hpp:77] Creating layer c_t=5_encode3_unit_t=5_0_split
I1223 00:14:24.501919 25375 net.cpp:84] Creating Layer c_t=5_encode3_unit_t=5_0_split
I1223 00:14:24.501921 25375 net.cpp:406] c_t=5_encode3_unit_t=5_0_split <- c_t=5
I1223 00:14:24.501927 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_0
I1223 00:14:24.501933 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_1
I1223 00:14:24.501955 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_2
I1223 00:14:24.501960 25375 net.cpp:380] c_t=5_encode3_unit_t=5_0_split -> c_t=5_encode3_unit_t=5_0_split_3
I1223 00:14:24.502024 25375 net.cpp:122] Setting up c_t=5_encode3_unit_t=5_0_split
I1223 00:14:24.502029 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502033 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502037 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502039 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502041 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:24.502044 25375 layer_factory.hpp:77] Creating layer h_t=5_encode3_unit_t=5_1_split
I1223 00:14:24.502048 25375 net.cpp:84] Creating Layer h_t=5_encode3_unit_t=5_1_split
I1223 00:14:24.502050 25375 net.cpp:406] h_t=5_encode3_unit_t=5_1_split <- h_t=5
I1223 00:14:24.502054 25375 net.cpp:380] h_t=5_encode3_unit_t=5_1_split -> h_t=5_encode3_unit_t=5_1_split_0
I1223 00:14:24.502059 25375 net.cpp:380] h_t=5_encode3_unit_t=5_1_split -> h_t=5_encode3_unit_t=5_1_split_1
I1223 00:14:24.502089 25375 net.cpp:122] Setting up h_t=5_encode3_unit_t=5_1_split
I1223 00:14:24.502094 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502097 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502099 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:24.502101 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=5
I1223 00:14:24.502105 25375 net.cpp:84] Creating Layer encode3_h_conted_t=5
I1223 00:14:24.502110 25375 net.cpp:406] encode3_h_conted_t=5 <- h_t=5_encode3_unit_t=5_1_split_0
I1223 00:14:24.502112 25375 net.cpp:406] encode3_h_conted_t=5 <- cont_t=6_encode3_cont_slice_5_split_0
I1223 00:14:24.502118 25375 net.cpp:380] encode3_h_conted_t=5 -> h_conted_t=5
I1223 00:14:24.502185 25375 net.cpp:122] Setting up encode3_h_conted_t=5
I1223 00:14:24.502205 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502208 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:24.502210 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->5
I1223 00:14:24.502218 25375 net.cpp:84] Creating Layer encode3_hidden->transform->5
I1223 00:14:24.502221 25375 net.cpp:406] encode3_hidden->transform->5 <- h_conted_t=5
I1223 00:14:24.502240 25375 net.cpp:380] encode3_hidden->transform->5 -> hidden->transform->5
I1223 00:14:24.502689 25375 net.cpp:122] Setting up encode3_hidden->transform->5
I1223 00:14:24.502696 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.502698 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:24.502701 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.502705 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.502707 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=5
I1223 00:14:24.502713 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=5
I1223 00:14:24.502717 25375 net.cpp:406] encode3_hadamard->input_t=5 <- c_t=5_encode3_unit_t=5_0_split_0
I1223 00:14:24.502722 25375 net.cpp:380] encode3_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:24.502837 25375 net.cpp:122] Setting up encode3_hadamard->input_t=5
I1223 00:14:24.502845 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502846 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:24.502849 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.502852 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=5
I1223 00:14:24.502858 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=5
I1223 00:14:24.502861 25375 net.cpp:406] encode3_hadamard->forget_t=5 <- c_t=5_encode3_unit_t=5_0_split_1
I1223 00:14:24.502866 25375 net.cpp:380] encode3_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:24.502960 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=5
I1223 00:14:24.502966 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.502970 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:24.502974 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.502977 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=5
I1223 00:14:24.502984 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=5
I1223 00:14:24.502986 25375 net.cpp:406] encode3_hadamard->output_t=5 <- c_t=5_encode3_unit_t=5_0_split_2
I1223 00:14:24.502991 25375 net.cpp:380] encode3_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:24.503087 25375 net.cpp:122] Setting up encode3_hadamard->output_t=5
I1223 00:14:24.503093 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503095 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:24.503101 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.503105 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=6
I1223 00:14:24.503123 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=6
I1223 00:14:24.503127 25375 net.cpp:380] encode3_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:24.503203 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=6
I1223 00:14:24.503211 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503213 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:24.503216 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=6
I1223 00:14:24.503221 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=6
I1223 00:14:24.503223 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:24.503240 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:24.503244 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:24.503248 25375 net.cpp:406] encode3_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:24.503253 25375 net.cpp:380] encode3_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:24.503291 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=6
I1223 00:14:24.503299 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.503302 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:24.503305 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_6
I1223 00:14:24.503311 25375 net.cpp:84] Creating Layer encode3_gate_input_6
I1223 00:14:24.503314 25375 net.cpp:406] encode3_gate_input_6 <- hidden->transform->5
I1223 00:14:24.503319 25375 net.cpp:406] encode3_gate_input_6 <- x->transform->t=6
I1223 00:14:24.503322 25375 net.cpp:406] encode3_gate_input_6 <- hadamard_t=6
I1223 00:14:24.503329 25375 net.cpp:380] encode3_gate_input_6 -> gate_input_6
I1223 00:14:24.503381 25375 net.cpp:122] Setting up encode3_gate_input_6
I1223 00:14:24.503386 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.503389 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:24.503392 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=6
I1223 00:14:24.503397 25375 net.cpp:84] Creating Layer encode3_unit_t=6
I1223 00:14:24.503401 25375 net.cpp:406] encode3_unit_t=6 <- c_t=5_encode3_unit_t=5_0_split_3
I1223 00:14:24.503418 25375 net.cpp:406] encode3_unit_t=6 <- gate_input_6
I1223 00:14:24.503422 25375 net.cpp:406] encode3_unit_t=6 <- cont_t=6_encode3_cont_slice_5_split_1
I1223 00:14:24.503427 25375 net.cpp:380] encode3_unit_t=6 -> c_t=6
I1223 00:14:24.503446 25375 net.cpp:380] encode3_unit_t=6 -> h_t=6
I1223 00:14:24.503513 25375 net.cpp:122] Setting up encode3_unit_t=6
I1223 00:14:24.503522 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503527 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503530 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:24.503532 25375 layer_factory.hpp:77] Creating layer c_t=6_encode3_unit_t=6_0_split
I1223 00:14:24.503551 25375 net.cpp:84] Creating Layer c_t=6_encode3_unit_t=6_0_split
I1223 00:14:24.503554 25375 net.cpp:406] c_t=6_encode3_unit_t=6_0_split <- c_t=6
I1223 00:14:24.503561 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_0
I1223 00:14:24.503568 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_1
I1223 00:14:24.503576 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_2
I1223 00:14:24.503585 25375 net.cpp:380] c_t=6_encode3_unit_t=6_0_split -> c_t=6_encode3_unit_t=6_0_split_3
I1223 00:14:24.503648 25375 net.cpp:122] Setting up c_t=6_encode3_unit_t=6_0_split
I1223 00:14:24.503670 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503674 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503679 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503682 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503684 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:24.503687 25375 layer_factory.hpp:77] Creating layer h_t=6_encode3_unit_t=6_1_split
I1223 00:14:24.503692 25375 net.cpp:84] Creating Layer h_t=6_encode3_unit_t=6_1_split
I1223 00:14:24.503710 25375 net.cpp:406] h_t=6_encode3_unit_t=6_1_split <- h_t=6
I1223 00:14:24.503716 25375 net.cpp:380] h_t=6_encode3_unit_t=6_1_split -> h_t=6_encode3_unit_t=6_1_split_0
I1223 00:14:24.503723 25375 net.cpp:380] h_t=6_encode3_unit_t=6_1_split -> h_t=6_encode3_unit_t=6_1_split_1
I1223 00:14:24.503774 25375 net.cpp:122] Setting up h_t=6_encode3_unit_t=6_1_split
I1223 00:14:24.503782 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503787 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503789 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:24.503793 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=6
I1223 00:14:24.503798 25375 net.cpp:84] Creating Layer encode3_h_conted_t=6
I1223 00:14:24.503814 25375 net.cpp:406] encode3_h_conted_t=6 <- h_t=6_encode3_unit_t=6_1_split_0
I1223 00:14:24.503819 25375 net.cpp:406] encode3_h_conted_t=6 <- cont_t=7_encode3_cont_slice_6_split_0
I1223 00:14:24.503824 25375 net.cpp:380] encode3_h_conted_t=6 -> h_conted_t=6
I1223 00:14:24.503918 25375 net.cpp:122] Setting up encode3_h_conted_t=6
I1223 00:14:24.503927 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.503931 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:24.503933 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->6
I1223 00:14:24.503942 25375 net.cpp:84] Creating Layer encode3_hidden->transform->6
I1223 00:14:24.503947 25375 net.cpp:406] encode3_hidden->transform->6 <- h_conted_t=6
I1223 00:14:24.503954 25375 net.cpp:380] encode3_hidden->transform->6 -> hidden->transform->6
I1223 00:14:24.504493 25375 net.cpp:122] Setting up encode3_hidden->transform->6
I1223 00:14:24.504503 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.504505 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:24.504509 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.504526 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.504529 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=6
I1223 00:14:24.504535 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=6
I1223 00:14:24.504539 25375 net.cpp:406] encode3_hadamard->input_t=6 <- c_t=6_encode3_unit_t=6_0_split_0
I1223 00:14:24.504545 25375 net.cpp:380] encode3_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:24.504660 25375 net.cpp:122] Setting up encode3_hadamard->input_t=6
I1223 00:14:24.504668 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.504673 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:24.504675 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.504679 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=6
I1223 00:14:24.504684 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=6
I1223 00:14:24.504688 25375 net.cpp:406] encode3_hadamard->forget_t=6 <- c_t=6_encode3_unit_t=6_0_split_1
I1223 00:14:24.504695 25375 net.cpp:380] encode3_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:24.504801 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=6
I1223 00:14:24.504811 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.504814 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:24.504818 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.504822 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=6
I1223 00:14:24.504840 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=6
I1223 00:14:24.504844 25375 net.cpp:406] encode3_hadamard->output_t=6 <- c_t=6_encode3_unit_t=6_0_split_2
I1223 00:14:24.504853 25375 net.cpp:380] encode3_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:24.504957 25375 net.cpp:122] Setting up encode3_hadamard->output_t=6
I1223 00:14:24.504966 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.504969 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:24.504972 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.504976 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=7
I1223 00:14:24.504994 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=7
I1223 00:14:24.505003 25375 net.cpp:380] encode3_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:24.505060 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=7
I1223 00:14:24.505072 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505076 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:24.505080 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=7
I1223 00:14:24.505087 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=7
I1223 00:14:24.505091 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:24.505096 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:24.505101 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:24.505105 25375 net.cpp:406] encode3_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:24.505110 25375 net.cpp:380] encode3_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:24.505137 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=7
I1223 00:14:24.505158 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.505162 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:24.505164 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_7
I1223 00:14:24.505170 25375 net.cpp:84] Creating Layer encode3_gate_input_7
I1223 00:14:24.505173 25375 net.cpp:406] encode3_gate_input_7 <- hidden->transform->6
I1223 00:14:24.505178 25375 net.cpp:406] encode3_gate_input_7 <- x->transform->t=7
I1223 00:14:24.505182 25375 net.cpp:406] encode3_gate_input_7 <- hadamard_t=7
I1223 00:14:24.505203 25375 net.cpp:380] encode3_gate_input_7 -> gate_input_7
I1223 00:14:24.505229 25375 net.cpp:122] Setting up encode3_gate_input_7
I1223 00:14:24.505236 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.505239 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:24.505242 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=7
I1223 00:14:24.505262 25375 net.cpp:84] Creating Layer encode3_unit_t=7
I1223 00:14:24.505265 25375 net.cpp:406] encode3_unit_t=7 <- c_t=6_encode3_unit_t=6_0_split_3
I1223 00:14:24.505270 25375 net.cpp:406] encode3_unit_t=7 <- gate_input_7
I1223 00:14:24.505287 25375 net.cpp:406] encode3_unit_t=7 <- cont_t=7_encode3_cont_slice_6_split_1
I1223 00:14:24.505295 25375 net.cpp:380] encode3_unit_t=7 -> c_t=7
I1223 00:14:24.505302 25375 net.cpp:380] encode3_unit_t=7 -> h_t=7
I1223 00:14:24.505368 25375 net.cpp:122] Setting up encode3_unit_t=7
I1223 00:14:24.505378 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505381 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505384 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:24.505388 25375 layer_factory.hpp:77] Creating layer c_t=7_encode3_unit_t=7_0_split
I1223 00:14:24.505393 25375 net.cpp:84] Creating Layer c_t=7_encode3_unit_t=7_0_split
I1223 00:14:24.505410 25375 net.cpp:406] c_t=7_encode3_unit_t=7_0_split <- c_t=7
I1223 00:14:24.505416 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_0
I1223 00:14:24.505424 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_1
I1223 00:14:24.505431 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_2
I1223 00:14:24.505439 25375 net.cpp:380] c_t=7_encode3_unit_t=7_0_split -> c_t=7_encode3_unit_t=7_0_split_3
I1223 00:14:24.505502 25375 net.cpp:122] Setting up c_t=7_encode3_unit_t=7_0_split
I1223 00:14:24.505523 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505527 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505532 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505535 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505538 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:24.505540 25375 layer_factory.hpp:77] Creating layer h_t=7_encode3_unit_t=7_1_split
I1223 00:14:24.505548 25375 net.cpp:84] Creating Layer h_t=7_encode3_unit_t=7_1_split
I1223 00:14:24.505551 25375 net.cpp:406] h_t=7_encode3_unit_t=7_1_split <- h_t=7
I1223 00:14:24.505570 25375 net.cpp:380] h_t=7_encode3_unit_t=7_1_split -> h_t=7_encode3_unit_t=7_1_split_0
I1223 00:14:24.505576 25375 net.cpp:380] h_t=7_encode3_unit_t=7_1_split -> h_t=7_encode3_unit_t=7_1_split_1
I1223 00:14:24.505614 25375 net.cpp:122] Setting up h_t=7_encode3_unit_t=7_1_split
I1223 00:14:24.505635 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505640 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505643 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:24.505646 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=7
I1223 00:14:24.505651 25375 net.cpp:84] Creating Layer encode3_h_conted_t=7
I1223 00:14:24.505656 25375 net.cpp:406] encode3_h_conted_t=7 <- h_t=7_encode3_unit_t=7_1_split_0
I1223 00:14:24.505672 25375 net.cpp:406] encode3_h_conted_t=7 <- cont_t=8_encode3_cont_slice_7_split_0
I1223 00:14:24.505679 25375 net.cpp:380] encode3_h_conted_t=7 -> h_conted_t=7
I1223 00:14:24.505772 25375 net.cpp:122] Setting up encode3_h_conted_t=7
I1223 00:14:24.505780 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.505784 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:24.505787 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->7
I1223 00:14:24.505797 25375 net.cpp:84] Creating Layer encode3_hidden->transform->7
I1223 00:14:24.505802 25375 net.cpp:406] encode3_hidden->transform->7 <- h_conted_t=7
I1223 00:14:24.505810 25375 net.cpp:380] encode3_hidden->transform->7 -> hidden->transform->7
I1223 00:14:24.506352 25375 net.cpp:122] Setting up encode3_hidden->transform->7
I1223 00:14:24.506362 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.506366 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:24.506369 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.506373 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.506376 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=7
I1223 00:14:24.506384 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=7
I1223 00:14:24.506388 25375 net.cpp:406] encode3_hadamard->input_t=7 <- c_t=7_encode3_unit_t=7_0_split_0
I1223 00:14:24.506394 25375 net.cpp:380] encode3_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:24.506518 25375 net.cpp:122] Setting up encode3_hadamard->input_t=7
I1223 00:14:24.506526 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.506531 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:24.506533 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.506537 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=7
I1223 00:14:24.506556 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=7
I1223 00:14:24.506559 25375 net.cpp:406] encode3_hadamard->forget_t=7 <- c_t=7_encode3_unit_t=7_0_split_1
I1223 00:14:24.506567 25375 net.cpp:380] encode3_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:24.506705 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=7
I1223 00:14:24.506713 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.506716 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:24.506721 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.506723 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=7
I1223 00:14:24.506731 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=7
I1223 00:14:24.506747 25375 net.cpp:406] encode3_hadamard->output_t=7 <- c_t=7_encode3_unit_t=7_0_split_2
I1223 00:14:24.506753 25375 net.cpp:380] encode3_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:24.506868 25375 net.cpp:122] Setting up encode3_hadamard->output_t=7
I1223 00:14:24.506877 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.506880 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:24.506884 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.506887 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=8
I1223 00:14:24.506911 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=8
I1223 00:14:24.506916 25375 net.cpp:380] encode3_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:24.506985 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=8
I1223 00:14:24.506994 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.506997 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:24.507000 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=8
I1223 00:14:24.507007 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=8
I1223 00:14:24.507012 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:24.507016 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:24.507020 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:24.507025 25375 net.cpp:406] encode3_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:24.507030 25375 net.cpp:380] encode3_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:24.507068 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=8
I1223 00:14:24.507076 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.507081 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:24.507083 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_8
I1223 00:14:24.507091 25375 net.cpp:84] Creating Layer encode3_gate_input_8
I1223 00:14:24.507094 25375 net.cpp:406] encode3_gate_input_8 <- hidden->transform->7
I1223 00:14:24.507099 25375 net.cpp:406] encode3_gate_input_8 <- x->transform->t=8
I1223 00:14:24.507102 25375 net.cpp:406] encode3_gate_input_8 <- hadamard_t=8
I1223 00:14:24.507108 25375 net.cpp:380] encode3_gate_input_8 -> gate_input_8
I1223 00:14:24.507134 25375 net.cpp:122] Setting up encode3_gate_input_8
I1223 00:14:24.507143 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.507145 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:24.507148 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=8
I1223 00:14:24.507155 25375 net.cpp:84] Creating Layer encode3_unit_t=8
I1223 00:14:24.507159 25375 net.cpp:406] encode3_unit_t=8 <- c_t=7_encode3_unit_t=7_0_split_3
I1223 00:14:24.507164 25375 net.cpp:406] encode3_unit_t=8 <- gate_input_8
I1223 00:14:24.507169 25375 net.cpp:406] encode3_unit_t=8 <- cont_t=8_encode3_cont_slice_7_split_1
I1223 00:14:24.507174 25375 net.cpp:380] encode3_unit_t=8 -> c_t=8
I1223 00:14:24.507180 25375 net.cpp:380] encode3_unit_t=8 -> h_t=8
I1223 00:14:24.507246 25375 net.cpp:122] Setting up encode3_unit_t=8
I1223 00:14:24.507254 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507258 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507261 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:24.507264 25375 layer_factory.hpp:77] Creating layer c_t=8_encode3_unit_t=8_0_split
I1223 00:14:24.507269 25375 net.cpp:84] Creating Layer c_t=8_encode3_unit_t=8_0_split
I1223 00:14:24.507273 25375 net.cpp:406] c_t=8_encode3_unit_t=8_0_split <- c_t=8
I1223 00:14:24.507282 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_0
I1223 00:14:24.507292 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_1
I1223 00:14:24.507298 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_2
I1223 00:14:24.507321 25375 net.cpp:380] c_t=8_encode3_unit_t=8_0_split -> c_t=8_encode3_unit_t=8_0_split_3
I1223 00:14:24.507400 25375 net.cpp:122] Setting up c_t=8_encode3_unit_t=8_0_split
I1223 00:14:24.507407 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507412 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507429 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507433 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507436 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:24.507439 25375 layer_factory.hpp:77] Creating layer h_t=8_encode3_unit_t=8_1_split
I1223 00:14:24.507444 25375 net.cpp:84] Creating Layer h_t=8_encode3_unit_t=8_1_split
I1223 00:14:24.507447 25375 net.cpp:406] h_t=8_encode3_unit_t=8_1_split <- h_t=8
I1223 00:14:24.507452 25375 net.cpp:380] h_t=8_encode3_unit_t=8_1_split -> h_t=8_encode3_unit_t=8_1_split_0
I1223 00:14:24.507459 25375 net.cpp:380] h_t=8_encode3_unit_t=8_1_split -> h_t=8_encode3_unit_t=8_1_split_1
I1223 00:14:24.507496 25375 net.cpp:122] Setting up h_t=8_encode3_unit_t=8_1_split
I1223 00:14:24.507504 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507508 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507511 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:24.507514 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=8
I1223 00:14:24.507521 25375 net.cpp:84] Creating Layer encode3_h_conted_t=8
I1223 00:14:24.507525 25375 net.cpp:406] encode3_h_conted_t=8 <- h_t=8_encode3_unit_t=8_1_split_0
I1223 00:14:24.507530 25375 net.cpp:406] encode3_h_conted_t=8 <- cont_t=9_encode3_cont_slice_8_split_0
I1223 00:14:24.507535 25375 net.cpp:380] encode3_h_conted_t=8 -> h_conted_t=8
I1223 00:14:24.507616 25375 net.cpp:122] Setting up encode3_h_conted_t=8
I1223 00:14:24.507625 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.507628 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:24.507632 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->8
I1223 00:14:24.507642 25375 net.cpp:84] Creating Layer encode3_hidden->transform->8
I1223 00:14:24.507647 25375 net.cpp:406] encode3_hidden->transform->8 <- h_conted_t=8
I1223 00:14:24.507654 25375 net.cpp:380] encode3_hidden->transform->8 -> hidden->transform->8
I1223 00:14:24.508157 25375 net.cpp:122] Setting up encode3_hidden->transform->8
I1223 00:14:24.508167 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.508170 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:24.508174 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.508178 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.508182 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=8
I1223 00:14:24.508189 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=8
I1223 00:14:24.508194 25375 net.cpp:406] encode3_hadamard->input_t=8 <- c_t=8_encode3_unit_t=8_0_split_0
I1223 00:14:24.508201 25375 net.cpp:380] encode3_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:24.508318 25375 net.cpp:122] Setting up encode3_hadamard->input_t=8
I1223 00:14:24.508327 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.508330 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:24.508334 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.508338 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=8
I1223 00:14:24.508345 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=8
I1223 00:14:24.508349 25375 net.cpp:406] encode3_hadamard->forget_t=8 <- c_t=8_encode3_unit_t=8_0_split_1
I1223 00:14:24.508357 25375 net.cpp:380] encode3_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:24.508487 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=8
I1223 00:14:24.508496 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.508499 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:24.508502 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.508507 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=8
I1223 00:14:24.508513 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=8
I1223 00:14:24.508517 25375 net.cpp:406] encode3_hadamard->output_t=8 <- c_t=8_encode3_unit_t=8_0_split_2
I1223 00:14:24.508536 25375 net.cpp:380] encode3_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:24.508644 25375 net.cpp:122] Setting up encode3_hadamard->output_t=8
I1223 00:14:24.508653 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.508656 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:24.508661 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.508664 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=9
I1223 00:14:24.508671 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=9
I1223 00:14:24.508690 25375 net.cpp:380] encode3_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:24.508759 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=9
I1223 00:14:24.508767 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.508770 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:24.508774 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=9
I1223 00:14:24.508779 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=9
I1223 00:14:24.508797 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:24.508801 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:24.508806 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:24.508810 25375 net.cpp:406] encode3_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:24.508816 25375 net.cpp:380] encode3_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:24.508841 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=9
I1223 00:14:24.508847 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.508850 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:24.508867 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_9
I1223 00:14:24.508875 25375 net.cpp:84] Creating Layer encode3_gate_input_9
I1223 00:14:24.508879 25375 net.cpp:406] encode3_gate_input_9 <- hidden->transform->8
I1223 00:14:24.508883 25375 net.cpp:406] encode3_gate_input_9 <- x->transform->t=9
I1223 00:14:24.508901 25375 net.cpp:406] encode3_gate_input_9 <- hadamard_t=9
I1223 00:14:24.508910 25375 net.cpp:380] encode3_gate_input_9 -> gate_input_9
I1223 00:14:24.508939 25375 net.cpp:122] Setting up encode3_gate_input_9
I1223 00:14:24.508946 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.508950 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:24.508966 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=9
I1223 00:14:24.508975 25375 net.cpp:84] Creating Layer encode3_unit_t=9
I1223 00:14:24.508980 25375 net.cpp:406] encode3_unit_t=9 <- c_t=8_encode3_unit_t=8_0_split_3
I1223 00:14:24.508985 25375 net.cpp:406] encode3_unit_t=9 <- gate_input_9
I1223 00:14:24.508988 25375 net.cpp:406] encode3_unit_t=9 <- cont_t=9_encode3_cont_slice_8_split_1
I1223 00:14:24.508993 25375 net.cpp:380] encode3_unit_t=9 -> c_t=9
I1223 00:14:24.508999 25375 net.cpp:380] encode3_unit_t=9 -> h_t=9
I1223 00:14:24.509052 25375 net.cpp:122] Setting up encode3_unit_t=9
I1223 00:14:24.509060 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509064 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509068 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:24.509075 25375 layer_factory.hpp:77] Creating layer c_t=9_encode3_unit_t=9_0_split
I1223 00:14:24.509080 25375 net.cpp:84] Creating Layer c_t=9_encode3_unit_t=9_0_split
I1223 00:14:24.509084 25375 net.cpp:406] c_t=9_encode3_unit_t=9_0_split <- c_t=9
I1223 00:14:24.509090 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_0
I1223 00:14:24.509114 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_1
I1223 00:14:24.509124 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_2
I1223 00:14:24.509130 25375 net.cpp:380] c_t=9_encode3_unit_t=9_0_split -> c_t=9_encode3_unit_t=9_0_split_3
I1223 00:14:24.509192 25375 net.cpp:122] Setting up c_t=9_encode3_unit_t=9_0_split
I1223 00:14:24.509202 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509205 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509209 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509213 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509217 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:24.509218 25375 layer_factory.hpp:77] Creating layer h_t=9_encode3_unit_t=9_1_split
I1223 00:14:24.509223 25375 net.cpp:84] Creating Layer h_t=9_encode3_unit_t=9_1_split
I1223 00:14:24.509227 25375 net.cpp:406] h_t=9_encode3_unit_t=9_1_split <- h_t=9
I1223 00:14:24.509232 25375 net.cpp:380] h_t=9_encode3_unit_t=9_1_split -> h_t=9_encode3_unit_t=9_1_split_0
I1223 00:14:24.509239 25375 net.cpp:380] h_t=9_encode3_unit_t=9_1_split -> h_t=9_encode3_unit_t=9_1_split_1
I1223 00:14:24.509276 25375 net.cpp:122] Setting up h_t=9_encode3_unit_t=9_1_split
I1223 00:14:24.509284 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509289 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509291 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:24.509294 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=9
I1223 00:14:24.509301 25375 net.cpp:84] Creating Layer encode3_h_conted_t=9
I1223 00:14:24.509305 25375 net.cpp:406] encode3_h_conted_t=9 <- h_t=9_encode3_unit_t=9_1_split_0
I1223 00:14:24.509310 25375 net.cpp:406] encode3_h_conted_t=9 <- cont_t=10_encode3_cont_slice_9_split_0
I1223 00:14:24.509315 25375 net.cpp:380] encode3_h_conted_t=9 -> h_conted_t=9
I1223 00:14:24.509413 25375 net.cpp:122] Setting up encode3_h_conted_t=9
I1223 00:14:24.509421 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.509424 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:24.509428 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->9
I1223 00:14:24.509438 25375 net.cpp:84] Creating Layer encode3_hidden->transform->9
I1223 00:14:24.509443 25375 net.cpp:406] encode3_hidden->transform->9 <- h_conted_t=9
I1223 00:14:24.509464 25375 net.cpp:380] encode3_hidden->transform->9 -> hidden->transform->9
I1223 00:14:24.510735 25375 net.cpp:122] Setting up encode3_hidden->transform->9
I1223 00:14:24.510746 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.510748 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:24.510752 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.510771 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.510773 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=9
I1223 00:14:24.510782 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=9
I1223 00:14:24.510787 25375 net.cpp:406] encode3_hadamard->input_t=9 <- c_t=9_encode3_unit_t=9_0_split_0
I1223 00:14:24.510792 25375 net.cpp:380] encode3_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:24.510912 25375 net.cpp:122] Setting up encode3_hadamard->input_t=9
I1223 00:14:24.510921 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.510924 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:24.510928 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.510932 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=9
I1223 00:14:24.510954 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=9
I1223 00:14:24.510958 25375 net.cpp:406] encode3_hadamard->forget_t=9 <- c_t=9_encode3_unit_t=9_0_split_1
I1223 00:14:24.510965 25375 net.cpp:380] encode3_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:24.511075 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=9
I1223 00:14:24.511096 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511099 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:24.511102 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.511106 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=9
I1223 00:14:24.511128 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=9
I1223 00:14:24.511132 25375 net.cpp:406] encode3_hadamard->output_t=9 <- c_t=9_encode3_unit_t=9_0_split_2
I1223 00:14:24.511137 25375 net.cpp:380] encode3_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:24.511250 25375 net.cpp:122] Setting up encode3_hadamard->output_t=9
I1223 00:14:24.511258 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511261 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:24.511265 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.511267 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=10
I1223 00:14:24.511294 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=10
I1223 00:14:24.511301 25375 net.cpp:380] encode3_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:24.511369 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=10
I1223 00:14:24.511378 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511380 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:24.511384 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=10
I1223 00:14:24.511389 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=10
I1223 00:14:24.511409 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:24.511413 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:24.511417 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:24.511421 25375 net.cpp:406] encode3_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:24.511427 25375 net.cpp:380] encode3_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:24.511466 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=10
I1223 00:14:24.511488 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.511504 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:24.511507 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_10
I1223 00:14:24.511512 25375 net.cpp:84] Creating Layer encode3_gate_input_10
I1223 00:14:24.511531 25375 net.cpp:406] encode3_gate_input_10 <- hidden->transform->9
I1223 00:14:24.511535 25375 net.cpp:406] encode3_gate_input_10 <- x->transform->t=10
I1223 00:14:24.511539 25375 net.cpp:406] encode3_gate_input_10 <- hadamard_t=10
I1223 00:14:24.511545 25375 net.cpp:380] encode3_gate_input_10 -> gate_input_10
I1223 00:14:24.511586 25375 net.cpp:122] Setting up encode3_gate_input_10
I1223 00:14:24.511595 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.511597 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:24.511600 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=10
I1223 00:14:24.511606 25375 net.cpp:84] Creating Layer encode3_unit_t=10
I1223 00:14:24.511610 25375 net.cpp:406] encode3_unit_t=10 <- c_t=9_encode3_unit_t=9_0_split_3
I1223 00:14:24.511615 25375 net.cpp:406] encode3_unit_t=10 <- gate_input_10
I1223 00:14:24.511618 25375 net.cpp:406] encode3_unit_t=10 <- cont_t=10_encode3_cont_slice_9_split_1
I1223 00:14:24.511623 25375 net.cpp:380] encode3_unit_t=10 -> c_t=10
I1223 00:14:24.511643 25375 net.cpp:380] encode3_unit_t=10 -> h_t=10
I1223 00:14:24.511711 25375 net.cpp:122] Setting up encode3_unit_t=10
I1223 00:14:24.511719 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511724 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511726 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:24.511730 25375 layer_factory.hpp:77] Creating layer c_t=10_encode3_unit_t=10_0_split
I1223 00:14:24.511750 25375 net.cpp:84] Creating Layer c_t=10_encode3_unit_t=10_0_split
I1223 00:14:24.511754 25375 net.cpp:406] c_t=10_encode3_unit_t=10_0_split <- c_t=10
I1223 00:14:24.511759 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_0
I1223 00:14:24.511766 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_1
I1223 00:14:24.511772 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_2
I1223 00:14:24.511780 25375 net.cpp:380] c_t=10_encode3_unit_t=10_0_split -> c_t=10_encode3_unit_t=10_0_split_3
I1223 00:14:24.511873 25375 net.cpp:122] Setting up c_t=10_encode3_unit_t=10_0_split
I1223 00:14:24.511881 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511886 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511904 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511907 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511909 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:24.511912 25375 layer_factory.hpp:77] Creating layer h_t=10_encode3_unit_t=10_1_split
I1223 00:14:24.511917 25375 net.cpp:84] Creating Layer h_t=10_encode3_unit_t=10_1_split
I1223 00:14:24.511921 25375 net.cpp:406] h_t=10_encode3_unit_t=10_1_split <- h_t=10
I1223 00:14:24.511927 25375 net.cpp:380] h_t=10_encode3_unit_t=10_1_split -> h_t=10_encode3_unit_t=10_1_split_0
I1223 00:14:24.511934 25375 net.cpp:380] h_t=10_encode3_unit_t=10_1_split -> h_t=10_encode3_unit_t=10_1_split_1
I1223 00:14:24.511972 25375 net.cpp:122] Setting up h_t=10_encode3_unit_t=10_1_split
I1223 00:14:24.511981 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511984 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.511987 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:24.511991 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=10
I1223 00:14:24.511996 25375 net.cpp:84] Creating Layer encode3_h_conted_t=10
I1223 00:14:24.511999 25375 net.cpp:406] encode3_h_conted_t=10 <- h_t=10_encode3_unit_t=10_1_split_0
I1223 00:14:24.512004 25375 net.cpp:406] encode3_h_conted_t=10 <- cont_t=11_encode3_cont_slice_10_split_0
I1223 00:14:24.512009 25375 net.cpp:380] encode3_h_conted_t=10 -> h_conted_t=10
I1223 00:14:24.512104 25375 net.cpp:122] Setting up encode3_h_conted_t=10
I1223 00:14:24.512114 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.512116 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:24.512120 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->10
I1223 00:14:24.512127 25375 net.cpp:84] Creating Layer encode3_hidden->transform->10
I1223 00:14:24.512132 25375 net.cpp:406] encode3_hidden->transform->10 <- h_conted_t=10
I1223 00:14:24.512156 25375 net.cpp:380] encode3_hidden->transform->10 -> hidden->transform->10
I1223 00:14:24.512675 25375 net.cpp:122] Setting up encode3_hidden->transform->10
I1223 00:14:24.512684 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.512687 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:24.512691 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.512696 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.512712 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=10
I1223 00:14:24.512718 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=10
I1223 00:14:24.512722 25375 net.cpp:406] encode3_hadamard->input_t=10 <- c_t=10_encode3_unit_t=10_0_split_0
I1223 00:14:24.512729 25375 net.cpp:380] encode3_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:24.512840 25375 net.cpp:122] Setting up encode3_hadamard->input_t=10
I1223 00:14:24.512850 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.512853 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:24.512857 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.512861 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=10
I1223 00:14:24.512881 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=10
I1223 00:14:24.512884 25375 net.cpp:406] encode3_hadamard->forget_t=10 <- c_t=10_encode3_unit_t=10_0_split_1
I1223 00:14:24.512892 25375 net.cpp:380] encode3_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:24.513036 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=10
I1223 00:14:24.513046 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513049 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:24.513052 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.513056 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=10
I1223 00:14:24.513062 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=10
I1223 00:14:24.513065 25375 net.cpp:406] encode3_hadamard->output_t=10 <- c_t=10_encode3_unit_t=10_0_split_2
I1223 00:14:24.513077 25375 net.cpp:380] encode3_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:24.513190 25375 net.cpp:122] Setting up encode3_hadamard->output_t=10
I1223 00:14:24.513200 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513202 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:24.513206 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.513209 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=11
I1223 00:14:24.513216 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=11
I1223 00:14:24.513234 25375 net.cpp:380] encode3_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:24.513301 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=11
I1223 00:14:24.513309 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513312 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:24.513315 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=11
I1223 00:14:24.513322 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=11
I1223 00:14:24.513341 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:24.513346 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:24.513351 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:24.513355 25375 net.cpp:406] encode3_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:24.513360 25375 net.cpp:380] encode3_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:24.513386 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=11
I1223 00:14:24.513393 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.513396 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:24.513399 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_11
I1223 00:14:24.513406 25375 net.cpp:84] Creating Layer encode3_gate_input_11
I1223 00:14:24.513409 25375 net.cpp:406] encode3_gate_input_11 <- hidden->transform->10
I1223 00:14:24.513413 25375 net.cpp:406] encode3_gate_input_11 <- x->transform->t=11
I1223 00:14:24.513417 25375 net.cpp:406] encode3_gate_input_11 <- hadamard_t=11
I1223 00:14:24.513424 25375 net.cpp:380] encode3_gate_input_11 -> gate_input_11
I1223 00:14:24.513464 25375 net.cpp:122] Setting up encode3_gate_input_11
I1223 00:14:24.513473 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.513475 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:24.513478 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=11
I1223 00:14:24.513484 25375 net.cpp:84] Creating Layer encode3_unit_t=11
I1223 00:14:24.513487 25375 net.cpp:406] encode3_unit_t=11 <- c_t=10_encode3_unit_t=10_0_split_3
I1223 00:14:24.513491 25375 net.cpp:406] encode3_unit_t=11 <- gate_input_11
I1223 00:14:24.513495 25375 net.cpp:406] encode3_unit_t=11 <- cont_t=11_encode3_cont_slice_10_split_1
I1223 00:14:24.513504 25375 net.cpp:380] encode3_unit_t=11 -> c_t=11
I1223 00:14:24.513511 25375 net.cpp:380] encode3_unit_t=11 -> h_t=11
I1223 00:14:24.513578 25375 net.cpp:122] Setting up encode3_unit_t=11
I1223 00:14:24.513586 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513590 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513593 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:24.513610 25375 layer_factory.hpp:77] Creating layer c_t=11_encode3_unit_t=11_0_split
I1223 00:14:24.513617 25375 net.cpp:84] Creating Layer c_t=11_encode3_unit_t=11_0_split
I1223 00:14:24.513619 25375 net.cpp:406] c_t=11_encode3_unit_t=11_0_split <- c_t=11
I1223 00:14:24.513626 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_0
I1223 00:14:24.513633 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_1
I1223 00:14:24.513640 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_2
I1223 00:14:24.513646 25375 net.cpp:380] c_t=11_encode3_unit_t=11_0_split -> c_t=11_encode3_unit_t=11_0_split_3
I1223 00:14:24.513710 25375 net.cpp:122] Setting up c_t=11_encode3_unit_t=11_0_split
I1223 00:14:24.513731 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513734 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513738 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513742 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513746 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:24.513748 25375 layer_factory.hpp:77] Creating layer h_t=11_encode3_unit_t=11_1_split
I1223 00:14:24.513767 25375 net.cpp:84] Creating Layer h_t=11_encode3_unit_t=11_1_split
I1223 00:14:24.513772 25375 net.cpp:406] h_t=11_encode3_unit_t=11_1_split <- h_t=11
I1223 00:14:24.513777 25375 net.cpp:380] h_t=11_encode3_unit_t=11_1_split -> h_t=11_encode3_unit_t=11_1_split_0
I1223 00:14:24.513782 25375 net.cpp:380] h_t=11_encode3_unit_t=11_1_split -> h_t=11_encode3_unit_t=11_1_split_1
I1223 00:14:24.513833 25375 net.cpp:122] Setting up h_t=11_encode3_unit_t=11_1_split
I1223 00:14:24.513841 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513846 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513849 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:24.513852 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=11
I1223 00:14:24.513857 25375 net.cpp:84] Creating Layer encode3_h_conted_t=11
I1223 00:14:24.513875 25375 net.cpp:406] encode3_h_conted_t=11 <- h_t=11_encode3_unit_t=11_1_split_0
I1223 00:14:24.513878 25375 net.cpp:406] encode3_h_conted_t=11 <- cont_t=12_encode3_cont_slice_11_split_0
I1223 00:14:24.513886 25375 net.cpp:380] encode3_h_conted_t=11 -> h_conted_t=11
I1223 00:14:24.513980 25375 net.cpp:122] Setting up encode3_h_conted_t=11
I1223 00:14:24.513989 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.513991 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:24.513995 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->11
I1223 00:14:24.514004 25375 net.cpp:84] Creating Layer encode3_hidden->transform->11
I1223 00:14:24.514010 25375 net.cpp:406] encode3_hidden->transform->11 <- h_conted_t=11
I1223 00:14:24.514017 25375 net.cpp:380] encode3_hidden->transform->11 -> hidden->transform->11
I1223 00:14:24.514528 25375 net.cpp:122] Setting up encode3_hidden->transform->11
I1223 00:14:24.514538 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.514540 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:24.514544 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.514549 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.514551 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=11
I1223 00:14:24.514572 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=11
I1223 00:14:24.514577 25375 net.cpp:406] encode3_hadamard->input_t=11 <- c_t=11_encode3_unit_t=11_0_split_0
I1223 00:14:24.514585 25375 net.cpp:380] encode3_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:24.514700 25375 net.cpp:122] Setting up encode3_hadamard->input_t=11
I1223 00:14:24.514708 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.514711 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:24.514715 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.514719 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=11
I1223 00:14:24.514739 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=11
I1223 00:14:24.514742 25375 net.cpp:406] encode3_hadamard->forget_t=11 <- c_t=11_encode3_unit_t=11_0_split_1
I1223 00:14:24.514750 25375 net.cpp:380] encode3_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:24.514866 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=11
I1223 00:14:24.514874 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.514878 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:24.514881 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.514885 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=11
I1223 00:14:24.514905 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=11
I1223 00:14:24.514909 25375 net.cpp:406] encode3_hadamard->output_t=11 <- c_t=11_encode3_unit_t=11_0_split_2
I1223 00:14:24.514915 25375 net.cpp:380] encode3_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:24.515028 25375 net.cpp:122] Setting up encode3_hadamard->output_t=11
I1223 00:14:24.515050 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515053 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:24.515058 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.515060 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=12
I1223 00:14:24.515069 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=12
I1223 00:14:24.515072 25375 net.cpp:380] encode3_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:24.515141 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=12
I1223 00:14:24.515163 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515166 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:24.515169 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=12
I1223 00:14:24.515175 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=12
I1223 00:14:24.515179 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:24.515184 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:24.515202 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:24.515206 25375 net.cpp:406] encode3_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:24.515211 25375 net.cpp:380] encode3_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:24.515239 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=12
I1223 00:14:24.515247 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.515250 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:24.515266 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_12
I1223 00:14:24.515272 25375 net.cpp:84] Creating Layer encode3_gate_input_12
I1223 00:14:24.515275 25375 net.cpp:406] encode3_gate_input_12 <- hidden->transform->11
I1223 00:14:24.515280 25375 net.cpp:406] encode3_gate_input_12 <- x->transform->t=12
I1223 00:14:24.515287 25375 net.cpp:406] encode3_gate_input_12 <- hadamard_t=12
I1223 00:14:24.515292 25375 net.cpp:380] encode3_gate_input_12 -> gate_input_12
I1223 00:14:24.515337 25375 net.cpp:122] Setting up encode3_gate_input_12
I1223 00:14:24.515347 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.515350 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:24.515353 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=12
I1223 00:14:24.515358 25375 net.cpp:84] Creating Layer encode3_unit_t=12
I1223 00:14:24.515362 25375 net.cpp:406] encode3_unit_t=12 <- c_t=11_encode3_unit_t=11_0_split_3
I1223 00:14:24.515367 25375 net.cpp:406] encode3_unit_t=12 <- gate_input_12
I1223 00:14:24.515372 25375 net.cpp:406] encode3_unit_t=12 <- cont_t=12_encode3_cont_slice_11_split_1
I1223 00:14:24.515377 25375 net.cpp:380] encode3_unit_t=12 -> c_t=12
I1223 00:14:24.515383 25375 net.cpp:380] encode3_unit_t=12 -> h_t=12
I1223 00:14:24.515446 25375 net.cpp:122] Setting up encode3_unit_t=12
I1223 00:14:24.515455 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515458 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515461 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:24.515465 25375 layer_factory.hpp:77] Creating layer c_t=12_encode3_unit_t=12_0_split
I1223 00:14:24.515470 25375 net.cpp:84] Creating Layer c_t=12_encode3_unit_t=12_0_split
I1223 00:14:24.515473 25375 net.cpp:406] c_t=12_encode3_unit_t=12_0_split <- c_t=12
I1223 00:14:24.515480 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_0
I1223 00:14:24.515487 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_1
I1223 00:14:24.515493 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_2
I1223 00:14:24.515514 25375 net.cpp:380] c_t=12_encode3_unit_t=12_0_split -> c_t=12_encode3_unit_t=12_0_split_3
I1223 00:14:24.515596 25375 net.cpp:122] Setting up c_t=12_encode3_unit_t=12_0_split
I1223 00:14:24.515605 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515624 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515626 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515631 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515633 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:24.515636 25375 layer_factory.hpp:77] Creating layer h_t=12_encode3_unit_t=12_1_split
I1223 00:14:24.515641 25375 net.cpp:84] Creating Layer h_t=12_encode3_unit_t=12_1_split
I1223 00:14:24.515645 25375 net.cpp:406] h_t=12_encode3_unit_t=12_1_split <- h_t=12
I1223 00:14:24.515652 25375 net.cpp:380] h_t=12_encode3_unit_t=12_1_split -> h_t=12_encode3_unit_t=12_1_split_0
I1223 00:14:24.515660 25375 net.cpp:380] h_t=12_encode3_unit_t=12_1_split -> h_t=12_encode3_unit_t=12_1_split_1
I1223 00:14:24.515697 25375 net.cpp:122] Setting up h_t=12_encode3_unit_t=12_1_split
I1223 00:14:24.515707 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515710 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515712 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:24.515715 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=12
I1223 00:14:24.515723 25375 net.cpp:84] Creating Layer encode3_h_conted_t=12
I1223 00:14:24.515727 25375 net.cpp:406] encode3_h_conted_t=12 <- h_t=12_encode3_unit_t=12_1_split_0
I1223 00:14:24.515732 25375 net.cpp:406] encode3_h_conted_t=12 <- cont_t=13_encode3_cont_slice_12_split_0
I1223 00:14:24.515738 25375 net.cpp:380] encode3_h_conted_t=12 -> h_conted_t=12
I1223 00:14:24.515832 25375 net.cpp:122] Setting up encode3_h_conted_t=12
I1223 00:14:24.515841 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.515844 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:24.515847 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->12
I1223 00:14:24.515857 25375 net.cpp:84] Creating Layer encode3_hidden->transform->12
I1223 00:14:24.515863 25375 net.cpp:406] encode3_hidden->transform->12 <- h_conted_t=12
I1223 00:14:24.515884 25375 net.cpp:380] encode3_hidden->transform->12 -> hidden->transform->12
I1223 00:14:24.516417 25375 net.cpp:122] Setting up encode3_hidden->transform->12
I1223 00:14:24.516427 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.516432 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:24.516434 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.516443 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.516449 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=12
I1223 00:14:24.516455 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=12
I1223 00:14:24.516458 25375 net.cpp:406] encode3_hadamard->input_t=12 <- c_t=12_encode3_unit_t=12_0_split_0
I1223 00:14:24.516479 25375 net.cpp:380] encode3_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:24.516599 25375 net.cpp:122] Setting up encode3_hadamard->input_t=12
I1223 00:14:24.516608 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.516611 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:24.516615 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.516619 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=12
I1223 00:14:24.516638 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=12
I1223 00:14:24.516641 25375 net.cpp:406] encode3_hadamard->forget_t=12 <- c_t=12_encode3_unit_t=12_0_split_1
I1223 00:14:24.516649 25375 net.cpp:380] encode3_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:24.516768 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=12
I1223 00:14:24.516777 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.516779 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:24.516798 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.516800 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=12
I1223 00:14:24.516808 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=12
I1223 00:14:24.516811 25375 net.cpp:406] encode3_hadamard->output_t=12 <- c_t=12_encode3_unit_t=12_0_split_2
I1223 00:14:24.516816 25375 net.cpp:380] encode3_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:24.516932 25375 net.cpp:122] Setting up encode3_hadamard->output_t=12
I1223 00:14:24.516939 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.516942 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:24.516947 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.516950 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=13
I1223 00:14:24.516957 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=13
I1223 00:14:24.516963 25375 net.cpp:380] encode3_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:24.517015 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=13
I1223 00:14:24.517024 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517027 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:24.517030 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=13
I1223 00:14:24.517038 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=13
I1223 00:14:24.517042 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:24.517047 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:24.517051 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:24.517055 25375 net.cpp:406] encode3_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:24.517060 25375 net.cpp:380] encode3_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:24.517105 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=13
I1223 00:14:24.517127 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.517130 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:24.517134 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_13
I1223 00:14:24.517154 25375 net.cpp:84] Creating Layer encode3_gate_input_13
I1223 00:14:24.517158 25375 net.cpp:406] encode3_gate_input_13 <- hidden->transform->12
I1223 00:14:24.517163 25375 net.cpp:406] encode3_gate_input_13 <- x->transform->t=13
I1223 00:14:24.517168 25375 net.cpp:406] encode3_gate_input_13 <- hadamard_t=13
I1223 00:14:24.517174 25375 net.cpp:380] encode3_gate_input_13 -> gate_input_13
I1223 00:14:24.517199 25375 net.cpp:122] Setting up encode3_gate_input_13
I1223 00:14:24.517206 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.517223 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:24.517226 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=13
I1223 00:14:24.517233 25375 net.cpp:84] Creating Layer encode3_unit_t=13
I1223 00:14:24.517236 25375 net.cpp:406] encode3_unit_t=13 <- c_t=12_encode3_unit_t=12_0_split_3
I1223 00:14:24.517241 25375 net.cpp:406] encode3_unit_t=13 <- gate_input_13
I1223 00:14:24.517246 25375 net.cpp:406] encode3_unit_t=13 <- cont_t=13_encode3_cont_slice_12_split_1
I1223 00:14:24.517263 25375 net.cpp:380] encode3_unit_t=13 -> c_t=13
I1223 00:14:24.517271 25375 net.cpp:380] encode3_unit_t=13 -> h_t=13
I1223 00:14:24.517338 25375 net.cpp:122] Setting up encode3_unit_t=13
I1223 00:14:24.517345 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517349 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517352 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:24.517369 25375 layer_factory.hpp:77] Creating layer c_t=13_encode3_unit_t=13_0_split
I1223 00:14:24.517374 25375 net.cpp:84] Creating Layer c_t=13_encode3_unit_t=13_0_split
I1223 00:14:24.517377 25375 net.cpp:406] c_t=13_encode3_unit_t=13_0_split <- c_t=13
I1223 00:14:24.517385 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_0
I1223 00:14:24.517392 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_1
I1223 00:14:24.517401 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_2
I1223 00:14:24.517410 25375 net.cpp:380] c_t=13_encode3_unit_t=13_0_split -> c_t=13_encode3_unit_t=13_0_split_3
I1223 00:14:24.517487 25375 net.cpp:122] Setting up c_t=13_encode3_unit_t=13_0_split
I1223 00:14:24.517494 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517498 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517503 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517506 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517509 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:24.517525 25375 layer_factory.hpp:77] Creating layer h_t=13_encode3_unit_t=13_1_split
I1223 00:14:24.517530 25375 net.cpp:84] Creating Layer h_t=13_encode3_unit_t=13_1_split
I1223 00:14:24.517534 25375 net.cpp:406] h_t=13_encode3_unit_t=13_1_split <- h_t=13
I1223 00:14:24.517539 25375 net.cpp:380] h_t=13_encode3_unit_t=13_1_split -> h_t=13_encode3_unit_t=13_1_split_0
I1223 00:14:24.517545 25375 net.cpp:380] h_t=13_encode3_unit_t=13_1_split -> h_t=13_encode3_unit_t=13_1_split_1
I1223 00:14:24.517597 25375 net.cpp:122] Setting up h_t=13_encode3_unit_t=13_1_split
I1223 00:14:24.517606 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517611 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517612 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:24.517616 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=13
I1223 00:14:24.517637 25375 net.cpp:84] Creating Layer encode3_h_conted_t=13
I1223 00:14:24.517640 25375 net.cpp:406] encode3_h_conted_t=13 <- h_t=13_encode3_unit_t=13_1_split_0
I1223 00:14:24.517645 25375 net.cpp:406] encode3_h_conted_t=13 <- cont_t=14_encode3_cont_slice_13_split_0
I1223 00:14:24.517650 25375 net.cpp:380] encode3_h_conted_t=13 -> h_conted_t=13
I1223 00:14:24.517743 25375 net.cpp:122] Setting up encode3_h_conted_t=13
I1223 00:14:24.517751 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.517755 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:24.517758 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->13
I1223 00:14:24.517768 25375 net.cpp:84] Creating Layer encode3_hidden->transform->13
I1223 00:14:24.517773 25375 net.cpp:406] encode3_hidden->transform->13 <- h_conted_t=13
I1223 00:14:24.517793 25375 net.cpp:380] encode3_hidden->transform->13 -> hidden->transform->13
I1223 00:14:24.518319 25375 net.cpp:122] Setting up encode3_hidden->transform->13
I1223 00:14:24.518328 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.518332 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:24.518337 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.518340 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.518343 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=13
I1223 00:14:24.518352 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=13
I1223 00:14:24.518355 25375 net.cpp:406] encode3_hadamard->input_t=13 <- c_t=13_encode3_unit_t=13_0_split_0
I1223 00:14:24.518362 25375 net.cpp:380] encode3_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:24.518491 25375 net.cpp:122] Setting up encode3_hadamard->input_t=13
I1223 00:14:24.518501 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.518503 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:24.518507 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.518512 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=13
I1223 00:14:24.518517 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=13
I1223 00:14:24.518522 25375 net.cpp:406] encode3_hadamard->forget_t=13 <- c_t=13_encode3_unit_t=13_0_split_1
I1223 00:14:24.518528 25375 net.cpp:380] encode3_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:24.518656 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=13
I1223 00:14:24.518664 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.518667 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:24.518671 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.518674 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=13
I1223 00:14:24.518693 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=13
I1223 00:14:24.518697 25375 net.cpp:406] encode3_hadamard->output_t=13 <- c_t=13_encode3_unit_t=13_0_split_2
I1223 00:14:24.518715 25375 net.cpp:380] encode3_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:24.518829 25375 net.cpp:122] Setting up encode3_hadamard->output_t=13
I1223 00:14:24.518838 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.518841 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:24.518844 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.518848 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=14
I1223 00:14:24.518867 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=14
I1223 00:14:24.518872 25375 net.cpp:380] encode3_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:24.518942 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=14
I1223 00:14:24.518950 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.518954 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:24.518957 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=14
I1223 00:14:24.518976 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=14
I1223 00:14:24.518980 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:24.518985 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:24.518988 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:24.518992 25375 net.cpp:406] encode3_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:24.518999 25375 net.cpp:380] encode3_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:24.519026 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=14
I1223 00:14:24.519035 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.519039 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:24.519042 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_14
I1223 00:14:24.519048 25375 net.cpp:84] Creating Layer encode3_gate_input_14
I1223 00:14:24.519052 25375 net.cpp:406] encode3_gate_input_14 <- hidden->transform->13
I1223 00:14:24.519057 25375 net.cpp:406] encode3_gate_input_14 <- x->transform->t=14
I1223 00:14:24.519062 25375 net.cpp:406] encode3_gate_input_14 <- hadamard_t=14
I1223 00:14:24.519067 25375 net.cpp:380] encode3_gate_input_14 -> gate_input_14
I1223 00:14:24.519093 25375 net.cpp:122] Setting up encode3_gate_input_14
I1223 00:14:24.519100 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.519104 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:24.519106 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=14
I1223 00:14:24.519112 25375 net.cpp:84] Creating Layer encode3_unit_t=14
I1223 00:14:24.519115 25375 net.cpp:406] encode3_unit_t=14 <- c_t=13_encode3_unit_t=13_0_split_3
I1223 00:14:24.519120 25375 net.cpp:406] encode3_unit_t=14 <- gate_input_14
I1223 00:14:24.519124 25375 net.cpp:406] encode3_unit_t=14 <- cont_t=14_encode3_cont_slice_13_split_1
I1223 00:14:24.519129 25375 net.cpp:380] encode3_unit_t=14 -> c_t=14
I1223 00:14:24.519136 25375 net.cpp:380] encode3_unit_t=14 -> h_t=14
I1223 00:14:24.519202 25375 net.cpp:122] Setting up encode3_unit_t=14
I1223 00:14:24.519212 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519215 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519232 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:24.519234 25375 layer_factory.hpp:77] Creating layer c_t=14_encode3_unit_t=14_0_split
I1223 00:14:24.519240 25375 net.cpp:84] Creating Layer c_t=14_encode3_unit_t=14_0_split
I1223 00:14:24.519243 25375 net.cpp:406] c_t=14_encode3_unit_t=14_0_split <- c_t=14
I1223 00:14:24.519250 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_0
I1223 00:14:24.519258 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_1
I1223 00:14:24.519266 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_2
I1223 00:14:24.519275 25375 net.cpp:380] c_t=14_encode3_unit_t=14_0_split -> c_t=14_encode3_unit_t=14_0_split_3
I1223 00:14:24.519356 25375 net.cpp:122] Setting up c_t=14_encode3_unit_t=14_0_split
I1223 00:14:24.519363 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519368 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519385 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519389 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519392 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:24.519394 25375 layer_factory.hpp:77] Creating layer h_t=14_encode3_unit_t=14_1_split
I1223 00:14:24.519399 25375 net.cpp:84] Creating Layer h_t=14_encode3_unit_t=14_1_split
I1223 00:14:24.519402 25375 net.cpp:406] h_t=14_encode3_unit_t=14_1_split <- h_t=14
I1223 00:14:24.519409 25375 net.cpp:380] h_t=14_encode3_unit_t=14_1_split -> h_t=14_encode3_unit_t=14_1_split_0
I1223 00:14:24.519417 25375 net.cpp:380] h_t=14_encode3_unit_t=14_1_split -> h_t=14_encode3_unit_t=14_1_split_1
I1223 00:14:24.519454 25375 net.cpp:122] Setting up h_t=14_encode3_unit_t=14_1_split
I1223 00:14:24.519462 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519466 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519469 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:24.519472 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=14
I1223 00:14:24.519477 25375 net.cpp:84] Creating Layer encode3_h_conted_t=14
I1223 00:14:24.519481 25375 net.cpp:406] encode3_h_conted_t=14 <- h_t=14_encode3_unit_t=14_1_split_0
I1223 00:14:24.519485 25375 net.cpp:406] encode3_h_conted_t=14 <- cont_t=15_encode3_cont_slice_14_split_0
I1223 00:14:24.519491 25375 net.cpp:380] encode3_h_conted_t=14 -> h_conted_t=14
I1223 00:14:24.519573 25375 net.cpp:122] Setting up encode3_h_conted_t=14
I1223 00:14:24.519582 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.519585 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:24.519588 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->14
I1223 00:14:24.519595 25375 net.cpp:84] Creating Layer encode3_hidden->transform->14
I1223 00:14:24.519600 25375 net.cpp:406] encode3_hidden->transform->14 <- h_conted_t=14
I1223 00:14:24.519609 25375 net.cpp:380] encode3_hidden->transform->14 -> hidden->transform->14
I1223 00:14:24.520840 25375 net.cpp:122] Setting up encode3_hidden->transform->14
I1223 00:14:24.520851 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.520854 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:24.520859 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.520864 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.520867 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=14
I1223 00:14:24.520877 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=14
I1223 00:14:24.520882 25375 net.cpp:406] encode3_hadamard->input_t=14 <- c_t=14_encode3_unit_t=14_0_split_0
I1223 00:14:24.520889 25375 net.cpp:380] encode3_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:24.521011 25375 net.cpp:122] Setting up encode3_hadamard->input_t=14
I1223 00:14:24.521020 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521024 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:24.521028 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.521031 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=14
I1223 00:14:24.521039 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=14
I1223 00:14:24.521042 25375 net.cpp:406] encode3_hadamard->forget_t=14 <- c_t=14_encode3_unit_t=14_0_split_1
I1223 00:14:24.521049 25375 net.cpp:380] encode3_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:24.521157 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=14
I1223 00:14:24.521165 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521169 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:24.521173 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.521176 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=14
I1223 00:14:24.521195 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=14
I1223 00:14:24.521199 25375 net.cpp:406] encode3_hadamard->output_t=14 <- c_t=14_encode3_unit_t=14_0_split_2
I1223 00:14:24.521204 25375 net.cpp:380] encode3_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:24.521318 25375 net.cpp:122] Setting up encode3_hadamard->output_t=14
I1223 00:14:24.521327 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521330 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:24.521333 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.521337 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=15
I1223 00:14:24.521355 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=15
I1223 00:14:24.521360 25375 net.cpp:380] encode3_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:24.521428 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=15
I1223 00:14:24.521436 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521440 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:24.521443 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=15
I1223 00:14:24.521448 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=15
I1223 00:14:24.521466 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:24.521469 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:24.521474 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:24.521477 25375 net.cpp:406] encode3_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:24.521486 25375 net.cpp:380] encode3_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:24.521538 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=15
I1223 00:14:24.521546 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.521549 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:24.521553 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_15
I1223 00:14:24.521559 25375 net.cpp:84] Creating Layer encode3_gate_input_15
I1223 00:14:24.521575 25375 net.cpp:406] encode3_gate_input_15 <- hidden->transform->14
I1223 00:14:24.521579 25375 net.cpp:406] encode3_gate_input_15 <- x->transform->t=15
I1223 00:14:24.521584 25375 net.cpp:406] encode3_gate_input_15 <- hadamard_t=15
I1223 00:14:24.521591 25375 net.cpp:380] encode3_gate_input_15 -> gate_input_15
I1223 00:14:24.521616 25375 net.cpp:122] Setting up encode3_gate_input_15
I1223 00:14:24.521626 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.521631 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:24.521633 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=15
I1223 00:14:24.521639 25375 net.cpp:84] Creating Layer encode3_unit_t=15
I1223 00:14:24.521642 25375 net.cpp:406] encode3_unit_t=15 <- c_t=14_encode3_unit_t=14_0_split_3
I1223 00:14:24.521646 25375 net.cpp:406] encode3_unit_t=15 <- gate_input_15
I1223 00:14:24.521651 25375 net.cpp:406] encode3_unit_t=15 <- cont_t=15_encode3_cont_slice_14_split_1
I1223 00:14:24.521656 25375 net.cpp:380] encode3_unit_t=15 -> c_t=15
I1223 00:14:24.521663 25375 net.cpp:380] encode3_unit_t=15 -> h_t=15
I1223 00:14:24.521744 25375 net.cpp:122] Setting up encode3_unit_t=15
I1223 00:14:24.521754 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521757 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521760 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:24.521764 25375 layer_factory.hpp:77] Creating layer c_t=15_encode3_unit_t=15_0_split
I1223 00:14:24.521769 25375 net.cpp:84] Creating Layer c_t=15_encode3_unit_t=15_0_split
I1223 00:14:24.521788 25375 net.cpp:406] c_t=15_encode3_unit_t=15_0_split <- c_t=15
I1223 00:14:24.521793 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_0
I1223 00:14:24.521800 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_1
I1223 00:14:24.521808 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_2
I1223 00:14:24.521817 25375 net.cpp:380] c_t=15_encode3_unit_t=15_0_split -> c_t=15_encode3_unit_t=15_0_split_3
I1223 00:14:24.521883 25375 net.cpp:122] Setting up c_t=15_encode3_unit_t=15_0_split
I1223 00:14:24.521904 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521908 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521912 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521915 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.521919 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:24.521921 25375 layer_factory.hpp:77] Creating layer h_t=15_encode3_unit_t=15_1_split
I1223 00:14:24.521929 25375 net.cpp:84] Creating Layer h_t=15_encode3_unit_t=15_1_split
I1223 00:14:24.521945 25375 net.cpp:406] h_t=15_encode3_unit_t=15_1_split <- h_t=15
I1223 00:14:24.521950 25375 net.cpp:380] h_t=15_encode3_unit_t=15_1_split -> h_t=15_encode3_unit_t=15_1_split_0
I1223 00:14:24.521957 25375 net.cpp:380] h_t=15_encode3_unit_t=15_1_split -> h_t=15_encode3_unit_t=15_1_split_1
I1223 00:14:24.521996 25375 net.cpp:122] Setting up h_t=15_encode3_unit_t=15_1_split
I1223 00:14:24.522003 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.522007 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.522011 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:24.522013 25375 layer_factory.hpp:77] Creating layer encode3_h_conted_t=15
I1223 00:14:24.522019 25375 net.cpp:84] Creating Layer encode3_h_conted_t=15
I1223 00:14:24.522022 25375 net.cpp:406] encode3_h_conted_t=15 <- h_t=15_encode3_unit_t=15_1_split_0
I1223 00:14:24.522027 25375 net.cpp:406] encode3_h_conted_t=15 <- cont_t=16_encode3_cont_slice_15_split_0
I1223 00:14:24.522033 25375 net.cpp:380] encode3_h_conted_t=15 -> h_conted_t=15
I1223 00:14:24.522127 25375 net.cpp:122] Setting up encode3_h_conted_t=15
I1223 00:14:24.522135 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.522138 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:24.522141 25375 layer_factory.hpp:77] Creating layer encode3_hidden->transform->15
I1223 00:14:24.522151 25375 net.cpp:84] Creating Layer encode3_hidden->transform->15
I1223 00:14:24.522156 25375 net.cpp:406] encode3_hidden->transform->15 <- h_conted_t=15
I1223 00:14:24.522164 25375 net.cpp:380] encode3_hidden->transform->15 -> hidden->transform->15
I1223 00:14:24.522692 25375 net.cpp:122] Setting up encode3_hidden->transform->15
I1223 00:14:24.522702 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.522706 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:24.522709 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode3_hidden->transform->0', param index 0
I1223 00:14:24.522713 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode3_hidden->transform->0', param index 1
I1223 00:14:24.522717 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->input_t=15
I1223 00:14:24.522722 25375 net.cpp:84] Creating Layer encode3_hadamard->input_t=15
I1223 00:14:24.522727 25375 net.cpp:406] encode3_hadamard->input_t=15 <- c_t=15_encode3_unit_t=15_0_split_0
I1223 00:14:24.522734 25375 net.cpp:380] encode3_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:24.522856 25375 net.cpp:122] Setting up encode3_hadamard->input_t=15
I1223 00:14:24.522864 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.522868 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:24.522871 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode3_hadamard->input_t=0', param index 0
I1223 00:14:24.522876 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->forget_t=15
I1223 00:14:24.522895 25375 net.cpp:84] Creating Layer encode3_hadamard->forget_t=15
I1223 00:14:24.522899 25375 net.cpp:406] encode3_hadamard->forget_t=15 <- c_t=15_encode3_unit_t=15_0_split_1
I1223 00:14:24.522918 25375 net.cpp:380] encode3_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:24.523035 25375 net.cpp:122] Setting up encode3_hadamard->forget_t=15
I1223 00:14:24.523042 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523046 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:24.523051 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode3_hadamard->forget_t=0', param index 0
I1223 00:14:24.523053 25375 layer_factory.hpp:77] Creating layer encode3_hadamard->output_t=15
I1223 00:14:24.523072 25375 net.cpp:84] Creating Layer encode3_hadamard->output_t=15
I1223 00:14:24.523077 25375 net.cpp:406] encode3_hadamard->output_t=15 <- c_t=15_encode3_unit_t=15_0_split_2
I1223 00:14:24.523082 25375 net.cpp:380] encode3_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:24.523192 25375 net.cpp:122] Setting up encode3_hadamard->output_t=15
I1223 00:14:24.523200 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523205 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:24.523208 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode3_hadamard->output_t=0', param index 0
I1223 00:14:24.523211 25375 layer_factory.hpp:77] Creating layer encode3_hadamard_gat_t=16
I1223 00:14:24.523231 25375 net.cpp:84] Creating Layer encode3_hadamard_gat_t=16
I1223 00:14:24.523236 25375 net.cpp:380] encode3_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:24.523293 25375 net.cpp:122] Setting up encode3_hadamard_gat_t=16
I1223 00:14:24.523300 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523303 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:24.523306 25375 layer_factory.hpp:77] Creating layer encode3_concat_hadamard_t=16
I1223 00:14:24.523313 25375 net.cpp:84] Creating Layer encode3_concat_hadamard_t=16
I1223 00:14:24.523316 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:24.523334 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:24.523337 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:24.523341 25375 net.cpp:406] encode3_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:24.523346 25375 net.cpp:380] encode3_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:24.523372 25375 net.cpp:122] Setting up encode3_concat_hadamard_t=16
I1223 00:14:24.523380 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.523396 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:24.523399 25375 layer_factory.hpp:77] Creating layer encode3_gate_input_16
I1223 00:14:24.523406 25375 net.cpp:84] Creating Layer encode3_gate_input_16
I1223 00:14:24.523411 25375 net.cpp:406] encode3_gate_input_16 <- hidden->transform->15
I1223 00:14:24.523416 25375 net.cpp:406] encode3_gate_input_16 <- x->transform->t=16
I1223 00:14:24.523421 25375 net.cpp:406] encode3_gate_input_16 <- hadamard_t=16
I1223 00:14:24.523440 25375 net.cpp:380] encode3_gate_input_16 -> gate_input_16
I1223 00:14:24.523464 25375 net.cpp:122] Setting up encode3_gate_input_16
I1223 00:14:24.523473 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.523475 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:24.523478 25375 layer_factory.hpp:77] Creating layer encode3_unit_t=16
I1223 00:14:24.523485 25375 net.cpp:84] Creating Layer encode3_unit_t=16
I1223 00:14:24.523491 25375 net.cpp:406] encode3_unit_t=16 <- c_t=15_encode3_unit_t=15_0_split_3
I1223 00:14:24.523495 25375 net.cpp:406] encode3_unit_t=16 <- gate_input_16
I1223 00:14:24.523499 25375 net.cpp:406] encode3_unit_t=16 <- cont_t=16_encode3_cont_slice_15_split_1
I1223 00:14:24.523504 25375 net.cpp:380] encode3_unit_t=16 -> c_t=16
I1223 00:14:24.523512 25375 net.cpp:380] encode3_unit_t=16 -> h_t=16
I1223 00:14:24.523576 25375 net.cpp:122] Setting up encode3_unit_t=16
I1223 00:14:24.523584 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523589 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523592 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:24.523594 25375 layer_factory.hpp:77] Creating layer h_t=16_encode3_unit_t=16_1_split
I1223 00:14:24.523599 25375 net.cpp:84] Creating Layer h_t=16_encode3_unit_t=16_1_split
I1223 00:14:24.523603 25375 net.cpp:406] h_t=16_encode3_unit_t=16_1_split <- h_t=16
I1223 00:14:24.523610 25375 net.cpp:380] h_t=16_encode3_unit_t=16_1_split -> h_t=16_encode3_unit_t=16_1_split_0
I1223 00:14:24.523618 25375 net.cpp:380] h_t=16_encode3_unit_t=16_1_split -> h_t=16_encode3_unit_t=16_1_split_1
I1223 00:14:24.523671 25375 net.cpp:122] Setting up h_t=16_encode3_unit_t=16_1_split
I1223 00:14:24.523679 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523684 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523686 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:24.523689 25375 layer_factory.hpp:77] Creating layer encode3_h_concat
I1223 00:14:24.523695 25375 net.cpp:84] Creating Layer encode3_h_concat
I1223 00:14:24.523699 25375 net.cpp:406] encode3_h_concat <- h_t=1_encode3_unit_t=1_1_split_1
I1223 00:14:24.523705 25375 net.cpp:406] encode3_h_concat <- h_t=2_encode3_unit_t=2_1_split_1
I1223 00:14:24.523708 25375 net.cpp:406] encode3_h_concat <- h_t=3_encode3_unit_t=3_1_split_1
I1223 00:14:24.523711 25375 net.cpp:406] encode3_h_concat <- h_t=4_encode3_unit_t=4_1_split_1
I1223 00:14:24.523715 25375 net.cpp:406] encode3_h_concat <- h_t=5_encode3_unit_t=5_1_split_1
I1223 00:14:24.523718 25375 net.cpp:406] encode3_h_concat <- h_t=6_encode3_unit_t=6_1_split_1
I1223 00:14:24.523722 25375 net.cpp:406] encode3_h_concat <- h_t=7_encode3_unit_t=7_1_split_1
I1223 00:14:24.523725 25375 net.cpp:406] encode3_h_concat <- h_t=8_encode3_unit_t=8_1_split_1
I1223 00:14:24.523730 25375 net.cpp:406] encode3_h_concat <- h_t=9_encode3_unit_t=9_1_split_1
I1223 00:14:24.523733 25375 net.cpp:406] encode3_h_concat <- h_t=10_encode3_unit_t=10_1_split_1
I1223 00:14:24.523736 25375 net.cpp:406] encode3_h_concat <- h_t=11_encode3_unit_t=11_1_split_1
I1223 00:14:24.523739 25375 net.cpp:406] encode3_h_concat <- h_t=12_encode3_unit_t=12_1_split_1
I1223 00:14:24.523743 25375 net.cpp:406] encode3_h_concat <- h_t=13_encode3_unit_t=13_1_split_1
I1223 00:14:24.523746 25375 net.cpp:406] encode3_h_concat <- h_t=14_encode3_unit_t=14_1_split_1
I1223 00:14:24.523749 25375 net.cpp:406] encode3_h_concat <- h_t=15_encode3_unit_t=15_1_split_1
I1223 00:14:24.523752 25375 net.cpp:406] encode3_h_concat <- h_t=16_encode3_unit_t=16_1_split_0
I1223 00:14:24.523761 25375 net.cpp:380] encode3_h_concat -> h
I1223 00:14:24.523788 25375 net.cpp:122] Setting up encode3_h_concat
I1223 00:14:24.523797 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.523799 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:24.523802 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_h
I1223 00:14:24.523808 25375 net.cpp:84] Creating Layer encode3_dummy_forward_h
I1223 00:14:24.523811 25375 net.cpp:406] encode3_dummy_forward_h <- h_t=16_encode3_unit_t=16_1_split_1
I1223 00:14:24.523816 25375 net.cpp:380] encode3_dummy_forward_h -> h_t=T
I1223 00:14:24.523856 25375 net.cpp:122] Setting up encode3_dummy_forward_h
I1223 00:14:24.523864 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523867 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:24.523874 25375 layer_factory.hpp:77] Creating layer encode3_dummy_forward_c
I1223 00:14:24.523880 25375 net.cpp:84] Creating Layer encode3_dummy_forward_c
I1223 00:14:24.523882 25375 net.cpp:406] encode3_dummy_forward_c <- c_t=16
I1223 00:14:24.523887 25375 net.cpp:380] encode3_dummy_forward_c -> c_t=T
I1223 00:14:24.523928 25375 net.cpp:122] Setting up encode3_dummy_forward_c
I1223 00:14:24.523937 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.523941 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:24.523944 25375 layer_factory.hpp:77] Creating layer encode3_h_t=T_pseudoloss
I1223 00:14:24.523950 25375 net.cpp:84] Creating Layer encode3_h_t=T_pseudoloss
I1223 00:14:24.523953 25375 net.cpp:406] encode3_h_t=T_pseudoloss <- h_t=T
I1223 00:14:24.523960 25375 net.cpp:380] encode3_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:24.524031 25375 net.cpp:122] Setting up encode3_h_t=T_pseudoloss
I1223 00:14:24.524039 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.524042 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.524052 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:24.524055 25375 layer_factory.hpp:77] Creating layer encode3_c_t=T_pseudoloss
I1223 00:14:24.524060 25375 net.cpp:84] Creating Layer encode3_c_t=T_pseudoloss
I1223 00:14:24.524063 25375 net.cpp:406] encode3_c_t=T_pseudoloss <- c_t=T
I1223 00:14:24.524068 25375 net.cpp:380] encode3_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:24.524137 25375 net.cpp:122] Setting up encode3_c_t=T_pseudoloss
I1223 00:14:24.524158 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.524161 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.524166 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:24.524169 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:24.524175 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:24.524178 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:24.524197 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:24.525287 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:24.525298 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.525301 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.525306 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:24.525310 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:24.525313 25375 net.cpp:198] encode3_c_t=T_pseudoloss needs backward computation.
I1223 00:14:24.525316 25375 net.cpp:198] encode3_h_t=T_pseudoloss needs backward computation.
I1223 00:14:24.525318 25375 net.cpp:198] encode3_dummy_forward_c needs backward computation.
I1223 00:14:24.525321 25375 net.cpp:198] encode3_dummy_forward_h needs backward computation.
I1223 00:14:24.525324 25375 net.cpp:198] encode3_h_concat needs backward computation.
I1223 00:14:24.525347 25375 net.cpp:198] h_t=16_encode3_unit_t=16_1_split needs backward computation.
I1223 00:14:24.525352 25375 net.cpp:198] encode3_unit_t=16 needs backward computation.
I1223 00:14:24.525357 25375 net.cpp:198] encode3_gate_input_16 needs backward computation.
I1223 00:14:24.525360 25375 net.cpp:198] encode3_concat_hadamard_t=16 needs backward computation.
I1223 00:14:24.525364 25375 net.cpp:200] encode3_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:24.525367 25375 net.cpp:198] encode3_hadamard->output_t=15 needs backward computation.
I1223 00:14:24.525372 25375 net.cpp:198] encode3_hadamard->forget_t=15 needs backward computation.
I1223 00:14:24.525374 25375 net.cpp:198] encode3_hadamard->input_t=15 needs backward computation.
I1223 00:14:24.525377 25375 net.cpp:198] encode3_hidden->transform->15 needs backward computation.
I1223 00:14:24.525380 25375 net.cpp:198] encode3_h_conted_t=15 needs backward computation.
I1223 00:14:24.525384 25375 net.cpp:198] h_t=15_encode3_unit_t=15_1_split needs backward computation.
I1223 00:14:24.525388 25375 net.cpp:198] c_t=15_encode3_unit_t=15_0_split needs backward computation.
I1223 00:14:24.525393 25375 net.cpp:198] encode3_unit_t=15 needs backward computation.
I1223 00:14:24.525396 25375 net.cpp:198] encode3_gate_input_15 needs backward computation.
I1223 00:14:24.525400 25375 net.cpp:198] encode3_concat_hadamard_t=15 needs backward computation.
I1223 00:14:24.525405 25375 net.cpp:200] encode3_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:24.525408 25375 net.cpp:198] encode3_hadamard->output_t=14 needs backward computation.
I1223 00:14:24.525411 25375 net.cpp:198] encode3_hadamard->forget_t=14 needs backward computation.
I1223 00:14:24.525414 25375 net.cpp:198] encode3_hadamard->input_t=14 needs backward computation.
I1223 00:14:24.525418 25375 net.cpp:198] encode3_hidden->transform->14 needs backward computation.
I1223 00:14:24.525420 25375 net.cpp:198] encode3_h_conted_t=14 needs backward computation.
I1223 00:14:24.525424 25375 net.cpp:198] h_t=14_encode3_unit_t=14_1_split needs backward computation.
I1223 00:14:24.525429 25375 net.cpp:198] c_t=14_encode3_unit_t=14_0_split needs backward computation.
I1223 00:14:24.525431 25375 net.cpp:198] encode3_unit_t=14 needs backward computation.
I1223 00:14:24.525435 25375 net.cpp:198] encode3_gate_input_14 needs backward computation.
I1223 00:14:24.525439 25375 net.cpp:198] encode3_concat_hadamard_t=14 needs backward computation.
I1223 00:14:24.525444 25375 net.cpp:200] encode3_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:24.525447 25375 net.cpp:198] encode3_hadamard->output_t=13 needs backward computation.
I1223 00:14:24.525450 25375 net.cpp:198] encode3_hadamard->forget_t=13 needs backward computation.
I1223 00:14:24.525454 25375 net.cpp:198] encode3_hadamard->input_t=13 needs backward computation.
I1223 00:14:24.525456 25375 net.cpp:198] encode3_hidden->transform->13 needs backward computation.
I1223 00:14:24.525461 25375 net.cpp:198] encode3_h_conted_t=13 needs backward computation.
I1223 00:14:24.525465 25375 net.cpp:198] h_t=13_encode3_unit_t=13_1_split needs backward computation.
I1223 00:14:24.525470 25375 net.cpp:198] c_t=13_encode3_unit_t=13_0_split needs backward computation.
I1223 00:14:24.525472 25375 net.cpp:198] encode3_unit_t=13 needs backward computation.
I1223 00:14:24.525476 25375 net.cpp:198] encode3_gate_input_13 needs backward computation.
I1223 00:14:24.525480 25375 net.cpp:198] encode3_concat_hadamard_t=13 needs backward computation.
I1223 00:14:24.525485 25375 net.cpp:200] encode3_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:24.525487 25375 net.cpp:198] encode3_hadamard->output_t=12 needs backward computation.
I1223 00:14:24.525491 25375 net.cpp:198] encode3_hadamard->forget_t=12 needs backward computation.
I1223 00:14:24.525494 25375 net.cpp:198] encode3_hadamard->input_t=12 needs backward computation.
I1223 00:14:24.525498 25375 net.cpp:198] encode3_hidden->transform->12 needs backward computation.
I1223 00:14:24.525501 25375 net.cpp:198] encode3_h_conted_t=12 needs backward computation.
I1223 00:14:24.525506 25375 net.cpp:198] h_t=12_encode3_unit_t=12_1_split needs backward computation.
I1223 00:14:24.525508 25375 net.cpp:198] c_t=12_encode3_unit_t=12_0_split needs backward computation.
I1223 00:14:24.525511 25375 net.cpp:198] encode3_unit_t=12 needs backward computation.
I1223 00:14:24.525516 25375 net.cpp:198] encode3_gate_input_12 needs backward computation.
I1223 00:14:24.525519 25375 net.cpp:198] encode3_concat_hadamard_t=12 needs backward computation.
I1223 00:14:24.525527 25375 net.cpp:200] encode3_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:24.525530 25375 net.cpp:198] encode3_hadamard->output_t=11 needs backward computation.
I1223 00:14:24.525533 25375 net.cpp:198] encode3_hadamard->forget_t=11 needs backward computation.
I1223 00:14:24.525537 25375 net.cpp:198] encode3_hadamard->input_t=11 needs backward computation.
I1223 00:14:24.525539 25375 net.cpp:198] encode3_hidden->transform->11 needs backward computation.
I1223 00:14:24.525543 25375 net.cpp:198] encode3_h_conted_t=11 needs backward computation.
I1223 00:14:24.525547 25375 net.cpp:198] h_t=11_encode3_unit_t=11_1_split needs backward computation.
I1223 00:14:24.525550 25375 net.cpp:198] c_t=11_encode3_unit_t=11_0_split needs backward computation.
I1223 00:14:24.525553 25375 net.cpp:198] encode3_unit_t=11 needs backward computation.
I1223 00:14:24.525558 25375 net.cpp:198] encode3_gate_input_11 needs backward computation.
I1223 00:14:24.525563 25375 net.cpp:198] encode3_concat_hadamard_t=11 needs backward computation.
I1223 00:14:24.525566 25375 net.cpp:200] encode3_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:24.525569 25375 net.cpp:198] encode3_hadamard->output_t=10 needs backward computation.
I1223 00:14:24.525573 25375 net.cpp:198] encode3_hadamard->forget_t=10 needs backward computation.
I1223 00:14:24.525576 25375 net.cpp:198] encode3_hadamard->input_t=10 needs backward computation.
I1223 00:14:24.525579 25375 net.cpp:198] encode3_hidden->transform->10 needs backward computation.
I1223 00:14:24.525583 25375 net.cpp:198] encode3_h_conted_t=10 needs backward computation.
I1223 00:14:24.525588 25375 net.cpp:198] h_t=10_encode3_unit_t=10_1_split needs backward computation.
I1223 00:14:24.525591 25375 net.cpp:198] c_t=10_encode3_unit_t=10_0_split needs backward computation.
I1223 00:14:24.525594 25375 net.cpp:198] encode3_unit_t=10 needs backward computation.
I1223 00:14:24.525599 25375 net.cpp:198] encode3_gate_input_10 needs backward computation.
I1223 00:14:24.525604 25375 net.cpp:198] encode3_concat_hadamard_t=10 needs backward computation.
I1223 00:14:24.525609 25375 net.cpp:200] encode3_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:24.525612 25375 net.cpp:198] encode3_hadamard->output_t=9 needs backward computation.
I1223 00:14:24.525615 25375 net.cpp:198] encode3_hadamard->forget_t=9 needs backward computation.
I1223 00:14:24.525619 25375 net.cpp:198] encode3_hadamard->input_t=9 needs backward computation.
I1223 00:14:24.525624 25375 net.cpp:198] encode3_hidden->transform->9 needs backward computation.
I1223 00:14:24.525626 25375 net.cpp:198] encode3_h_conted_t=9 needs backward computation.
I1223 00:14:24.525630 25375 net.cpp:198] h_t=9_encode3_unit_t=9_1_split needs backward computation.
I1223 00:14:24.525635 25375 net.cpp:198] c_t=9_encode3_unit_t=9_0_split needs backward computation.
I1223 00:14:24.525637 25375 net.cpp:198] encode3_unit_t=9 needs backward computation.
I1223 00:14:24.525642 25375 net.cpp:198] encode3_gate_input_9 needs backward computation.
I1223 00:14:24.525647 25375 net.cpp:198] encode3_concat_hadamard_t=9 needs backward computation.
I1223 00:14:24.525652 25375 net.cpp:200] encode3_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:24.525655 25375 net.cpp:198] encode3_hadamard->output_t=8 needs backward computation.
I1223 00:14:24.525660 25375 net.cpp:198] encode3_hadamard->forget_t=8 needs backward computation.
I1223 00:14:24.525662 25375 net.cpp:198] encode3_hadamard->input_t=8 needs backward computation.
I1223 00:14:24.525666 25375 net.cpp:198] encode3_hidden->transform->8 needs backward computation.
I1223 00:14:24.525671 25375 net.cpp:198] encode3_h_conted_t=8 needs backward computation.
I1223 00:14:24.525674 25375 net.cpp:198] h_t=8_encode3_unit_t=8_1_split needs backward computation.
I1223 00:14:24.525678 25375 net.cpp:198] c_t=8_encode3_unit_t=8_0_split needs backward computation.
I1223 00:14:24.525681 25375 net.cpp:198] encode3_unit_t=8 needs backward computation.
I1223 00:14:24.525688 25375 net.cpp:198] encode3_gate_input_8 needs backward computation.
I1223 00:14:24.525693 25375 net.cpp:198] encode3_concat_hadamard_t=8 needs backward computation.
I1223 00:14:24.525699 25375 net.cpp:200] encode3_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:24.525702 25375 net.cpp:198] encode3_hadamard->output_t=7 needs backward computation.
I1223 00:14:24.525705 25375 net.cpp:198] encode3_hadamard->forget_t=7 needs backward computation.
I1223 00:14:24.525709 25375 net.cpp:198] encode3_hadamard->input_t=7 needs backward computation.
I1223 00:14:24.525712 25375 net.cpp:198] encode3_hidden->transform->7 needs backward computation.
I1223 00:14:24.525717 25375 net.cpp:198] encode3_h_conted_t=7 needs backward computation.
I1223 00:14:24.525722 25375 net.cpp:198] h_t=7_encode3_unit_t=7_1_split needs backward computation.
I1223 00:14:24.525724 25375 net.cpp:198] c_t=7_encode3_unit_t=7_0_split needs backward computation.
I1223 00:14:24.525727 25375 net.cpp:198] encode3_unit_t=7 needs backward computation.
I1223 00:14:24.525732 25375 net.cpp:198] encode3_gate_input_7 needs backward computation.
I1223 00:14:24.525738 25375 net.cpp:198] encode3_concat_hadamard_t=7 needs backward computation.
I1223 00:14:24.525743 25375 net.cpp:200] encode3_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:24.525745 25375 net.cpp:198] encode3_hadamard->output_t=6 needs backward computation.
I1223 00:14:24.525748 25375 net.cpp:198] encode3_hadamard->forget_t=6 needs backward computation.
I1223 00:14:24.525753 25375 net.cpp:198] encode3_hadamard->input_t=6 needs backward computation.
I1223 00:14:24.525755 25375 net.cpp:198] encode3_hidden->transform->6 needs backward computation.
I1223 00:14:24.525759 25375 net.cpp:198] encode3_h_conted_t=6 needs backward computation.
I1223 00:14:24.525765 25375 net.cpp:198] h_t=6_encode3_unit_t=6_1_split needs backward computation.
I1223 00:14:24.525768 25375 net.cpp:198] c_t=6_encode3_unit_t=6_0_split needs backward computation.
I1223 00:14:24.525773 25375 net.cpp:198] encode3_unit_t=6 needs backward computation.
I1223 00:14:24.525776 25375 net.cpp:198] encode3_gate_input_6 needs backward computation.
I1223 00:14:24.525781 25375 net.cpp:198] encode3_concat_hadamard_t=6 needs backward computation.
I1223 00:14:24.525786 25375 net.cpp:200] encode3_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:24.525789 25375 net.cpp:198] encode3_hadamard->output_t=5 needs backward computation.
I1223 00:14:24.525794 25375 net.cpp:198] encode3_hadamard->forget_t=5 needs backward computation.
I1223 00:14:24.525796 25375 net.cpp:198] encode3_hadamard->input_t=5 needs backward computation.
I1223 00:14:24.525800 25375 net.cpp:198] encode3_hidden->transform->5 needs backward computation.
I1223 00:14:24.525804 25375 net.cpp:198] encode3_h_conted_t=5 needs backward computation.
I1223 00:14:24.525807 25375 net.cpp:198] h_t=5_encode3_unit_t=5_1_split needs backward computation.
I1223 00:14:24.525811 25375 net.cpp:198] c_t=5_encode3_unit_t=5_0_split needs backward computation.
I1223 00:14:24.525815 25375 net.cpp:198] encode3_unit_t=5 needs backward computation.
I1223 00:14:24.525820 25375 net.cpp:198] encode3_gate_input_5 needs backward computation.
I1223 00:14:24.525823 25375 net.cpp:198] encode3_concat_hadamard_t=5 needs backward computation.
I1223 00:14:24.525828 25375 net.cpp:200] encode3_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:24.525831 25375 net.cpp:198] encode3_hadamard->output_t=4 needs backward computation.
I1223 00:14:24.525836 25375 net.cpp:198] encode3_hadamard->forget_t=4 needs backward computation.
I1223 00:14:24.525840 25375 net.cpp:198] encode3_hadamard->input_t=4 needs backward computation.
I1223 00:14:24.525843 25375 net.cpp:198] encode3_hidden->transform->4 needs backward computation.
I1223 00:14:24.525846 25375 net.cpp:198] encode3_h_conted_t=4 needs backward computation.
I1223 00:14:24.525851 25375 net.cpp:198] h_t=4_encode3_unit_t=4_1_split needs backward computation.
I1223 00:14:24.525854 25375 net.cpp:198] c_t=4_encode3_unit_t=4_0_split needs backward computation.
I1223 00:14:24.525857 25375 net.cpp:198] encode3_unit_t=4 needs backward computation.
I1223 00:14:24.525862 25375 net.cpp:198] encode3_gate_input_4 needs backward computation.
I1223 00:14:24.525866 25375 net.cpp:198] encode3_concat_hadamard_t=4 needs backward computation.
I1223 00:14:24.525871 25375 net.cpp:200] encode3_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:24.525874 25375 net.cpp:198] encode3_hadamard->output_t=3 needs backward computation.
I1223 00:14:24.525878 25375 net.cpp:198] encode3_hadamard->forget_t=3 needs backward computation.
I1223 00:14:24.525882 25375 net.cpp:198] encode3_hadamard->input_t=3 needs backward computation.
I1223 00:14:24.525885 25375 net.cpp:198] encode3_hidden->transform->3 needs backward computation.
I1223 00:14:24.525889 25375 net.cpp:198] encode3_h_conted_t=3 needs backward computation.
I1223 00:14:24.525893 25375 net.cpp:198] h_t=3_encode3_unit_t=3_1_split needs backward computation.
I1223 00:14:24.525897 25375 net.cpp:198] c_t=3_encode3_unit_t=3_0_split needs backward computation.
I1223 00:14:24.525899 25375 net.cpp:198] encode3_unit_t=3 needs backward computation.
I1223 00:14:24.525904 25375 net.cpp:198] encode3_gate_input_3 needs backward computation.
I1223 00:14:24.525909 25375 net.cpp:198] encode3_concat_hadamard_t=3 needs backward computation.
I1223 00:14:24.525915 25375 net.cpp:200] encode3_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:24.525918 25375 net.cpp:198] encode3_hadamard->output_t=2 needs backward computation.
I1223 00:14:24.525923 25375 net.cpp:198] encode3_hadamard->forget_t=2 needs backward computation.
I1223 00:14:24.525925 25375 net.cpp:198] encode3_hadamard->input_t=2 needs backward computation.
I1223 00:14:24.525929 25375 net.cpp:198] encode3_hidden->transform->2 needs backward computation.
I1223 00:14:24.525933 25375 net.cpp:198] encode3_h_conted_t=2 needs backward computation.
I1223 00:14:24.525936 25375 net.cpp:198] h_t=2_encode3_unit_t=2_1_split needs backward computation.
I1223 00:14:24.525939 25375 net.cpp:198] c_t=2_encode3_unit_t=2_0_split needs backward computation.
I1223 00:14:24.525943 25375 net.cpp:198] encode3_unit_t=2 needs backward computation.
I1223 00:14:24.525948 25375 net.cpp:198] encode3_gate_input_2 needs backward computation.
I1223 00:14:24.525952 25375 net.cpp:198] encode3_concat_hadamard_t=2 needs backward computation.
I1223 00:14:24.525956 25375 net.cpp:200] encode3_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:24.525959 25375 net.cpp:198] encode3_hadamard->output_t=1 needs backward computation.
I1223 00:14:24.525962 25375 net.cpp:198] encode3_hadamard->forget_t=1 needs backward computation.
I1223 00:14:24.525966 25375 net.cpp:198] encode3_hadamard->input_t=1 needs backward computation.
I1223 00:14:24.525970 25375 net.cpp:198] encode3_hidden->transform->1 needs backward computation.
I1223 00:14:24.525974 25375 net.cpp:198] encode3_h_conted_t=1 needs backward computation.
I1223 00:14:24.525977 25375 net.cpp:198] h_t=1_encode3_unit_t=1_1_split needs backward computation.
I1223 00:14:24.525981 25375 net.cpp:198] c_t=1_encode3_unit_t=1_0_split needs backward computation.
I1223 00:14:24.525985 25375 net.cpp:198] encode3_unit_t=1 needs backward computation.
I1223 00:14:24.525991 25375 net.cpp:198] encode3_gate_input_1 needs backward computation.
I1223 00:14:24.525996 25375 net.cpp:198] encode3_concat_hadamard_t=1 needs backward computation.
I1223 00:14:24.526001 25375 net.cpp:200] encode3_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:24.526005 25375 net.cpp:198] encode3_hadamard->output_t=0 needs backward computation.
I1223 00:14:24.526008 25375 net.cpp:198] encode3_hadamard->forget_t=0 needs backward computation.
I1223 00:14:24.526011 25375 net.cpp:198] encode3_hadamard->input_t=0 needs backward computation.
I1223 00:14:24.526015 25375 net.cpp:198] encode3_hidden->transform->0 needs backward computation.
I1223 00:14:24.526018 25375 net.cpp:198] encode3_h_conted_t=0 needs backward computation.
I1223 00:14:24.526023 25375 net.cpp:198] encode3_dummy_forward_h0 needs backward computation.
I1223 00:14:24.526026 25375 net.cpp:198] c_t=0_encode3_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:24.526029 25375 net.cpp:198] encode3_dummy_forward_c0 needs backward computation.
I1223 00:14:24.526033 25375 net.cpp:200] cont_t=16_encode3_cont_slice_15_split does not need backward computation.
I1223 00:14:24.526037 25375 net.cpp:200] cont_t=15_encode3_cont_slice_14_split does not need backward computation.
I1223 00:14:24.526041 25375 net.cpp:200] cont_t=14_encode3_cont_slice_13_split does not need backward computation.
I1223 00:14:24.526044 25375 net.cpp:200] cont_t=13_encode3_cont_slice_12_split does not need backward computation.
I1223 00:14:24.526048 25375 net.cpp:200] cont_t=12_encode3_cont_slice_11_split does not need backward computation.
I1223 00:14:24.526052 25375 net.cpp:200] cont_t=11_encode3_cont_slice_10_split does not need backward computation.
I1223 00:14:24.526057 25375 net.cpp:200] cont_t=10_encode3_cont_slice_9_split does not need backward computation.
I1223 00:14:24.526060 25375 net.cpp:200] cont_t=9_encode3_cont_slice_8_split does not need backward computation.
I1223 00:14:24.526064 25375 net.cpp:200] cont_t=8_encode3_cont_slice_7_split does not need backward computation.
I1223 00:14:24.526067 25375 net.cpp:200] cont_t=7_encode3_cont_slice_6_split does not need backward computation.
I1223 00:14:24.526072 25375 net.cpp:200] cont_t=6_encode3_cont_slice_5_split does not need backward computation.
I1223 00:14:24.526075 25375 net.cpp:200] cont_t=5_encode3_cont_slice_4_split does not need backward computation.
I1223 00:14:24.526078 25375 net.cpp:200] cont_t=4_encode3_cont_slice_3_split does not need backward computation.
I1223 00:14:24.526082 25375 net.cpp:200] cont_t=3_encode3_cont_slice_2_split does not need backward computation.
I1223 00:14:24.526087 25375 net.cpp:200] cont_t=2_encode3_cont_slice_1_split does not need backward computation.
I1223 00:14:24.526091 25375 net.cpp:200] cont_t=1_encode3_cont_slice_0_split does not need backward computation.
I1223 00:14:24.526098 25375 net.cpp:200] encode3_cont_slice does not need backward computation.
I1223 00:14:24.526103 25375 net.cpp:198] encode3_W_xc_x_slice needs backward computation.
I1223 00:14:24.526106 25375 net.cpp:200] encode3_input->cell_hidden does not need backward computation.
I1223 00:14:24.526110 25375 net.cpp:198] encode3_x->transform needs backward computation.
I1223 00:14:24.526113 25375 net.cpp:200] encode3_ does not need backward computation.
I1223 00:14:24.526116 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:24.526120 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:24.526124 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:24.527041 25375 net.cpp:255] Network initialization done.
I1223 00:14:24.527493 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:24.527501 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:24.527505 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:24.527508 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:24.527510 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:24.527513 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:24.527515 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:24.527518 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:24.527534 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:24.527537 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:24.528244 25375 net.cpp:122] Setting up encode3
I1223 00:14:24.528254 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.528259 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.528264 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.528266 25375 net.cpp:137] Memory required for data: 4286972288
I1223 00:14:24.528303 25375 layer_factory.hpp:77] Creating layer encode4
I1223 00:14:24.528347 25375 net.cpp:84] Creating Layer encode4
I1223 00:14:24.528353 25375 net.cpp:406] encode4 <- conv6-reshape_reshape-data_0_split_3
I1223 00:14:24.528359 25375 net.cpp:406] encode4 <- reshape-cm_reshape-cm_0_split_3
I1223 00:14:24.528364 25375 net.cpp:406] encode4 <- dummy_dummy_0_split_6
I1223 00:14:24.528368 25375 net.cpp:406] encode4 <- dummy_dummy_0_split_7
I1223 00:14:24.528374 25375 net.cpp:380] encode4 -> encode4
I1223 00:14:24.528399 25375 net.cpp:380] encode4 -> encode4_h
I1223 00:14:24.528421 25375 net.cpp:380] encode4 -> encode4_c
I1223 00:14:24.528432 25375 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 1 independent streams.
Unrolling ConvLSTM
Unrolling T=1
Building ConvLSTMUnit layer
Unrolling T=2
Building ConvLSTMUnit layer
Unrolling T=3
Building ConvLSTMUnit layer
Unrolling T=4
Building ConvLSTMUnit layer
Unrolling T=5
Building ConvLSTMUnit layer
Unrolling T=6
Building ConvLSTMUnit layer
Unrolling T=7
Building ConvLSTMUnit layer
Unrolling T=8
Building ConvLSTMUnit layer
Unrolling T=9
Building ConvLSTMUnit layer
Unrolling T=10
Building ConvLSTMUnit layer
Unrolling T=11
Building ConvLSTMUnit layer
Unrolling T=12
Building ConvLSTMUnit layer
Unrolling T=13
Building ConvLSTMUnit layer
Unrolling T=14
Building ConvLSTMUnit layer
Unrolling T=15
Building ConvLSTMUnit layer
Unrolling T=16
Building ConvLSTMUnit layer
I1223 00:14:24.529840 25375 net.cpp:51] Initializing net from parameters: 
layer {
  name: "encode4_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 32
      dim: 32
    }
    shape {
      dim: 16
      dim: 1
    }
  }
}
layer {
  name: "encode4_x->transform"
  type: "Convolution"
  bottom: "x"
  top: "x->transform"
  param {
    name: "x_transform"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_input->cell_hidden"
  type: "Input"
  top: "c_t=0"
  top: "h_t=0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_W_xc_x_slice"
  type: "Slice"
  bottom: "x->transform"
  top: "x->transform->t=1"
  top: "x->transform->t=2"
  top: "x->transform->t=3"
  top: "x->transform->t=4"
  top: "x->transform->t=5"
  top: "x->transform->t=6"
  top: "x->transform->t=7"
  top: "x->transform->t=8"
  top: "x->transform->t=9"
  top: "x->transform->t=10"
  top: "x->transform->t=11"
  top: "x->transform->t=12"
  top: "x->transform->t=13"
  top: "x->transform->t=14"
  top: "x->transform->t=15"
  top: "x->transform->t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode4_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_t=1"
  top: "cont_t=2"
  top: "cont_t=3"
  top: "cont_t=4"
  top: "cont_t=5"
  top: "cont_t=6"
  top: "cont_t=7"
  top: "cont_t=8"
  top: "cont_t=9"
  top: "cont_t=10"
  top: "cont_t=11"
  top: "cont_t=12"
  top: "cont_t=13"
  top: "cont_t=14"
  top: "cont_t=15"
  top: "cont_t=16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "encode4_dummy_forward_c0"
  type: "DummyForward"
  bottom: "c_t=0"
  top: "c_t=0"
  propagate_down: true
}
layer {
  name: "encode4_dummy_forward_h0"
  type: "DummyForward"
  bottom: "h_t=0"
  top: "h_t=0"
  propagate_down: true
}
layer {
  name: "encode4_h_conted_t=0"
  type: "Scale"
  bottom: "h_t=0"
  bottom: "cont_t=1"
  top: "h_conted_t=0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->0"
  type: "Convolution"
  bottom: "h_conted_t=0"
  top: "hidden->transform->0"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_in_t=1"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_fog_t=1"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=0"
  type: "Scale"
  bottom: "c_t=0"
  top: "hadamard_out_t=1"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=1"
  type: "DummyData"
  top: "hadamard_gat_t=1"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=1"
  type: "Concat"
  bottom: "hadamard_in_t=1"
  bottom: "hadamard_fog_t=1"
  bottom: "hadamard_out_t=1"
  bottom: "hadamard_gat_t=1"
  top: "hadamard_t=1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_1"
  type: "Eltwise"
  bottom: "hidden->transform->0"
  bottom: "x->transform->t=1"
  bottom: "hadamard_t=1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=1"
  type: "ConvLSTMUnit"
  bottom: "c_t=0"
  bottom: "gate_input_1"
  bottom: "cont_t=1"
  top: "c_t=1"
  top: "h_t=1"
}
layer {
  name: "encode4_h_conted_t=1"
  type: "Scale"
  bottom: "h_t=1"
  bottom: "cont_t=2"
  top: "h_conted_t=1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->1"
  type: "Convolution"
  bottom: "h_conted_t=1"
  top: "hidden->transform->1"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_in_t=2"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_fog_t=2"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=1"
  type: "Scale"
  bottom: "c_t=1"
  top: "hadamard_out_t=2"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=2"
  type: "DummyData"
  top: "hadamard_gat_t=2"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=2"
  type: "Concat"
  bottom: "hadamard_in_t=2"
  bottom: "hadamard_fog_t=2"
  bottom: "hadamard_out_t=2"
  bottom: "hadamard_gat_t=2"
  top: "hadamard_t=2"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_2"
  type: "Eltwise"
  bottom: "hidden->transform->1"
  bottom: "x->transform->t=2"
  bottom: "hadamard_t=2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=2"
  type: "ConvLSTMUnit"
  bottom: "c_t=1"
  bottom: "gate_input_2"
  bottom: "cont_t=2"
  top: "c_t=2"
  top: "h_t=2"
}
layer {
  name: "encode4_h_conted_t=2"
  type: "Scale"
  bottom: "h_t=2"
  bottom: "cont_t=3"
  top: "h_conted_t=2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->2"
  type: "Convolution"
  bottom: "h_conted_t=2"
  top: "hidden->transform->2"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_in_t=3"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_fog_t=3"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=2"
  type: "Scale"
  bottom: "c_t=2"
  top: "hadamard_out_t=3"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=3"
  type: "DummyData"
  top: "hadamard_gat_t=3"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=3"
  type: "Concat"
  bottom: "hadamard_in_t=3"
  bottom: "hadamard_fog_t=3"
  bottom: "hadamard_out_t=3"
  bottom: "hadamard_gat_t=3"
  top: "hadamard_t=3"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_3"
  type: "Eltwise"
  bottom: "hidden->transform->2"
  bottom: "x->transform->t=3"
  bottom: "hadamard_t=3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=3"
  type: "ConvLSTMUnit"
  bottom: "c_t=2"
  bottom: "gate_input_3"
  bottom: "cont_t=3"
  top: "c_t=3"
  top: "h_t=3"
}
layer {
  name: "encode4_h_conted_t=3"
  type: "Scale"
  bottom: "h_t=3"
  bottom: "cont_t=4"
  top: "h_conted_t=3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->3"
  type: "Convolution"
  bottom: "h_conted_t=3"
  top: "hidden->transform->3"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_in_t=4"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_fog_t=4"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=3"
  type: "Scale"
  bottom: "c_t=3"
  top: "hadamard_out_t=4"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=4"
  type: "DummyData"
  top: "hadamard_gat_t=4"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=4"
  type: "Concat"
  bottom: "hadamard_in_t=4"
  bottom: "hadamard_fog_t=4"
  bottom: "hadamard_out_t=4"
  bottom: "hadamard_gat_t=4"
  top: "hadamard_t=4"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_4"
  type: "Eltwise"
  bottom: "hidden->transform->3"
  bottom: "x->transform->t=4"
  bottom: "hadamard_t=4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=4"
  type: "ConvLSTMUnit"
  bottom: "c_t=3"
  bottom: "gate_input_4"
  bottom: "cont_t=4"
  top: "c_t=4"
  top: "h_t=4"
}
layer {
  name: "encode4_h_conted_t=4"
  type: "Scale"
  bottom: "h_t=4"
  bottom: "cont_t=5"
  top: "h_conted_t=4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->4"
  type: "Convolution"
  bottom: "h_conted_t=4"
  top: "hidden->transform->4"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_in_t=5"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_fog_t=5"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=4"
  type: "Scale"
  bottom: "c_t=4"
  top: "hadamard_out_t=5"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=5"
  type: "DummyData"
  top: "hadamard_gat_t=5"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=5"
  type: "Concat"
  bottom: "hadamard_in_t=5"
  bottom: "hadamard_fog_t=5"
  bottom: "hadamard_out_t=5"
  bottom: "hadamard_gat_t=5"
  top: "hadamard_t=5"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_5"
  type: "Eltwise"
  bottom: "hidden->transform->4"
  bottom: "x->transform->t=5"
  bottom: "hadamard_t=5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=5"
  type: "ConvLSTMUnit"
  bottom: "c_t=4"
  bottom: "gate_input_5"
  bottom: "cont_t=5"
  top: "c_t=5"
  top: "h_t=5"
}
layer {
  name: "encode4_h_conted_t=5"
  type: "Scale"
  bottom: "h_t=5"
  bottom: "cont_t=6"
  top: "h_conted_t=5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->5"
  type: "Convolution"
  bottom: "h_conted_t=5"
  top: "hidden->transform->5"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_in_t=6"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_fog_t=6"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=5"
  type: "Scale"
  bottom: "c_t=5"
  top: "hadamard_out_t=6"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=6"
  type: "DummyData"
  top: "hadamard_gat_t=6"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=6"
  type: "Concat"
  bottom: "hadamard_in_t=6"
  bottom: "hadamard_fog_t=6"
  bottom: "hadamard_out_t=6"
  bottom: "hadamard_gat_t=6"
  top: "hadamard_t=6"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_6"
  type: "Eltwise"
  bottom: "hidden->transform->5"
  bottom: "x->transform->t=6"
  bottom: "hadamard_t=6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=6"
  type: "ConvLSTMUnit"
  bottom: "c_t=5"
  bottom: "gate_input_6"
  bottom: "cont_t=6"
  top: "c_t=6"
  top: "h_t=6"
}
layer {
  name: "encode4_h_conted_t=6"
  type: "Scale"
  bottom: "h_t=6"
  bottom: "cont_t=7"
  top: "h_conted_t=6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->6"
  type: "Convolution"
  bottom: "h_conted_t=6"
  top: "hidden->transform->6"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_in_t=7"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_fog_t=7"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=6"
  type: "Scale"
  bottom: "c_t=6"
  top: "hadamard_out_t=7"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=7"
  type: "DummyData"
  top: "hadamard_gat_t=7"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=7"
  type: "Concat"
  bottom: "hadamard_in_t=7"
  bottom: "hadamard_fog_t=7"
  bottom: "hadamard_out_t=7"
  bottom: "hadamard_gat_t=7"
  top: "hadamard_t=7"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_7"
  type: "Eltwise"
  bottom: "hidden->transform->6"
  bottom: "x->transform->t=7"
  bottom: "hadamard_t=7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=7"
  type: "ConvLSTMUnit"
  bottom: "c_t=6"
  bottom: "gate_input_7"
  bottom: "cont_t=7"
  top: "c_t=7"
  top: "h_t=7"
}
layer {
  name: "encode4_h_conted_t=7"
  type: "Scale"
  bottom: "h_t=7"
  bottom: "cont_t=8"
  top: "h_conted_t=7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->7"
  type: "Convolution"
  bottom: "h_conted_t=7"
  top: "hidden->transform->7"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_in_t=8"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_fog_t=8"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=7"
  type: "Scale"
  bottom: "c_t=7"
  top: "hadamard_out_t=8"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=8"
  type: "DummyData"
  top: "hadamard_gat_t=8"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=8"
  type: "Concat"
  bottom: "hadamard_in_t=8"
  bottom: "hadamard_fog_t=8"
  bottom: "hadamard_out_t=8"
  bottom: "hadamard_gat_t=8"
  top: "hadamard_t=8"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_8"
  type: "Eltwise"
  bottom: "hidden->transform->7"
  bottom: "x->transform->t=8"
  bottom: "hadamard_t=8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=8"
  type: "ConvLSTMUnit"
  bottom: "c_t=7"
  bottom: "gate_input_8"
  bottom: "cont_t=8"
  top: "c_t=8"
  top: "h_t=8"
}
layer {
  name: "encode4_h_conted_t=8"
  type: "Scale"
  bottom: "h_t=8"
  bottom: "cont_t=9"
  top: "h_conted_t=8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->8"
  type: "Convolution"
  bottom: "h_conted_t=8"
  top: "hidden->transform->8"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_in_t=9"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_fog_t=9"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=8"
  type: "Scale"
  bottom: "c_t=8"
  top: "hadamard_out_t=9"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=9"
  type: "DummyData"
  top: "hadamard_gat_t=9"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=9"
  type: "Concat"
  bottom: "hadamard_in_t=9"
  bottom: "hadamard_fog_t=9"
  bottom: "hadamard_out_t=9"
  bottom: "hadamard_gat_t=9"
  top: "hadamard_t=9"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_9"
  type: "Eltwise"
  bottom: "hidden->transform->8"
  bottom: "x->transform->t=9"
  bottom: "hadamard_t=9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=9"
  type: "ConvLSTMUnit"
  bottom: "c_t=8"
  bottom: "gate_input_9"
  bottom: "cont_t=9"
  top: "c_t=9"
  top: "h_t=9"
}
layer {
  name: "encode4_h_conted_t=9"
  type: "Scale"
  bottom: "h_t=9"
  bottom: "cont_t=10"
  top: "h_conted_t=9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->9"
  type: "Convolution"
  bottom: "h_conted_t=9"
  top: "hidden->transform->9"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_in_t=10"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_fog_t=10"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=9"
  type: "Scale"
  bottom: "c_t=9"
  top: "hadamard_out_t=10"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=10"
  type: "DummyData"
  top: "hadamard_gat_t=10"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=10"
  type: "Concat"
  bottom: "hadamard_in_t=10"
  bottom: "hadamard_fog_t=10"
  bottom: "hadamard_out_t=10"
  bottom: "hadamard_gat_t=10"
  top: "hadamard_t=10"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_10"
  type: "Eltwise"
  bottom: "hidden->transform->9"
  bottom: "x->transform->t=10"
  bottom: "hadamard_t=10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=10"
  type: "ConvLSTMUnit"
  bottom: "c_t=9"
  bottom: "gate_input_10"
  bottom: "cont_t=10"
  top: "c_t=10"
  top: "h_t=10"
}
layer {
  name: "encode4_h_conted_t=10"
  type: "Scale"
  bottom: "h_t=10"
  bottom: "cont_t=11"
  top: "h_conted_t=10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->10"
  type: "Convolution"
  bottom: "h_conted_t=10"
  top: "hidden->transform->10"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_in_t=11"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_fog_t=11"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=10"
  type: "Scale"
  bottom: "c_t=10"
  top: "hadamard_out_t=11"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=11"
  type: "DummyData"
  top: "hadamard_gat_t=11"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=11"
  type: "Concat"
  bottom: "hadamard_in_t=11"
  bottom: "hadamard_fog_t=11"
  bottom: "hadamard_out_t=11"
  bottom: "hadamard_gat_t=11"
  top: "hadamard_t=11"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_11"
  type: "Eltwise"
  bottom: "hidden->transform->10"
  bottom: "x->transform->t=11"
  bottom: "hadamard_t=11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=11"
  type: "ConvLSTMUnit"
  bottom: "c_t=10"
  bottom: "gate_input_11"
  bottom: "cont_t=11"
  top: "c_t=11"
  top: "h_t=11"
}
layer {
  name: "encode4_h_conted_t=11"
  type: "Scale"
  bottom: "h_t=11"
  bottom: "cont_t=12"
  top: "h_conted_t=11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->11"
  type: "Convolution"
  bottom: "h_conted_t=11"
  top: "hidden->transform->11"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_in_t=12"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_fog_t=12"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=11"
  type: "Scale"
  bottom: "c_t=11"
  top: "hadamard_out_t=12"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=12"
  type: "DummyData"
  top: "hadamard_gat_t=12"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=12"
  type: "Concat"
  bottom: "hadamard_in_t=12"
  bottom: "hadamard_fog_t=12"
  bottom: "hadamard_out_t=12"
  bottom: "hadamard_gat_t=12"
  top: "hadamard_t=12"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_12"
  type: "Eltwise"
  bottom: "hidden->transform->11"
  bottom: "x->transform->t=12"
  bottom: "hadamard_t=12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=12"
  type: "ConvLSTMUnit"
  bottom: "c_t=11"
  bottom: "gate_input_12"
  bottom: "cont_t=12"
  top: "c_t=12"
  top: "h_t=12"
}
layer {
  name: "encode4_h_conted_t=12"
  type: "Scale"
  bottom: "h_t=12"
  bottom: "cont_t=13"
  top: "h_conted_t=12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transform->12"
  type: "Convolution"
  bottom: "h_conted_t=12"
  top: "hidden->transform->12"
  param {
    name: "h->transform"
  }
  param {
    name: "h->transform_bias"
  }
  propagate_down: true
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 8
    kernel_size: 3
    group: 1
    weight_filler {
      type: "uniform"
      min: -0.0297
      max: 0.0297
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: DEFAULT
    axis: 2
    force_nd_im2col: false
    dilation: 8
  }
}
layer {
  name: "encode4_hadamard->input_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_in_t=13"
  param {
    name: "hadamard.input"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->forget_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_fog_t=13"
  param {
    name: "hadamard.forget"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard->output_t=12"
  type: "Scale"
  bottom: "c_t=12"
  top: "hadamard_out_t=13"
  param {
    name: "hadamard.output"
  }
  scale_param {
    axis: 3
    num_axes: 2
  }
}
layer {
  name: "encode4_hadamard_gat_t=13"
  type: "DummyData"
  top: "hadamard_gat_t=13"
  dummy_data_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "encode4_concat_hadamard_t=13"
  type: "Concat"
  bottom: "hadamard_in_t=13"
  bottom: "hadamard_fog_t=13"
  bottom: "hadamard_out_t=13"
  bottom: "hadamard_gat_t=13"
  top: "hadamard_t=13"
  concat_param {
    axis: 2
  }
}
layer {
  name: "encode4_gate_input_13"
  type: "Eltwise"
  bottom: "hidden->transform->12"
  bottom: "x->transform->t=13"
  bottom: "hadamard_t=13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "encode4_unit_t=13"
  type: "ConvLSTMUnit"
  bottom: "c_t=12"
  bottom: "gate_input_13"
  bottom: "cont_t=13"
  top: "c_t=13"
  top: "h_t=13"
}
layer {
  name: "encode4_h_conted_t=13"
  type: "Scale"
  bottom: "h_t=13"
  bottom: "cont_t=14"
  top: "h_conted_t=13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "encode4_hidden->transfor
I1223 00:14:24.530773 25375 layer_factory.hpp:77] Creating layer encode4_
I1223 00:14:24.530786 25375 net.cpp:84] Creating Layer encode4_
I1223 00:14:24.530791 25375 net.cpp:380] encode4_ -> x
I1223 00:14:24.530798 25375 net.cpp:380] encode4_ -> cont
I1223 00:14:24.530864 25375 net.cpp:122] Setting up encode4_
I1223 00:14:24.530872 25375 net.cpp:129] Top shape: 16 1 1 32 32 (16384)
I1223 00:14:24.530877 25375 net.cpp:129] Top shape: 16 1 (16)
I1223 00:14:24.530879 25375 net.cpp:137] Memory required for data: 65600
I1223 00:14:24.530884 25375 layer_factory.hpp:77] Creating layer encode4_x->transform
I1223 00:14:24.530892 25375 net.cpp:84] Creating Layer encode4_x->transform
I1223 00:14:24.530896 25375 net.cpp:406] encode4_x->transform <- x
I1223 00:14:24.530901 25375 net.cpp:380] encode4_x->transform -> x->transform
I1223 00:14:24.531219 25375 net.cpp:122] Setting up encode4_x->transform
I1223 00:14:24.531229 25375 net.cpp:129] Top shape: 16 1 128 32 32 (2097152)
I1223 00:14:24.531232 25375 net.cpp:137] Memory required for data: 8454208
I1223 00:14:24.531237 25375 layer_factory.hpp:77] Creating layer encode4_input->cell_hidden
I1223 00:14:24.531251 25375 net.cpp:84] Creating Layer encode4_input->cell_hidden
I1223 00:14:24.531258 25375 net.cpp:380] encode4_input->cell_hidden -> c_t=0
I1223 00:14:24.531266 25375 net.cpp:380] encode4_input->cell_hidden -> h_t=0
I1223 00:14:24.531311 25375 net.cpp:122] Setting up encode4_input->cell_hidden
I1223 00:14:24.531319 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.531324 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.531327 25375 net.cpp:137] Memory required for data: 8716352
I1223 00:14:24.531329 25375 layer_factory.hpp:77] Creating layer encode4_W_xc_x_slice
I1223 00:14:24.531337 25375 net.cpp:84] Creating Layer encode4_W_xc_x_slice
I1223 00:14:24.531339 25375 net.cpp:406] encode4_W_xc_x_slice <- x->transform
I1223 00:14:24.531347 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=1
I1223 00:14:24.531357 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=2
I1223 00:14:24.531365 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=3
I1223 00:14:24.531374 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=4
I1223 00:14:24.531383 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=5
I1223 00:14:24.531391 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=6
I1223 00:14:24.531399 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=7
I1223 00:14:24.531406 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=8
I1223 00:14:24.531414 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=9
I1223 00:14:24.531424 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=10
I1223 00:14:24.531431 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=11
I1223 00:14:24.531440 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=12
I1223 00:14:24.531450 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=13
I1223 00:14:24.531457 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=14
I1223 00:14:24.531466 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=15
I1223 00:14:24.531473 25375 net.cpp:380] encode4_W_xc_x_slice -> x->transform->t=16
I1223 00:14:24.531702 25375 net.cpp:122] Setting up encode4_W_xc_x_slice
I1223 00:14:24.531711 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531716 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531720 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531724 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531728 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531731 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531735 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531739 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531743 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531746 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531750 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531754 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531759 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531762 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531765 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531769 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.531772 25375 net.cpp:137] Memory required for data: 17104960
I1223 00:14:24.531775 25375 layer_factory.hpp:77] Creating layer encode4_cont_slice
I1223 00:14:24.531782 25375 net.cpp:84] Creating Layer encode4_cont_slice
I1223 00:14:24.531785 25375 net.cpp:406] encode4_cont_slice <- cont
I1223 00:14:24.531791 25375 net.cpp:380] encode4_cont_slice -> cont_t=1
I1223 00:14:24.531800 25375 net.cpp:380] encode4_cont_slice -> cont_t=2
I1223 00:14:24.531805 25375 net.cpp:380] encode4_cont_slice -> cont_t=3
I1223 00:14:24.531812 25375 net.cpp:380] encode4_cont_slice -> cont_t=4
I1223 00:14:24.531819 25375 net.cpp:380] encode4_cont_slice -> cont_t=5
I1223 00:14:24.531826 25375 net.cpp:380] encode4_cont_slice -> cont_t=6
I1223 00:14:24.531832 25375 net.cpp:380] encode4_cont_slice -> cont_t=7
I1223 00:14:24.531839 25375 net.cpp:380] encode4_cont_slice -> cont_t=8
I1223 00:14:24.531846 25375 net.cpp:380] encode4_cont_slice -> cont_t=9
I1223 00:14:24.531853 25375 net.cpp:380] encode4_cont_slice -> cont_t=10
I1223 00:14:24.531860 25375 net.cpp:380] encode4_cont_slice -> cont_t=11
I1223 00:14:24.531867 25375 net.cpp:380] encode4_cont_slice -> cont_t=12
I1223 00:14:24.531877 25375 net.cpp:380] encode4_cont_slice -> cont_t=13
I1223 00:14:24.531884 25375 net.cpp:380] encode4_cont_slice -> cont_t=14
I1223 00:14:24.531890 25375 net.cpp:380] encode4_cont_slice -> cont_t=15
I1223 00:14:24.531896 25375 net.cpp:380] encode4_cont_slice -> cont_t=16
I1223 00:14:24.532130 25375 net.cpp:122] Setting up encode4_cont_slice
I1223 00:14:24.532140 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532143 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532146 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532150 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532153 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532157 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532160 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532163 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532166 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532171 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532173 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532176 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532181 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532183 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532187 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532191 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532193 25375 net.cpp:137] Memory required for data: 17105024
I1223 00:14:24.532196 25375 layer_factory.hpp:77] Creating layer cont_t=1_encode4_cont_slice_0_split
I1223 00:14:24.532202 25375 net.cpp:84] Creating Layer cont_t=1_encode4_cont_slice_0_split
I1223 00:14:24.532204 25375 net.cpp:406] cont_t=1_encode4_cont_slice_0_split <- cont_t=1
I1223 00:14:24.532210 25375 net.cpp:380] cont_t=1_encode4_cont_slice_0_split -> cont_t=1_encode4_cont_slice_0_split_0
I1223 00:14:24.532217 25375 net.cpp:380] cont_t=1_encode4_cont_slice_0_split -> cont_t=1_encode4_cont_slice_0_split_1
I1223 00:14:24.532256 25375 net.cpp:122] Setting up cont_t=1_encode4_cont_slice_0_split
I1223 00:14:24.532264 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532269 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532271 25375 net.cpp:137] Memory required for data: 17105032
I1223 00:14:24.532274 25375 layer_factory.hpp:77] Creating layer cont_t=2_encode4_cont_slice_1_split
I1223 00:14:24.532279 25375 net.cpp:84] Creating Layer cont_t=2_encode4_cont_slice_1_split
I1223 00:14:24.532282 25375 net.cpp:406] cont_t=2_encode4_cont_slice_1_split <- cont_t=2
I1223 00:14:24.532287 25375 net.cpp:380] cont_t=2_encode4_cont_slice_1_split -> cont_t=2_encode4_cont_slice_1_split_0
I1223 00:14:24.532294 25375 net.cpp:380] cont_t=2_encode4_cont_slice_1_split -> cont_t=2_encode4_cont_slice_1_split_1
I1223 00:14:24.532331 25375 net.cpp:122] Setting up cont_t=2_encode4_cont_slice_1_split
I1223 00:14:24.532341 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532346 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532347 25375 net.cpp:137] Memory required for data: 17105040
I1223 00:14:24.532351 25375 layer_factory.hpp:77] Creating layer cont_t=3_encode4_cont_slice_2_split
I1223 00:14:24.532356 25375 net.cpp:84] Creating Layer cont_t=3_encode4_cont_slice_2_split
I1223 00:14:24.532359 25375 net.cpp:406] cont_t=3_encode4_cont_slice_2_split <- cont_t=3
I1223 00:14:24.532363 25375 net.cpp:380] cont_t=3_encode4_cont_slice_2_split -> cont_t=3_encode4_cont_slice_2_split_0
I1223 00:14:24.532372 25375 net.cpp:380] cont_t=3_encode4_cont_slice_2_split -> cont_t=3_encode4_cont_slice_2_split_1
I1223 00:14:24.532413 25375 net.cpp:122] Setting up cont_t=3_encode4_cont_slice_2_split
I1223 00:14:24.532420 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532424 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532426 25375 net.cpp:137] Memory required for data: 17105048
I1223 00:14:24.532429 25375 layer_factory.hpp:77] Creating layer cont_t=4_encode4_cont_slice_3_split
I1223 00:14:24.532438 25375 net.cpp:84] Creating Layer cont_t=4_encode4_cont_slice_3_split
I1223 00:14:24.532440 25375 net.cpp:406] cont_t=4_encode4_cont_slice_3_split <- cont_t=4
I1223 00:14:24.532447 25375 net.cpp:380] cont_t=4_encode4_cont_slice_3_split -> cont_t=4_encode4_cont_slice_3_split_0
I1223 00:14:24.532454 25375 net.cpp:380] cont_t=4_encode4_cont_slice_3_split -> cont_t=4_encode4_cont_slice_3_split_1
I1223 00:14:24.532493 25375 net.cpp:122] Setting up cont_t=4_encode4_cont_slice_3_split
I1223 00:14:24.532502 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532507 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532510 25375 net.cpp:137] Memory required for data: 17105056
I1223 00:14:24.532512 25375 layer_factory.hpp:77] Creating layer cont_t=5_encode4_cont_slice_4_split
I1223 00:14:24.532517 25375 net.cpp:84] Creating Layer cont_t=5_encode4_cont_slice_4_split
I1223 00:14:24.532521 25375 net.cpp:406] cont_t=5_encode4_cont_slice_4_split <- cont_t=5
I1223 00:14:24.532526 25375 net.cpp:380] cont_t=5_encode4_cont_slice_4_split -> cont_t=5_encode4_cont_slice_4_split_0
I1223 00:14:24.532533 25375 net.cpp:380] cont_t=5_encode4_cont_slice_4_split -> cont_t=5_encode4_cont_slice_4_split_1
I1223 00:14:24.532572 25375 net.cpp:122] Setting up cont_t=5_encode4_cont_slice_4_split
I1223 00:14:24.532579 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532583 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532586 25375 net.cpp:137] Memory required for data: 17105064
I1223 00:14:24.532588 25375 layer_factory.hpp:77] Creating layer cont_t=6_encode4_cont_slice_5_split
I1223 00:14:24.532595 25375 net.cpp:84] Creating Layer cont_t=6_encode4_cont_slice_5_split
I1223 00:14:24.532598 25375 net.cpp:406] cont_t=6_encode4_cont_slice_5_split <- cont_t=6
I1223 00:14:24.532603 25375 net.cpp:380] cont_t=6_encode4_cont_slice_5_split -> cont_t=6_encode4_cont_slice_5_split_0
I1223 00:14:24.532609 25375 net.cpp:380] cont_t=6_encode4_cont_slice_5_split -> cont_t=6_encode4_cont_slice_5_split_1
I1223 00:14:24.532647 25375 net.cpp:122] Setting up cont_t=6_encode4_cont_slice_5_split
I1223 00:14:24.532655 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532660 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532661 25375 net.cpp:137] Memory required for data: 17105072
I1223 00:14:24.532665 25375 layer_factory.hpp:77] Creating layer cont_t=7_encode4_cont_slice_6_split
I1223 00:14:24.532670 25375 net.cpp:84] Creating Layer cont_t=7_encode4_cont_slice_6_split
I1223 00:14:24.532686 25375 net.cpp:406] cont_t=7_encode4_cont_slice_6_split <- cont_t=7
I1223 00:14:24.532691 25375 net.cpp:380] cont_t=7_encode4_cont_slice_6_split -> cont_t=7_encode4_cont_slice_6_split_0
I1223 00:14:24.532711 25375 net.cpp:380] cont_t=7_encode4_cont_slice_6_split -> cont_t=7_encode4_cont_slice_6_split_1
I1223 00:14:24.532748 25375 net.cpp:122] Setting up cont_t=7_encode4_cont_slice_6_split
I1223 00:14:24.532757 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532760 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532763 25375 net.cpp:137] Memory required for data: 17105080
I1223 00:14:24.532765 25375 layer_factory.hpp:77] Creating layer cont_t=8_encode4_cont_slice_7_split
I1223 00:14:24.532771 25375 net.cpp:84] Creating Layer cont_t=8_encode4_cont_slice_7_split
I1223 00:14:24.532775 25375 net.cpp:406] cont_t=8_encode4_cont_slice_7_split <- cont_t=8
I1223 00:14:24.532780 25375 net.cpp:380] cont_t=8_encode4_cont_slice_7_split -> cont_t=8_encode4_cont_slice_7_split_0
I1223 00:14:24.532788 25375 net.cpp:380] cont_t=8_encode4_cont_slice_7_split -> cont_t=8_encode4_cont_slice_7_split_1
I1223 00:14:24.532824 25375 net.cpp:122] Setting up cont_t=8_encode4_cont_slice_7_split
I1223 00:14:24.532845 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532850 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532851 25375 net.cpp:137] Memory required for data: 17105088
I1223 00:14:24.532855 25375 layer_factory.hpp:77] Creating layer cont_t=9_encode4_cont_slice_8_split
I1223 00:14:24.532858 25375 net.cpp:84] Creating Layer cont_t=9_encode4_cont_slice_8_split
I1223 00:14:24.532862 25375 net.cpp:406] cont_t=9_encode4_cont_slice_8_split <- cont_t=9
I1223 00:14:24.532867 25375 net.cpp:380] cont_t=9_encode4_cont_slice_8_split -> cont_t=9_encode4_cont_slice_8_split_0
I1223 00:14:24.532887 25375 net.cpp:380] cont_t=9_encode4_cont_slice_8_split -> cont_t=9_encode4_cont_slice_8_split_1
I1223 00:14:24.532924 25375 net.cpp:122] Setting up cont_t=9_encode4_cont_slice_8_split
I1223 00:14:24.532945 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532949 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.532953 25375 net.cpp:137] Memory required for data: 17105096
I1223 00:14:24.532954 25375 layer_factory.hpp:77] Creating layer cont_t=10_encode4_cont_slice_9_split
I1223 00:14:24.532959 25375 net.cpp:84] Creating Layer cont_t=10_encode4_cont_slice_9_split
I1223 00:14:24.532963 25375 net.cpp:406] cont_t=10_encode4_cont_slice_9_split <- cont_t=10
I1223 00:14:24.532969 25375 net.cpp:380] cont_t=10_encode4_cont_slice_9_split -> cont_t=10_encode4_cont_slice_9_split_0
I1223 00:14:24.532989 25375 net.cpp:380] cont_t=10_encode4_cont_slice_9_split -> cont_t=10_encode4_cont_slice_9_split_1
I1223 00:14:24.533027 25375 net.cpp:122] Setting up cont_t=10_encode4_cont_slice_9_split
I1223 00:14:24.533035 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533040 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533041 25375 net.cpp:137] Memory required for data: 17105104
I1223 00:14:24.533044 25375 layer_factory.hpp:77] Creating layer cont_t=11_encode4_cont_slice_10_split
I1223 00:14:24.533049 25375 net.cpp:84] Creating Layer cont_t=11_encode4_cont_slice_10_split
I1223 00:14:24.533052 25375 net.cpp:406] cont_t=11_encode4_cont_slice_10_split <- cont_t=11
I1223 00:14:24.533057 25375 net.cpp:380] cont_t=11_encode4_cont_slice_10_split -> cont_t=11_encode4_cont_slice_10_split_0
I1223 00:14:24.533063 25375 net.cpp:380] cont_t=11_encode4_cont_slice_10_split -> cont_t=11_encode4_cont_slice_10_split_1
I1223 00:14:24.533108 25375 net.cpp:122] Setting up cont_t=11_encode4_cont_slice_10_split
I1223 00:14:24.533118 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533121 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533123 25375 net.cpp:137] Memory required for data: 17105112
I1223 00:14:24.533126 25375 layer_factory.hpp:77] Creating layer cont_t=12_encode4_cont_slice_11_split
I1223 00:14:24.533134 25375 net.cpp:84] Creating Layer cont_t=12_encode4_cont_slice_11_split
I1223 00:14:24.533138 25375 net.cpp:406] cont_t=12_encode4_cont_slice_11_split <- cont_t=12
I1223 00:14:24.533143 25375 net.cpp:380] cont_t=12_encode4_cont_slice_11_split -> cont_t=12_encode4_cont_slice_11_split_0
I1223 00:14:24.533149 25375 net.cpp:380] cont_t=12_encode4_cont_slice_11_split -> cont_t=12_encode4_cont_slice_11_split_1
I1223 00:14:24.533201 25375 net.cpp:122] Setting up cont_t=12_encode4_cont_slice_11_split
I1223 00:14:24.533210 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533213 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533216 25375 net.cpp:137] Memory required for data: 17105120
I1223 00:14:24.533218 25375 layer_factory.hpp:77] Creating layer cont_t=13_encode4_cont_slice_12_split
I1223 00:14:24.533223 25375 net.cpp:84] Creating Layer cont_t=13_encode4_cont_slice_12_split
I1223 00:14:24.533239 25375 net.cpp:406] cont_t=13_encode4_cont_slice_12_split <- cont_t=13
I1223 00:14:24.533246 25375 net.cpp:380] cont_t=13_encode4_cont_slice_12_split -> cont_t=13_encode4_cont_slice_12_split_0
I1223 00:14:24.533252 25375 net.cpp:380] cont_t=13_encode4_cont_slice_12_split -> cont_t=13_encode4_cont_slice_12_split_1
I1223 00:14:24.533288 25375 net.cpp:122] Setting up cont_t=13_encode4_cont_slice_12_split
I1223 00:14:24.533309 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533313 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533316 25375 net.cpp:137] Memory required for data: 17105128
I1223 00:14:24.533319 25375 layer_factory.hpp:77] Creating layer cont_t=14_encode4_cont_slice_13_split
I1223 00:14:24.533325 25375 net.cpp:84] Creating Layer cont_t=14_encode4_cont_slice_13_split
I1223 00:14:24.533329 25375 net.cpp:406] cont_t=14_encode4_cont_slice_13_split <- cont_t=14
I1223 00:14:24.533347 25375 net.cpp:380] cont_t=14_encode4_cont_slice_13_split -> cont_t=14_encode4_cont_slice_13_split_0
I1223 00:14:24.533354 25375 net.cpp:380] cont_t=14_encode4_cont_slice_13_split -> cont_t=14_encode4_cont_slice_13_split_1
I1223 00:14:24.533394 25375 net.cpp:122] Setting up cont_t=14_encode4_cont_slice_13_split
I1223 00:14:24.533416 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533419 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533422 25375 net.cpp:137] Memory required for data: 17105136
I1223 00:14:24.533424 25375 layer_factory.hpp:77] Creating layer cont_t=15_encode4_cont_slice_14_split
I1223 00:14:24.533429 25375 net.cpp:84] Creating Layer cont_t=15_encode4_cont_slice_14_split
I1223 00:14:24.533433 25375 net.cpp:406] cont_t=15_encode4_cont_slice_14_split <- cont_t=15
I1223 00:14:24.533438 25375 net.cpp:380] cont_t=15_encode4_cont_slice_14_split -> cont_t=15_encode4_cont_slice_14_split_0
I1223 00:14:24.533457 25375 net.cpp:380] cont_t=15_encode4_cont_slice_14_split -> cont_t=15_encode4_cont_slice_14_split_1
I1223 00:14:24.533495 25375 net.cpp:122] Setting up cont_t=15_encode4_cont_slice_14_split
I1223 00:14:24.533516 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533520 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533522 25375 net.cpp:137] Memory required for data: 17105144
I1223 00:14:24.533525 25375 layer_factory.hpp:77] Creating layer cont_t=16_encode4_cont_slice_15_split
I1223 00:14:24.533530 25375 net.cpp:84] Creating Layer cont_t=16_encode4_cont_slice_15_split
I1223 00:14:24.533534 25375 net.cpp:406] cont_t=16_encode4_cont_slice_15_split <- cont_t=16
I1223 00:14:24.533540 25375 net.cpp:380] cont_t=16_encode4_cont_slice_15_split -> cont_t=16_encode4_cont_slice_15_split_0
I1223 00:14:24.533560 25375 net.cpp:380] cont_t=16_encode4_cont_slice_15_split -> cont_t=16_encode4_cont_slice_15_split_1
I1223 00:14:24.533597 25375 net.cpp:122] Setting up cont_t=16_encode4_cont_slice_15_split
I1223 00:14:24.533604 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533608 25375 net.cpp:129] Top shape: 1 1 (1)
I1223 00:14:24.533624 25375 net.cpp:137] Memory required for data: 17105152
I1223 00:14:24.533627 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_c0
I1223 00:14:24.533632 25375 net.cpp:84] Creating Layer encode4_dummy_forward_c0
I1223 00:14:24.533637 25375 net.cpp:406] encode4_dummy_forward_c0 <- c_t=0
I1223 00:14:24.533641 25375 net.cpp:367] encode4_dummy_forward_c0 -> c_t=0 (in-place)
I1223 00:14:24.533677 25375 net.cpp:122] Setting up encode4_dummy_forward_c0
I1223 00:14:24.533684 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.533687 25375 net.cpp:137] Memory required for data: 17236224
I1223 00:14:24.533694 25375 layer_factory.hpp:77] Creating layer c_t=0_encode4_dummy_forward_c0_0_split
I1223 00:14:24.533701 25375 net.cpp:84] Creating Layer c_t=0_encode4_dummy_forward_c0_0_split
I1223 00:14:24.533704 25375 net.cpp:406] c_t=0_encode4_dummy_forward_c0_0_split <- c_t=0
I1223 00:14:24.533710 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_0
I1223 00:14:24.533717 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_1
I1223 00:14:24.533723 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_2
I1223 00:14:24.533730 25375 net.cpp:380] c_t=0_encode4_dummy_forward_c0_0_split -> c_t=0_encode4_dummy_forward_c0_0_split_3
I1223 00:14:24.533814 25375 net.cpp:122] Setting up c_t=0_encode4_dummy_forward_c0_0_split
I1223 00:14:24.533823 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.533828 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.533831 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.533835 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.533838 25375 net.cpp:137] Memory required for data: 17760512
I1223 00:14:24.533841 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_h0
I1223 00:14:24.533845 25375 net.cpp:84] Creating Layer encode4_dummy_forward_h0
I1223 00:14:24.533849 25375 net.cpp:406] encode4_dummy_forward_h0 <- h_t=0
I1223 00:14:24.533856 25375 net.cpp:367] encode4_dummy_forward_h0 -> h_t=0 (in-place)
I1223 00:14:24.533893 25375 net.cpp:122] Setting up encode4_dummy_forward_h0
I1223 00:14:24.533901 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.533905 25375 net.cpp:137] Memory required for data: 17891584
I1223 00:14:24.533910 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=0
I1223 00:14:24.533915 25375 net.cpp:84] Creating Layer encode4_h_conted_t=0
I1223 00:14:24.533918 25375 net.cpp:406] encode4_h_conted_t=0 <- h_t=0
I1223 00:14:24.533923 25375 net.cpp:406] encode4_h_conted_t=0 <- cont_t=1_encode4_cont_slice_0_split_0
I1223 00:14:24.533931 25375 net.cpp:380] encode4_h_conted_t=0 -> h_conted_t=0
I1223 00:14:24.534032 25375 net.cpp:122] Setting up encode4_h_conted_t=0
I1223 00:14:24.534040 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.534044 25375 net.cpp:137] Memory required for data: 18022656
I1223 00:14:24.534047 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->0
I1223 00:14:24.534056 25375 net.cpp:84] Creating Layer encode4_hidden->transform->0
I1223 00:14:24.534061 25375 net.cpp:406] encode4_hidden->transform->0 <- h_conted_t=0
I1223 00:14:24.534068 25375 net.cpp:380] encode4_hidden->transform->0 -> hidden->transform->0
I1223 00:14:24.534600 25375 net.cpp:122] Setting up encode4_hidden->transform->0
I1223 00:14:24.534610 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.534612 25375 net.cpp:137] Memory required for data: 18546944
I1223 00:14:24.534620 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=0
I1223 00:14:24.534627 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=0
I1223 00:14:24.534631 25375 net.cpp:406] encode4_hadamard->input_t=0 <- c_t=0_encode4_dummy_forward_c0_0_split_0
I1223 00:14:24.534637 25375 net.cpp:380] encode4_hadamard->input_t=0 -> hadamard_in_t=1
I1223 00:14:24.534752 25375 net.cpp:122] Setting up encode4_hadamard->input_t=0
I1223 00:14:24.534761 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.534765 25375 net.cpp:137] Memory required for data: 18678016
I1223 00:14:24.534770 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=0
I1223 00:14:24.534790 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=0
I1223 00:14:24.534796 25375 net.cpp:406] encode4_hadamard->forget_t=0 <- c_t=0_encode4_dummy_forward_c0_0_split_1
I1223 00:14:24.534801 25375 net.cpp:380] encode4_hadamard->forget_t=0 -> hadamard_fog_t=1
I1223 00:14:24.534916 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=0
I1223 00:14:24.534925 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.534929 25375 net.cpp:137] Memory required for data: 18809088
I1223 00:14:24.534934 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=0
I1223 00:14:24.534939 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=0
I1223 00:14:24.534956 25375 net.cpp:406] encode4_hadamard->output_t=0 <- c_t=0_encode4_dummy_forward_c0_0_split_2
I1223 00:14:24.534965 25375 net.cpp:380] encode4_hadamard->output_t=0 -> hadamard_out_t=1
I1223 00:14:24.535073 25375 net.cpp:122] Setting up encode4_hadamard->output_t=0
I1223 00:14:24.535080 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535084 25375 net.cpp:137] Memory required for data: 18940160
I1223 00:14:24.535089 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=1
I1223 00:14:24.535094 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=1
I1223 00:14:24.535117 25375 net.cpp:380] encode4_hadamard_gat_t=1 -> hadamard_gat_t=1
I1223 00:14:24.535188 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=1
I1223 00:14:24.535197 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535199 25375 net.cpp:137] Memory required for data: 19071232
I1223 00:14:24.535202 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=1
I1223 00:14:24.535209 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=1
I1223 00:14:24.535229 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_in_t=1
I1223 00:14:24.535234 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_fog_t=1
I1223 00:14:24.535238 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_out_t=1
I1223 00:14:24.535243 25375 net.cpp:406] encode4_concat_hadamard_t=1 <- hadamard_gat_t=1
I1223 00:14:24.535248 25375 net.cpp:380] encode4_concat_hadamard_t=1 -> hadamard_t=1
I1223 00:14:24.535290 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=1
I1223 00:14:24.535297 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.535300 25375 net.cpp:137] Memory required for data: 19595520
I1223 00:14:24.535303 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_1
I1223 00:14:24.535310 25375 net.cpp:84] Creating Layer encode4_gate_input_1
I1223 00:14:24.535313 25375 net.cpp:406] encode4_gate_input_1 <- hidden->transform->0
I1223 00:14:24.535317 25375 net.cpp:406] encode4_gate_input_1 <- x->transform->t=1
I1223 00:14:24.535321 25375 net.cpp:406] encode4_gate_input_1 <- hadamard_t=1
I1223 00:14:24.535346 25375 net.cpp:380] encode4_gate_input_1 -> gate_input_1
I1223 00:14:24.535385 25375 net.cpp:122] Setting up encode4_gate_input_1
I1223 00:14:24.535393 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.535396 25375 net.cpp:137] Memory required for data: 20119808
I1223 00:14:24.535399 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=1
I1223 00:14:24.535423 25375 net.cpp:84] Creating Layer encode4_unit_t=1
I1223 00:14:24.535426 25375 net.cpp:406] encode4_unit_t=1 <- c_t=0_encode4_dummy_forward_c0_0_split_3
I1223 00:14:24.535444 25375 net.cpp:406] encode4_unit_t=1 <- gate_input_1
I1223 00:14:24.535449 25375 net.cpp:406] encode4_unit_t=1 <- cont_t=1_encode4_cont_slice_0_split_1
I1223 00:14:24.535454 25375 net.cpp:380] encode4_unit_t=1 -> c_t=1
I1223 00:14:24.535461 25375 net.cpp:380] encode4_unit_t=1 -> h_t=1
I1223 00:14:24.535542 25375 net.cpp:122] Setting up encode4_unit_t=1
I1223 00:14:24.535549 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535554 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535557 25375 net.cpp:137] Memory required for data: 20381952
I1223 00:14:24.535559 25375 layer_factory.hpp:77] Creating layer c_t=1_encode4_unit_t=1_0_split
I1223 00:14:24.535579 25375 net.cpp:84] Creating Layer c_t=1_encode4_unit_t=1_0_split
I1223 00:14:24.535583 25375 net.cpp:406] c_t=1_encode4_unit_t=1_0_split <- c_t=1
I1223 00:14:24.535589 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_0
I1223 00:14:24.535614 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_1
I1223 00:14:24.535620 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_2
I1223 00:14:24.535627 25375 net.cpp:380] c_t=1_encode4_unit_t=1_0_split -> c_t=1_encode4_unit_t=1_0_split_3
I1223 00:14:24.535692 25375 net.cpp:122] Setting up c_t=1_encode4_unit_t=1_0_split
I1223 00:14:24.535701 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535706 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535722 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535725 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535728 25375 net.cpp:137] Memory required for data: 20906240
I1223 00:14:24.535745 25375 layer_factory.hpp:77] Creating layer h_t=1_encode4_unit_t=1_1_split
I1223 00:14:24.535750 25375 net.cpp:84] Creating Layer h_t=1_encode4_unit_t=1_1_split
I1223 00:14:24.535768 25375 net.cpp:406] h_t=1_encode4_unit_t=1_1_split <- h_t=1
I1223 00:14:24.535773 25375 net.cpp:380] h_t=1_encode4_unit_t=1_1_split -> h_t=1_encode4_unit_t=1_1_split_0
I1223 00:14:24.535781 25375 net.cpp:380] h_t=1_encode4_unit_t=1_1_split -> h_t=1_encode4_unit_t=1_1_split_1
I1223 00:14:24.535820 25375 net.cpp:122] Setting up h_t=1_encode4_unit_t=1_1_split
I1223 00:14:24.535840 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535845 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535846 25375 net.cpp:137] Memory required for data: 21168384
I1223 00:14:24.535850 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=1
I1223 00:14:24.535871 25375 net.cpp:84] Creating Layer encode4_h_conted_t=1
I1223 00:14:24.535876 25375 net.cpp:406] encode4_h_conted_t=1 <- h_t=1_encode4_unit_t=1_1_split_0
I1223 00:14:24.535879 25375 net.cpp:406] encode4_h_conted_t=1 <- cont_t=2_encode4_cont_slice_1_split_0
I1223 00:14:24.535884 25375 net.cpp:380] encode4_h_conted_t=1 -> h_conted_t=1
I1223 00:14:24.535979 25375 net.cpp:122] Setting up encode4_h_conted_t=1
I1223 00:14:24.535989 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.535991 25375 net.cpp:137] Memory required for data: 21299456
I1223 00:14:24.535995 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->1
I1223 00:14:24.536017 25375 net.cpp:84] Creating Layer encode4_hidden->transform->1
I1223 00:14:24.536022 25375 net.cpp:406] encode4_hidden->transform->1 <- h_conted_t=1
I1223 00:14:24.536029 25375 net.cpp:380] encode4_hidden->transform->1 -> hidden->transform->1
I1223 00:14:24.536552 25375 net.cpp:122] Setting up encode4_hidden->transform->1
I1223 00:14:24.536561 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.536566 25375 net.cpp:137] Memory required for data: 21823744
I1223 00:14:24.536571 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.536590 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.536593 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=1
I1223 00:14:24.536599 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=1
I1223 00:14:24.536604 25375 net.cpp:406] encode4_hadamard->input_t=1 <- c_t=1_encode4_unit_t=1_0_split_0
I1223 00:14:24.536610 25375 net.cpp:380] encode4_hadamard->input_t=1 -> hadamard_in_t=2
I1223 00:14:24.536737 25375 net.cpp:122] Setting up encode4_hadamard->input_t=1
I1223 00:14:24.536746 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.536751 25375 net.cpp:137] Memory required for data: 21954816
I1223 00:14:24.536754 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.536757 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=1
I1223 00:14:24.536778 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=1
I1223 00:14:24.536782 25375 net.cpp:406] encode4_hadamard->forget_t=1 <- c_t=1_encode4_unit_t=1_0_split_1
I1223 00:14:24.536803 25375 net.cpp:380] encode4_hadamard->forget_t=1 -> hadamard_fog_t=2
I1223 00:14:24.536917 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=1
I1223 00:14:24.536926 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.536929 25375 net.cpp:137] Memory required for data: 22085888
I1223 00:14:24.536932 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.536936 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=1
I1223 00:14:24.536943 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=1
I1223 00:14:24.536960 25375 net.cpp:406] encode4_hadamard->output_t=1 <- c_t=1_encode4_unit_t=1_0_split_2
I1223 00:14:24.536965 25375 net.cpp:380] encode4_hadamard->output_t=1 -> hadamard_out_t=2
I1223 00:14:24.537081 25375 net.cpp:122] Setting up encode4_hadamard->output_t=1
I1223 00:14:24.537089 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537092 25375 net.cpp:137] Memory required for data: 22216960
I1223 00:14:24.537109 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.537112 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=2
I1223 00:14:24.537120 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=2
I1223 00:14:24.537125 25375 net.cpp:380] encode4_hadamard_gat_t=2 -> hadamard_gat_t=2
I1223 00:14:24.537181 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=2
I1223 00:14:24.537189 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537194 25375 net.cpp:137] Memory required for data: 22348032
I1223 00:14:24.537196 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=2
I1223 00:14:24.537204 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=2
I1223 00:14:24.537220 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_in_t=2
I1223 00:14:24.537225 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_fog_t=2
I1223 00:14:24.537242 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_out_t=2
I1223 00:14:24.537246 25375 net.cpp:406] encode4_concat_hadamard_t=2 <- hadamard_gat_t=2
I1223 00:14:24.537251 25375 net.cpp:380] encode4_concat_hadamard_t=2 -> hadamard_t=2
I1223 00:14:24.537279 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=2
I1223 00:14:24.537287 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.537291 25375 net.cpp:137] Memory required for data: 22872320
I1223 00:14:24.537293 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_2
I1223 00:14:24.537302 25375 net.cpp:84] Creating Layer encode4_gate_input_2
I1223 00:14:24.537305 25375 net.cpp:406] encode4_gate_input_2 <- hidden->transform->1
I1223 00:14:24.537309 25375 net.cpp:406] encode4_gate_input_2 <- x->transform->t=2
I1223 00:14:24.537314 25375 net.cpp:406] encode4_gate_input_2 <- hadamard_t=2
I1223 00:14:24.537319 25375 net.cpp:380] encode4_gate_input_2 -> gate_input_2
I1223 00:14:24.537349 25375 net.cpp:122] Setting up encode4_gate_input_2
I1223 00:14:24.537358 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.537360 25375 net.cpp:137] Memory required for data: 23396608
I1223 00:14:24.537376 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=2
I1223 00:14:24.537384 25375 net.cpp:84] Creating Layer encode4_unit_t=2
I1223 00:14:24.537387 25375 net.cpp:406] encode4_unit_t=2 <- c_t=1_encode4_unit_t=1_0_split_3
I1223 00:14:24.537391 25375 net.cpp:406] encode4_unit_t=2 <- gate_input_2
I1223 00:14:24.537396 25375 net.cpp:406] encode4_unit_t=2 <- cont_t=2_encode4_cont_slice_1_split_1
I1223 00:14:24.537401 25375 net.cpp:380] encode4_unit_t=2 -> c_t=2
I1223 00:14:24.537421 25375 net.cpp:380] encode4_unit_t=2 -> h_t=2
I1223 00:14:24.537490 25375 net.cpp:122] Setting up encode4_unit_t=2
I1223 00:14:24.537498 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537503 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537505 25375 net.cpp:137] Memory required for data: 23658752
I1223 00:14:24.537508 25375 layer_factory.hpp:77] Creating layer c_t=2_encode4_unit_t=2_0_split
I1223 00:14:24.537528 25375 net.cpp:84] Creating Layer c_t=2_encode4_unit_t=2_0_split
I1223 00:14:24.537531 25375 net.cpp:406] c_t=2_encode4_unit_t=2_0_split <- c_t=2
I1223 00:14:24.537539 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_0
I1223 00:14:24.537545 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_1
I1223 00:14:24.537551 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_2
I1223 00:14:24.537559 25375 net.cpp:380] c_t=2_encode4_unit_t=2_0_split -> c_t=2_encode4_unit_t=2_0_split_3
I1223 00:14:24.537638 25375 net.cpp:122] Setting up c_t=2_encode4_unit_t=2_0_split
I1223 00:14:24.537647 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537652 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537654 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537658 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537662 25375 net.cpp:137] Memory required for data: 24183040
I1223 00:14:24.537664 25375 layer_factory.hpp:77] Creating layer h_t=2_encode4_unit_t=2_1_split
I1223 00:14:24.537683 25375 net.cpp:84] Creating Layer h_t=2_encode4_unit_t=2_1_split
I1223 00:14:24.537685 25375 net.cpp:406] h_t=2_encode4_unit_t=2_1_split <- h_t=2
I1223 00:14:24.537691 25375 net.cpp:380] h_t=2_encode4_unit_t=2_1_split -> h_t=2_encode4_unit_t=2_1_split_0
I1223 00:14:24.537698 25375 net.cpp:380] h_t=2_encode4_unit_t=2_1_split -> h_t=2_encode4_unit_t=2_1_split_1
I1223 00:14:24.537750 25375 net.cpp:122] Setting up h_t=2_encode4_unit_t=2_1_split
I1223 00:14:24.537758 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537762 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537765 25375 net.cpp:137] Memory required for data: 24445184
I1223 00:14:24.537768 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=2
I1223 00:14:24.537788 25375 net.cpp:84] Creating Layer encode4_h_conted_t=2
I1223 00:14:24.537792 25375 net.cpp:406] encode4_h_conted_t=2 <- h_t=2_encode4_unit_t=2_1_split_0
I1223 00:14:24.537796 25375 net.cpp:406] encode4_h_conted_t=2 <- cont_t=3_encode4_cont_slice_2_split_0
I1223 00:14:24.537802 25375 net.cpp:380] encode4_h_conted_t=2 -> h_conted_t=2
I1223 00:14:24.537899 25375 net.cpp:122] Setting up encode4_h_conted_t=2
I1223 00:14:24.537907 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.537911 25375 net.cpp:137] Memory required for data: 24576256
I1223 00:14:24.537914 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->2
I1223 00:14:24.537923 25375 net.cpp:84] Creating Layer encode4_hidden->transform->2
I1223 00:14:24.537928 25375 net.cpp:406] encode4_hidden->transform->2 <- h_conted_t=2
I1223 00:14:24.537950 25375 net.cpp:380] encode4_hidden->transform->2 -> hidden->transform->2
I1223 00:14:24.538468 25375 net.cpp:122] Setting up encode4_hidden->transform->2
I1223 00:14:24.538477 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.538481 25375 net.cpp:137] Memory required for data: 25100544
I1223 00:14:24.538486 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.538489 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.538492 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=2
I1223 00:14:24.538499 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=2
I1223 00:14:24.538503 25375 net.cpp:406] encode4_hadamard->input_t=2 <- c_t=2_encode4_unit_t=2_0_split_0
I1223 00:14:24.538511 25375 net.cpp:380] encode4_hadamard->input_t=2 -> hadamard_in_t=3
I1223 00:14:24.538637 25375 net.cpp:122] Setting up encode4_hadamard->input_t=2
I1223 00:14:24.538645 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.538650 25375 net.cpp:137] Memory required for data: 25231616
I1223 00:14:24.538652 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.538655 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=2
I1223 00:14:24.538676 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=2
I1223 00:14:24.538679 25375 net.cpp:406] encode4_hadamard->forget_t=2 <- c_t=2_encode4_unit_t=2_0_split_1
I1223 00:14:24.538686 25375 net.cpp:380] encode4_hadamard->forget_t=2 -> hadamard_fog_t=3
I1223 00:14:24.538822 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=2
I1223 00:14:24.538830 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.538835 25375 net.cpp:137] Memory required for data: 25362688
I1223 00:14:24.538839 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.538842 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=2
I1223 00:14:24.538862 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=2
I1223 00:14:24.538866 25375 net.cpp:406] encode4_hadamard->output_t=2 <- c_t=2_encode4_unit_t=2_0_split_2
I1223 00:14:24.538872 25375 net.cpp:380] encode4_hadamard->output_t=2 -> hadamard_out_t=3
I1223 00:14:24.538981 25375 net.cpp:122] Setting up encode4_hadamard->output_t=2
I1223 00:14:24.538990 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.538992 25375 net.cpp:137] Memory required for data: 25493760
I1223 00:14:24.538996 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.539000 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=3
I1223 00:14:24.539019 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=3
I1223 00:14:24.539024 25375 net.cpp:380] encode4_hadamard_gat_t=3 -> hadamard_gat_t=3
I1223 00:14:24.539090 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=3
I1223 00:14:24.539098 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539101 25375 net.cpp:137] Memory required for data: 25624832
I1223 00:14:24.539105 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=3
I1223 00:14:24.539124 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=3
I1223 00:14:24.539129 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_in_t=3
I1223 00:14:24.539132 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_fog_t=3
I1223 00:14:24.539137 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_out_t=3
I1223 00:14:24.539141 25375 net.cpp:406] encode4_concat_hadamard_t=3 <- hadamard_gat_t=3
I1223 00:14:24.539146 25375 net.cpp:380] encode4_concat_hadamard_t=3 -> hadamard_t=3
I1223 00:14:24.539175 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=3
I1223 00:14:24.539183 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.539186 25375 net.cpp:137] Memory required for data: 26149120
I1223 00:14:24.539189 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_3
I1223 00:14:24.539194 25375 net.cpp:84] Creating Layer encode4_gate_input_3
I1223 00:14:24.539199 25375 net.cpp:406] encode4_gate_input_3 <- hidden->transform->2
I1223 00:14:24.539204 25375 net.cpp:406] encode4_gate_input_3 <- x->transform->t=3
I1223 00:14:24.539209 25375 net.cpp:406] encode4_gate_input_3 <- hadamard_t=3
I1223 00:14:24.539214 25375 net.cpp:380] encode4_gate_input_3 -> gate_input_3
I1223 00:14:24.539242 25375 net.cpp:122] Setting up encode4_gate_input_3
I1223 00:14:24.539249 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.539253 25375 net.cpp:137] Memory required for data: 26673408
I1223 00:14:24.539255 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=3
I1223 00:14:24.539261 25375 net.cpp:84] Creating Layer encode4_unit_t=3
I1223 00:14:24.539265 25375 net.cpp:406] encode4_unit_t=3 <- c_t=2_encode4_unit_t=2_0_split_3
I1223 00:14:24.539269 25375 net.cpp:406] encode4_unit_t=3 <- gate_input_3
I1223 00:14:24.539273 25375 net.cpp:406] encode4_unit_t=3 <- cont_t=3_encode4_cont_slice_2_split_1
I1223 00:14:24.539279 25375 net.cpp:380] encode4_unit_t=3 -> c_t=3
I1223 00:14:24.539285 25375 net.cpp:380] encode4_unit_t=3 -> h_t=3
I1223 00:14:24.539352 25375 net.cpp:122] Setting up encode4_unit_t=3
I1223 00:14:24.539361 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539366 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539381 25375 net.cpp:137] Memory required for data: 26935552
I1223 00:14:24.539383 25375 layer_factory.hpp:77] Creating layer c_t=3_encode4_unit_t=3_0_split
I1223 00:14:24.539393 25375 net.cpp:84] Creating Layer c_t=3_encode4_unit_t=3_0_split
I1223 00:14:24.539398 25375 net.cpp:406] c_t=3_encode4_unit_t=3_0_split <- c_t=3
I1223 00:14:24.539405 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_0
I1223 00:14:24.539413 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_1
I1223 00:14:24.539420 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_2
I1223 00:14:24.539427 25375 net.cpp:380] c_t=3_encode4_unit_t=3_0_split -> c_t=3_encode4_unit_t=3_0_split_3
I1223 00:14:24.539507 25375 net.cpp:122] Setting up c_t=3_encode4_unit_t=3_0_split
I1223 00:14:24.539515 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539520 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539537 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539541 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539544 25375 net.cpp:137] Memory required for data: 27459840
I1223 00:14:24.539547 25375 layer_factory.hpp:77] Creating layer h_t=3_encode4_unit_t=3_1_split
I1223 00:14:24.539552 25375 net.cpp:84] Creating Layer h_t=3_encode4_unit_t=3_1_split
I1223 00:14:24.539556 25375 net.cpp:406] h_t=3_encode4_unit_t=3_1_split <- h_t=3
I1223 00:14:24.539562 25375 net.cpp:380] h_t=3_encode4_unit_t=3_1_split -> h_t=3_encode4_unit_t=3_1_split_0
I1223 00:14:24.539569 25375 net.cpp:380] h_t=3_encode4_unit_t=3_1_split -> h_t=3_encode4_unit_t=3_1_split_1
I1223 00:14:24.539608 25375 net.cpp:122] Setting up h_t=3_encode4_unit_t=3_1_split
I1223 00:14:24.539615 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539619 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539623 25375 net.cpp:137] Memory required for data: 27721984
I1223 00:14:24.539625 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=3
I1223 00:14:24.539633 25375 net.cpp:84] Creating Layer encode4_h_conted_t=3
I1223 00:14:24.539636 25375 net.cpp:406] encode4_h_conted_t=3 <- h_t=3_encode4_unit_t=3_1_split_0
I1223 00:14:24.539640 25375 net.cpp:406] encode4_h_conted_t=3 <- cont_t=4_encode4_cont_slice_3_split_0
I1223 00:14:24.539646 25375 net.cpp:380] encode4_h_conted_t=3 -> h_conted_t=3
I1223 00:14:24.539744 25375 net.cpp:122] Setting up encode4_h_conted_t=3
I1223 00:14:24.539752 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.539755 25375 net.cpp:137] Memory required for data: 27853056
I1223 00:14:24.539758 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->3
I1223 00:14:24.539767 25375 net.cpp:84] Creating Layer encode4_hidden->transform->3
I1223 00:14:24.539772 25375 net.cpp:406] encode4_hidden->transform->3 <- h_conted_t=3
I1223 00:14:24.539793 25375 net.cpp:380] encode4_hidden->transform->3 -> hidden->transform->3
I1223 00:14:24.540329 25375 net.cpp:122] Setting up encode4_hidden->transform->3
I1223 00:14:24.540339 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.540343 25375 net.cpp:137] Memory required for data: 28377344
I1223 00:14:24.540346 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.540350 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.540354 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=3
I1223 00:14:24.540359 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=3
I1223 00:14:24.540364 25375 net.cpp:406] encode4_hadamard->input_t=3 <- c_t=3_encode4_unit_t=3_0_split_0
I1223 00:14:24.540369 25375 net.cpp:380] encode4_hadamard->input_t=3 -> hadamard_in_t=4
I1223 00:14:24.540496 25375 net.cpp:122] Setting up encode4_hadamard->input_t=3
I1223 00:14:24.540504 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.540508 25375 net.cpp:137] Memory required for data: 28508416
I1223 00:14:24.540511 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.540514 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=3
I1223 00:14:24.540534 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=3
I1223 00:14:24.540539 25375 net.cpp:406] encode4_hadamard->forget_t=3 <- c_t=3_encode4_unit_t=3_0_split_1
I1223 00:14:24.540560 25375 net.cpp:380] encode4_hadamard->forget_t=3 -> hadamard_fog_t=4
I1223 00:14:24.540681 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=3
I1223 00:14:24.540689 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.540693 25375 net.cpp:137] Memory required for data: 28639488
I1223 00:14:24.540697 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.540700 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=3
I1223 00:14:24.540720 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=3
I1223 00:14:24.540724 25375 net.cpp:406] encode4_hadamard->output_t=3 <- c_t=3_encode4_unit_t=3_0_split_2
I1223 00:14:24.540729 25375 net.cpp:380] encode4_hadamard->output_t=3 -> hadamard_out_t=4
I1223 00:14:24.540840 25375 net.cpp:122] Setting up encode4_hadamard->output_t=3
I1223 00:14:24.540849 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.540853 25375 net.cpp:137] Memory required for data: 28770560
I1223 00:14:24.540856 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.540874 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=4
I1223 00:14:24.540880 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=4
I1223 00:14:24.540885 25375 net.cpp:380] encode4_hadamard_gat_t=4 -> hadamard_gat_t=4
I1223 00:14:24.540961 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=4
I1223 00:14:24.540969 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.540972 25375 net.cpp:137] Memory required for data: 28901632
I1223 00:14:24.540976 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=4
I1223 00:14:24.540982 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=4
I1223 00:14:24.540985 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_in_t=4
I1223 00:14:24.540989 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_fog_t=4
I1223 00:14:24.540994 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_out_t=4
I1223 00:14:24.540998 25375 net.cpp:406] encode4_concat_hadamard_t=4 <- hadamard_gat_t=4
I1223 00:14:24.541003 25375 net.cpp:380] encode4_concat_hadamard_t=4 -> hadamard_t=4
I1223 00:14:24.541031 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=4
I1223 00:14:24.541039 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.541043 25375 net.cpp:137] Memory required for data: 29425920
I1223 00:14:24.541045 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_4
I1223 00:14:24.541074 25375 net.cpp:84] Creating Layer encode4_gate_input_4
I1223 00:14:24.541080 25375 net.cpp:406] encode4_gate_input_4 <- hidden->transform->3
I1223 00:14:24.541086 25375 net.cpp:406] encode4_gate_input_4 <- x->transform->t=4
I1223 00:14:24.541090 25375 net.cpp:406] encode4_gate_input_4 <- hadamard_t=4
I1223 00:14:24.541095 25375 net.cpp:380] encode4_gate_input_4 -> gate_input_4
I1223 00:14:24.541126 25375 net.cpp:122] Setting up encode4_gate_input_4
I1223 00:14:24.541136 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.541138 25375 net.cpp:137] Memory required for data: 29950208
I1223 00:14:24.541142 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=4
I1223 00:14:24.541147 25375 net.cpp:84] Creating Layer encode4_unit_t=4
I1223 00:14:24.541152 25375 net.cpp:406] encode4_unit_t=4 <- c_t=3_encode4_unit_t=3_0_split_3
I1223 00:14:24.541155 25375 net.cpp:406] encode4_unit_t=4 <- gate_input_4
I1223 00:14:24.541159 25375 net.cpp:406] encode4_unit_t=4 <- cont_t=4_encode4_cont_slice_3_split_1
I1223 00:14:24.541163 25375 net.cpp:380] encode4_unit_t=4 -> c_t=4
I1223 00:14:24.541170 25375 net.cpp:380] encode4_unit_t=4 -> h_t=4
I1223 00:14:24.541239 25375 net.cpp:122] Setting up encode4_unit_t=4
I1223 00:14:24.541247 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541251 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541254 25375 net.cpp:137] Memory required for data: 30212352
I1223 00:14:24.541257 25375 layer_factory.hpp:77] Creating layer c_t=4_encode4_unit_t=4_0_split
I1223 00:14:24.541263 25375 net.cpp:84] Creating Layer c_t=4_encode4_unit_t=4_0_split
I1223 00:14:24.541280 25375 net.cpp:406] c_t=4_encode4_unit_t=4_0_split <- c_t=4
I1223 00:14:24.541285 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_0
I1223 00:14:24.541292 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_1
I1223 00:14:24.541301 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_2
I1223 00:14:24.541308 25375 net.cpp:380] c_t=4_encode4_unit_t=4_0_split -> c_t=4_encode4_unit_t=4_0_split_3
I1223 00:14:24.541378 25375 net.cpp:122] Setting up c_t=4_encode4_unit_t=4_0_split
I1223 00:14:24.541400 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541404 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541409 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541412 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541415 25375 net.cpp:137] Memory required for data: 30736640
I1223 00:14:24.541419 25375 layer_factory.hpp:77] Creating layer h_t=4_encode4_unit_t=4_1_split
I1223 00:14:24.541438 25375 net.cpp:84] Creating Layer h_t=4_encode4_unit_t=4_1_split
I1223 00:14:24.541443 25375 net.cpp:406] h_t=4_encode4_unit_t=4_1_split <- h_t=4
I1223 00:14:24.541448 25375 net.cpp:380] h_t=4_encode4_unit_t=4_1_split -> h_t=4_encode4_unit_t=4_1_split_0
I1223 00:14:24.541455 25375 net.cpp:380] h_t=4_encode4_unit_t=4_1_split -> h_t=4_encode4_unit_t=4_1_split_1
I1223 00:14:24.541507 25375 net.cpp:122] Setting up h_t=4_encode4_unit_t=4_1_split
I1223 00:14:24.541517 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541520 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541523 25375 net.cpp:137] Memory required for data: 30998784
I1223 00:14:24.541527 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=4
I1223 00:14:24.541546 25375 net.cpp:84] Creating Layer encode4_h_conted_t=4
I1223 00:14:24.541550 25375 net.cpp:406] encode4_h_conted_t=4 <- h_t=4_encode4_unit_t=4_1_split_0
I1223 00:14:24.541554 25375 net.cpp:406] encode4_h_conted_t=4 <- cont_t=5_encode4_cont_slice_4_split_0
I1223 00:14:24.541560 25375 net.cpp:380] encode4_h_conted_t=4 -> h_conted_t=4
I1223 00:14:24.541662 25375 net.cpp:122] Setting up encode4_h_conted_t=4
I1223 00:14:24.541671 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.541674 25375 net.cpp:137] Memory required for data: 31129856
I1223 00:14:24.541677 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->4
I1223 00:14:24.541700 25375 net.cpp:84] Creating Layer encode4_hidden->transform->4
I1223 00:14:24.541705 25375 net.cpp:406] encode4_hidden->transform->4 <- h_conted_t=4
I1223 00:14:24.541712 25375 net.cpp:380] encode4_hidden->transform->4 -> hidden->transform->4
I1223 00:14:24.542279 25375 net.cpp:122] Setting up encode4_hidden->transform->4
I1223 00:14:24.542289 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.542292 25375 net.cpp:137] Memory required for data: 31654144
I1223 00:14:24.542295 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.542299 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.542304 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=4
I1223 00:14:24.542309 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=4
I1223 00:14:24.542312 25375 net.cpp:406] encode4_hadamard->input_t=4 <- c_t=4_encode4_unit_t=4_0_split_0
I1223 00:14:24.542320 25375 net.cpp:380] encode4_hadamard->input_t=4 -> hadamard_in_t=5
I1223 00:14:24.542450 25375 net.cpp:122] Setting up encode4_hadamard->input_t=4
I1223 00:14:24.542460 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.542464 25375 net.cpp:137] Memory required for data: 31785216
I1223 00:14:24.542467 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.542471 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=4
I1223 00:14:24.542490 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=4
I1223 00:14:24.542493 25375 net.cpp:406] encode4_hadamard->forget_t=4 <- c_t=4_encode4_unit_t=4_0_split_1
I1223 00:14:24.542513 25375 net.cpp:380] encode4_hadamard->forget_t=4 -> hadamard_fog_t=5
I1223 00:14:24.542637 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=4
I1223 00:14:24.542647 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.542650 25375 net.cpp:137] Memory required for data: 31916288
I1223 00:14:24.542654 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.542671 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=4
I1223 00:14:24.542676 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=4
I1223 00:14:24.542680 25375 net.cpp:406] encode4_hadamard->output_t=4 <- c_t=4_encode4_unit_t=4_0_split_2
I1223 00:14:24.542686 25375 net.cpp:380] encode4_hadamard->output_t=4 -> hadamard_out_t=5
I1223 00:14:24.542798 25375 net.cpp:122] Setting up encode4_hadamard->output_t=4
I1223 00:14:24.542807 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.542810 25375 net.cpp:137] Memory required for data: 32047360
I1223 00:14:24.542827 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.542831 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=5
I1223 00:14:24.542837 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=5
I1223 00:14:24.542841 25375 net.cpp:380] encode4_hadamard_gat_t=5 -> hadamard_gat_t=5
I1223 00:14:24.542913 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=5
I1223 00:14:24.542922 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.542925 25375 net.cpp:137] Memory required for data: 32178432
I1223 00:14:24.542928 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=5
I1223 00:14:24.542934 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=5
I1223 00:14:24.542938 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_in_t=5
I1223 00:14:24.542943 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_fog_t=5
I1223 00:14:24.542948 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_out_t=5
I1223 00:14:24.542950 25375 net.cpp:406] encode4_concat_hadamard_t=5 <- hadamard_gat_t=5
I1223 00:14:24.542958 25375 net.cpp:380] encode4_concat_hadamard_t=5 -> hadamard_t=5
I1223 00:14:24.542999 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=5
I1223 00:14:24.543006 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.543009 25375 net.cpp:137] Memory required for data: 32702720
I1223 00:14:24.543014 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_5
I1223 00:14:24.543018 25375 net.cpp:84] Creating Layer encode4_gate_input_5
I1223 00:14:24.543021 25375 net.cpp:406] encode4_gate_input_5 <- hidden->transform->4
I1223 00:14:24.543026 25375 net.cpp:406] encode4_gate_input_5 <- x->transform->t=5
I1223 00:14:24.543030 25375 net.cpp:406] encode4_gate_input_5 <- hadamard_t=5
I1223 00:14:24.543037 25375 net.cpp:380] encode4_gate_input_5 -> gate_input_5
I1223 00:14:24.543062 25375 net.cpp:122] Setting up encode4_gate_input_5
I1223 00:14:24.543072 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.543076 25375 net.cpp:137] Memory required for data: 33227008
I1223 00:14:24.543092 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=5
I1223 00:14:24.543098 25375 net.cpp:84] Creating Layer encode4_unit_t=5
I1223 00:14:24.543115 25375 net.cpp:406] encode4_unit_t=5 <- c_t=4_encode4_unit_t=4_0_split_3
I1223 00:14:24.543120 25375 net.cpp:406] encode4_unit_t=5 <- gate_input_5
I1223 00:14:24.543124 25375 net.cpp:406] encode4_unit_t=5 <- cont_t=5_encode4_cont_slice_4_split_1
I1223 00:14:24.543129 25375 net.cpp:380] encode4_unit_t=5 -> c_t=5
I1223 00:14:24.543135 25375 net.cpp:380] encode4_unit_t=5 -> h_t=5
I1223 00:14:24.543191 25375 net.cpp:122] Setting up encode4_unit_t=5
I1223 00:14:24.543198 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543202 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543205 25375 net.cpp:137] Memory required for data: 33489152
I1223 00:14:24.543208 25375 layer_factory.hpp:77] Creating layer c_t=5_encode4_unit_t=5_0_split
I1223 00:14:24.543213 25375 net.cpp:84] Creating Layer c_t=5_encode4_unit_t=5_0_split
I1223 00:14:24.543217 25375 net.cpp:406] c_t=5_encode4_unit_t=5_0_split <- c_t=5
I1223 00:14:24.543222 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_0
I1223 00:14:24.543229 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_1
I1223 00:14:24.543238 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_2
I1223 00:14:24.543244 25375 net.cpp:380] c_t=5_encode4_unit_t=5_0_split -> c_t=5_encode4_unit_t=5_0_split_3
I1223 00:14:24.543313 25375 net.cpp:122] Setting up c_t=5_encode4_unit_t=5_0_split
I1223 00:14:24.543319 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543323 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543328 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543331 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543334 25375 net.cpp:137] Memory required for data: 34013440
I1223 00:14:24.543336 25375 layer_factory.hpp:77] Creating layer h_t=5_encode4_unit_t=5_1_split
I1223 00:14:24.543344 25375 net.cpp:84] Creating Layer h_t=5_encode4_unit_t=5_1_split
I1223 00:14:24.543346 25375 net.cpp:406] h_t=5_encode4_unit_t=5_1_split <- h_t=5
I1223 00:14:24.543352 25375 net.cpp:380] h_t=5_encode4_unit_t=5_1_split -> h_t=5_encode4_unit_t=5_1_split_0
I1223 00:14:24.543359 25375 net.cpp:380] h_t=5_encode4_unit_t=5_1_split -> h_t=5_encode4_unit_t=5_1_split_1
I1223 00:14:24.543401 25375 net.cpp:122] Setting up h_t=5_encode4_unit_t=5_1_split
I1223 00:14:24.543407 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543411 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543414 25375 net.cpp:137] Memory required for data: 34275584
I1223 00:14:24.543417 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=5
I1223 00:14:24.543422 25375 net.cpp:84] Creating Layer encode4_h_conted_t=5
I1223 00:14:24.543426 25375 net.cpp:406] encode4_h_conted_t=5 <- h_t=5_encode4_unit_t=5_1_split_0
I1223 00:14:24.543431 25375 net.cpp:406] encode4_h_conted_t=5 <- cont_t=6_encode4_cont_slice_5_split_0
I1223 00:14:24.543436 25375 net.cpp:380] encode4_h_conted_t=5 -> h_conted_t=5
I1223 00:14:24.543534 25375 net.cpp:122] Setting up encode4_h_conted_t=5
I1223 00:14:24.543545 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.543547 25375 net.cpp:137] Memory required for data: 34406656
I1223 00:14:24.543550 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->5
I1223 00:14:24.543560 25375 net.cpp:84] Creating Layer encode4_hidden->transform->5
I1223 00:14:24.543565 25375 net.cpp:406] encode4_hidden->transform->5 <- h_conted_t=5
I1223 00:14:24.543572 25375 net.cpp:380] encode4_hidden->transform->5 -> hidden->transform->5
I1223 00:14:24.544145 25375 net.cpp:122] Setting up encode4_hidden->transform->5
I1223 00:14:24.544155 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.544159 25375 net.cpp:137] Memory required for data: 34930944
I1223 00:14:24.544162 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.544167 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.544170 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=5
I1223 00:14:24.544176 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=5
I1223 00:14:24.544179 25375 net.cpp:406] encode4_hadamard->input_t=5 <- c_t=5_encode4_unit_t=5_0_split_0
I1223 00:14:24.544186 25375 net.cpp:380] encode4_hadamard->input_t=5 -> hadamard_in_t=6
I1223 00:14:24.544289 25375 net.cpp:122] Setting up encode4_hadamard->input_t=5
I1223 00:14:24.544297 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.544301 25375 net.cpp:137] Memory required for data: 35062016
I1223 00:14:24.544304 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.544307 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=5
I1223 00:14:24.544315 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=5
I1223 00:14:24.544319 25375 net.cpp:406] encode4_hadamard->forget_t=5 <- c_t=5_encode4_unit_t=5_0_split_1
I1223 00:14:24.544324 25375 net.cpp:380] encode4_hadamard->forget_t=5 -> hadamard_fog_t=6
I1223 00:14:24.544436 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=5
I1223 00:14:24.544446 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.544450 25375 net.cpp:137] Memory required for data: 35193088
I1223 00:14:24.544454 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.544457 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=5
I1223 00:14:24.544462 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=5
I1223 00:14:24.544467 25375 net.cpp:406] encode4_hadamard->output_t=5 <- c_t=5_encode4_unit_t=5_0_split_2
I1223 00:14:24.544474 25375 net.cpp:380] encode4_hadamard->output_t=5 -> hadamard_out_t=6
I1223 00:14:24.544585 25375 net.cpp:122] Setting up encode4_hadamard->output_t=5
I1223 00:14:24.544595 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.544597 25375 net.cpp:137] Memory required for data: 35324160
I1223 00:14:24.544605 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.544622 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=6
I1223 00:14:24.544631 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=6
I1223 00:14:24.544636 25375 net.cpp:380] encode4_hadamard_gat_t=6 -> hadamard_gat_t=6
I1223 00:14:24.544706 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=6
I1223 00:14:24.544715 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.544718 25375 net.cpp:137] Memory required for data: 35455232
I1223 00:14:24.544721 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=6
I1223 00:14:24.544729 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=6
I1223 00:14:24.544747 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_in_t=6
I1223 00:14:24.544752 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_fog_t=6
I1223 00:14:24.544756 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_out_t=6
I1223 00:14:24.544760 25375 net.cpp:406] encode4_concat_hadamard_t=6 <- hadamard_gat_t=6
I1223 00:14:24.544767 25375 net.cpp:380] encode4_concat_hadamard_t=6 -> hadamard_t=6
I1223 00:14:24.544809 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=6
I1223 00:14:24.544817 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.544821 25375 net.cpp:137] Memory required for data: 35979520
I1223 00:14:24.544823 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_6
I1223 00:14:24.544831 25375 net.cpp:84] Creating Layer encode4_gate_input_6
I1223 00:14:24.544836 25375 net.cpp:406] encode4_gate_input_6 <- hidden->transform->5
I1223 00:14:24.544842 25375 net.cpp:406] encode4_gate_input_6 <- x->transform->t=6
I1223 00:14:24.544845 25375 net.cpp:406] encode4_gate_input_6 <- hadamard_t=6
I1223 00:14:24.544852 25375 net.cpp:380] encode4_gate_input_6 -> gate_input_6
I1223 00:14:24.544878 25375 net.cpp:122] Setting up encode4_gate_input_6
I1223 00:14:24.544885 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.544888 25375 net.cpp:137] Memory required for data: 36503808
I1223 00:14:24.544893 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=6
I1223 00:14:24.544899 25375 net.cpp:84] Creating Layer encode4_unit_t=6
I1223 00:14:24.544904 25375 net.cpp:406] encode4_unit_t=6 <- c_t=5_encode4_unit_t=5_0_split_3
I1223 00:14:24.544909 25375 net.cpp:406] encode4_unit_t=6 <- gate_input_6
I1223 00:14:24.544914 25375 net.cpp:406] encode4_unit_t=6 <- cont_t=6_encode4_cont_slice_5_split_1
I1223 00:14:24.544919 25375 net.cpp:380] encode4_unit_t=6 -> c_t=6
I1223 00:14:24.544924 25375 net.cpp:380] encode4_unit_t=6 -> h_t=6
I1223 00:14:24.544981 25375 net.cpp:122] Setting up encode4_unit_t=6
I1223 00:14:24.544988 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.544993 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.544996 25375 net.cpp:137] Memory required for data: 36765952
I1223 00:14:24.544999 25375 layer_factory.hpp:77] Creating layer c_t=6_encode4_unit_t=6_0_split
I1223 00:14:24.545006 25375 net.cpp:84] Creating Layer c_t=6_encode4_unit_t=6_0_split
I1223 00:14:24.545008 25375 net.cpp:406] c_t=6_encode4_unit_t=6_0_split <- c_t=6
I1223 00:14:24.545016 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_0
I1223 00:14:24.545023 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_1
I1223 00:14:24.545033 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_2
I1223 00:14:24.545040 25375 net.cpp:380] c_t=6_encode4_unit_t=6_0_split -> c_t=6_encode4_unit_t=6_0_split_3
I1223 00:14:24.545111 25375 net.cpp:122] Setting up c_t=6_encode4_unit_t=6_0_split
I1223 00:14:24.545120 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.545125 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.545128 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.545132 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.545135 25375 net.cpp:137] Memory required for data: 37290240
I1223 00:14:24.545138 25375 layer_factory.hpp:77] Creating layer h_t=6_encode4_unit_t=6_1_split
I1223 00:14:24.545143 25375 net.cpp:84] Creating Layer h_t=6_encode4_unit_t=6_1_split
I1223 00:14:24.545146 25375 net.cpp:406] h_t=6_encode4_unit_t=6_1_split <- h_t=6
I1223 00:14:24.545151 25375 net.cpp:380] h_t=6_encode4_unit_t=6_1_split -> h_t=6_encode4_unit_t=6_1_split_0
I1223 00:14:24.545158 25375 net.cpp:380] h_t=6_encode4_unit_t=6_1_split -> h_t=6_encode4_unit_t=6_1_split_1
I1223 00:14:24.545199 25375 net.cpp:122] Setting up h_t=6_encode4_unit_t=6_1_split
I1223 00:14:24.545207 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.545212 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.545214 25375 net.cpp:137] Memory required for data: 37552384
I1223 00:14:24.545217 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=6
I1223 00:14:24.545228 25375 net.cpp:84] Creating Layer encode4_h_conted_t=6
I1223 00:14:24.545233 25375 net.cpp:406] encode4_h_conted_t=6 <- h_t=6_encode4_unit_t=6_1_split_0
I1223 00:14:24.545238 25375 net.cpp:406] encode4_h_conted_t=6 <- cont_t=7_encode4_cont_slice_6_split_0
I1223 00:14:24.545243 25375 net.cpp:380] encode4_h_conted_t=6 -> h_conted_t=6
I1223 00:14:24.545331 25375 net.cpp:122] Setting up encode4_h_conted_t=6
I1223 00:14:24.545341 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.545343 25375 net.cpp:137] Memory required for data: 37683456
I1223 00:14:24.545346 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->6
I1223 00:14:24.545359 25375 net.cpp:84] Creating Layer encode4_hidden->transform->6
I1223 00:14:24.545366 25375 net.cpp:406] encode4_hidden->transform->6 <- h_conted_t=6
I1223 00:14:24.545373 25375 net.cpp:380] encode4_hidden->transform->6 -> hidden->transform->6
I1223 00:14:24.545904 25375 net.cpp:122] Setting up encode4_hidden->transform->6
I1223 00:14:24.545913 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.545917 25375 net.cpp:137] Memory required for data: 38207744
I1223 00:14:24.545920 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.545925 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.545928 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=6
I1223 00:14:24.545935 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=6
I1223 00:14:24.545941 25375 net.cpp:406] encode4_hadamard->input_t=6 <- c_t=6_encode4_unit_t=6_0_split_0
I1223 00:14:24.545948 25375 net.cpp:380] encode4_hadamard->input_t=6 -> hadamard_in_t=7
I1223 00:14:24.546058 25375 net.cpp:122] Setting up encode4_hadamard->input_t=6
I1223 00:14:24.546066 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546070 25375 net.cpp:137] Memory required for data: 38338816
I1223 00:14:24.546073 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.546077 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=6
I1223 00:14:24.546085 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=6
I1223 00:14:24.546090 25375 net.cpp:406] encode4_hadamard->forget_t=6 <- c_t=6_encode4_unit_t=6_0_split_1
I1223 00:14:24.546097 25375 net.cpp:380] encode4_hadamard->forget_t=6 -> hadamard_fog_t=7
I1223 00:14:24.546200 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=6
I1223 00:14:24.546208 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546212 25375 net.cpp:137] Memory required for data: 38469888
I1223 00:14:24.546216 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.546219 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=6
I1223 00:14:24.546227 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=6
I1223 00:14:24.546232 25375 net.cpp:406] encode4_hadamard->output_t=6 <- c_t=6_encode4_unit_t=6_0_split_2
I1223 00:14:24.546238 25375 net.cpp:380] encode4_hadamard->output_t=6 -> hadamard_out_t=7
I1223 00:14:24.546346 25375 net.cpp:122] Setting up encode4_hadamard->output_t=6
I1223 00:14:24.546355 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546358 25375 net.cpp:137] Memory required for data: 38600960
I1223 00:14:24.546362 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.546365 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=7
I1223 00:14:24.546373 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=7
I1223 00:14:24.546378 25375 net.cpp:380] encode4_hadamard_gat_t=7 -> hadamard_gat_t=7
I1223 00:14:24.546442 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=7
I1223 00:14:24.546450 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546453 25375 net.cpp:137] Memory required for data: 38732032
I1223 00:14:24.546456 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=7
I1223 00:14:24.546463 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=7
I1223 00:14:24.546466 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_in_t=7
I1223 00:14:24.546470 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_fog_t=7
I1223 00:14:24.546476 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_out_t=7
I1223 00:14:24.546480 25375 net.cpp:406] encode4_concat_hadamard_t=7 <- hadamard_gat_t=7
I1223 00:14:24.546485 25375 net.cpp:380] encode4_concat_hadamard_t=7 -> hadamard_t=7
I1223 00:14:24.546515 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=7
I1223 00:14:24.546524 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.546526 25375 net.cpp:137] Memory required for data: 39256320
I1223 00:14:24.546530 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_7
I1223 00:14:24.546535 25375 net.cpp:84] Creating Layer encode4_gate_input_7
I1223 00:14:24.546540 25375 net.cpp:406] encode4_gate_input_7 <- hidden->transform->6
I1223 00:14:24.546545 25375 net.cpp:406] encode4_gate_input_7 <- x->transform->t=7
I1223 00:14:24.546550 25375 net.cpp:406] encode4_gate_input_7 <- hadamard_t=7
I1223 00:14:24.546556 25375 net.cpp:380] encode4_gate_input_7 -> gate_input_7
I1223 00:14:24.546583 25375 net.cpp:122] Setting up encode4_gate_input_7
I1223 00:14:24.546591 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.546593 25375 net.cpp:137] Memory required for data: 39780608
I1223 00:14:24.546597 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=7
I1223 00:14:24.546604 25375 net.cpp:84] Creating Layer encode4_unit_t=7
I1223 00:14:24.546608 25375 net.cpp:406] encode4_unit_t=7 <- c_t=6_encode4_unit_t=6_0_split_3
I1223 00:14:24.546613 25375 net.cpp:406] encode4_unit_t=7 <- gate_input_7
I1223 00:14:24.546617 25375 net.cpp:406] encode4_unit_t=7 <- cont_t=7_encode4_cont_slice_6_split_1
I1223 00:14:24.546622 25375 net.cpp:380] encode4_unit_t=7 -> c_t=7
I1223 00:14:24.546630 25375 net.cpp:380] encode4_unit_t=7 -> h_t=7
I1223 00:14:24.546685 25375 net.cpp:122] Setting up encode4_unit_t=7
I1223 00:14:24.546694 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546699 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546700 25375 net.cpp:137] Memory required for data: 40042752
I1223 00:14:24.546703 25375 layer_factory.hpp:77] Creating layer c_t=7_encode4_unit_t=7_0_split
I1223 00:14:24.546708 25375 net.cpp:84] Creating Layer c_t=7_encode4_unit_t=7_0_split
I1223 00:14:24.546712 25375 net.cpp:406] c_t=7_encode4_unit_t=7_0_split <- c_t=7
I1223 00:14:24.546720 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_0
I1223 00:14:24.546727 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_1
I1223 00:14:24.546737 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_2
I1223 00:14:24.546744 25375 net.cpp:380] c_t=7_encode4_unit_t=7_0_split -> c_t=7_encode4_unit_t=7_0_split_3
I1223 00:14:24.546810 25375 net.cpp:122] Setting up c_t=7_encode4_unit_t=7_0_split
I1223 00:14:24.546818 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546823 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546826 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546829 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546833 25375 net.cpp:137] Memory required for data: 40567040
I1223 00:14:24.546835 25375 layer_factory.hpp:77] Creating layer h_t=7_encode4_unit_t=7_1_split
I1223 00:14:24.546840 25375 net.cpp:84] Creating Layer h_t=7_encode4_unit_t=7_1_split
I1223 00:14:24.546844 25375 net.cpp:406] h_t=7_encode4_unit_t=7_1_split <- h_t=7
I1223 00:14:24.546849 25375 net.cpp:380] h_t=7_encode4_unit_t=7_1_split -> h_t=7_encode4_unit_t=7_1_split_0
I1223 00:14:24.546855 25375 net.cpp:380] h_t=7_encode4_unit_t=7_1_split -> h_t=7_encode4_unit_t=7_1_split_1
I1223 00:14:24.546895 25375 net.cpp:122] Setting up h_t=7_encode4_unit_t=7_1_split
I1223 00:14:24.546902 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546907 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.546910 25375 net.cpp:137] Memory required for data: 40829184
I1223 00:14:24.546912 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=7
I1223 00:14:24.546919 25375 net.cpp:84] Creating Layer encode4_h_conted_t=7
I1223 00:14:24.546924 25375 net.cpp:406] encode4_h_conted_t=7 <- h_t=7_encode4_unit_t=7_1_split_0
I1223 00:14:24.546928 25375 net.cpp:406] encode4_h_conted_t=7 <- cont_t=8_encode4_cont_slice_7_split_0
I1223 00:14:24.546934 25375 net.cpp:380] encode4_h_conted_t=7 -> h_conted_t=7
I1223 00:14:24.547817 25375 net.cpp:122] Setting up encode4_h_conted_t=7
I1223 00:14:24.547828 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.547832 25375 net.cpp:137] Memory required for data: 40960256
I1223 00:14:24.547835 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->7
I1223 00:14:24.547861 25375 net.cpp:84] Creating Layer encode4_hidden->transform->7
I1223 00:14:24.547868 25375 net.cpp:406] encode4_hidden->transform->7 <- h_conted_t=7
I1223 00:14:24.547888 25375 net.cpp:380] encode4_hidden->transform->7 -> hidden->transform->7
I1223 00:14:24.548481 25375 net.cpp:122] Setting up encode4_hidden->transform->7
I1223 00:14:24.548491 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.548493 25375 net.cpp:137] Memory required for data: 41484544
I1223 00:14:24.548497 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.548503 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.548506 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=7
I1223 00:14:24.548516 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=7
I1223 00:14:24.548519 25375 net.cpp:406] encode4_hadamard->input_t=7 <- c_t=7_encode4_unit_t=7_0_split_0
I1223 00:14:24.548526 25375 net.cpp:380] encode4_hadamard->input_t=7 -> hadamard_in_t=8
I1223 00:14:24.548633 25375 net.cpp:122] Setting up encode4_hadamard->input_t=7
I1223 00:14:24.548642 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.548645 25375 net.cpp:137] Memory required for data: 41615616
I1223 00:14:24.548650 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.548653 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=7
I1223 00:14:24.548660 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=7
I1223 00:14:24.548663 25375 net.cpp:406] encode4_hadamard->forget_t=7 <- c_t=7_encode4_unit_t=7_0_split_1
I1223 00:14:24.548671 25375 net.cpp:380] encode4_hadamard->forget_t=7 -> hadamard_fog_t=8
I1223 00:14:24.548785 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=7
I1223 00:14:24.548794 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.548796 25375 net.cpp:137] Memory required for data: 41746688
I1223 00:14:24.548800 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.548804 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=7
I1223 00:14:24.548811 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=7
I1223 00:14:24.548815 25375 net.cpp:406] encode4_hadamard->output_t=7 <- c_t=7_encode4_unit_t=7_0_split_2
I1223 00:14:24.548822 25375 net.cpp:380] encode4_hadamard->output_t=7 -> hadamard_out_t=8
I1223 00:14:24.548925 25375 net.cpp:122] Setting up encode4_hadamard->output_t=7
I1223 00:14:24.548934 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.548938 25375 net.cpp:137] Memory required for data: 41877760
I1223 00:14:24.548941 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.548945 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=8
I1223 00:14:24.548954 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=8
I1223 00:14:24.548959 25375 net.cpp:380] encode4_hadamard_gat_t=8 -> hadamard_gat_t=8
I1223 00:14:24.549015 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=8
I1223 00:14:24.549023 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549026 25375 net.cpp:137] Memory required for data: 42008832
I1223 00:14:24.549029 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=8
I1223 00:14:24.549041 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=8
I1223 00:14:24.549046 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_in_t=8
I1223 00:14:24.549051 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_fog_t=8
I1223 00:14:24.549055 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_out_t=8
I1223 00:14:24.549059 25375 net.cpp:406] encode4_concat_hadamard_t=8 <- hadamard_gat_t=8
I1223 00:14:24.549064 25375 net.cpp:380] encode4_concat_hadamard_t=8 -> hadamard_t=8
I1223 00:14:24.549099 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=8
I1223 00:14:24.549108 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.549111 25375 net.cpp:137] Memory required for data: 42533120
I1223 00:14:24.549114 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_8
I1223 00:14:24.549124 25375 net.cpp:84] Creating Layer encode4_gate_input_8
I1223 00:14:24.549129 25375 net.cpp:406] encode4_gate_input_8 <- hidden->transform->7
I1223 00:14:24.549134 25375 net.cpp:406] encode4_gate_input_8 <- x->transform->t=8
I1223 00:14:24.549139 25375 net.cpp:406] encode4_gate_input_8 <- hadamard_t=8
I1223 00:14:24.549144 25375 net.cpp:380] encode4_gate_input_8 -> gate_input_8
I1223 00:14:24.549171 25375 net.cpp:122] Setting up encode4_gate_input_8
I1223 00:14:24.549180 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.549182 25375 net.cpp:137] Memory required for data: 43057408
I1223 00:14:24.549185 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=8
I1223 00:14:24.549192 25375 net.cpp:84] Creating Layer encode4_unit_t=8
I1223 00:14:24.549197 25375 net.cpp:406] encode4_unit_t=8 <- c_t=7_encode4_unit_t=7_0_split_3
I1223 00:14:24.549202 25375 net.cpp:406] encode4_unit_t=8 <- gate_input_8
I1223 00:14:24.549206 25375 net.cpp:406] encode4_unit_t=8 <- cont_t=8_encode4_cont_slice_7_split_1
I1223 00:14:24.549212 25375 net.cpp:380] encode4_unit_t=8 -> c_t=8
I1223 00:14:24.549219 25375 net.cpp:380] encode4_unit_t=8 -> h_t=8
I1223 00:14:24.549288 25375 net.cpp:122] Setting up encode4_unit_t=8
I1223 00:14:24.549295 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549299 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549302 25375 net.cpp:137] Memory required for data: 43319552
I1223 00:14:24.549305 25375 layer_factory.hpp:77] Creating layer c_t=8_encode4_unit_t=8_0_split
I1223 00:14:24.549324 25375 net.cpp:84] Creating Layer c_t=8_encode4_unit_t=8_0_split
I1223 00:14:24.549327 25375 net.cpp:406] c_t=8_encode4_unit_t=8_0_split <- c_t=8
I1223 00:14:24.549335 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_0
I1223 00:14:24.549343 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_1
I1223 00:14:24.549350 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_2
I1223 00:14:24.549360 25375 net.cpp:380] c_t=8_encode4_unit_t=8_0_split -> c_t=8_encode4_unit_t=8_0_split_3
I1223 00:14:24.549423 25375 net.cpp:122] Setting up c_t=8_encode4_unit_t=8_0_split
I1223 00:14:24.549445 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549449 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549453 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549458 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549460 25375 net.cpp:137] Memory required for data: 43843840
I1223 00:14:24.549463 25375 layer_factory.hpp:77] Creating layer h_t=8_encode4_unit_t=8_1_split
I1223 00:14:24.549481 25375 net.cpp:84] Creating Layer h_t=8_encode4_unit_t=8_1_split
I1223 00:14:24.549485 25375 net.cpp:406] h_t=8_encode4_unit_t=8_1_split <- h_t=8
I1223 00:14:24.549490 25375 net.cpp:380] h_t=8_encode4_unit_t=8_1_split -> h_t=8_encode4_unit_t=8_1_split_0
I1223 00:14:24.549496 25375 net.cpp:380] h_t=8_encode4_unit_t=8_1_split -> h_t=8_encode4_unit_t=8_1_split_1
I1223 00:14:24.549549 25375 net.cpp:122] Setting up h_t=8_encode4_unit_t=8_1_split
I1223 00:14:24.549557 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549562 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549564 25375 net.cpp:137] Memory required for data: 44105984
I1223 00:14:24.549567 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=8
I1223 00:14:24.549587 25375 net.cpp:84] Creating Layer encode4_h_conted_t=8
I1223 00:14:24.549592 25375 net.cpp:406] encode4_h_conted_t=8 <- h_t=8_encode4_unit_t=8_1_split_0
I1223 00:14:24.549597 25375 net.cpp:406] encode4_h_conted_t=8 <- cont_t=9_encode4_cont_slice_8_split_0
I1223 00:14:24.549602 25375 net.cpp:380] encode4_h_conted_t=8 -> h_conted_t=8
I1223 00:14:24.549701 25375 net.cpp:122] Setting up encode4_h_conted_t=8
I1223 00:14:24.549710 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.549712 25375 net.cpp:137] Memory required for data: 44237056
I1223 00:14:24.549715 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->8
I1223 00:14:24.549726 25375 net.cpp:84] Creating Layer encode4_hidden->transform->8
I1223 00:14:24.549744 25375 net.cpp:406] encode4_hidden->transform->8 <- h_conted_t=8
I1223 00:14:24.549751 25375 net.cpp:380] encode4_hidden->transform->8 -> hidden->transform->8
I1223 00:14:24.550317 25375 net.cpp:122] Setting up encode4_hidden->transform->8
I1223 00:14:24.550325 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.550328 25375 net.cpp:137] Memory required for data: 44761344
I1223 00:14:24.550331 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.550335 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.550339 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=8
I1223 00:14:24.550359 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=8
I1223 00:14:24.550364 25375 net.cpp:406] encode4_hadamard->input_t=8 <- c_t=8_encode4_unit_t=8_0_split_0
I1223 00:14:24.550370 25375 net.cpp:380] encode4_hadamard->input_t=8 -> hadamard_in_t=9
I1223 00:14:24.550488 25375 net.cpp:122] Setting up encode4_hadamard->input_t=8
I1223 00:14:24.550498 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.550500 25375 net.cpp:137] Memory required for data: 44892416
I1223 00:14:24.550504 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.550521 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=8
I1223 00:14:24.550529 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=8
I1223 00:14:24.550532 25375 net.cpp:406] encode4_hadamard->forget_t=8 <- c_t=8_encode4_unit_t=8_0_split_1
I1223 00:14:24.550539 25375 net.cpp:380] encode4_hadamard->forget_t=8 -> hadamard_fog_t=9
I1223 00:14:24.550659 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=8
I1223 00:14:24.550668 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.550671 25375 net.cpp:137] Memory required for data: 45023488
I1223 00:14:24.550675 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.550678 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=8
I1223 00:14:24.550698 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=8
I1223 00:14:24.550701 25375 net.cpp:406] encode4_hadamard->output_t=8 <- c_t=8_encode4_unit_t=8_0_split_2
I1223 00:14:24.550707 25375 net.cpp:380] encode4_hadamard->output_t=8 -> hadamard_out_t=9
I1223 00:14:24.550827 25375 net.cpp:122] Setting up encode4_hadamard->output_t=8
I1223 00:14:24.550834 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.550837 25375 net.cpp:137] Memory required for data: 45154560
I1223 00:14:24.550840 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.550844 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=9
I1223 00:14:24.550864 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=9
I1223 00:14:24.550870 25375 net.cpp:380] encode4_hadamard_gat_t=9 -> hadamard_gat_t=9
I1223 00:14:24.550940 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=9
I1223 00:14:24.550961 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.550964 25375 net.cpp:137] Memory required for data: 45285632
I1223 00:14:24.550967 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=9
I1223 00:14:24.550972 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=9
I1223 00:14:24.550976 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_in_t=9
I1223 00:14:24.550993 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_fog_t=9
I1223 00:14:24.550997 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_out_t=9
I1223 00:14:24.551002 25375 net.cpp:406] encode4_concat_hadamard_t=9 <- hadamard_gat_t=9
I1223 00:14:24.551007 25375 net.cpp:380] encode4_concat_hadamard_t=9 -> hadamard_t=9
I1223 00:14:24.551048 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=9
I1223 00:14:24.551067 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.551070 25375 net.cpp:137] Memory required for data: 45809920
I1223 00:14:24.551074 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_9
I1223 00:14:24.551081 25375 net.cpp:84] Creating Layer encode4_gate_input_9
I1223 00:14:24.551086 25375 net.cpp:406] encode4_gate_input_9 <- hidden->transform->8
I1223 00:14:24.551105 25375 net.cpp:406] encode4_gate_input_9 <- x->transform->t=9
I1223 00:14:24.551110 25375 net.cpp:406] encode4_gate_input_9 <- hadamard_t=9
I1223 00:14:24.551116 25375 net.cpp:380] encode4_gate_input_9 -> gate_input_9
I1223 00:14:24.551141 25375 net.cpp:122] Setting up encode4_gate_input_9
I1223 00:14:24.551147 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.551151 25375 net.cpp:137] Memory required for data: 46334208
I1223 00:14:24.551153 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=9
I1223 00:14:24.551177 25375 net.cpp:84] Creating Layer encode4_unit_t=9
I1223 00:14:24.551194 25375 net.cpp:406] encode4_unit_t=9 <- c_t=8_encode4_unit_t=8_0_split_3
I1223 00:14:24.551199 25375 net.cpp:406] encode4_unit_t=9 <- gate_input_9
I1223 00:14:24.551203 25375 net.cpp:406] encode4_unit_t=9 <- cont_t=9_encode4_cont_slice_8_split_1
I1223 00:14:24.551208 25375 net.cpp:380] encode4_unit_t=9 -> c_t=9
I1223 00:14:24.551214 25375 net.cpp:380] encode4_unit_t=9 -> h_t=9
I1223 00:14:24.551280 25375 net.cpp:122] Setting up encode4_unit_t=9
I1223 00:14:24.551287 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551291 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551295 25375 net.cpp:137] Memory required for data: 46596352
I1223 00:14:24.551297 25375 layer_factory.hpp:77] Creating layer c_t=9_encode4_unit_t=9_0_split
I1223 00:14:24.551302 25375 net.cpp:84] Creating Layer c_t=9_encode4_unit_t=9_0_split
I1223 00:14:24.551319 25375 net.cpp:406] c_t=9_encode4_unit_t=9_0_split <- c_t=9
I1223 00:14:24.551326 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_0
I1223 00:14:24.551333 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_1
I1223 00:14:24.551342 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_2
I1223 00:14:24.551348 25375 net.cpp:380] c_t=9_encode4_unit_t=9_0_split -> c_t=9_encode4_unit_t=9_0_split_3
I1223 00:14:24.551410 25375 net.cpp:122] Setting up c_t=9_encode4_unit_t=9_0_split
I1223 00:14:24.551419 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551437 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551441 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551445 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551447 25375 net.cpp:137] Memory required for data: 47120640
I1223 00:14:24.551450 25375 layer_factory.hpp:77] Creating layer h_t=9_encode4_unit_t=9_1_split
I1223 00:14:24.551455 25375 net.cpp:84] Creating Layer h_t=9_encode4_unit_t=9_1_split
I1223 00:14:24.551458 25375 net.cpp:406] h_t=9_encode4_unit_t=9_1_split <- h_t=9
I1223 00:14:24.551477 25375 net.cpp:380] h_t=9_encode4_unit_t=9_1_split -> h_t=9_encode4_unit_t=9_1_split_0
I1223 00:14:24.551484 25375 net.cpp:380] h_t=9_encode4_unit_t=9_1_split -> h_t=9_encode4_unit_t=9_1_split_1
I1223 00:14:24.551522 25375 net.cpp:122] Setting up h_t=9_encode4_unit_t=9_1_split
I1223 00:14:24.551542 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551547 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551549 25375 net.cpp:137] Memory required for data: 47382784
I1223 00:14:24.551553 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=9
I1223 00:14:24.551558 25375 net.cpp:84] Creating Layer encode4_h_conted_t=9
I1223 00:14:24.551563 25375 net.cpp:406] encode4_h_conted_t=9 <- h_t=9_encode4_unit_t=9_1_split_0
I1223 00:14:24.551568 25375 net.cpp:406] encode4_h_conted_t=9 <- cont_t=10_encode4_cont_slice_9_split_0
I1223 00:14:24.551586 25375 net.cpp:380] encode4_h_conted_t=9 -> h_conted_t=9
I1223 00:14:24.551681 25375 net.cpp:122] Setting up encode4_h_conted_t=9
I1223 00:14:24.551689 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.551692 25375 net.cpp:137] Memory required for data: 47513856
I1223 00:14:24.551695 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->9
I1223 00:14:24.551705 25375 net.cpp:84] Creating Layer encode4_hidden->transform->9
I1223 00:14:24.551712 25375 net.cpp:406] encode4_hidden->transform->9 <- h_conted_t=9
I1223 00:14:24.551718 25375 net.cpp:380] encode4_hidden->transform->9 -> hidden->transform->9
I1223 00:14:24.552278 25375 net.cpp:122] Setting up encode4_hidden->transform->9
I1223 00:14:24.552287 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.552290 25375 net.cpp:137] Memory required for data: 48038144
I1223 00:14:24.552294 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.552299 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.552301 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=9
I1223 00:14:24.552307 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=9
I1223 00:14:24.552314 25375 net.cpp:406] encode4_hadamard->input_t=9 <- c_t=9_encode4_unit_t=9_0_split_0
I1223 00:14:24.552320 25375 net.cpp:380] encode4_hadamard->input_t=9 -> hadamard_in_t=10
I1223 00:14:24.552453 25375 net.cpp:122] Setting up encode4_hadamard->input_t=9
I1223 00:14:24.552462 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.552465 25375 net.cpp:137] Memory required for data: 48169216
I1223 00:14:24.552469 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.552472 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=9
I1223 00:14:24.552479 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=9
I1223 00:14:24.552484 25375 net.cpp:406] encode4_hadamard->forget_t=9 <- c_t=9_encode4_unit_t=9_0_split_1
I1223 00:14:24.552503 25375 net.cpp:380] encode4_hadamard->forget_t=9 -> hadamard_fog_t=10
I1223 00:14:24.552611 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=9
I1223 00:14:24.552619 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.552623 25375 net.cpp:137] Memory required for data: 48300288
I1223 00:14:24.552626 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.552629 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=9
I1223 00:14:24.552650 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=9
I1223 00:14:24.552654 25375 net.cpp:406] encode4_hadamard->output_t=9 <- c_t=9_encode4_unit_t=9_0_split_2
I1223 00:14:24.552659 25375 net.cpp:380] encode4_hadamard->output_t=9 -> hadamard_out_t=10
I1223 00:14:24.552770 25375 net.cpp:122] Setting up encode4_hadamard->output_t=9
I1223 00:14:24.552778 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.552781 25375 net.cpp:137] Memory required for data: 48431360
I1223 00:14:24.552785 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.552788 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=10
I1223 00:14:24.552831 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=10
I1223 00:14:24.552839 25375 net.cpp:380] encode4_hadamard_gat_t=10 -> hadamard_gat_t=10
I1223 00:14:24.552919 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=10
I1223 00:14:24.552927 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.552930 25375 net.cpp:137] Memory required for data: 48562432
I1223 00:14:24.552934 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=10
I1223 00:14:24.552939 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=10
I1223 00:14:24.552958 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_in_t=10
I1223 00:14:24.552963 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_fog_t=10
I1223 00:14:24.552968 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_out_t=10
I1223 00:14:24.552984 25375 net.cpp:406] encode4_concat_hadamard_t=10 <- hadamard_gat_t=10
I1223 00:14:24.552989 25375 net.cpp:380] encode4_concat_hadamard_t=10 -> hadamard_t=10
I1223 00:14:24.553016 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=10
I1223 00:14:24.553023 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.553025 25375 net.cpp:137] Memory required for data: 49086720
I1223 00:14:24.553028 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_10
I1223 00:14:24.553036 25375 net.cpp:84] Creating Layer encode4_gate_input_10
I1223 00:14:24.553040 25375 net.cpp:406] encode4_gate_input_10 <- hidden->transform->9
I1223 00:14:24.553045 25375 net.cpp:406] encode4_gate_input_10 <- x->transform->t=10
I1223 00:14:24.553048 25375 net.cpp:406] encode4_gate_input_10 <- hadamard_t=10
I1223 00:14:24.553053 25375 net.cpp:380] encode4_gate_input_10 -> gate_input_10
I1223 00:14:24.553083 25375 net.cpp:122] Setting up encode4_gate_input_10
I1223 00:14:24.553092 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.553094 25375 net.cpp:137] Memory required for data: 49611008
I1223 00:14:24.553097 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=10
I1223 00:14:24.553103 25375 net.cpp:84] Creating Layer encode4_unit_t=10
I1223 00:14:24.553107 25375 net.cpp:406] encode4_unit_t=10 <- c_t=9_encode4_unit_t=9_0_split_3
I1223 00:14:24.553110 25375 net.cpp:406] encode4_unit_t=10 <- gate_input_10
I1223 00:14:24.553115 25375 net.cpp:406] encode4_unit_t=10 <- cont_t=10_encode4_cont_slice_9_split_1
I1223 00:14:24.553122 25375 net.cpp:380] encode4_unit_t=10 -> c_t=10
I1223 00:14:24.553128 25375 net.cpp:380] encode4_unit_t=10 -> h_t=10
I1223 00:14:24.553184 25375 net.cpp:122] Setting up encode4_unit_t=10
I1223 00:14:24.553191 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553195 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553198 25375 net.cpp:137] Memory required for data: 49873152
I1223 00:14:24.553201 25375 layer_factory.hpp:77] Creating layer c_t=10_encode4_unit_t=10_0_split
I1223 00:14:24.553206 25375 net.cpp:84] Creating Layer c_t=10_encode4_unit_t=10_0_split
I1223 00:14:24.553210 25375 net.cpp:406] c_t=10_encode4_unit_t=10_0_split <- c_t=10
I1223 00:14:24.553220 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_0
I1223 00:14:24.553228 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_1
I1223 00:14:24.553234 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_2
I1223 00:14:24.553239 25375 net.cpp:380] c_t=10_encode4_unit_t=10_0_split -> c_t=10_encode4_unit_t=10_0_split_3
I1223 00:14:24.553318 25375 net.cpp:122] Setting up c_t=10_encode4_unit_t=10_0_split
I1223 00:14:24.553326 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553331 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553334 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553351 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553354 25375 net.cpp:137] Memory required for data: 50397440
I1223 00:14:24.553357 25375 layer_factory.hpp:77] Creating layer h_t=10_encode4_unit_t=10_1_split
I1223 00:14:24.553362 25375 net.cpp:84] Creating Layer h_t=10_encode4_unit_t=10_1_split
I1223 00:14:24.553365 25375 net.cpp:406] h_t=10_encode4_unit_t=10_1_split <- h_t=10
I1223 00:14:24.553371 25375 net.cpp:380] h_t=10_encode4_unit_t=10_1_split -> h_t=10_encode4_unit_t=10_1_split_0
I1223 00:14:24.553378 25375 net.cpp:380] h_t=10_encode4_unit_t=10_1_split -> h_t=10_encode4_unit_t=10_1_split_1
I1223 00:14:24.553416 25375 net.cpp:122] Setting up h_t=10_encode4_unit_t=10_1_split
I1223 00:14:24.553422 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553426 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553429 25375 net.cpp:137] Memory required for data: 50659584
I1223 00:14:24.553432 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=10
I1223 00:14:24.553437 25375 net.cpp:84] Creating Layer encode4_h_conted_t=10
I1223 00:14:24.553442 25375 net.cpp:406] encode4_h_conted_t=10 <- h_t=10_encode4_unit_t=10_1_split_0
I1223 00:14:24.553447 25375 net.cpp:406] encode4_h_conted_t=10 <- cont_t=11_encode4_cont_slice_10_split_0
I1223 00:14:24.553453 25375 net.cpp:380] encode4_h_conted_t=10 -> h_conted_t=10
I1223 00:14:24.553547 25375 net.cpp:122] Setting up encode4_h_conted_t=10
I1223 00:14:24.553556 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.553560 25375 net.cpp:137] Memory required for data: 50790656
I1223 00:14:24.553562 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->10
I1223 00:14:24.553572 25375 net.cpp:84] Creating Layer encode4_hidden->transform->10
I1223 00:14:24.553576 25375 net.cpp:406] encode4_hidden->transform->10 <- h_conted_t=10
I1223 00:14:24.553583 25375 net.cpp:380] encode4_hidden->transform->10 -> hidden->transform->10
I1223 00:14:24.554134 25375 net.cpp:122] Setting up encode4_hidden->transform->10
I1223 00:14:24.554143 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.554147 25375 net.cpp:137] Memory required for data: 51314944
I1223 00:14:24.554163 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.554167 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.554170 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=10
I1223 00:14:24.554177 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=10
I1223 00:14:24.554181 25375 net.cpp:406] encode4_hadamard->input_t=10 <- c_t=10_encode4_unit_t=10_0_split_0
I1223 00:14:24.554188 25375 net.cpp:380] encode4_hadamard->input_t=10 -> hadamard_in_t=11
I1223 00:14:24.554301 25375 net.cpp:122] Setting up encode4_hadamard->input_t=10
I1223 00:14:24.554322 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.554327 25375 net.cpp:137] Memory required for data: 51446016
I1223 00:14:24.554330 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.554333 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=10
I1223 00:14:24.554340 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=10
I1223 00:14:24.554343 25375 net.cpp:406] encode4_hadamard->forget_t=10 <- c_t=10_encode4_unit_t=10_0_split_1
I1223 00:14:24.554350 25375 net.cpp:380] encode4_hadamard->forget_t=10 -> hadamard_fog_t=11
I1223 00:14:24.554466 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=10
I1223 00:14:24.554473 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.554476 25375 net.cpp:137] Memory required for data: 51577088
I1223 00:14:24.554479 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.554482 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=10
I1223 00:14:24.554502 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=10
I1223 00:14:24.554507 25375 net.cpp:406] encode4_hadamard->output_t=10 <- c_t=10_encode4_unit_t=10_0_split_2
I1223 00:14:24.554512 25375 net.cpp:380] encode4_hadamard->output_t=10 -> hadamard_out_t=11
I1223 00:14:24.554636 25375 net.cpp:122] Setting up encode4_hadamard->output_t=10
I1223 00:14:24.554644 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.554647 25375 net.cpp:137] Memory required for data: 51708160
I1223 00:14:24.554651 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.554654 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=11
I1223 00:14:24.554675 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=11
I1223 00:14:24.554679 25375 net.cpp:380] encode4_hadamard_gat_t=11 -> hadamard_gat_t=11
I1223 00:14:24.554749 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=11
I1223 00:14:24.554769 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.554771 25375 net.cpp:137] Memory required for data: 51839232
I1223 00:14:24.554775 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=11
I1223 00:14:24.554780 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=11
I1223 00:14:24.554797 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_in_t=11
I1223 00:14:24.554802 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_fog_t=11
I1223 00:14:24.554819 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_out_t=11
I1223 00:14:24.554823 25375 net.cpp:406] encode4_concat_hadamard_t=11 <- hadamard_gat_t=11
I1223 00:14:24.554828 25375 net.cpp:380] encode4_concat_hadamard_t=11 -> hadamard_t=11
I1223 00:14:24.554855 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=11
I1223 00:14:24.554875 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.554878 25375 net.cpp:137] Memory required for data: 52363520
I1223 00:14:24.554882 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_11
I1223 00:14:24.554899 25375 net.cpp:84] Creating Layer encode4_gate_input_11
I1223 00:14:24.554903 25375 net.cpp:406] encode4_gate_input_11 <- hidden->transform->10
I1223 00:14:24.554921 25375 net.cpp:406] encode4_gate_input_11 <- x->transform->t=11
I1223 00:14:24.554925 25375 net.cpp:406] encode4_gate_input_11 <- hadamard_t=11
I1223 00:14:24.554931 25375 net.cpp:380] encode4_gate_input_11 -> gate_input_11
I1223 00:14:24.554956 25375 net.cpp:122] Setting up encode4_gate_input_11
I1223 00:14:24.554963 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.554966 25375 net.cpp:137] Memory required for data: 52887808
I1223 00:14:24.554981 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=11
I1223 00:14:24.554989 25375 net.cpp:84] Creating Layer encode4_unit_t=11
I1223 00:14:24.554992 25375 net.cpp:406] encode4_unit_t=11 <- c_t=10_encode4_unit_t=10_0_split_3
I1223 00:14:24.554997 25375 net.cpp:406] encode4_unit_t=11 <- gate_input_11
I1223 00:14:24.555001 25375 net.cpp:406] encode4_unit_t=11 <- cont_t=11_encode4_cont_slice_10_split_1
I1223 00:14:24.555006 25375 net.cpp:380] encode4_unit_t=11 -> c_t=11
I1223 00:14:24.555012 25375 net.cpp:380] encode4_unit_t=11 -> h_t=11
I1223 00:14:24.555064 25375 net.cpp:122] Setting up encode4_unit_t=11
I1223 00:14:24.555085 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555090 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555093 25375 net.cpp:137] Memory required for data: 53149952
I1223 00:14:24.555095 25375 layer_factory.hpp:77] Creating layer c_t=11_encode4_unit_t=11_0_split
I1223 00:14:24.555102 25375 net.cpp:84] Creating Layer c_t=11_encode4_unit_t=11_0_split
I1223 00:14:24.555106 25375 net.cpp:406] c_t=11_encode4_unit_t=11_0_split <- c_t=11
I1223 00:14:24.555125 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_0
I1223 00:14:24.555132 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_1
I1223 00:14:24.555140 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_2
I1223 00:14:24.555145 25375 net.cpp:380] c_t=11_encode4_unit_t=11_0_split -> c_t=11_encode4_unit_t=11_0_split_3
I1223 00:14:24.555225 25375 net.cpp:122] Setting up c_t=11_encode4_unit_t=11_0_split
I1223 00:14:24.555234 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555238 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555243 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555246 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555248 25375 net.cpp:137] Memory required for data: 53674240
I1223 00:14:24.555251 25375 layer_factory.hpp:77] Creating layer h_t=11_encode4_unit_t=11_1_split
I1223 00:14:24.555256 25375 net.cpp:84] Creating Layer h_t=11_encode4_unit_t=11_1_split
I1223 00:14:24.555259 25375 net.cpp:406] h_t=11_encode4_unit_t=11_1_split <- h_t=11
I1223 00:14:24.555264 25375 net.cpp:380] h_t=11_encode4_unit_t=11_1_split -> h_t=11_encode4_unit_t=11_1_split_0
I1223 00:14:24.555284 25375 net.cpp:380] h_t=11_encode4_unit_t=11_1_split -> h_t=11_encode4_unit_t=11_1_split_1
I1223 00:14:24.555322 25375 net.cpp:122] Setting up h_t=11_encode4_unit_t=11_1_split
I1223 00:14:24.555330 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555346 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555349 25375 net.cpp:137] Memory required for data: 53936384
I1223 00:14:24.555352 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=11
I1223 00:14:24.555359 25375 net.cpp:84] Creating Layer encode4_h_conted_t=11
I1223 00:14:24.555363 25375 net.cpp:406] encode4_h_conted_t=11 <- h_t=11_encode4_unit_t=11_1_split_0
I1223 00:14:24.555368 25375 net.cpp:406] encode4_h_conted_t=11 <- cont_t=12_encode4_cont_slice_11_split_0
I1223 00:14:24.555373 25375 net.cpp:380] encode4_h_conted_t=11 -> h_conted_t=11
I1223 00:14:24.555480 25375 net.cpp:122] Setting up encode4_h_conted_t=11
I1223 00:14:24.555488 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.555491 25375 net.cpp:137] Memory required for data: 54067456
I1223 00:14:24.555495 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->11
I1223 00:14:24.555505 25375 net.cpp:84] Creating Layer encode4_hidden->transform->11
I1223 00:14:24.555510 25375 net.cpp:406] encode4_hidden->transform->11 <- h_conted_t=11
I1223 00:14:24.555516 25375 net.cpp:380] encode4_hidden->transform->11 -> hidden->transform->11
I1223 00:14:24.556049 25375 net.cpp:122] Setting up encode4_hidden->transform->11
I1223 00:14:24.556058 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.556061 25375 net.cpp:137] Memory required for data: 54591744
I1223 00:14:24.556066 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.556069 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.556072 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=11
I1223 00:14:24.556078 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=11
I1223 00:14:24.556082 25375 net.cpp:406] encode4_hadamard->input_t=11 <- c_t=11_encode4_unit_t=11_0_split_0
I1223 00:14:24.556088 25375 net.cpp:380] encode4_hadamard->input_t=11 -> hadamard_in_t=12
I1223 00:14:24.556202 25375 net.cpp:122] Setting up encode4_hadamard->input_t=11
I1223 00:14:24.556210 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.556213 25375 net.cpp:137] Memory required for data: 54722816
I1223 00:14:24.556217 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.556221 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=11
I1223 00:14:24.556226 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=11
I1223 00:14:24.556243 25375 net.cpp:406] encode4_hadamard->forget_t=11 <- c_t=11_encode4_unit_t=11_0_split_1
I1223 00:14:24.556249 25375 net.cpp:380] encode4_hadamard->forget_t=11 -> hadamard_fog_t=12
I1223 00:14:24.556361 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=11
I1223 00:14:24.556370 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.556372 25375 net.cpp:137] Memory required for data: 54853888
I1223 00:14:24.556376 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.556380 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=11
I1223 00:14:24.556399 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=11
I1223 00:14:24.556402 25375 net.cpp:406] encode4_hadamard->output_t=11 <- c_t=11_encode4_unit_t=11_0_split_2
I1223 00:14:24.556422 25375 net.cpp:380] encode4_hadamard->output_t=11 -> hadamard_out_t=12
I1223 00:14:24.556536 25375 net.cpp:122] Setting up encode4_hadamard->output_t=11
I1223 00:14:24.556545 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.556550 25375 net.cpp:137] Memory required for data: 54984960
I1223 00:14:24.556553 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.556569 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=12
I1223 00:14:24.556576 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=12
I1223 00:14:24.556579 25375 net.cpp:380] encode4_hadamard_gat_t=12 -> hadamard_gat_t=12
I1223 00:14:24.556651 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=12
I1223 00:14:24.556660 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.556663 25375 net.cpp:137] Memory required for data: 55116032
I1223 00:14:24.556665 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=12
I1223 00:14:24.556684 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=12
I1223 00:14:24.556689 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_in_t=12
I1223 00:14:24.556694 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_fog_t=12
I1223 00:14:24.556697 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_out_t=12
I1223 00:14:24.556701 25375 net.cpp:406] encode4_concat_hadamard_t=12 <- hadamard_gat_t=12
I1223 00:14:24.556708 25375 net.cpp:380] encode4_concat_hadamard_t=12 -> hadamard_t=12
I1223 00:14:24.556736 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=12
I1223 00:14:24.556744 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.556747 25375 net.cpp:137] Memory required for data: 55640320
I1223 00:14:24.556751 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_12
I1223 00:14:24.556756 25375 net.cpp:84] Creating Layer encode4_gate_input_12
I1223 00:14:24.556758 25375 net.cpp:406] encode4_gate_input_12 <- hidden->transform->11
I1223 00:14:24.556763 25375 net.cpp:406] encode4_gate_input_12 <- x->transform->t=12
I1223 00:14:24.556767 25375 net.cpp:406] encode4_gate_input_12 <- hadamard_t=12
I1223 00:14:24.556773 25375 net.cpp:380] encode4_gate_input_12 -> gate_input_12
I1223 00:14:24.556807 25375 net.cpp:122] Setting up encode4_gate_input_12
I1223 00:14:24.556815 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.556818 25375 net.cpp:137] Memory required for data: 56164608
I1223 00:14:24.556821 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=12
I1223 00:14:24.556826 25375 net.cpp:84] Creating Layer encode4_unit_t=12
I1223 00:14:24.556843 25375 net.cpp:406] encode4_unit_t=12 <- c_t=11_encode4_unit_t=11_0_split_3
I1223 00:14:24.556848 25375 net.cpp:406] encode4_unit_t=12 <- gate_input_12
I1223 00:14:24.556864 25375 net.cpp:406] encode4_unit_t=12 <- cont_t=12_encode4_cont_slice_11_split_1
I1223 00:14:24.556869 25375 net.cpp:380] encode4_unit_t=12 -> c_t=12
I1223 00:14:24.556876 25375 net.cpp:380] encode4_unit_t=12 -> h_t=12
I1223 00:14:24.556927 25375 net.cpp:122] Setting up encode4_unit_t=12
I1223 00:14:24.556949 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.556954 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.556957 25375 net.cpp:137] Memory required for data: 56426752
I1223 00:14:24.556959 25375 layer_factory.hpp:77] Creating layer c_t=12_encode4_unit_t=12_0_split
I1223 00:14:24.556965 25375 net.cpp:84] Creating Layer c_t=12_encode4_unit_t=12_0_split
I1223 00:14:24.556968 25375 net.cpp:406] c_t=12_encode4_unit_t=12_0_split <- c_t=12
I1223 00:14:24.556988 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_0
I1223 00:14:24.556995 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_1
I1223 00:14:24.557001 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_2
I1223 00:14:24.557008 25375 net.cpp:380] c_t=12_encode4_unit_t=12_0_split -> c_t=12_encode4_unit_t=12_0_split_3
I1223 00:14:24.557077 25375 net.cpp:122] Setting up c_t=12_encode4_unit_t=12_0_split
I1223 00:14:24.557085 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.557090 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.557106 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.557111 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.557112 25375 net.cpp:137] Memory required for data: 56951040
I1223 00:14:24.557116 25375 layer_factory.hpp:77] Creating layer h_t=12_encode4_unit_t=12_1_split
I1223 00:14:24.557121 25375 net.cpp:84] Creating Layer h_t=12_encode4_unit_t=12_1_split
I1223 00:14:24.557124 25375 net.cpp:406] h_t=12_encode4_unit_t=12_1_split <- h_t=12
I1223 00:14:24.557132 25375 net.cpp:380] h_t=12_encode4_unit_t=12_1_split -> h_t=12_encode4_unit_t=12_1_split_0
I1223 00:14:24.557152 25375 net.cpp:380] h_t=12_encode4_unit_t=12_1_split -> h_t=12_encode4_unit_t=12_1_split_1
I1223 00:14:24.557209 25375 net.cpp:122] Setting up h_t=12_encode4_unit_t=12_1_split
I1223 00:14:24.557217 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.557222 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.557224 25375 net.cpp:137] Memory required for data: 57213184
I1223 00:14:24.557227 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=12
I1223 00:14:24.557234 25375 net.cpp:84] Creating Layer encode4_h_conted_t=12
I1223 00:14:24.557236 25375 net.cpp:406] encode4_h_conted_t=12 <- h_t=12_encode4_unit_t=12_1_split_0
I1223 00:14:24.557255 25375 net.cpp:406] encode4_h_conted_t=12 <- cont_t=13_encode4_cont_slice_12_split_0
I1223 00:14:24.557260 25375 net.cpp:380] encode4_h_conted_t=12 -> h_conted_t=12
I1223 00:14:24.558131 25375 net.cpp:122] Setting up encode4_h_conted_t=12
I1223 00:14:24.558141 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.558145 25375 net.cpp:137] Memory required for data: 57344256
I1223 00:14:24.558148 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->12
I1223 00:14:24.558171 25375 net.cpp:84] Creating Layer encode4_hidden->transform->12
I1223 00:14:24.558176 25375 net.cpp:406] encode4_hidden->transform->12 <- h_conted_t=12
I1223 00:14:24.558184 25375 net.cpp:380] encode4_hidden->transform->12 -> hidden->transform->12
I1223 00:14:24.558737 25375 net.cpp:122] Setting up encode4_hidden->transform->12
I1223 00:14:24.558748 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.558750 25375 net.cpp:137] Memory required for data: 57868544
I1223 00:14:24.558754 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.558763 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.558781 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=12
I1223 00:14:24.558787 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=12
I1223 00:14:24.558790 25375 net.cpp:406] encode4_hadamard->input_t=12 <- c_t=12_encode4_unit_t=12_0_split_0
I1223 00:14:24.558799 25375 net.cpp:380] encode4_hadamard->input_t=12 -> hadamard_in_t=13
I1223 00:14:24.558925 25375 net.cpp:122] Setting up encode4_hadamard->input_t=12
I1223 00:14:24.558934 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.558938 25375 net.cpp:137] Memory required for data: 57999616
I1223 00:14:24.558941 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.558944 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=12
I1223 00:14:24.558950 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=12
I1223 00:14:24.558954 25375 net.cpp:406] encode4_hadamard->forget_t=12 <- c_t=12_encode4_unit_t=12_0_split_1
I1223 00:14:24.558960 25375 net.cpp:380] encode4_hadamard->forget_t=12 -> hadamard_fog_t=13
I1223 00:14:24.559104 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=12
I1223 00:14:24.559113 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559115 25375 net.cpp:137] Memory required for data: 58130688
I1223 00:14:24.559118 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.559123 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=12
I1223 00:14:24.559141 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=12
I1223 00:14:24.559145 25375 net.cpp:406] encode4_hadamard->output_t=12 <- c_t=12_encode4_unit_t=12_0_split_2
I1223 00:14:24.559150 25375 net.cpp:380] encode4_hadamard->output_t=12 -> hadamard_out_t=13
I1223 00:14:24.559252 25375 net.cpp:122] Setting up encode4_hadamard->output_t=12
I1223 00:14:24.559259 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559262 25375 net.cpp:137] Memory required for data: 58261760
I1223 00:14:24.559267 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.559270 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=13
I1223 00:14:24.559278 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=13
I1223 00:14:24.559281 25375 net.cpp:380] encode4_hadamard_gat_t=13 -> hadamard_gat_t=13
I1223 00:14:24.559350 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=13
I1223 00:14:24.559372 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559376 25375 net.cpp:137] Memory required for data: 58392832
I1223 00:14:24.559378 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=13
I1223 00:14:24.559386 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=13
I1223 00:14:24.559389 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_in_t=13
I1223 00:14:24.559394 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_fog_t=13
I1223 00:14:24.559412 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_out_t=13
I1223 00:14:24.559414 25375 net.cpp:406] encode4_concat_hadamard_t=13 <- hadamard_gat_t=13
I1223 00:14:24.559420 25375 net.cpp:380] encode4_concat_hadamard_t=13 -> hadamard_t=13
I1223 00:14:24.559447 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=13
I1223 00:14:24.559453 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.559455 25375 net.cpp:137] Memory required for data: 58917120
I1223 00:14:24.559473 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_13
I1223 00:14:24.559480 25375 net.cpp:84] Creating Layer encode4_gate_input_13
I1223 00:14:24.559484 25375 net.cpp:406] encode4_gate_input_13 <- hidden->transform->12
I1223 00:14:24.559487 25375 net.cpp:406] encode4_gate_input_13 <- x->transform->t=13
I1223 00:14:24.559492 25375 net.cpp:406] encode4_gate_input_13 <- hadamard_t=13
I1223 00:14:24.559499 25375 net.cpp:380] encode4_gate_input_13 -> gate_input_13
I1223 00:14:24.559536 25375 net.cpp:122] Setting up encode4_gate_input_13
I1223 00:14:24.559543 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.559546 25375 net.cpp:137] Memory required for data: 59441408
I1223 00:14:24.559550 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=13
I1223 00:14:24.559556 25375 net.cpp:84] Creating Layer encode4_unit_t=13
I1223 00:14:24.559559 25375 net.cpp:406] encode4_unit_t=13 <- c_t=12_encode4_unit_t=12_0_split_3
I1223 00:14:24.559564 25375 net.cpp:406] encode4_unit_t=13 <- gate_input_13
I1223 00:14:24.559568 25375 net.cpp:406] encode4_unit_t=13 <- cont_t=13_encode4_cont_slice_12_split_1
I1223 00:14:24.559573 25375 net.cpp:380] encode4_unit_t=13 -> c_t=13
I1223 00:14:24.559581 25375 net.cpp:380] encode4_unit_t=13 -> h_t=13
I1223 00:14:24.559646 25375 net.cpp:122] Setting up encode4_unit_t=13
I1223 00:14:24.559654 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559658 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559674 25375 net.cpp:137] Memory required for data: 59703552
I1223 00:14:24.559676 25375 layer_factory.hpp:77] Creating layer c_t=13_encode4_unit_t=13_0_split
I1223 00:14:24.559682 25375 net.cpp:84] Creating Layer c_t=13_encode4_unit_t=13_0_split
I1223 00:14:24.559685 25375 net.cpp:406] c_t=13_encode4_unit_t=13_0_split <- c_t=13
I1223 00:14:24.559691 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_0
I1223 00:14:24.559700 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_1
I1223 00:14:24.559706 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_2
I1223 00:14:24.559715 25375 net.cpp:380] c_t=13_encode4_unit_t=13_0_split -> c_t=13_encode4_unit_t=13_0_split_3
I1223 00:14:24.559792 25375 net.cpp:122] Setting up c_t=13_encode4_unit_t=13_0_split
I1223 00:14:24.559800 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559804 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559808 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559811 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559814 25375 net.cpp:137] Memory required for data: 60227840
I1223 00:14:24.559830 25375 layer_factory.hpp:77] Creating layer h_t=13_encode4_unit_t=13_1_split
I1223 00:14:24.559835 25375 net.cpp:84] Creating Layer h_t=13_encode4_unit_t=13_1_split
I1223 00:14:24.559839 25375 net.cpp:406] h_t=13_encode4_unit_t=13_1_split <- h_t=13
I1223 00:14:24.559844 25375 net.cpp:380] h_t=13_encode4_unit_t=13_1_split -> h_t=13_encode4_unit_t=13_1_split_0
I1223 00:14:24.559850 25375 net.cpp:380] h_t=13_encode4_unit_t=13_1_split -> h_t=13_encode4_unit_t=13_1_split_1
I1223 00:14:24.559900 25375 net.cpp:122] Setting up h_t=13_encode4_unit_t=13_1_split
I1223 00:14:24.559907 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559912 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.559914 25375 net.cpp:137] Memory required for data: 60489984
I1223 00:14:24.559917 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=13
I1223 00:14:24.559937 25375 net.cpp:84] Creating Layer encode4_h_conted_t=13
I1223 00:14:24.559942 25375 net.cpp:406] encode4_h_conted_t=13 <- h_t=13_encode4_unit_t=13_1_split_0
I1223 00:14:24.559945 25375 net.cpp:406] encode4_h_conted_t=13 <- cont_t=14_encode4_cont_slice_13_split_0
I1223 00:14:24.559950 25375 net.cpp:380] encode4_h_conted_t=13 -> h_conted_t=13
I1223 00:14:24.560045 25375 net.cpp:122] Setting up encode4_h_conted_t=13
I1223 00:14:24.560055 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.560057 25375 net.cpp:137] Memory required for data: 60621056
I1223 00:14:24.560060 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->13
I1223 00:14:24.560071 25375 net.cpp:84] Creating Layer encode4_hidden->transform->13
I1223 00:14:24.560091 25375 net.cpp:406] encode4_hidden->transform->13 <- h_conted_t=13
I1223 00:14:24.560096 25375 net.cpp:380] encode4_hidden->transform->13 -> hidden->transform->13
I1223 00:14:24.560653 25375 net.cpp:122] Setting up encode4_hidden->transform->13
I1223 00:14:24.560662 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.560667 25375 net.cpp:137] Memory required for data: 61145344
I1223 00:14:24.560669 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.560673 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.560676 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=13
I1223 00:14:24.560683 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=13
I1223 00:14:24.560700 25375 net.cpp:406] encode4_hadamard->input_t=13 <- c_t=13_encode4_unit_t=13_0_split_0
I1223 00:14:24.560708 25375 net.cpp:380] encode4_hadamard->input_t=13 -> hadamard_in_t=14
I1223 00:14:24.560823 25375 net.cpp:122] Setting up encode4_hadamard->input_t=13
I1223 00:14:24.560832 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.560835 25375 net.cpp:137] Memory required for data: 61276416
I1223 00:14:24.560838 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.560842 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=13
I1223 00:14:24.560860 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=13
I1223 00:14:24.560863 25375 net.cpp:406] encode4_hadamard->forget_t=13 <- c_t=13_encode4_unit_t=13_0_split_1
I1223 00:14:24.560870 25375 net.cpp:380] encode4_hadamard->forget_t=13 -> hadamard_fog_t=14
I1223 00:14:24.560986 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=13
I1223 00:14:24.560994 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.560997 25375 net.cpp:137] Memory required for data: 61407488
I1223 00:14:24.561002 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.561004 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=13
I1223 00:14:24.561022 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=13
I1223 00:14:24.561027 25375 net.cpp:406] encode4_hadamard->output_t=13 <- c_t=13_encode4_unit_t=13_0_split_2
I1223 00:14:24.561031 25375 net.cpp:380] encode4_hadamard->output_t=13 -> hadamard_out_t=14
I1223 00:14:24.561163 25375 net.cpp:122] Setting up encode4_hadamard->output_t=13
I1223 00:14:24.561172 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561175 25375 net.cpp:137] Memory required for data: 61538560
I1223 00:14:24.561178 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.561182 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=14
I1223 00:14:24.561200 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=14
I1223 00:14:24.561204 25375 net.cpp:380] encode4_hadamard_gat_t=14 -> hadamard_gat_t=14
I1223 00:14:24.561275 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=14
I1223 00:14:24.561295 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561298 25375 net.cpp:137] Memory required for data: 61669632
I1223 00:14:24.561301 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=14
I1223 00:14:24.561306 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=14
I1223 00:14:24.561311 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_in_t=14
I1223 00:14:24.561316 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_fog_t=14
I1223 00:14:24.561319 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_out_t=14
I1223 00:14:24.561322 25375 net.cpp:406] encode4_concat_hadamard_t=14 <- hadamard_gat_t=14
I1223 00:14:24.561342 25375 net.cpp:380] encode4_concat_hadamard_t=14 -> hadamard_t=14
I1223 00:14:24.561368 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=14
I1223 00:14:24.561378 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.561383 25375 net.cpp:137] Memory required for data: 62193920
I1223 00:14:24.561385 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_14
I1223 00:14:24.561404 25375 net.cpp:84] Creating Layer encode4_gate_input_14
I1223 00:14:24.561408 25375 net.cpp:406] encode4_gate_input_14 <- hidden->transform->13
I1223 00:14:24.561425 25375 net.cpp:406] encode4_gate_input_14 <- x->transform->t=14
I1223 00:14:24.561429 25375 net.cpp:406] encode4_gate_input_14 <- hadamard_t=14
I1223 00:14:24.561435 25375 net.cpp:380] encode4_gate_input_14 -> gate_input_14
I1223 00:14:24.561460 25375 net.cpp:122] Setting up encode4_gate_input_14
I1223 00:14:24.561467 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.561470 25375 net.cpp:137] Memory required for data: 62718208
I1223 00:14:24.561473 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=14
I1223 00:14:24.561478 25375 net.cpp:84] Creating Layer encode4_unit_t=14
I1223 00:14:24.561481 25375 net.cpp:406] encode4_unit_t=14 <- c_t=13_encode4_unit_t=13_0_split_3
I1223 00:14:24.561486 25375 net.cpp:406] encode4_unit_t=14 <- gate_input_14
I1223 00:14:24.561491 25375 net.cpp:406] encode4_unit_t=14 <- cont_t=14_encode4_cont_slice_13_split_1
I1223 00:14:24.561496 25375 net.cpp:380] encode4_unit_t=14 -> c_t=14
I1223 00:14:24.561501 25375 net.cpp:380] encode4_unit_t=14 -> h_t=14
I1223 00:14:24.561565 25375 net.cpp:122] Setting up encode4_unit_t=14
I1223 00:14:24.561573 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561578 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561580 25375 net.cpp:137] Memory required for data: 62980352
I1223 00:14:24.561583 25375 layer_factory.hpp:77] Creating layer c_t=14_encode4_unit_t=14_0_split
I1223 00:14:24.561604 25375 net.cpp:84] Creating Layer c_t=14_encode4_unit_t=14_0_split
I1223 00:14:24.561606 25375 net.cpp:406] c_t=14_encode4_unit_t=14_0_split <- c_t=14
I1223 00:14:24.561612 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_0
I1223 00:14:24.561620 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_1
I1223 00:14:24.561628 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_2
I1223 00:14:24.561637 25375 net.cpp:380] c_t=14_encode4_unit_t=14_0_split -> c_t=14_encode4_unit_t=14_0_split_3
I1223 00:14:24.561715 25375 net.cpp:122] Setting up c_t=14_encode4_unit_t=14_0_split
I1223 00:14:24.561723 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561728 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561730 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561734 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561738 25375 net.cpp:137] Memory required for data: 63504640
I1223 00:14:24.561740 25375 layer_factory.hpp:77] Creating layer h_t=14_encode4_unit_t=14_1_split
I1223 00:14:24.561758 25375 net.cpp:84] Creating Layer h_t=14_encode4_unit_t=14_1_split
I1223 00:14:24.561761 25375 net.cpp:406] h_t=14_encode4_unit_t=14_1_split <- h_t=14
I1223 00:14:24.561767 25375 net.cpp:380] h_t=14_encode4_unit_t=14_1_split -> h_t=14_encode4_unit_t=14_1_split_0
I1223 00:14:24.561775 25375 net.cpp:380] h_t=14_encode4_unit_t=14_1_split -> h_t=14_encode4_unit_t=14_1_split_1
I1223 00:14:24.561826 25375 net.cpp:122] Setting up h_t=14_encode4_unit_t=14_1_split
I1223 00:14:24.561833 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561837 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561841 25375 net.cpp:137] Memory required for data: 63766784
I1223 00:14:24.561843 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=14
I1223 00:14:24.561848 25375 net.cpp:84] Creating Layer encode4_h_conted_t=14
I1223 00:14:24.561866 25375 net.cpp:406] encode4_h_conted_t=14 <- h_t=14_encode4_unit_t=14_1_split_0
I1223 00:14:24.561870 25375 net.cpp:406] encode4_h_conted_t=14 <- cont_t=15_encode4_cont_slice_14_split_0
I1223 00:14:24.561875 25375 net.cpp:380] encode4_h_conted_t=14 -> h_conted_t=14
I1223 00:14:24.561969 25375 net.cpp:122] Setting up encode4_h_conted_t=14
I1223 00:14:24.561976 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.561980 25375 net.cpp:137] Memory required for data: 63897856
I1223 00:14:24.561982 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->14
I1223 00:14:24.561990 25375 net.cpp:84] Creating Layer encode4_hidden->transform->14
I1223 00:14:24.561995 25375 net.cpp:406] encode4_hidden->transform->14 <- h_conted_t=14
I1223 00:14:24.562003 25375 net.cpp:380] encode4_hidden->transform->14 -> hidden->transform->14
I1223 00:14:24.562548 25375 net.cpp:122] Setting up encode4_hidden->transform->14
I1223 00:14:24.562557 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.562561 25375 net.cpp:137] Memory required for data: 64422144
I1223 00:14:24.562564 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.562568 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.562572 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=14
I1223 00:14:24.562577 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=14
I1223 00:14:24.562582 25375 net.cpp:406] encode4_hadamard->input_t=14 <- c_t=14_encode4_unit_t=14_0_split_0
I1223 00:14:24.562589 25375 net.cpp:380] encode4_hadamard->input_t=14 -> hadamard_in_t=15
I1223 00:14:24.562723 25375 net.cpp:122] Setting up encode4_hadamard->input_t=14
I1223 00:14:24.562731 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.562734 25375 net.cpp:137] Memory required for data: 64553216
I1223 00:14:24.562738 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.562741 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=14
I1223 00:14:24.562747 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=14
I1223 00:14:24.562750 25375 net.cpp:406] encode4_hadamard->forget_t=14 <- c_t=14_encode4_unit_t=14_0_split_1
I1223 00:14:24.562757 25375 net.cpp:380] encode4_hadamard->forget_t=14 -> hadamard_fog_t=15
I1223 00:14:24.562887 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=14
I1223 00:14:24.562896 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.562899 25375 net.cpp:137] Memory required for data: 64684288
I1223 00:14:24.562902 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.562906 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=14
I1223 00:14:24.562911 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=14
I1223 00:14:24.562914 25375 net.cpp:406] encode4_hadamard->output_t=14 <- c_t=14_encode4_unit_t=14_0_split_2
I1223 00:14:24.562937 25375 net.cpp:380] encode4_hadamard->output_t=14 -> hadamard_out_t=15
I1223 00:14:24.563051 25375 net.cpp:122] Setting up encode4_hadamard->output_t=14
I1223 00:14:24.563060 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563062 25375 net.cpp:137] Memory required for data: 64815360
I1223 00:14:24.563066 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.563069 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=15
I1223 00:14:24.563088 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=15
I1223 00:14:24.563094 25375 net.cpp:380] encode4_hadamard_gat_t=15 -> hadamard_gat_t=15
I1223 00:14:24.563161 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=15
I1223 00:14:24.563169 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563172 25375 net.cpp:137] Memory required for data: 64946432
I1223 00:14:24.563176 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=15
I1223 00:14:24.563197 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=15
I1223 00:14:24.563200 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_in_t=15
I1223 00:14:24.563205 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_fog_t=15
I1223 00:14:24.563210 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_out_t=15
I1223 00:14:24.563212 25375 net.cpp:406] encode4_concat_hadamard_t=15 <- hadamard_gat_t=15
I1223 00:14:24.563217 25375 net.cpp:380] encode4_concat_hadamard_t=15 -> hadamard_t=15
I1223 00:14:24.563244 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=15
I1223 00:14:24.563252 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.563254 25375 net.cpp:137] Memory required for data: 65470720
I1223 00:14:24.563257 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_15
I1223 00:14:24.563264 25375 net.cpp:84] Creating Layer encode4_gate_input_15
I1223 00:14:24.563268 25375 net.cpp:406] encode4_gate_input_15 <- hidden->transform->14
I1223 00:14:24.563272 25375 net.cpp:406] encode4_gate_input_15 <- x->transform->t=15
I1223 00:14:24.563277 25375 net.cpp:406] encode4_gate_input_15 <- hadamard_t=15
I1223 00:14:24.563282 25375 net.cpp:380] encode4_gate_input_15 -> gate_input_15
I1223 00:14:24.563308 25375 net.cpp:122] Setting up encode4_gate_input_15
I1223 00:14:24.563315 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.563318 25375 net.cpp:137] Memory required for data: 65995008
I1223 00:14:24.563321 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=15
I1223 00:14:24.563326 25375 net.cpp:84] Creating Layer encode4_unit_t=15
I1223 00:14:24.563330 25375 net.cpp:406] encode4_unit_t=15 <- c_t=14_encode4_unit_t=14_0_split_3
I1223 00:14:24.563334 25375 net.cpp:406] encode4_unit_t=15 <- gate_input_15
I1223 00:14:24.563338 25375 net.cpp:406] encode4_unit_t=15 <- cont_t=15_encode4_cont_slice_14_split_1
I1223 00:14:24.563345 25375 net.cpp:380] encode4_unit_t=15 -> c_t=15
I1223 00:14:24.563352 25375 net.cpp:380] encode4_unit_t=15 -> h_t=15
I1223 00:14:24.563418 25375 net.cpp:122] Setting up encode4_unit_t=15
I1223 00:14:24.563426 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563431 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563433 25375 net.cpp:137] Memory required for data: 66257152
I1223 00:14:24.563436 25375 layer_factory.hpp:77] Creating layer c_t=15_encode4_unit_t=15_0_split
I1223 00:14:24.563454 25375 net.cpp:84] Creating Layer c_t=15_encode4_unit_t=15_0_split
I1223 00:14:24.563458 25375 net.cpp:406] c_t=15_encode4_unit_t=15_0_split <- c_t=15
I1223 00:14:24.563465 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_0
I1223 00:14:24.563473 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_1
I1223 00:14:24.563479 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_2
I1223 00:14:24.563488 25375 net.cpp:380] c_t=15_encode4_unit_t=15_0_split -> c_t=15_encode4_unit_t=15_0_split_3
I1223 00:14:24.563552 25375 net.cpp:122] Setting up c_t=15_encode4_unit_t=15_0_split
I1223 00:14:24.563573 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563577 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563581 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563585 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563587 25375 net.cpp:137] Memory required for data: 66781440
I1223 00:14:24.563591 25375 layer_factory.hpp:77] Creating layer h_t=15_encode4_unit_t=15_1_split
I1223 00:14:24.563608 25375 net.cpp:84] Creating Layer h_t=15_encode4_unit_t=15_1_split
I1223 00:14:24.563612 25375 net.cpp:406] h_t=15_encode4_unit_t=15_1_split <- h_t=15
I1223 00:14:24.563616 25375 net.cpp:380] h_t=15_encode4_unit_t=15_1_split -> h_t=15_encode4_unit_t=15_1_split_0
I1223 00:14:24.563623 25375 net.cpp:380] h_t=15_encode4_unit_t=15_1_split -> h_t=15_encode4_unit_t=15_1_split_1
I1223 00:14:24.563675 25375 net.cpp:122] Setting up h_t=15_encode4_unit_t=15_1_split
I1223 00:14:24.563683 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563688 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563689 25375 net.cpp:137] Memory required for data: 67043584
I1223 00:14:24.563694 25375 layer_factory.hpp:77] Creating layer encode4_h_conted_t=15
I1223 00:14:24.563699 25375 net.cpp:84] Creating Layer encode4_h_conted_t=15
I1223 00:14:24.563701 25375 net.cpp:406] encode4_h_conted_t=15 <- h_t=15_encode4_unit_t=15_1_split_0
I1223 00:14:24.563719 25375 net.cpp:406] encode4_h_conted_t=15 <- cont_t=16_encode4_cont_slice_15_split_0
I1223 00:14:24.563726 25375 net.cpp:380] encode4_h_conted_t=15 -> h_conted_t=15
I1223 00:14:24.563822 25375 net.cpp:122] Setting up encode4_h_conted_t=15
I1223 00:14:24.563829 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.563832 25375 net.cpp:137] Memory required for data: 67174656
I1223 00:14:24.563836 25375 layer_factory.hpp:77] Creating layer encode4_hidden->transform->15
I1223 00:14:24.563846 25375 net.cpp:84] Creating Layer encode4_hidden->transform->15
I1223 00:14:24.563851 25375 net.cpp:406] encode4_hidden->transform->15 <- h_conted_t=15
I1223 00:14:24.563858 25375 net.cpp:380] encode4_hidden->transform->15 -> hidden->transform->15
I1223 00:14:24.564429 25375 net.cpp:122] Setting up encode4_hidden->transform->15
I1223 00:14:24.564437 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.564440 25375 net.cpp:137] Memory required for data: 67698944
I1223 00:14:24.564445 25375 net.cpp:465] Sharing parameters 'h->transform' owned by layer 'encode4_hidden->transform->0', param index 0
I1223 00:14:24.564448 25375 net.cpp:465] Sharing parameters 'h->transform_bias' owned by layer 'encode4_hidden->transform->0', param index 1
I1223 00:14:24.564451 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->input_t=15
I1223 00:14:24.564473 25375 net.cpp:84] Creating Layer encode4_hadamard->input_t=15
I1223 00:14:24.564477 25375 net.cpp:406] encode4_hadamard->input_t=15 <- c_t=15_encode4_unit_t=15_0_split_0
I1223 00:14:24.564484 25375 net.cpp:380] encode4_hadamard->input_t=15 -> hadamard_in_t=16
I1223 00:14:24.564599 25375 net.cpp:122] Setting up encode4_hadamard->input_t=15
I1223 00:14:24.564607 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.564610 25375 net.cpp:137] Memory required for data: 67830016
I1223 00:14:24.564615 25375 net.cpp:465] Sharing parameters 'hadamard.input' owned by layer 'encode4_hadamard->input_t=0', param index 0
I1223 00:14:24.564617 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->forget_t=15
I1223 00:14:24.564637 25375 net.cpp:84] Creating Layer encode4_hadamard->forget_t=15
I1223 00:14:24.564641 25375 net.cpp:406] encode4_hadamard->forget_t=15 <- c_t=15_encode4_unit_t=15_0_split_1
I1223 00:14:24.564648 25375 net.cpp:380] encode4_hadamard->forget_t=15 -> hadamard_fog_t=16
I1223 00:14:24.564765 25375 net.cpp:122] Setting up encode4_hadamard->forget_t=15
I1223 00:14:24.564774 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.564777 25375 net.cpp:137] Memory required for data: 67961088
I1223 00:14:24.564781 25375 net.cpp:465] Sharing parameters 'hadamard.forget' owned by layer 'encode4_hadamard->forget_t=0', param index 0
I1223 00:14:24.564785 25375 layer_factory.hpp:77] Creating layer encode4_hadamard->output_t=15
I1223 00:14:24.564803 25375 net.cpp:84] Creating Layer encode4_hadamard->output_t=15
I1223 00:14:24.564806 25375 net.cpp:406] encode4_hadamard->output_t=15 <- c_t=15_encode4_unit_t=15_0_split_2
I1223 00:14:24.564812 25375 net.cpp:380] encode4_hadamard->output_t=15 -> hadamard_out_t=16
I1223 00:14:24.564913 25375 net.cpp:122] Setting up encode4_hadamard->output_t=15
I1223 00:14:24.564920 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.564924 25375 net.cpp:137] Memory required for data: 68092160
I1223 00:14:24.564927 25375 net.cpp:465] Sharing parameters 'hadamard.output' owned by layer 'encode4_hadamard->output_t=0', param index 0
I1223 00:14:24.564930 25375 layer_factory.hpp:77] Creating layer encode4_hadamard_gat_t=16
I1223 00:14:24.564949 25375 net.cpp:84] Creating Layer encode4_hadamard_gat_t=16
I1223 00:14:24.564954 25375 net.cpp:380] encode4_hadamard_gat_t=16 -> hadamard_gat_t=16
I1223 00:14:24.565011 25375 net.cpp:122] Setting up encode4_hadamard_gat_t=16
I1223 00:14:24.565019 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.565022 25375 net.cpp:137] Memory required for data: 68223232
I1223 00:14:24.565026 25375 layer_factory.hpp:77] Creating layer encode4_concat_hadamard_t=16
I1223 00:14:24.565032 25375 net.cpp:84] Creating Layer encode4_concat_hadamard_t=16
I1223 00:14:24.565048 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_in_t=16
I1223 00:14:24.565052 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_fog_t=16
I1223 00:14:24.565057 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_out_t=16
I1223 00:14:24.565080 25375 net.cpp:406] encode4_concat_hadamard_t=16 <- hadamard_gat_t=16
I1223 00:14:24.565088 25375 net.cpp:380] encode4_concat_hadamard_t=16 -> hadamard_t=16
I1223 00:14:24.565114 25375 net.cpp:122] Setting up encode4_concat_hadamard_t=16
I1223 00:14:24.565124 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.565127 25375 net.cpp:137] Memory required for data: 68747520
I1223 00:14:24.565130 25375 layer_factory.hpp:77] Creating layer encode4_gate_input_16
I1223 00:14:24.565135 25375 net.cpp:84] Creating Layer encode4_gate_input_16
I1223 00:14:24.565138 25375 net.cpp:406] encode4_gate_input_16 <- hidden->transform->15
I1223 00:14:24.565143 25375 net.cpp:406] encode4_gate_input_16 <- x->transform->t=16
I1223 00:14:24.565148 25375 net.cpp:406] encode4_gate_input_16 <- hadamard_t=16
I1223 00:14:24.565153 25375 net.cpp:380] encode4_gate_input_16 -> gate_input_16
I1223 00:14:24.565179 25375 net.cpp:122] Setting up encode4_gate_input_16
I1223 00:14:24.565186 25375 net.cpp:129] Top shape: 1 1 128 32 32 (131072)
I1223 00:14:24.565189 25375 net.cpp:137] Memory required for data: 69271808
I1223 00:14:24.565192 25375 layer_factory.hpp:77] Creating layer encode4_unit_t=16
I1223 00:14:24.565212 25375 net.cpp:84] Creating Layer encode4_unit_t=16
I1223 00:14:24.565215 25375 net.cpp:406] encode4_unit_t=16 <- c_t=15_encode4_unit_t=15_0_split_3
I1223 00:14:24.565219 25375 net.cpp:406] encode4_unit_t=16 <- gate_input_16
I1223 00:14:24.565237 25375 net.cpp:406] encode4_unit_t=16 <- cont_t=16_encode4_cont_slice_15_split_1
I1223 00:14:24.565243 25375 net.cpp:380] encode4_unit_t=16 -> c_t=16
I1223 00:14:24.565248 25375 net.cpp:380] encode4_unit_t=16 -> h_t=16
I1223 00:14:24.565301 25375 net.cpp:122] Setting up encode4_unit_t=16
I1223 00:14:24.565323 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.565326 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.565330 25375 net.cpp:137] Memory required for data: 69533952
I1223 00:14:24.565332 25375 layer_factory.hpp:77] Creating layer h_t=16_encode4_unit_t=16_1_split
I1223 00:14:24.565338 25375 net.cpp:84] Creating Layer h_t=16_encode4_unit_t=16_1_split
I1223 00:14:24.565342 25375 net.cpp:406] h_t=16_encode4_unit_t=16_1_split <- h_t=16
I1223 00:14:24.565362 25375 net.cpp:380] h_t=16_encode4_unit_t=16_1_split -> h_t=16_encode4_unit_t=16_1_split_0
I1223 00:14:24.565368 25375 net.cpp:380] h_t=16_encode4_unit_t=16_1_split -> h_t=16_encode4_unit_t=16_1_split_1
I1223 00:14:24.565407 25375 net.cpp:122] Setting up h_t=16_encode4_unit_t=16_1_split
I1223 00:14:24.565429 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.565433 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.565436 25375 net.cpp:137] Memory required for data: 69796096
I1223 00:14:24.565439 25375 layer_factory.hpp:77] Creating layer encode4_h_concat
I1223 00:14:24.565448 25375 net.cpp:84] Creating Layer encode4_h_concat
I1223 00:14:24.565464 25375 net.cpp:406] encode4_h_concat <- h_t=1_encode4_unit_t=1_1_split_1
I1223 00:14:24.565469 25375 net.cpp:406] encode4_h_concat <- h_t=2_encode4_unit_t=2_1_split_1
I1223 00:14:24.565474 25375 net.cpp:406] encode4_h_concat <- h_t=3_encode4_unit_t=3_1_split_1
I1223 00:14:24.565476 25375 net.cpp:406] encode4_h_concat <- h_t=4_encode4_unit_t=4_1_split_1
I1223 00:14:24.565480 25375 net.cpp:406] encode4_h_concat <- h_t=5_encode4_unit_t=5_1_split_1
I1223 00:14:24.565484 25375 net.cpp:406] encode4_h_concat <- h_t=6_encode4_unit_t=6_1_split_1
I1223 00:14:24.565487 25375 net.cpp:406] encode4_h_concat <- h_t=7_encode4_unit_t=7_1_split_1
I1223 00:14:24.565490 25375 net.cpp:406] encode4_h_concat <- h_t=8_encode4_unit_t=8_1_split_1
I1223 00:14:24.565493 25375 net.cpp:406] encode4_h_concat <- h_t=9_encode4_unit_t=9_1_split_1
I1223 00:14:24.565497 25375 net.cpp:406] encode4_h_concat <- h_t=10_encode4_unit_t=10_1_split_1
I1223 00:14:24.565500 25375 net.cpp:406] encode4_h_concat <- h_t=11_encode4_unit_t=11_1_split_1
I1223 00:14:24.565503 25375 net.cpp:406] encode4_h_concat <- h_t=12_encode4_unit_t=12_1_split_1
I1223 00:14:24.565507 25375 net.cpp:406] encode4_h_concat <- h_t=13_encode4_unit_t=13_1_split_1
I1223 00:14:24.565510 25375 net.cpp:406] encode4_h_concat <- h_t=14_encode4_unit_t=14_1_split_1
I1223 00:14:24.565513 25375 net.cpp:406] encode4_h_concat <- h_t=15_encode4_unit_t=15_1_split_1
I1223 00:14:24.565516 25375 net.cpp:406] encode4_h_concat <- h_t=16_encode4_unit_t=16_1_split_0
I1223 00:14:24.565523 25375 net.cpp:380] encode4_h_concat -> h
I1223 00:14:24.565551 25375 net.cpp:122] Setting up encode4_h_concat
I1223 00:14:24.565557 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.565560 25375 net.cpp:137] Memory required for data: 71893248
I1223 00:14:24.565563 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_h
I1223 00:14:24.565582 25375 net.cpp:84] Creating Layer encode4_dummy_forward_h
I1223 00:14:24.565585 25375 net.cpp:406] encode4_dummy_forward_h <- h_t=16_encode4_unit_t=16_1_split_1
I1223 00:14:24.565604 25375 net.cpp:380] encode4_dummy_forward_h -> h_t=T
I1223 00:14:24.565646 25375 net.cpp:122] Setting up encode4_dummy_forward_h
I1223 00:14:24.565654 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.565656 25375 net.cpp:137] Memory required for data: 72024320
I1223 00:14:24.565663 25375 layer_factory.hpp:77] Creating layer encode4_dummy_forward_c
I1223 00:14:24.565668 25375 net.cpp:84] Creating Layer encode4_dummy_forward_c
I1223 00:14:24.565671 25375 net.cpp:406] encode4_dummy_forward_c <- c_t=16
I1223 00:14:24.565678 25375 net.cpp:380] encode4_dummy_forward_c -> c_t=T
I1223 00:14:24.565716 25375 net.cpp:122] Setting up encode4_dummy_forward_c
I1223 00:14:24.565737 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.565739 25375 net.cpp:137] Memory required for data: 72155392
I1223 00:14:24.565744 25375 layer_factory.hpp:77] Creating layer encode4_h_t=T_pseudoloss
I1223 00:14:24.565752 25375 net.cpp:84] Creating Layer encode4_h_t=T_pseudoloss
I1223 00:14:24.565755 25375 net.cpp:406] encode4_h_t=T_pseudoloss <- h_t=T
I1223 00:14:24.565760 25375 net.cpp:380] encode4_h_t=T_pseudoloss -> h_t=T_pseudoloss
I1223 00:14:24.565856 25375 net.cpp:122] Setting up encode4_h_t=T_pseudoloss
I1223 00:14:24.565863 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.565867 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.565889 25375 net.cpp:137] Memory required for data: 72155396
I1223 00:14:24.565892 25375 layer_factory.hpp:77] Creating layer encode4_c_t=T_pseudoloss
I1223 00:14:24.565897 25375 net.cpp:84] Creating Layer encode4_c_t=T_pseudoloss
I1223 00:14:24.565901 25375 net.cpp:406] encode4_c_t=T_pseudoloss <- c_t=T
I1223 00:14:24.565907 25375 net.cpp:380] encode4_c_t=T_pseudoloss -> c_t=T_pseudoloss
I1223 00:14:24.565991 25375 net.cpp:122] Setting up encode4_c_t=T_pseudoloss
I1223 00:14:24.565999 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.566001 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.566005 25375 net.cpp:137] Memory required for data: 72155400
I1223 00:14:24.566009 25375 layer_factory.hpp:77] Creating layer h_pseudoloss
I1223 00:14:24.566013 25375 net.cpp:84] Creating Layer h_pseudoloss
I1223 00:14:24.566016 25375 net.cpp:406] h_pseudoloss <- h
I1223 00:14:24.566021 25375 net.cpp:380] h_pseudoloss -> h_pseudoloss
I1223 00:14:24.567143 25375 net.cpp:122] Setting up h_pseudoloss
I1223 00:14:24.567154 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.567157 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.567162 25375 net.cpp:137] Memory required for data: 72155404
I1223 00:14:24.567165 25375 net.cpp:198] h_pseudoloss needs backward computation.
I1223 00:14:24.567168 25375 net.cpp:198] encode4_c_t=T_pseudoloss needs backward computation.
I1223 00:14:24.567172 25375 net.cpp:198] encode4_h_t=T_pseudoloss needs backward computation.
I1223 00:14:24.567174 25375 net.cpp:198] encode4_dummy_forward_c needs backward computation.
I1223 00:14:24.567178 25375 net.cpp:198] encode4_dummy_forward_h needs backward computation.
I1223 00:14:24.567179 25375 net.cpp:198] encode4_h_concat needs backward computation.
I1223 00:14:24.567188 25375 net.cpp:198] h_t=16_encode4_unit_t=16_1_split needs backward computation.
I1223 00:14:24.567204 25375 net.cpp:198] encode4_unit_t=16 needs backward computation.
I1223 00:14:24.567209 25375 net.cpp:198] encode4_gate_input_16 needs backward computation.
I1223 00:14:24.567212 25375 net.cpp:198] encode4_concat_hadamard_t=16 needs backward computation.
I1223 00:14:24.567219 25375 net.cpp:200] encode4_hadamard_gat_t=16 does not need backward computation.
I1223 00:14:24.567221 25375 net.cpp:198] encode4_hadamard->output_t=15 needs backward computation.
I1223 00:14:24.567224 25375 net.cpp:198] encode4_hadamard->forget_t=15 needs backward computation.
I1223 00:14:24.567227 25375 net.cpp:198] encode4_hadamard->input_t=15 needs backward computation.
I1223 00:14:24.567231 25375 net.cpp:198] encode4_hidden->transform->15 needs backward computation.
I1223 00:14:24.567234 25375 net.cpp:198] encode4_h_conted_t=15 needs backward computation.
I1223 00:14:24.567237 25375 net.cpp:198] h_t=15_encode4_unit_t=15_1_split needs backward computation.
I1223 00:14:24.567240 25375 net.cpp:198] c_t=15_encode4_unit_t=15_0_split needs backward computation.
I1223 00:14:24.567243 25375 net.cpp:198] encode4_unit_t=15 needs backward computation.
I1223 00:14:24.567247 25375 net.cpp:198] encode4_gate_input_15 needs backward computation.
I1223 00:14:24.567251 25375 net.cpp:198] encode4_concat_hadamard_t=15 needs backward computation.
I1223 00:14:24.567256 25375 net.cpp:200] encode4_hadamard_gat_t=15 does not need backward computation.
I1223 00:14:24.567260 25375 net.cpp:198] encode4_hadamard->output_t=14 needs backward computation.
I1223 00:14:24.567262 25375 net.cpp:198] encode4_hadamard->forget_t=14 needs backward computation.
I1223 00:14:24.567265 25375 net.cpp:198] encode4_hadamard->input_t=14 needs backward computation.
I1223 00:14:24.567268 25375 net.cpp:198] encode4_hidden->transform->14 needs backward computation.
I1223 00:14:24.567272 25375 net.cpp:198] encode4_h_conted_t=14 needs backward computation.
I1223 00:14:24.567276 25375 net.cpp:198] h_t=14_encode4_unit_t=14_1_split needs backward computation.
I1223 00:14:24.567279 25375 net.cpp:198] c_t=14_encode4_unit_t=14_0_split needs backward computation.
I1223 00:14:24.567282 25375 net.cpp:198] encode4_unit_t=14 needs backward computation.
I1223 00:14:24.567288 25375 net.cpp:198] encode4_gate_input_14 needs backward computation.
I1223 00:14:24.567292 25375 net.cpp:198] encode4_concat_hadamard_t=14 needs backward computation.
I1223 00:14:24.567297 25375 net.cpp:200] encode4_hadamard_gat_t=14 does not need backward computation.
I1223 00:14:24.567299 25375 net.cpp:198] encode4_hadamard->output_t=13 needs backward computation.
I1223 00:14:24.567303 25375 net.cpp:198] encode4_hadamard->forget_t=13 needs backward computation.
I1223 00:14:24.567306 25375 net.cpp:198] encode4_hadamard->input_t=13 needs backward computation.
I1223 00:14:24.567309 25375 net.cpp:198] encode4_hidden->transform->13 needs backward computation.
I1223 00:14:24.567312 25375 net.cpp:198] encode4_h_conted_t=13 needs backward computation.
I1223 00:14:24.567317 25375 net.cpp:198] h_t=13_encode4_unit_t=13_1_split needs backward computation.
I1223 00:14:24.567319 25375 net.cpp:198] c_t=13_encode4_unit_t=13_0_split needs backward computation.
I1223 00:14:24.567322 25375 net.cpp:198] encode4_unit_t=13 needs backward computation.
I1223 00:14:24.567327 25375 net.cpp:198] encode4_gate_input_13 needs backward computation.
I1223 00:14:24.567330 25375 net.cpp:198] encode4_concat_hadamard_t=13 needs backward computation.
I1223 00:14:24.567335 25375 net.cpp:200] encode4_hadamard_gat_t=13 does not need backward computation.
I1223 00:14:24.567338 25375 net.cpp:198] encode4_hadamard->output_t=12 needs backward computation.
I1223 00:14:24.567342 25375 net.cpp:198] encode4_hadamard->forget_t=12 needs backward computation.
I1223 00:14:24.567344 25375 net.cpp:198] encode4_hadamard->input_t=12 needs backward computation.
I1223 00:14:24.567348 25375 net.cpp:198] encode4_hidden->transform->12 needs backward computation.
I1223 00:14:24.567351 25375 net.cpp:198] encode4_h_conted_t=12 needs backward computation.
I1223 00:14:24.567356 25375 net.cpp:198] h_t=12_encode4_unit_t=12_1_split needs backward computation.
I1223 00:14:24.567360 25375 net.cpp:198] c_t=12_encode4_unit_t=12_0_split needs backward computation.
I1223 00:14:24.567363 25375 net.cpp:198] encode4_unit_t=12 needs backward computation.
I1223 00:14:24.567368 25375 net.cpp:198] encode4_gate_input_12 needs backward computation.
I1223 00:14:24.567371 25375 net.cpp:198] encode4_concat_hadamard_t=12 needs backward computation.
I1223 00:14:24.567376 25375 net.cpp:200] encode4_hadamard_gat_t=12 does not need backward computation.
I1223 00:14:24.567379 25375 net.cpp:198] encode4_hadamard->output_t=11 needs backward computation.
I1223 00:14:24.567382 25375 net.cpp:198] encode4_hadamard->forget_t=11 needs backward computation.
I1223 00:14:24.567385 25375 net.cpp:198] encode4_hadamard->input_t=11 needs backward computation.
I1223 00:14:24.567389 25375 net.cpp:198] encode4_hidden->transform->11 needs backward computation.
I1223 00:14:24.567392 25375 net.cpp:198] encode4_h_conted_t=11 needs backward computation.
I1223 00:14:24.567396 25375 net.cpp:198] h_t=11_encode4_unit_t=11_1_split needs backward computation.
I1223 00:14:24.567399 25375 net.cpp:198] c_t=11_encode4_unit_t=11_0_split needs backward computation.
I1223 00:14:24.567402 25375 net.cpp:198] encode4_unit_t=11 needs backward computation.
I1223 00:14:24.567406 25375 net.cpp:198] encode4_gate_input_11 needs backward computation.
I1223 00:14:24.567411 25375 net.cpp:198] encode4_concat_hadamard_t=11 needs backward computation.
I1223 00:14:24.567415 25375 net.cpp:200] encode4_hadamard_gat_t=11 does not need backward computation.
I1223 00:14:24.567420 25375 net.cpp:198] encode4_hadamard->output_t=10 needs backward computation.
I1223 00:14:24.567423 25375 net.cpp:198] encode4_hadamard->forget_t=10 needs backward computation.
I1223 00:14:24.567427 25375 net.cpp:198] encode4_hadamard->input_t=10 needs backward computation.
I1223 00:14:24.567430 25375 net.cpp:198] encode4_hidden->transform->10 needs backward computation.
I1223 00:14:24.567433 25375 net.cpp:198] encode4_h_conted_t=10 needs backward computation.
I1223 00:14:24.567438 25375 net.cpp:198] h_t=10_encode4_unit_t=10_1_split needs backward computation.
I1223 00:14:24.567441 25375 net.cpp:198] c_t=10_encode4_unit_t=10_0_split needs backward computation.
I1223 00:14:24.567445 25375 net.cpp:198] encode4_unit_t=10 needs backward computation.
I1223 00:14:24.567448 25375 net.cpp:198] encode4_gate_input_10 needs backward computation.
I1223 00:14:24.567453 25375 net.cpp:198] encode4_concat_hadamard_t=10 needs backward computation.
I1223 00:14:24.567457 25375 net.cpp:200] encode4_hadamard_gat_t=10 does not need backward computation.
I1223 00:14:24.567461 25375 net.cpp:198] encode4_hadamard->output_t=9 needs backward computation.
I1223 00:14:24.567463 25375 net.cpp:198] encode4_hadamard->forget_t=9 needs backward computation.
I1223 00:14:24.567467 25375 net.cpp:198] encode4_hadamard->input_t=9 needs backward computation.
I1223 00:14:24.567471 25375 net.cpp:198] encode4_hidden->transform->9 needs backward computation.
I1223 00:14:24.567474 25375 net.cpp:198] encode4_h_conted_t=9 needs backward computation.
I1223 00:14:24.567478 25375 net.cpp:198] h_t=9_encode4_unit_t=9_1_split needs backward computation.
I1223 00:14:24.567481 25375 net.cpp:198] c_t=9_encode4_unit_t=9_0_split needs backward computation.
I1223 00:14:24.567486 25375 net.cpp:198] encode4_unit_t=9 needs backward computation.
I1223 00:14:24.567490 25375 net.cpp:198] encode4_gate_input_9 needs backward computation.
I1223 00:14:24.567494 25375 net.cpp:198] encode4_concat_hadamard_t=9 needs backward computation.
I1223 00:14:24.567502 25375 net.cpp:200] encode4_hadamard_gat_t=9 does not need backward computation.
I1223 00:14:24.567504 25375 net.cpp:198] encode4_hadamard->output_t=8 needs backward computation.
I1223 00:14:24.567508 25375 net.cpp:198] encode4_hadamard->forget_t=8 needs backward computation.
I1223 00:14:24.567512 25375 net.cpp:198] encode4_hadamard->input_t=8 needs backward computation.
I1223 00:14:24.567515 25375 net.cpp:198] encode4_hidden->transform->8 needs backward computation.
I1223 00:14:24.567519 25375 net.cpp:198] encode4_h_conted_t=8 needs backward computation.
I1223 00:14:24.567523 25375 net.cpp:198] h_t=8_encode4_unit_t=8_1_split needs backward computation.
I1223 00:14:24.567526 25375 net.cpp:198] c_t=8_encode4_unit_t=8_0_split needs backward computation.
I1223 00:14:24.567530 25375 net.cpp:198] encode4_unit_t=8 needs backward computation.
I1223 00:14:24.567535 25375 net.cpp:198] encode4_gate_input_8 needs backward computation.
I1223 00:14:24.567539 25375 net.cpp:198] encode4_concat_hadamard_t=8 needs backward computation.
I1223 00:14:24.567544 25375 net.cpp:200] encode4_hadamard_gat_t=8 does not need backward computation.
I1223 00:14:24.567548 25375 net.cpp:198] encode4_hadamard->output_t=7 needs backward computation.
I1223 00:14:24.567551 25375 net.cpp:198] encode4_hadamard->forget_t=7 needs backward computation.
I1223 00:14:24.567554 25375 net.cpp:198] encode4_hadamard->input_t=7 needs backward computation.
I1223 00:14:24.567559 25375 net.cpp:198] encode4_hidden->transform->7 needs backward computation.
I1223 00:14:24.567562 25375 net.cpp:198] encode4_h_conted_t=7 needs backward computation.
I1223 00:14:24.567566 25375 net.cpp:198] h_t=7_encode4_unit_t=7_1_split needs backward computation.
I1223 00:14:24.567569 25375 net.cpp:198] c_t=7_encode4_unit_t=7_0_split needs backward computation.
I1223 00:14:24.567572 25375 net.cpp:198] encode4_unit_t=7 needs backward computation.
I1223 00:14:24.567580 25375 net.cpp:198] encode4_gate_input_7 needs backward computation.
I1223 00:14:24.567585 25375 net.cpp:198] encode4_concat_hadamard_t=7 needs backward computation.
I1223 00:14:24.567589 25375 net.cpp:200] encode4_hadamard_gat_t=7 does not need backward computation.
I1223 00:14:24.567592 25375 net.cpp:198] encode4_hadamard->output_t=6 needs backward computation.
I1223 00:14:24.567595 25375 net.cpp:198] encode4_hadamard->forget_t=6 needs backward computation.
I1223 00:14:24.567600 25375 net.cpp:198] encode4_hadamard->input_t=6 needs backward computation.
I1223 00:14:24.567602 25375 net.cpp:198] encode4_hidden->transform->6 needs backward computation.
I1223 00:14:24.567606 25375 net.cpp:198] encode4_h_conted_t=6 needs backward computation.
I1223 00:14:24.567610 25375 net.cpp:198] h_t=6_encode4_unit_t=6_1_split needs backward computation.
I1223 00:14:24.567615 25375 net.cpp:198] c_t=6_encode4_unit_t=6_0_split needs backward computation.
I1223 00:14:24.567618 25375 net.cpp:198] encode4_unit_t=6 needs backward computation.
I1223 00:14:24.567623 25375 net.cpp:198] encode4_gate_input_6 needs backward computation.
I1223 00:14:24.567628 25375 net.cpp:198] encode4_concat_hadamard_t=6 needs backward computation.
I1223 00:14:24.567633 25375 net.cpp:200] encode4_hadamard_gat_t=6 does not need backward computation.
I1223 00:14:24.567636 25375 net.cpp:198] encode4_hadamard->output_t=5 needs backward computation.
I1223 00:14:24.567639 25375 net.cpp:198] encode4_hadamard->forget_t=5 needs backward computation.
I1223 00:14:24.567643 25375 net.cpp:198] encode4_hadamard->input_t=5 needs backward computation.
I1223 00:14:24.567646 25375 net.cpp:198] encode4_hidden->transform->5 needs backward computation.
I1223 00:14:24.567651 25375 net.cpp:198] encode4_h_conted_t=5 needs backward computation.
I1223 00:14:24.567656 25375 net.cpp:198] h_t=5_encode4_unit_t=5_1_split needs backward computation.
I1223 00:14:24.567659 25375 net.cpp:198] c_t=5_encode4_unit_t=5_0_split needs backward computation.
I1223 00:14:24.567662 25375 net.cpp:198] encode4_unit_t=5 needs backward computation.
I1223 00:14:24.567667 25375 net.cpp:198] encode4_gate_input_5 needs backward computation.
I1223 00:14:24.567672 25375 net.cpp:198] encode4_concat_hadamard_t=5 needs backward computation.
I1223 00:14:24.567677 25375 net.cpp:200] encode4_hadamard_gat_t=5 does not need backward computation.
I1223 00:14:24.567679 25375 net.cpp:198] encode4_hadamard->output_t=4 needs backward computation.
I1223 00:14:24.567682 25375 net.cpp:198] encode4_hadamard->forget_t=4 needs backward computation.
I1223 00:14:24.567685 25375 net.cpp:198] encode4_hadamard->input_t=4 needs backward computation.
I1223 00:14:24.567689 25375 net.cpp:198] encode4_hidden->transform->4 needs backward computation.
I1223 00:14:24.567692 25375 net.cpp:198] encode4_h_conted_t=4 needs backward computation.
I1223 00:14:24.567697 25375 net.cpp:198] h_t=4_encode4_unit_t=4_1_split needs backward computation.
I1223 00:14:24.567699 25375 net.cpp:198] c_t=4_encode4_unit_t=4_0_split needs backward computation.
I1223 00:14:24.567703 25375 net.cpp:198] encode4_unit_t=4 needs backward computation.
I1223 00:14:24.567708 25375 net.cpp:198] encode4_gate_input_4 needs backward computation.
I1223 00:14:24.567711 25375 net.cpp:198] encode4_concat_hadamard_t=4 needs backward computation.
I1223 00:14:24.567716 25375 net.cpp:200] encode4_hadamard_gat_t=4 does not need backward computation.
I1223 00:14:24.567720 25375 net.cpp:198] encode4_hadamard->output_t=3 needs backward computation.
I1223 00:14:24.567723 25375 net.cpp:198] encode4_hadamard->forget_t=3 needs backward computation.
I1223 00:14:24.567726 25375 net.cpp:198] encode4_hadamard->input_t=3 needs backward computation.
I1223 00:14:24.567731 25375 net.cpp:198] encode4_hidden->transform->3 needs backward computation.
I1223 00:14:24.567735 25375 net.cpp:198] encode4_h_conted_t=3 needs backward computation.
I1223 00:14:24.567739 25375 net.cpp:198] h_t=3_encode4_unit_t=3_1_split needs backward computation.
I1223 00:14:24.567742 25375 net.cpp:198] c_t=3_encode4_unit_t=3_0_split needs backward computation.
I1223 00:14:24.567745 25375 net.cpp:198] encode4_unit_t=3 needs backward computation.
I1223 00:14:24.567749 25375 net.cpp:198] encode4_gate_input_3 needs backward computation.
I1223 00:14:24.567754 25375 net.cpp:198] encode4_concat_hadamard_t=3 needs backward computation.
I1223 00:14:24.567759 25375 net.cpp:200] encode4_hadamard_gat_t=3 does not need backward computation.
I1223 00:14:24.567761 25375 net.cpp:198] encode4_hadamard->output_t=2 needs backward computation.
I1223 00:14:24.567765 25375 net.cpp:198] encode4_hadamard->forget_t=2 needs backward computation.
I1223 00:14:24.567769 25375 net.cpp:198] encode4_hadamard->input_t=2 needs backward computation.
I1223 00:14:24.567771 25375 net.cpp:198] encode4_hidden->transform->2 needs backward computation.
I1223 00:14:24.567775 25375 net.cpp:198] encode4_h_conted_t=2 needs backward computation.
I1223 00:14:24.567780 25375 net.cpp:198] h_t=2_encode4_unit_t=2_1_split needs backward computation.
I1223 00:14:24.567782 25375 net.cpp:198] c_t=2_encode4_unit_t=2_0_split needs backward computation.
I1223 00:14:24.567785 25375 net.cpp:198] encode4_unit_t=2 needs backward computation.
I1223 00:14:24.567790 25375 net.cpp:198] encode4_gate_input_2 needs backward computation.
I1223 00:14:24.567795 25375 net.cpp:198] encode4_concat_hadamard_t=2 needs backward computation.
I1223 00:14:24.567801 25375 net.cpp:200] encode4_hadamard_gat_t=2 does not need backward computation.
I1223 00:14:24.567804 25375 net.cpp:198] encode4_hadamard->output_t=1 needs backward computation.
I1223 00:14:24.567807 25375 net.cpp:198] encode4_hadamard->forget_t=1 needs backward computation.
I1223 00:14:24.567811 25375 net.cpp:198] encode4_hadamard->input_t=1 needs backward computation.
I1223 00:14:24.567814 25375 net.cpp:198] encode4_hidden->transform->1 needs backward computation.
I1223 00:14:24.567818 25375 net.cpp:198] encode4_h_conted_t=1 needs backward computation.
I1223 00:14:24.567822 25375 net.cpp:198] h_t=1_encode4_unit_t=1_1_split needs backward computation.
I1223 00:14:24.567826 25375 net.cpp:198] c_t=1_encode4_unit_t=1_0_split needs backward computation.
I1223 00:14:24.567829 25375 net.cpp:198] encode4_unit_t=1 needs backward computation.
I1223 00:14:24.567833 25375 net.cpp:198] encode4_gate_input_1 needs backward computation.
I1223 00:14:24.567837 25375 net.cpp:198] encode4_concat_hadamard_t=1 needs backward computation.
I1223 00:14:24.567843 25375 net.cpp:200] encode4_hadamard_gat_t=1 does not need backward computation.
I1223 00:14:24.567847 25375 net.cpp:198] encode4_hadamard->output_t=0 needs backward computation.
I1223 00:14:24.567849 25375 net.cpp:198] encode4_hadamard->forget_t=0 needs backward computation.
I1223 00:14:24.567852 25375 net.cpp:198] encode4_hadamard->input_t=0 needs backward computation.
I1223 00:14:24.567857 25375 net.cpp:198] encode4_hidden->transform->0 needs backward computation.
I1223 00:14:24.567859 25375 net.cpp:198] encode4_h_conted_t=0 needs backward computation.
I1223 00:14:24.567863 25375 net.cpp:198] encode4_dummy_forward_h0 needs backward computation.
I1223 00:14:24.567867 25375 net.cpp:198] c_t=0_encode4_dummy_forward_c0_0_split needs backward computation.
I1223 00:14:24.567870 25375 net.cpp:198] encode4_dummy_forward_c0 needs backward computation.
I1223 00:14:24.567874 25375 net.cpp:200] cont_t=16_encode4_cont_slice_15_split does not need backward computation.
I1223 00:14:24.567878 25375 net.cpp:200] cont_t=15_encode4_cont_slice_14_split does not need backward computation.
I1223 00:14:24.567883 25375 net.cpp:200] cont_t=14_encode4_cont_slice_13_split does not need backward computation.
I1223 00:14:24.567885 25375 net.cpp:200] cont_t=13_encode4_cont_slice_12_split does not need backward computation.
I1223 00:14:24.567889 25375 net.cpp:200] cont_t=12_encode4_cont_slice_11_split does not need backward computation.
I1223 00:14:24.567894 25375 net.cpp:200] cont_t=11_encode4_cont_slice_10_split does not need backward computation.
I1223 00:14:24.567898 25375 net.cpp:200] cont_t=10_encode4_cont_slice_9_split does not need backward computation.
I1223 00:14:24.567903 25375 net.cpp:200] cont_t=9_encode4_cont_slice_8_split does not need backward computation.
I1223 00:14:24.567906 25375 net.cpp:200] cont_t=8_encode4_cont_slice_7_split does not need backward computation.
I1223 00:14:24.567909 25375 net.cpp:200] cont_t=7_encode4_cont_slice_6_split does not need backward computation.
I1223 00:14:24.567914 25375 net.cpp:200] cont_t=6_encode4_cont_slice_5_split does not need backward computation.
I1223 00:14:24.567916 25375 net.cpp:200] cont_t=5_encode4_cont_slice_4_split does not need backward computation.
I1223 00:14:24.567920 25375 net.cpp:200] cont_t=4_encode4_cont_slice_3_split does not need backward computation.
I1223 00:14:24.567924 25375 net.cpp:200] cont_t=3_encode4_cont_slice_2_split does not need backward computation.
I1223 00:14:24.567929 25375 net.cpp:200] cont_t=2_encode4_cont_slice_1_split does not need backward computation.
I1223 00:14:24.567932 25375 net.cpp:200] cont_t=1_encode4_cont_slice_0_split does not need backward computation.
I1223 00:14:24.567939 25375 net.cpp:200] encode4_cont_slice does not need backward computation.
I1223 00:14:24.567945 25375 net.cpp:198] encode4_W_xc_x_slice needs backward computation.
I1223 00:14:24.567948 25375 net.cpp:200] encode4_input->cell_hidden does not need backward computation.
I1223 00:14:24.567951 25375 net.cpp:198] encode4_x->transform needs backward computation.
I1223 00:14:24.567955 25375 net.cpp:200] encode4_ does not need backward computation.
I1223 00:14:24.567957 25375 net.cpp:242] This network produces output c_t=T_pseudoloss
I1223 00:14:24.567961 25375 net.cpp:242] This network produces output h_pseudoloss
I1223 00:14:24.567965 25375 net.cpp:242] This network produces output h_t=T_pseudoloss
I1223 00:14:24.568861 25375 net.cpp:255] Network initialization done.
I1223 00:14:24.569344 25375 recurrent_layer.cpp:150] Adding parameter 0: x_transform
I1223 00:14:24.569352 25375 recurrent_layer.cpp:150] Adding parameter 1: 0
I1223 00:14:24.569355 25375 recurrent_layer.cpp:150] Adding parameter 2: 0
I1223 00:14:24.569358 25375 recurrent_layer.cpp:150] Adding parameter 3: h->transform
I1223 00:14:24.569360 25375 recurrent_layer.cpp:150] Adding parameter 4: h->transform_bias
I1223 00:14:24.569363 25375 recurrent_layer.cpp:150] Adding parameter 5: hadamard.input
I1223 00:14:24.569366 25375 recurrent_layer.cpp:150] Adding parameter 6: hadamard.forget
I1223 00:14:24.569368 25375 recurrent_layer.cpp:150] Adding parameter 7: hadamard.output
I1223 00:14:24.569388 25375 recurrent_layer.cpp:150] Adding parameter 83: 0
I1223 00:14:24.569391 25375 recurrent_layer.cpp:150] Adding parameter 84: 0
I1223 00:14:24.570116 25375 net.cpp:122] Setting up encode4
I1223 00:14:24.570127 25375 net.cpp:129] Top shape: 16 1 32 32 32 (524288)
I1223 00:14:24.570132 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.570149 25375 net.cpp:129] Top shape: 1 1 32 32 32 (32768)
I1223 00:14:24.570152 25375 net.cpp:137] Memory required for data: 4289331584
I1223 00:14:24.570192 25375 layer_factory.hpp:77] Creating layer reshape_encode1
I1223 00:14:24.570215 25375 net.cpp:84] Creating Layer reshape_encode1
I1223 00:14:24.570220 25375 net.cpp:406] reshape_encode1 <- encode1
I1223 00:14:24.570241 25375 net.cpp:380] reshape_encode1 -> reshape_encode1
I1223 00:14:24.570278 25375 net.cpp:122] Setting up reshape_encode1
I1223 00:14:24.570300 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:24.570303 25375 net.cpp:137] Memory required for data: 4291428736
I1223 00:14:24.570307 25375 layer_factory.hpp:77] Creating layer reshape_encode2
I1223 00:14:24.570310 25375 net.cpp:84] Creating Layer reshape_encode2
I1223 00:14:24.570314 25375 net.cpp:406] reshape_encode2 <- encode2
I1223 00:14:24.570319 25375 net.cpp:380] reshape_encode2 -> reshape_encode2
I1223 00:14:24.570350 25375 net.cpp:122] Setting up reshape_encode2
I1223 00:14:24.570358 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:24.570360 25375 net.cpp:137] Memory required for data: 4293525888
I1223 00:14:24.570363 25375 layer_factory.hpp:77] Creating layer reshape_encode3
I1223 00:14:24.570369 25375 net.cpp:84] Creating Layer reshape_encode3
I1223 00:14:24.570372 25375 net.cpp:406] reshape_encode3 <- encode3
I1223 00:14:24.570376 25375 net.cpp:380] reshape_encode3 -> reshape_encode3
I1223 00:14:24.570406 25375 net.cpp:122] Setting up reshape_encode3
I1223 00:14:24.570415 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:24.570417 25375 net.cpp:137] Memory required for data: 4295623040
I1223 00:14:24.570425 25375 layer_factory.hpp:77] Creating layer reshape_encode4
I1223 00:14:24.570430 25375 net.cpp:84] Creating Layer reshape_encode4
I1223 00:14:24.570435 25375 net.cpp:406] reshape_encode4 <- encode4
I1223 00:14:24.570439 25375 net.cpp:380] reshape_encode4 -> reshape_encode4
I1223 00:14:24.570468 25375 net.cpp:122] Setting up reshape_encode4
I1223 00:14:24.570475 25375 net.cpp:129] Top shape: 16 32 32 32 (524288)
I1223 00:14:24.570478 25375 net.cpp:137] Memory required for data: 4297720192
I1223 00:14:24.570482 25375 layer_factory.hpp:77] Creating layer concat_encode1234
I1223 00:14:24.570487 25375 net.cpp:84] Creating Layer concat_encode1234
I1223 00:14:24.570490 25375 net.cpp:406] concat_encode1234 <- reshape_encode1
I1223 00:14:24.570495 25375 net.cpp:406] concat_encode1234 <- reshape_encode2
I1223 00:14:24.570499 25375 net.cpp:406] concat_encode1234 <- reshape_encode3
I1223 00:14:24.570502 25375 net.cpp:406] concat_encode1234 <- reshape_encode4
I1223 00:14:24.570508 25375 net.cpp:380] concat_encode1234 -> concat_encode1234
I1223 00:14:24.570536 25375 net.cpp:122] Setting up concat_encode1234
I1223 00:14:24.570544 25375 net.cpp:129] Top shape: 16 128 32 32 (2097152)
I1223 00:14:24.570546 25375 net.cpp:137] Memory required for data: 4306108800
I1223 00:14:24.570549 25375 layer_factory.hpp:77] Creating layer conv7_
I1223 00:14:24.570557 25375 net.cpp:84] Creating Layer conv7_
I1223 00:14:24.570560 25375 net.cpp:406] conv7_ <- concat_encode1234
I1223 00:14:24.570566 25375 net.cpp:380] conv7_ -> conv7
I1223 00:14:24.570880 25375 net.cpp:122] Setting up conv7_
I1223 00:14:24.570889 25375 net.cpp:129] Top shape: 16 1 32 32 (16384)
I1223 00:14:24.570893 25375 net.cpp:137] Memory required for data: 4306174336
I1223 00:14:24.570899 25375 layer_factory.hpp:77] Creating layer conv7_interp
I1223 00:14:24.570917 25375 net.cpp:84] Creating Layer conv7_interp
I1223 00:14:24.570921 25375 net.cpp:406] conv7_interp <- conv7
I1223 00:14:24.570926 25375 net.cpp:380] conv7_interp -> conv7_interp
I1223 00:14:24.570964 25375 net.cpp:122] Setting up conv7_interp
I1223 00:14:24.570971 25375 net.cpp:129] Top shape: 16 1 256 256 (1048576)
I1223 00:14:24.570973 25375 net.cpp:137] Memory required for data: 4310368640
I1223 00:14:24.570976 25375 layer_factory.hpp:77] Creating layer loss
I1223 00:14:24.570982 25375 net.cpp:84] Creating Layer loss
I1223 00:14:24.570986 25375 net.cpp:406] loss <- conv7_interp
I1223 00:14:24.570991 25375 net.cpp:406] loss <- label
I1223 00:14:24.570996 25375 net.cpp:380] loss -> loss
I1223 00:14:24.571034 25375 net.cpp:122] Setting up loss
I1223 00:14:24.571055 25375 net.cpp:129] Top shape: (1)
I1223 00:14:24.571058 25375 net.cpp:132]     with loss weight 1
I1223 00:14:24.571065 25375 net.cpp:137] Memory required for data: 4310368644
I1223 00:14:24.571069 25375 layer_factory.hpp:77] Creating layer silence
I1223 00:14:24.571072 25375 net.cpp:84] Creating Layer silence
I1223 00:14:24.571076 25375 net.cpp:406] silence <- encode1_h
I1223 00:14:24.571080 25375 net.cpp:406] silence <- encode2_h
I1223 00:14:24.571084 25375 net.cpp:406] silence <- encode3_h
I1223 00:14:24.571087 25375 net.cpp:406] silence <- encode4_h
I1223 00:14:24.571105 25375 net.cpp:406] silence <- encode1_c
I1223 00:14:24.571108 25375 net.cpp:406] silence <- encode2_c
I1223 00:14:24.571111 25375 net.cpp:406] silence <- encode3_c
I1223 00:14:24.571115 25375 net.cpp:406] silence <- encode4_c
I1223 00:14:24.571117 25375 net.cpp:122] Setting up silence
I1223 00:14:24.571120 25375 net.cpp:137] Memory required for data: 4310368644
I1223 00:14:24.571123 25375 net.cpp:200] silence does not need backward computation.
I1223 00:14:24.571127 25375 net.cpp:198] loss needs backward computation.
I1223 00:14:24.571131 25375 net.cpp:198] conv7_interp needs backward computation.
I1223 00:14:24.571133 25375 net.cpp:198] conv7_ needs backward computation.
I1223 00:14:24.571136 25375 net.cpp:198] concat_encode1234 needs backward computation.
I1223 00:14:24.571141 25375 net.cpp:198] reshape_encode4 needs backward computation.
I1223 00:14:24.571143 25375 net.cpp:198] reshape_encode3 needs backward computation.
I1223 00:14:24.571146 25375 net.cpp:198] reshape_encode2 needs backward computation.
I1223 00:14:24.571149 25375 net.cpp:198] reshape_encode1 needs backward computation.
I1223 00:14:24.571152 25375 net.cpp:198] encode4 needs backward computation.
I1223 00:14:24.571157 25375 net.cpp:198] encode3 needs backward computation.
I1223 00:14:24.571163 25375 net.cpp:198] encode2 needs backward computation.
I1223 00:14:24.571168 25375 net.cpp:198] encode1 needs backward computation.
I1223 00:14:24.571174 25375 net.cpp:200] dummy_dummy_0_split does not need backward computation.
I1223 00:14:24.571179 25375 net.cpp:200] dummy does not need backward computation.
I1223 00:14:24.571182 25375 net.cpp:198] conv6-reshape_reshape-data_0_split needs backward computation.
I1223 00:14:24.571187 25375 net.cpp:198] reshape-data needs backward computation.
I1223 00:14:24.571190 25375 net.cpp:200] reshape-cm_reshape-cm_0_split does not need backward computation.
I1223 00:14:24.571194 25375 net.cpp:200] reshape-cm does not need backward computation.
I1223 00:14:24.571198 25375 net.cpp:198] relu6 needs backward computation.
I1223 00:14:24.571202 25375 net.cpp:198] conv6/bn needs backward computation.
I1223 00:14:24.571204 25375 net.cpp:198] conv6 needs backward computation.
I1223 00:14:24.571208 25375 net.cpp:198] conv5_4/dropout needs backward computation.
I1223 00:14:24.571211 25375 net.cpp:198] conv5_4/relu needs backward computation.
I1223 00:14:24.571214 25375 net.cpp:198] conv5_4/bn needs backward computation.
I1223 00:14:24.571218 25375 net.cpp:198] conv5_4 needs backward computation.
I1223 00:14:24.571220 25375 net.cpp:198] relu_sum needs backward computation.
I1223 00:14:24.571223 25375 net.cpp:198] sum_5_concat4 needs backward computation.
I1223 00:14:24.571228 25375 net.cpp:198] concat4_512 needs backward computation.
I1223 00:14:24.571231 25375 net.cpp:198] concat4 needs backward computation.
I1223 00:14:24.571235 25375 net.cpp:198] relu6_4 needs backward computation.
I1223 00:14:24.571238 25375 net.cpp:198] fc6_4 needs backward computation.
I1223 00:14:24.571243 25375 net.cpp:198] relu6_3 needs backward computation.
I1223 00:14:24.571245 25375 net.cpp:198] fc6_3 needs backward computation.
I1223 00:14:24.571249 25375 net.cpp:198] relu6_2 needs backward computation.
I1223 00:14:24.571251 25375 net.cpp:198] fc6_2 needs backward computation.
I1223 00:14:24.571254 25375 net.cpp:198] relu6_1 needs backward computation.
I1223 00:14:24.571257 25375 net.cpp:198] fc6_1 needs backward computation.
I1223 00:14:24.571261 25375 net.cpp:198] relu5_relu5_0_split needs backward computation.
I1223 00:14:24.571264 25375 net.cpp:198] relu5 needs backward computation.
I1223 00:14:24.571269 25375 net.cpp:198] conv5_conv5_0_split needs backward computation.
I1223 00:14:24.571272 25375 net.cpp:198] conv5 needs backward computation.
I1223 00:14:24.571276 25375 net.cpp:198] conv5_3_bn needs backward computation.
I1223 00:14:24.571280 25375 net.cpp:198] conv5_3 needs backward computation.
I1223 00:14:24.571282 25375 net.cpp:198] relu5_2 needs backward computation.
I1223 00:14:24.571285 25375 net.cpp:198] conv5_2_bn needs backward computation.
I1223 00:14:24.571288 25375 net.cpp:198] conv5_2 needs backward computation.
I1223 00:14:24.571291 25375 net.cpp:198] relu5_1 needs backward computation.
I1223 00:14:24.571293 25375 net.cpp:198] conv5_1_bn needs backward computation.
I1223 00:14:24.571296 25375 net.cpp:198] conv5_1 needs backward computation.
I1223 00:14:24.571300 25375 net.cpp:198] relu4_3 needs backward computation.
I1223 00:14:24.571303 25375 net.cpp:198] conv4_3_conv4_3_bn_0_split needs backward computation.
I1223 00:14:24.571307 25375 net.cpp:198] conv4_3_bn needs backward computation.
I1223 00:14:24.571310 25375 net.cpp:198] conv4_3 needs backward computation.
I1223 00:14:24.571313 25375 net.cpp:198] relu4_2 needs backward computation.
I1223 00:14:24.571316 25375 net.cpp:198] conv4_2_bn needs backward computation.
I1223 00:14:24.571319 25375 net.cpp:198] conv4_2 needs backward computation.
I1223 00:14:24.571322 25375 net.cpp:198] relu4_1 needs backward computation.
I1223 00:14:24.571326 25375 net.cpp:198] conv4_1_bn needs backward computation.
I1223 00:14:24.571328 25375 net.cpp:198] conv4_1 needs backward computation.
I1223 00:14:24.571331 25375 net.cpp:198] pool3 needs backward computation.
I1223 00:14:24.571334 25375 net.cpp:198] relu3_3 needs backward computation.
I1223 00:14:24.571338 25375 net.cpp:198] conv3_3_bn needs backward computation.
I1223 00:14:24.571341 25375 net.cpp:198] conv3_3 needs backward computation.
I1223 00:14:24.571343 25375 net.cpp:198] relu3_2 needs backward computation.
I1223 00:14:24.571346 25375 net.cpp:198] conv3_2_bn needs backward computation.
I1223 00:14:24.571349 25375 net.cpp:198] conv3_2 needs backward computation.
I1223 00:14:24.571352 25375 net.cpp:198] relu3_1 needs backward computation.
I1223 00:14:24.571355 25375 net.cpp:198] conv3_1_bn needs backward computation.
I1223 00:14:24.571358 25375 net.cpp:198] conv3_1 needs backward computation.
I1223 00:14:24.571362 25375 net.cpp:198] pool2 needs backward computation.
I1223 00:14:24.571364 25375 net.cpp:198] relu2_2 needs backward computation.
I1223 00:14:24.571367 25375 net.cpp:198] conv2_2_bn needs backward computation.
I1223 00:14:24.571370 25375 net.cpp:198] conv2_2 needs backward computation.
I1223 00:14:24.571374 25375 net.cpp:198] relu2_1 needs backward computation.
I1223 00:14:24.571377 25375 net.cpp:198] conv2_1_bn needs backward computation.
I1223 00:14:24.571379 25375 net.cpp:198] conv2_1 needs backward computation.
I1223 00:14:24.571382 25375 net.cpp:198] pool1 needs backward computation.
I1223 00:14:24.571386 25375 net.cpp:198] relu1_2 needs backward computation.
I1223 00:14:24.571388 25375 net.cpp:198] conv1_2_bn needs backward computation.
I1223 00:14:24.571391 25375 net.cpp:198] conv1_2 needs backward computation.
I1223 00:14:24.571394 25375 net.cpp:198] relu1_1 needs backward computation.
I1223 00:14:24.571398 25375 net.cpp:198] conv1_1_bn needs backward computation.
I1223 00:14:24.571401 25375 net.cpp:198] conv1_1 needs backward computation.
I1223 00:14:24.571405 25375 net.cpp:200] data does not need backward computation.
I1223 00:14:24.571408 25375 net.cpp:242] This network produces output loss
I1223 00:14:24.571471 25375 net.cpp:255] Network initialization done.
I1223 00:14:24.572569 25375 solver.cpp:56] Solver scaffolding done.
I1223 00:14:24.578227 25375 caffe.cpp:155] Finetuning from ./model6/c6_iter_25000.caffemodel
I1223 00:14:24.618000 25375 net.cpp:744] Ignoring source layer conv6_conv6/bn_0_split
I1223 00:14:24.618019 25375 net.cpp:744] Ignoring source layer convLstm1
I1223 00:14:24.618023 25375 net.cpp:744] Ignoring source layer reshape_convlstm
I1223 00:14:24.618026 25375 net.cpp:744] Ignoring source layer conv7
I1223 00:14:24.618043 25375 net.cpp:744] Ignoring source layer conv7/bn
I1223 00:14:24.618046 25375 net.cpp:744] Ignoring source layer conv6_interp
I1223 00:14:24.618048 25375 net.cpp:744] Ignoring source layer sum67
I1223 00:14:24.659327 25375 net.cpp:744] Ignoring source layer conv6_conv6/bn_0_split
I1223 00:14:24.659345 25375 net.cpp:744] Ignoring source layer convLstm1
I1223 00:14:24.659348 25375 net.cpp:744] Ignoring source layer reshape_convlstm
I1223 00:14:24.659348 25375 net.cpp:744] Ignoring source layer conv7
I1223 00:14:24.659350 25375 net.cpp:744] Ignoring source layer conv7/bn
I1223 00:14:24.659353 25375 net.cpp:744] Ignoring source layer conv6_interp
I1223 00:14:24.659354 25375 net.cpp:744] Ignoring source layer sum67
I1223 00:14:24.660828 25375 caffe.cpp:248] Starting Optimization
I1223 00:14:24.660835 25375 solver.cpp:273] Solving May_lstm
I1223 00:14:24.660837 25375 solver.cpp:274] Learning Rate Policy: step
I1223 00:14:24.664011 25375 solver.cpp:331] Iteration 0, Testing net (#0)
I1223 00:15:31.081446 25375 solver.cpp:398]     Test net output #0: loss = 45426.1 (* 1 = 45426.1 loss)
I1223 00:15:32.023139 25375 solver.cpp:219] Iteration 0 (-3.77131e+19 iter/s, 67.3603s/50 iters), loss = 45426.1
I1223 00:15:32.023176 25375 solver.cpp:238]     Train net output #0: loss = 45426.1 (* 1 = 45426.1 loss)
I1223 00:15:32.023188 25375 sgd_solver.cpp:105] Iteration 0, lr = 1e-08
I1223 00:16:24.141392 25375 solver.cpp:219] Iteration 50 (0.959385 iter/s, 52.1167s/50 iters), loss = 42850.1
I1223 00:16:24.141433 25375 solver.cpp:238]     Train net output #0: loss = 38894.5 (* 1 = 38894.5 loss)
I1223 00:16:24.141440 25375 sgd_solver.cpp:105] Iteration 50, lr = 1e-08
I1223 00:17:16.249263 25375 solver.cpp:219] Iteration 100 (0.959576 iter/s, 52.1064s/50 iters), loss = 40046.2
I1223 00:17:16.249292 25375 solver.cpp:238]     Train net output #0: loss = 33833.3 (* 1 = 33833.3 loss)
I1223 00:17:16.249297 25375 sgd_solver.cpp:105] Iteration 100, lr = 1e-08
I1223 00:18:09.135298 25375 solver.cpp:219] Iteration 150 (0.945454 iter/s, 52.8847s/50 iters), loss = 37541.3
I1223 00:18:09.135334 25375 solver.cpp:238]     Train net output #0: loss = 31614.5 (* 1 = 31614.5 loss)
I1223 00:18:09.135341 25375 sgd_solver.cpp:105] Iteration 150, lr = 1e-08
I1223 00:19:00.610787 25375 solver.cpp:219] Iteration 200 (0.971346 iter/s, 51.475s/50 iters), loss = 35395.6
I1223 00:19:00.610818 25375 solver.cpp:238]     Train net output #0: loss = 24538.9 (* 1 = 24538.9 loss)
I1223 00:19:00.610839 25375 sgd_solver.cpp:105] Iteration 200, lr = 1e-08
I1223 00:19:52.093864 25375 solver.cpp:219] Iteration 250 (0.971205 iter/s, 51.4824s/50 iters), loss = 33596.6
I1223 00:19:52.093894 25375 solver.cpp:238]     Train net output #0: loss = 22884 (* 1 = 22884 loss)
I1223 00:19:52.093900 25375 sgd_solver.cpp:105] Iteration 250, lr = 1e-08
I1223 00:20:42.388012 25375 solver.cpp:219] Iteration 300 (0.994166 iter/s, 50.2934s/50 iters), loss = 31493.3
I1223 00:20:42.388043 25375 solver.cpp:238]     Train net output #0: loss = 20851.7 (* 1 = 20851.7 loss)
I1223 00:20:42.388051 25375 sgd_solver.cpp:105] Iteration 300, lr = 1e-08
I1223 00:21:34.378197 25375 solver.cpp:219] Iteration 350 (0.961735 iter/s, 51.9894s/50 iters), loss = 28916.8
I1223 00:21:34.378227 25375 solver.cpp:238]     Train net output #0: loss = 6346.32 (* 1 = 6346.32 loss)
I1223 00:21:34.378234 25375 sgd_solver.cpp:105] Iteration 350, lr = 1e-08
I1223 00:22:26.493834 25375 solver.cpp:219] Iteration 400 (0.959421 iter/s, 52.1148s/50 iters), loss = 26589.5
I1223 00:22:26.493870 25375 solver.cpp:238]     Train net output #0: loss = 7647.67 (* 1 = 7647.67 loss)
I1223 00:22:26.493876 25375 sgd_solver.cpp:105] Iteration 400, lr = 1e-08
I1223 00:23:20.937307 25375 solver.cpp:219] Iteration 450 (0.918399 iter/s, 54.4426s/50 iters), loss = 24658.1
I1223 00:23:20.937340 25375 solver.cpp:238]     Train net output #0: loss = 8018.16 (* 1 = 8018.16 loss)
I1223 00:23:20.937347 25375 sgd_solver.cpp:105] Iteration 450, lr = 1e-08
I1223 00:24:12.942008 25375 solver.cpp:219] Iteration 500 (0.961468 iter/s, 52.0038s/50 iters), loss = 23021.8
I1223 00:24:12.942044 25375 solver.cpp:238]     Train net output #0: loss = 3361.07 (* 1 = 3361.07 loss)
I1223 00:24:12.942049 25375 sgd_solver.cpp:105] Iteration 500, lr = 1e-08
I1223 00:25:03.933059 25375 solver.cpp:219] Iteration 550 (0.980582 iter/s, 50.9901s/50 iters), loss = 21693.8
I1223 00:25:03.933099 25375 solver.cpp:238]     Train net output #0: loss = 5716.6 (* 1 = 5716.6 loss)
I1223 00:25:03.933109 25375 sgd_solver.cpp:105] Iteration 550, lr = 1e-08
I1223 00:25:58.108150 25375 solver.cpp:219] Iteration 600 (0.92295 iter/s, 54.1741s/50 iters), loss = 20473.2
I1223 00:25:58.108186 25375 solver.cpp:238]     Train net output #0: loss = 6132.98 (* 1 = 6132.98 loss)
I1223 00:25:58.108192 25375 sgd_solver.cpp:105] Iteration 600, lr = 1e-08
I1223 00:26:49.077811 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_650.caffemodel
I1223 00:26:49.627245 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_650.solverstate
I1223 00:26:49.720151 25375 solver.cpp:331] Iteration 650, Testing net (#0)
I1223 00:28:02.197739 25375 solver.cpp:398]     Test net output #0: loss = 7691.04 (* 1 = 7691.04 loss)
I1223 00:28:02.992950 25375 solver.cpp:219] Iteration 650 (0.400376 iter/s, 124.883s/50 iters), loss = 19423
I1223 00:28:02.992987 25375 solver.cpp:238]     Train net output #0: loss = 2897.03 (* 1 = 2897.03 loss)
I1223 00:28:02.992995 25375 sgd_solver.cpp:105] Iteration 650, lr = 1e-08
I1223 00:28:57.818249 25375 solver.cpp:219] Iteration 700 (0.912003 iter/s, 54.8244s/50 iters), loss = 18520.6
I1223 00:28:57.818287 25375 solver.cpp:238]     Train net output #0: loss = 5053.79 (* 1 = 5053.79 loss)
I1223 00:28:57.818295 25375 sgd_solver.cpp:105] Iteration 700, lr = 1e-08
I1223 00:29:51.267202 25375 solver.cpp:219] Iteration 750 (0.935488 iter/s, 53.448s/50 iters), loss = 17723.9
I1223 00:29:51.267237 25375 solver.cpp:238]     Train net output #0: loss = 4977.71 (* 1 = 4977.71 loss)
I1223 00:29:51.267243 25375 sgd_solver.cpp:105] Iteration 750, lr = 1e-08
I1223 00:30:46.363071 25375 solver.cpp:219] Iteration 800 (0.907525 iter/s, 55.0949s/50 iters), loss = 17003.2
I1223 00:30:46.363107 25375 solver.cpp:238]     Train net output #0: loss = 2487.96 (* 1 = 2487.96 loss)
I1223 00:30:46.363114 25375 sgd_solver.cpp:105] Iteration 800, lr = 1e-08
I1223 00:31:40.451529 25375 solver.cpp:219] Iteration 850 (0.924428 iter/s, 54.0875s/50 iters), loss = 16392.9
I1223 00:31:40.451563 25375 solver.cpp:238]     Train net output #0: loss = 5614.28 (* 1 = 5614.28 loss)
I1223 00:31:40.451570 25375 sgd_solver.cpp:105] Iteration 850, lr = 1e-08
I1223 00:32:34.553359 25375 solver.cpp:219] Iteration 900 (0.9242 iter/s, 54.1008s/50 iters), loss = 15817
I1223 00:32:34.553405 25375 solver.cpp:238]     Train net output #0: loss = 4919.38 (* 1 = 4919.38 loss)
I1223 00:32:34.553413 25375 sgd_solver.cpp:105] Iteration 900, lr = 1e-08
I1223 00:33:27.564294 25375 solver.cpp:219] Iteration 950 (0.943219 iter/s, 53.0099s/50 iters), loss = 15311.4
I1223 00:33:27.564330 25375 solver.cpp:238]     Train net output #0: loss = 1970.36 (* 1 = 1970.36 loss)
I1223 00:33:27.564337 25375 sgd_solver.cpp:105] Iteration 950, lr = 1e-08
I1223 00:34:21.887610 25375 solver.cpp:219] Iteration 1000 (0.920432 iter/s, 54.3223s/50 iters), loss = 14795.7
I1223 00:34:21.887645 25375 solver.cpp:238]     Train net output #0: loss = 4265.35 (* 1 = 4265.35 loss)
I1223 00:34:21.887650 25375 sgd_solver.cpp:105] Iteration 1000, lr = 1e-08
I1223 00:35:15.782716 25375 solver.cpp:219] Iteration 1050 (0.927745 iter/s, 53.8941s/50 iters), loss = 12938.1
I1223 00:35:15.782749 25375 solver.cpp:238]     Train net output #0: loss = 4314.67 (* 1 = 4314.67 loss)
I1223 00:35:15.782755 25375 sgd_solver.cpp:105] Iteration 1050, lr = 1e-08
I1223 00:36:11.233693 25375 solver.cpp:219] Iteration 1100 (0.901714 iter/s, 55.4499s/50 iters), loss = 11370.2
I1223 00:36:11.233731 25375 solver.cpp:238]     Train net output #0: loss = 2048.67 (* 1 = 2048.67 loss)
I1223 00:36:11.233736 25375 sgd_solver.cpp:105] Iteration 1100, lr = 1e-08
I1223 00:37:05.218933 25375 solver.cpp:219] Iteration 1150 (0.926196 iter/s, 53.9842s/50 iters), loss = 10002.3
I1223 00:37:05.218971 25375 solver.cpp:238]     Train net output #0: loss = 5053.24 (* 1 = 5053.24 loss)
I1223 00:37:05.218979 25375 sgd_solver.cpp:105] Iteration 1150, lr = 1e-08
I1223 00:37:58.515094 25375 solver.cpp:219] Iteration 1200 (0.938171 iter/s, 53.2952s/50 iters), loss = 8813.04
I1223 00:37:58.515128 25375 solver.cpp:238]     Train net output #0: loss = 4160.15 (* 1 = 4160.15 loss)
I1223 00:37:58.515136 25375 sgd_solver.cpp:105] Iteration 1200, lr = 1e-08
I1223 00:38:52.045347 25375 solver.cpp:219] Iteration 1250 (0.934069 iter/s, 53.5293s/50 iters), loss = 7755.71
I1223 00:38:52.045382 25375 solver.cpp:238]     Train net output #0: loss = 1737.18 (* 1 = 1737.18 loss)
I1223 00:38:52.045388 25375 sgd_solver.cpp:105] Iteration 1250, lr = 1e-08
I1223 00:39:44.774528 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_1300.caffemodel
I1223 00:39:45.301131 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_1300.solverstate
I1223 00:39:45.394214 25375 solver.cpp:331] Iteration 1300, Testing net (#0)
I1223 00:40:58.373512 25375 solver.cpp:398]     Test net output #0: loss = 6599.21 (* 1 = 6599.21 loss)
I1223 00:40:59.172567 25375 solver.cpp:219] Iteration 1300 (0.393314 iter/s, 127.125s/50 iters), loss = 6962.37
I1223 00:40:59.172605 25375 solver.cpp:238]     Train net output #0: loss = 3693.27 (* 1 = 3693.27 loss)
I1223 00:40:59.172613 25375 sgd_solver.cpp:105] Iteration 1300, lr = 1e-08
I1223 00:41:52.980157 25375 solver.cpp:219] Iteration 1350 (0.929253 iter/s, 53.8066s/50 iters), loss = 6538.55
I1223 00:41:52.980190 25375 solver.cpp:238]     Train net output #0: loss = 3930.29 (* 1 = 3930.29 loss)
I1223 00:41:52.980195 25375 sgd_solver.cpp:105] Iteration 1350, lr = 1e-08
I1223 00:42:45.806962 25375 solver.cpp:219] Iteration 1400 (0.946507 iter/s, 52.8258s/50 iters), loss = 6273.77
I1223 00:42:45.807006 25375 solver.cpp:238]     Train net output #0: loss = 2271.59 (* 1 = 2271.59 loss)
I1223 00:42:45.807015 25375 sgd_solver.cpp:105] Iteration 1400, lr = 1e-08
I1223 00:43:39.694933 25375 solver.cpp:219] Iteration 1450 (0.927868 iter/s, 53.887s/50 iters), loss = 6050.07
I1223 00:43:39.694975 25375 solver.cpp:238]     Train net output #0: loss = 4009.18 (* 1 = 4009.18 loss)
I1223 00:43:39.694983 25375 sgd_solver.cpp:105] Iteration 1450, lr = 1e-08
I1223 00:44:32.064508 25375 solver.cpp:219] Iteration 1500 (0.954771 iter/s, 52.3686s/50 iters), loss = 5875.26
I1223 00:44:32.064545 25375 solver.cpp:238]     Train net output #0: loss = 3616.87 (* 1 = 3616.87 loss)
I1223 00:44:32.064553 25375 sgd_solver.cpp:105] Iteration 1500, lr = 1e-08
I1223 00:45:26.235545 25375 solver.cpp:219] Iteration 1550 (0.92302 iter/s, 54.17s/50 iters), loss = 5705.08
I1223 00:45:26.235580 25375 solver.cpp:238]     Train net output #0: loss = 1937.97 (* 1 = 1937.97 loss)
I1223 00:45:26.235586 25375 sgd_solver.cpp:105] Iteration 1550, lr = 1e-08
I1223 00:46:20.284013 25375 solver.cpp:219] Iteration 1600 (0.925113 iter/s, 54.0475s/50 iters), loss = 5583.7
I1223 00:46:20.284046 25375 solver.cpp:238]     Train net output #0: loss = 4025.26 (* 1 = 4025.26 loss)
I1223 00:46:20.284052 25375 sgd_solver.cpp:105] Iteration 1600, lr = 1e-08
I1223 00:47:15.174939 25375 solver.cpp:219] Iteration 1650 (0.910914 iter/s, 54.8899s/50 iters), loss = 5463.91
I1223 00:47:15.174976 25375 solver.cpp:238]     Train net output #0: loss = 3590.9 (* 1 = 3590.9 loss)
I1223 00:47:15.174983 25375 sgd_solver.cpp:105] Iteration 1650, lr = 1e-08
I1223 00:48:08.970598 25375 solver.cpp:219] Iteration 1700 (0.92946 iter/s, 53.7947s/50 iters), loss = 5349.7
I1223 00:48:08.970635 25375 solver.cpp:238]     Train net output #0: loss = 1630.66 (* 1 = 1630.66 loss)
I1223 00:48:08.970643 25375 sgd_solver.cpp:105] Iteration 1700, lr = 1e-08
I1223 00:49:03.041998 25375 solver.cpp:219] Iteration 1750 (0.924721 iter/s, 54.0704s/50 iters), loss = 5252.19
I1223 00:49:03.042039 25375 solver.cpp:238]     Train net output #0: loss = 3766.75 (* 1 = 3766.75 loss)
I1223 00:49:03.042047 25375 sgd_solver.cpp:105] Iteration 1750, lr = 1e-08
I1223 00:49:57.651329 25375 solver.cpp:219] Iteration 1800 (0.915612 iter/s, 54.6083s/50 iters), loss = 5159.79
I1223 00:49:57.651365 25375 solver.cpp:238]     Train net output #0: loss = 3361.22 (* 1 = 3361.22 loss)
I1223 00:49:57.651372 25375 sgd_solver.cpp:105] Iteration 1800, lr = 1e-08
I1223 00:50:53.746919 25375 solver.cpp:219] Iteration 1850 (0.891352 iter/s, 56.0945s/50 iters), loss = 5045.49
I1223 00:50:53.746955 25375 solver.cpp:238]     Train net output #0: loss = 1385.78 (* 1 = 1385.78 loss)
I1223 00:50:53.746961 25375 sgd_solver.cpp:105] Iteration 1850, lr = 1e-08
I1223 00:51:48.489917 25375 solver.cpp:219] Iteration 1900 (0.913376 iter/s, 54.742s/50 iters), loss = 4954.14
I1223 00:51:48.489950 25375 solver.cpp:238]     Train net output #0: loss = 3812.84 (* 1 = 3812.84 loss)
I1223 00:51:48.489956 25375 sgd_solver.cpp:105] Iteration 1900, lr = 1e-08
I1223 00:52:41.034361 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_1950.caffemodel
I1223 00:52:41.564147 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_1950.solverstate
I1223 00:52:41.657016 25375 solver.cpp:331] Iteration 1950, Testing net (#0)
I1223 00:53:55.487223 25375 solver.cpp:398]     Test net output #0: loss = 6372.36 (* 1 = 6372.36 loss)
I1223 00:53:56.284620 25375 solver.cpp:219] Iteration 1950 (0.39126 iter/s, 127.792s/50 iters), loss = 4840.22
I1223 00:53:56.284657 25375 solver.cpp:238]     Train net output #0: loss = 2932.74 (* 1 = 2932.74 loss)
I1223 00:53:56.284663 25375 sgd_solver.cpp:105] Iteration 1950, lr = 1e-08
I1223 00:54:49.486218 25375 solver.cpp:219] Iteration 2000 (0.939838 iter/s, 53.2007s/50 iters), loss = 4774.42
I1223 00:54:49.486268 25375 solver.cpp:238]     Train net output #0: loss = 1462.11 (* 1 = 1462.11 loss)
I1223 00:54:49.486279 25375 sgd_solver.cpp:105] Iteration 2000, lr = 1e-08
I1223 00:55:43.585880 25375 solver.cpp:219] Iteration 2050 (0.924237 iter/s, 54.0987s/50 iters), loss = 4695.46
I1223 00:55:43.585925 25375 solver.cpp:238]     Train net output #0: loss = 3670.96 (* 1 = 3670.96 loss)
I1223 00:55:43.585933 25375 sgd_solver.cpp:105] Iteration 2050, lr = 1e-08
I1223 00:56:37.920442 25375 solver.cpp:219] Iteration 2100 (0.920242 iter/s, 54.3335s/50 iters), loss = 4610.67
I1223 00:56:37.920481 25375 solver.cpp:238]     Train net output #0: loss = 3646.82 (* 1 = 3646.82 loss)
I1223 00:56:37.920490 25375 sgd_solver.cpp:105] Iteration 2100, lr = 1e-08
I1223 00:57:31.327962 25375 solver.cpp:219] Iteration 2150 (0.936215 iter/s, 53.4065s/50 iters), loss = 4557.08
I1223 00:57:31.328004 25375 solver.cpp:238]     Train net output #0: loss = 1189.92 (* 1 = 1189.92 loss)
I1223 00:57:31.328012 25375 sgd_solver.cpp:105] Iteration 2150, lr = 1e-08
I1223 00:58:24.332208 25375 solver.cpp:219] Iteration 2200 (0.943338 iter/s, 53.0033s/50 iters), loss = 4495.46
I1223 00:58:24.332247 25375 solver.cpp:238]     Train net output #0: loss = 3490.46 (* 1 = 3490.46 loss)
I1223 00:58:24.332253 25375 sgd_solver.cpp:105] Iteration 2200, lr = 1e-08
I1223 00:59:17.935757 25375 solver.cpp:219] Iteration 2250 (0.932792 iter/s, 53.6025s/50 iters), loss = 4429.99
I1223 00:59:17.935793 25375 solver.cpp:238]     Train net output #0: loss = 2705.66 (* 1 = 2705.66 loss)
I1223 00:59:17.935801 25375 sgd_solver.cpp:105] Iteration 2250, lr = 1e-08
I1223 01:00:10.698459 25375 solver.cpp:219] Iteration 2300 (0.947657 iter/s, 52.7617s/50 iters), loss = 4371.25
I1223 01:00:10.698506 25375 solver.cpp:238]     Train net output #0: loss = 1533.21 (* 1 = 1533.21 loss)
I1223 01:00:10.698515 25375 sgd_solver.cpp:105] Iteration 2300, lr = 1e-08
I1223 01:01:05.241050 25375 solver.cpp:219] Iteration 2350 (0.916732 iter/s, 54.5416s/50 iters), loss = 4319.62
I1223 01:01:05.241086 25375 solver.cpp:238]     Train net output #0: loss = 3070.6 (* 1 = 3070.6 loss)
I1223 01:01:05.241091 25375 sgd_solver.cpp:105] Iteration 2350, lr = 1e-08
I1223 01:01:59.099963 25375 solver.cpp:219] Iteration 2400 (0.928369 iter/s, 53.8579s/50 iters), loss = 4256.23
I1223 01:01:59.099998 25375 solver.cpp:238]     Train net output #0: loss = 3372.69 (* 1 = 3372.69 loss)
I1223 01:01:59.100005 25375 sgd_solver.cpp:105] Iteration 2400, lr = 1e-08
I1223 01:02:54.549123 25375 solver.cpp:219] Iteration 2450 (0.901744 iter/s, 55.4481s/50 iters), loss = 4198.02
I1223 01:02:54.549151 25375 solver.cpp:238]     Train net output #0: loss = 1222.31 (* 1 = 1222.31 loss)
I1223 01:02:54.549159 25375 sgd_solver.cpp:105] Iteration 2450, lr = 1e-08
I1223 01:03:47.453086 25375 solver.cpp:219] Iteration 2500 (0.945126 iter/s, 52.903s/50 iters), loss = 4142.5
I1223 01:03:47.453124 25375 solver.cpp:238]     Train net output #0: loss = 3332.91 (* 1 = 3332.91 loss)
I1223 01:03:47.453131 25375 sgd_solver.cpp:105] Iteration 2500, lr = 1e-08
I1223 01:04:41.955060 25375 solver.cpp:219] Iteration 2550 (0.917415 iter/s, 54.5009s/50 iters), loss = 4078.09
I1223 01:04:41.955096 25375 solver.cpp:238]     Train net output #0: loss = 2709.71 (* 1 = 2709.71 loss)
I1223 01:04:41.955103 25375 sgd_solver.cpp:105] Iteration 2550, lr = 1e-08
I1223 01:05:34.424146 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_2600.caffemodel
I1223 01:05:34.953399 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_2600.solverstate
I1223 01:05:35.046051 25375 solver.cpp:331] Iteration 2600, Testing net (#0)
I1223 01:06:47.304826 25375 solver.cpp:398]     Test net output #0: loss = 5962.9 (* 1 = 5962.9 loss)
I1223 01:06:48.104351 25375 solver.cpp:219] Iteration 2600 (0.396363 iter/s, 126.147s/50 iters), loss = 4042.31
I1223 01:06:48.104393 25375 solver.cpp:238]     Train net output #0: loss = 1047.19 (* 1 = 1047.19 loss)
I1223 01:06:48.104400 25375 sgd_solver.cpp:105] Iteration 2600, lr = 1e-08
I1223 01:07:42.185698 25375 solver.cpp:219] Iteration 2650 (0.92455 iter/s, 54.0804s/50 iters), loss = 4006.33
I1223 01:07:42.185735 25375 solver.cpp:238]     Train net output #0: loss = 3920.18 (* 1 = 3920.18 loss)
I1223 01:07:42.185742 25375 sgd_solver.cpp:105] Iteration 2650, lr = 1e-08
I1223 01:08:37.027153 25375 solver.cpp:219] Iteration 2700 (0.911736 iter/s, 54.8404s/50 iters), loss = 3963.22
I1223 01:08:37.027195 25375 solver.cpp:238]     Train net output #0: loss = 2771.89 (* 1 = 2771.89 loss)
I1223 01:08:37.027204 25375 sgd_solver.cpp:105] Iteration 2700, lr = 1e-08
I1223 01:09:30.464421 25375 solver.cpp:219] Iteration 2750 (0.935694 iter/s, 53.4363s/50 iters), loss = 3923.65
I1223 01:09:30.464464 25375 solver.cpp:238]     Train net output #0: loss = 1200.61 (* 1 = 1200.61 loss)
I1223 01:09:30.464474 25375 sgd_solver.cpp:105] Iteration 2750, lr = 1e-08
I1223 01:10:26.625394 25375 solver.cpp:219] Iteration 2800 (0.890315 iter/s, 56.1599s/50 iters), loss = 3887.54
I1223 01:10:26.625427 25375 solver.cpp:238]     Train net output #0: loss = 2956.77 (* 1 = 2956.77 loss)
I1223 01:10:26.625433 25375 sgd_solver.cpp:105] Iteration 2800, lr = 1e-08
I1223 01:11:21.868542 25375 solver.cpp:219] Iteration 2850 (0.905106 iter/s, 55.2421s/50 iters), loss = 3854.52
I1223 01:11:21.868577 25375 solver.cpp:238]     Train net output #0: loss = 2985.42 (* 1 = 2985.42 loss)
I1223 01:11:21.868585 25375 sgd_solver.cpp:105] Iteration 2850, lr = 1e-08
I1223 01:12:16.164094 25375 solver.cpp:219] Iteration 2900 (0.920903 iter/s, 54.2945s/50 iters), loss = 3816.87
I1223 01:12:16.164131 25375 solver.cpp:238]     Train net output #0: loss = 1261.04 (* 1 = 1261.04 loss)
I1223 01:12:16.164139 25375 sgd_solver.cpp:105] Iteration 2900, lr = 1e-08
I1223 01:13:10.136840 25375 solver.cpp:219] Iteration 2950 (0.926411 iter/s, 53.9717s/50 iters), loss = 3786.43
I1223 01:13:10.136876 25375 solver.cpp:238]     Train net output #0: loss = 3339.3 (* 1 = 3339.3 loss)
I1223 01:13:10.136883 25375 sgd_solver.cpp:105] Iteration 2950, lr = 1e-08
I1223 01:14:03.166510 25375 solver.cpp:219] Iteration 3000 (0.942886 iter/s, 53.0287s/50 iters), loss = 3741.08
I1223 01:14:03.166551 25375 solver.cpp:238]     Train net output #0: loss = 2594.41 (* 1 = 2594.41 loss)
I1223 01:14:03.166561 25375 sgd_solver.cpp:105] Iteration 3000, lr = 1e-08
I1223 01:14:57.456288 25375 solver.cpp:219] Iteration 3050 (0.921001 iter/s, 54.2887s/50 iters), loss = 3715.38
I1223 01:14:57.456328 25375 solver.cpp:238]     Train net output #0: loss = 1034.57 (* 1 = 1034.57 loss)
I1223 01:14:57.456336 25375 sgd_solver.cpp:105] Iteration 3050, lr = 1e-08
I1223 01:15:51.992581 25375 solver.cpp:219] Iteration 3100 (0.916838 iter/s, 54.5353s/50 iters), loss = 3684.25
I1223 01:15:51.992619 25375 solver.cpp:238]     Train net output #0: loss = 2989.77 (* 1 = 2989.77 loss)
I1223 01:15:51.992624 25375 sgd_solver.cpp:105] Iteration 3100, lr = 1e-08
I1223 01:16:47.422871 25375 solver.cpp:219] Iteration 3150 (0.902051 iter/s, 55.4292s/50 iters), loss = 3649.81
I1223 01:16:47.422909 25375 solver.cpp:238]     Train net output #0: loss = 2534.01 (* 1 = 2534.01 loss)
I1223 01:16:47.422915 25375 sgd_solver.cpp:105] Iteration 3150, lr = 1e-08
I1223 01:17:41.420495 25375 solver.cpp:219] Iteration 3200 (0.925984 iter/s, 53.9966s/50 iters), loss = 3620.68
I1223 01:17:41.420531 25375 solver.cpp:238]     Train net output #0: loss = 1126 (* 1 = 1126 loss)
I1223 01:17:41.420537 25375 sgd_solver.cpp:105] Iteration 3200, lr = 1e-08
I1223 01:18:33.940340 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_3250.caffemodel
I1223 01:18:34.446411 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_3250.solverstate
I1223 01:18:34.528940 25375 solver.cpp:331] Iteration 3250, Testing net (#0)
I1223 01:19:46.502336 25375 solver.cpp:398]     Test net output #0: loss = 6324.01 (* 1 = 6324.01 loss)
I1223 01:19:47.301041 25375 solver.cpp:219] Iteration 3250 (0.397209 iter/s, 125.878s/50 iters), loss = 3601.53
I1223 01:19:47.301080 25375 solver.cpp:238]     Train net output #0: loss = 3363.41 (* 1 = 3363.41 loss)
I1223 01:19:47.301086 25375 sgd_solver.cpp:105] Iteration 3250, lr = 1e-08
I1223 01:20:42.106896 25375 solver.cpp:219] Iteration 3300 (0.912328 iter/s, 54.8049s/50 iters), loss = 3573.56
I1223 01:20:42.106933 25375 solver.cpp:238]     Train net output #0: loss = 2753.53 (* 1 = 2753.53 loss)
I1223 01:20:42.106940 25375 sgd_solver.cpp:105] Iteration 3300, lr = 1e-08
I1223 01:21:35.944545 25375 solver.cpp:219] Iteration 3350 (0.928735 iter/s, 53.8367s/50 iters), loss = 3541.9
I1223 01:21:35.944582 25375 solver.cpp:238]     Train net output #0: loss = 1011.37 (* 1 = 1011.37 loss)
I1223 01:21:35.944588 25375 sgd_solver.cpp:105] Iteration 3350, lr = 1e-08
I1223 01:22:30.547338 25375 solver.cpp:219] Iteration 3400 (0.915721 iter/s, 54.6018s/50 iters), loss = 3519.5
I1223 01:22:30.547377 25375 solver.cpp:238]     Train net output #0: loss = 2707.32 (* 1 = 2707.32 loss)
I1223 01:22:30.547386 25375 sgd_solver.cpp:105] Iteration 3400, lr = 1e-08
I1223 01:23:24.508462 25375 solver.cpp:219] Iteration 3450 (0.92661 iter/s, 53.9601s/50 iters), loss = 3515.73
I1223 01:23:24.508497 25375 solver.cpp:238]     Train net output #0: loss = 2617.94 (* 1 = 2617.94 loss)
I1223 01:23:24.508504 25375 sgd_solver.cpp:105] Iteration 3450, lr = 1e-08
I1223 01:24:19.604192 25375 solver.cpp:219] Iteration 3500 (0.907528 iter/s, 55.0947s/50 iters), loss = 3508.5
I1223 01:24:19.604236 25375 solver.cpp:238]     Train net output #0: loss = 1018.49 (* 1 = 1018.49 loss)
I1223 01:24:19.604244 25375 sgd_solver.cpp:105] Iteration 3500, lr = 1e-08
I1223 01:25:14.275112 25375 solver.cpp:219] Iteration 3550 (0.91458 iter/s, 54.6699s/50 iters), loss = 3496.68
I1223 01:25:14.275154 25375 solver.cpp:238]     Train net output #0: loss = 3518.96 (* 1 = 3518.96 loss)
I1223 01:25:14.275163 25375 sgd_solver.cpp:105] Iteration 3550, lr = 1e-08
I1223 01:26:07.285168 25375 solver.cpp:219] Iteration 3600 (0.943235 iter/s, 53.0091s/50 iters), loss = 3460.5
I1223 01:26:07.285210 25375 solver.cpp:238]     Train net output #0: loss = 2677.55 (* 1 = 2677.55 loss)
I1223 01:26:07.285218 25375 sgd_solver.cpp:105] Iteration 3600, lr = 1e-08
I1223 01:27:02.578451 25375 solver.cpp:219] Iteration 3650 (0.904286 iter/s, 55.2922s/50 iters), loss = 3446.76
I1223 01:27:02.578487 25375 solver.cpp:238]     Train net output #0: loss = 1086.05 (* 1 = 1086.05 loss)
I1223 01:27:02.578495 25375 sgd_solver.cpp:105] Iteration 3650, lr = 1e-08
I1223 01:27:58.271327 25375 solver.cpp:219] Iteration 3700 (0.897798 iter/s, 55.6918s/50 iters), loss = 3427.23
I1223 01:27:58.271368 25375 solver.cpp:238]     Train net output #0: loss = 2759.51 (* 1 = 2759.51 loss)
I1223 01:27:58.271374 25375 sgd_solver.cpp:105] Iteration 3700, lr = 1e-08
I1223 01:28:52.740784 25375 solver.cpp:219] Iteration 3750 (0.917963 iter/s, 54.4684s/50 iters), loss = 3393.71
I1223 01:28:52.740824 25375 solver.cpp:238]     Train net output #0: loss = 2809.75 (* 1 = 2809.75 loss)
I1223 01:28:52.740833 25375 sgd_solver.cpp:105] Iteration 3750, lr = 1e-08
I1223 01:29:48.305577 25375 solver.cpp:219] Iteration 3800 (0.899867 iter/s, 55.5637s/50 iters), loss = 3379.42
I1223 01:29:48.305613 25375 solver.cpp:238]     Train net output #0: loss = 918.881 (* 1 = 918.881 loss)
I1223 01:29:48.305620 25375 sgd_solver.cpp:105] Iteration 3800, lr = 1e-08
I1223 01:30:42.075263 25375 solver.cpp:219] Iteration 3850 (0.92991 iter/s, 53.7687s/50 iters), loss = 3359.01
I1223 01:30:42.075302 25375 solver.cpp:238]     Train net output #0: loss = 2761.37 (* 1 = 2761.37 loss)
I1223 01:30:42.075310 25375 sgd_solver.cpp:105] Iteration 3850, lr = 1e-08
I1223 01:31:36.175132 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_3900.caffemodel
I1223 01:31:36.697878 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_3900.solverstate
I1223 01:31:36.790407 25375 solver.cpp:331] Iteration 3900, Testing net (#0)
I1223 01:32:49.719247 25375 solver.cpp:398]     Test net output #0: loss = 6410.56 (* 1 = 6410.56 loss)
I1223 01:32:50.518332 25375 solver.cpp:219] Iteration 3900 (0.389285 iter/s, 128.441s/50 iters), loss = 3349.79
I1223 01:32:50.518373 25375 solver.cpp:238]     Train net output #0: loss = 2437.04 (* 1 = 2437.04 loss)
I1223 01:32:50.518380 25375 sgd_solver.cpp:105] Iteration 3900, lr = 1e-08
I1223 01:33:44.210517 25375 solver.cpp:219] Iteration 3950 (0.931251 iter/s, 53.6912s/50 iters), loss = 3348.93
I1223 01:33:44.210551 25375 solver.cpp:238]     Train net output #0: loss = 938.66 (* 1 = 938.66 loss)
I1223 01:33:44.210556 25375 sgd_solver.cpp:105] Iteration 3950, lr = 1e-08
I1223 01:34:38.162973 25375 solver.cpp:219] Iteration 4000 (0.926759 iter/s, 53.9515s/50 iters), loss = 3338.8
I1223 01:34:38.163008 25375 solver.cpp:238]     Train net output #0: loss = 2687.31 (* 1 = 2687.31 loss)
I1223 01:34:38.163014 25375 sgd_solver.cpp:105] Iteration 4000, lr = 1e-08
I1223 01:35:32.108569 25375 solver.cpp:219] Iteration 4050 (0.926877 iter/s, 53.9446s/50 iters), loss = 3316.94
I1223 01:35:32.108598 25375 solver.cpp:238]     Train net output #0: loss = 2153.74 (* 1 = 2153.74 loss)
I1223 01:35:32.108604 25375 sgd_solver.cpp:105] Iteration 4050, lr = 1e-08
I1223 01:36:25.261632 25375 solver.cpp:219] Iteration 4100 (0.940697 iter/s, 53.1521s/50 iters), loss = 3295.04
I1223 01:36:25.261667 25375 solver.cpp:238]     Train net output #0: loss = 903.073 (* 1 = 903.073 loss)
I1223 01:36:25.261673 25375 sgd_solver.cpp:105] Iteration 4100, lr = 1e-08
I1223 01:37:19.566689 25375 solver.cpp:219] Iteration 4150 (0.920742 iter/s, 54.304s/50 iters), loss = 3284.02
I1223 01:37:19.566730 25375 solver.cpp:238]     Train net output #0: loss = 3311.94 (* 1 = 3311.94 loss)
I1223 01:37:19.566736 25375 sgd_solver.cpp:105] Iteration 4150, lr = 1e-08
I1223 01:38:14.207253 25375 solver.cpp:219] Iteration 4200 (0.915088 iter/s, 54.6395s/50 iters), loss = 3278.43
I1223 01:38:14.207288 25375 solver.cpp:238]     Train net output #0: loss = 2233.97 (* 1 = 2233.97 loss)
I1223 01:38:14.207298 25375 sgd_solver.cpp:105] Iteration 4200, lr = 1e-08
I1223 01:39:08.835518 25375 solver.cpp:219] Iteration 4250 (0.915294 iter/s, 54.6272s/50 iters), loss = 3258.96
I1223 01:39:08.835554 25375 solver.cpp:238]     Train net output #0: loss = 929.664 (* 1 = 929.664 loss)
I1223 01:39:08.835561 25375 sgd_solver.cpp:105] Iteration 4250, lr = 1e-08
I1223 01:40:01.842996 25375 solver.cpp:219] Iteration 4300 (0.943281 iter/s, 53.0065s/50 iters), loss = 3249.19
I1223 01:40:01.843035 25375 solver.cpp:238]     Train net output #0: loss = 2960.3 (* 1 = 2960.3 loss)
I1223 01:40:01.843042 25375 sgd_solver.cpp:105] Iteration 4300, lr = 1e-08
I1223 01:40:56.544942 25375 solver.cpp:219] Iteration 4350 (0.914062 iter/s, 54.7009s/50 iters), loss = 3242.05
I1223 01:40:56.544982 25375 solver.cpp:238]     Train net output #0: loss = 2577.23 (* 1 = 2577.23 loss)
I1223 01:40:56.544991 25375 sgd_solver.cpp:105] Iteration 4350, lr = 1e-08
I1223 01:41:51.540735 25375 solver.cpp:219] Iteration 4400 (0.909178 iter/s, 54.9948s/50 iters), loss = 3241.8
I1223 01:41:51.540771 25375 solver.cpp:238]     Train net output #0: loss = 923.437 (* 1 = 923.437 loss)
I1223 01:41:51.540777 25375 sgd_solver.cpp:105] Iteration 4400, lr = 1e-08
I1223 01:42:45.682072 25375 solver.cpp:219] Iteration 4450 (0.923526 iter/s, 54.1403s/50 iters), loss = 3213.17
I1223 01:42:45.682109 25375 solver.cpp:238]     Train net output #0: loss = 3416.1 (* 1 = 3416.1 loss)
I1223 01:42:45.682116 25375 sgd_solver.cpp:105] Iteration 4450, lr = 1e-08
I1223 01:43:39.279798 25375 solver.cpp:219] Iteration 4500 (0.932893 iter/s, 53.5967s/50 iters), loss = 3196.41
I1223 01:43:39.279830 25375 solver.cpp:238]     Train net output #0: loss = 2365.62 (* 1 = 2365.62 loss)
I1223 01:43:39.279836 25375 sgd_solver.cpp:105] Iteration 4500, lr = 1e-08
I1223 01:44:32.278281 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_4550.caffemodel
I1223 01:44:32.802233 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_4550.solverstate
I1223 01:44:32.894569 25375 solver.cpp:331] Iteration 4550, Testing net (#0)
I1223 01:45:45.733958 25375 solver.cpp:398]     Test net output #0: loss = 6356.47 (* 1 = 6356.47 loss)
I1223 01:45:46.532352 25375 solver.cpp:219] Iteration 4550 (0.392927 iter/s, 127.25s/50 iters), loss = 3174.7
I1223 01:45:46.532387 25375 solver.cpp:238]     Train net output #0: loss = 869.734 (* 1 = 869.734 loss)
I1223 01:45:46.532397 25375 sgd_solver.cpp:105] Iteration 4550, lr = 1e-08
I1223 01:46:40.359431 25375 solver.cpp:219] Iteration 4600 (0.928917 iter/s, 53.8261s/50 iters), loss = 3173.47
I1223 01:46:40.359467 25375 solver.cpp:238]     Train net output #0: loss = 2689.46 (* 1 = 2689.46 loss)
I1223 01:46:40.359472 25375 sgd_solver.cpp:105] Iteration 4600, lr = 1e-08
I1223 01:47:33.717362 25375 solver.cpp:219] Iteration 4650 (0.937085 iter/s, 53.357s/50 iters), loss = 3150.02
I1223 01:47:33.717397 25375 solver.cpp:238]     Train net output #0: loss = 2451.11 (* 1 = 2451.11 loss)
I1223 01:47:33.717404 25375 sgd_solver.cpp:105] Iteration 4650, lr = 1e-08
I1223 01:48:28.125535 25375 solver.cpp:219] Iteration 4700 (0.918997 iter/s, 54.4072s/50 iters), loss = 3144.99
I1223 01:48:28.125576 25375 solver.cpp:238]     Train net output #0: loss = 865.873 (* 1 = 865.873 loss)
I1223 01:48:28.125583 25375 sgd_solver.cpp:105] Iteration 4700, lr = 1e-08
I1223 01:49:22.758621 25375 solver.cpp:219] Iteration 4750 (0.915213 iter/s, 54.6321s/50 iters), loss = 3144.75
I1223 01:49:22.758662 25375 solver.cpp:238]     Train net output #0: loss = 2753.04 (* 1 = 2753.04 loss)
I1223 01:49:22.758671 25375 sgd_solver.cpp:105] Iteration 4750, lr = 1e-08
I1223 01:50:17.958045 25375 solver.cpp:219] Iteration 4800 (0.905824 iter/s, 55.1984s/50 iters), loss = 3130.69
I1223 01:50:17.958083 25375 solver.cpp:238]     Train net output #0: loss = 2612.02 (* 1 = 2612.02 loss)
I1223 01:50:17.958091 25375 sgd_solver.cpp:105] Iteration 4800, lr = 1e-08
I1223 01:51:13.323966 25375 solver.cpp:219] Iteration 4850 (0.903099 iter/s, 55.3649s/50 iters), loss = 3126.27
I1223 01:51:13.324002 25375 solver.cpp:238]     Train net output #0: loss = 845.308 (* 1 = 845.308 loss)
I1223 01:51:13.324008 25375 sgd_solver.cpp:105] Iteration 4850, lr = 1e-08
I1223 01:52:08.603245 25375 solver.cpp:219] Iteration 4900 (0.904515 iter/s, 55.2782s/50 iters), loss = 3113.73
I1223 01:52:08.603282 25375 solver.cpp:238]     Train net output #0: loss = 2973.24 (* 1 = 2973.24 loss)
I1223 01:52:08.603291 25375 sgd_solver.cpp:105] Iteration 4900, lr = 1e-08
I1223 01:53:03.868855 25375 solver.cpp:219] Iteration 4950 (0.904739 iter/s, 55.2646s/50 iters), loss = 3103.99
I1223 01:53:03.868885 25375 solver.cpp:238]     Train net output #0: loss = 2478.18 (* 1 = 2478.18 loss)
I1223 01:53:03.868891 25375 sgd_solver.cpp:105] Iteration 4950, lr = 1e-08
I1223 01:53:58.210274 25375 solver.cpp:219] Iteration 5000 (0.920126 iter/s, 54.3404s/50 iters), loss = 3103.65
I1223 01:53:58.210309 25375 solver.cpp:238]     Train net output #0: loss = 853.256 (* 1 = 853.256 loss)
I1223 01:53:58.210316 25375 sgd_solver.cpp:105] Iteration 5000, lr = 1e-08
I1223 01:54:53.237238 25375 solver.cpp:219] Iteration 5050 (0.908663 iter/s, 55.0259s/50 iters), loss = 3090.72
I1223 01:54:53.237279 25375 solver.cpp:238]     Train net output #0: loss = 3224.94 (* 1 = 3224.94 loss)
I1223 01:54:53.237288 25375 sgd_solver.cpp:105] Iteration 5050, lr = 1e-08
I1223 01:55:49.050453 25375 solver.cpp:219] Iteration 5100 (0.895862 iter/s, 55.8122s/50 iters), loss = 3087.68
I1223 01:55:49.050493 25375 solver.cpp:238]     Train net output #0: loss = 2731.98 (* 1 = 2731.98 loss)
I1223 01:55:49.050499 25375 sgd_solver.cpp:105] Iteration 5100, lr = 1e-08
I1223 01:56:42.445304 25375 solver.cpp:219] Iteration 5150 (0.936438 iter/s, 53.3938s/50 iters), loss = 3069.92
I1223 01:56:42.445340 25375 solver.cpp:238]     Train net output #0: loss = 835.258 (* 1 = 835.258 loss)
I1223 01:56:42.445346 25375 sgd_solver.cpp:105] Iteration 5150, lr = 1e-08
I1223 01:57:35.496619 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_5200.caffemodel
I1223 01:57:36.369078 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_5200.solverstate
I1223 01:57:36.455781 25375 solver.cpp:331] Iteration 5200, Testing net (#0)
I1223 01:58:50.144206 25375 solver.cpp:398]     Test net output #0: loss = 5997.89 (* 1 = 5997.89 loss)
I1223 01:58:50.938791 25375 solver.cpp:219] Iteration 5200 (0.389132 iter/s, 128.491s/50 iters), loss = 3057.75
I1223 01:58:50.938832 25375 solver.cpp:238]     Train net output #0: loss = 2980.45 (* 1 = 2980.45 loss)
I1223 01:58:50.938838 25375 sgd_solver.cpp:105] Iteration 5200, lr = 1e-08
I1223 01:59:44.071470 25375 solver.cpp:219] Iteration 5250 (0.941057 iter/s, 53.1317s/50 iters), loss = 3052.74
I1223 01:59:44.071504 25375 solver.cpp:238]     Train net output #0: loss = 2080.84 (* 1 = 2080.84 loss)
I1223 01:59:44.071511 25375 sgd_solver.cpp:105] Iteration 5250, lr = 1e-08
I1223 02:00:37.432593 25375 solver.cpp:219] Iteration 5300 (0.937029 iter/s, 53.3602s/50 iters), loss = 3045.94
I1223 02:00:37.432626 25375 solver.cpp:238]     Train net output #0: loss = 913.31 (* 1 = 913.31 loss)
I1223 02:00:37.432631 25375 sgd_solver.cpp:105] Iteration 5300, lr = 1e-08
I1223 02:01:31.861428 25375 solver.cpp:219] Iteration 5350 (0.918648 iter/s, 54.4278s/50 iters), loss = 3041.09
I1223 02:01:31.861469 25375 solver.cpp:238]     Train net output #0: loss = 2495.33 (* 1 = 2495.33 loss)
I1223 02:01:31.861475 25375 sgd_solver.cpp:105] Iteration 5350, lr = 1e-08
I1223 02:02:24.435696 25375 solver.cpp:219] Iteration 5400 (0.951054 iter/s, 52.5733s/50 iters), loss = 3023.51
I1223 02:02:24.435734 25375 solver.cpp:238]     Train net output #0: loss = 2341.05 (* 1 = 2341.05 loss)
I1223 02:02:24.435740 25375 sgd_solver.cpp:105] Iteration 5400, lr = 1e-08
I1223 02:03:18.254128 25375 solver.cpp:219] Iteration 5450 (0.929067 iter/s, 53.8174s/50 iters), loss = 3024.68
I1223 02:03:18.254169 25375 solver.cpp:238]     Train net output #0: loss = 898.338 (* 1 = 898.338 loss)
I1223 02:03:18.254176 25375 sgd_solver.cpp:105] Iteration 5450, lr = 1e-08
I1223 02:04:14.996608 25375 solver.cpp:219] Iteration 5500 (0.881191 iter/s, 56.7414s/50 iters), loss = 3009.4
I1223 02:04:14.996639 25375 solver.cpp:238]     Train net output #0: loss = 2626.05 (* 1 = 2626.05 loss)
I1223 02:04:14.996645 25375 sgd_solver.cpp:105] Iteration 5500, lr = 1e-08
I1223 02:05:08.516921 25375 solver.cpp:219] Iteration 5550 (0.934242 iter/s, 53.5193s/50 iters), loss = 3007.24
I1223 02:05:08.516960 25375 solver.cpp:238]     Train net output #0: loss = 2177.13 (* 1 = 2177.13 loss)
I1223 02:05:08.516968 25375 sgd_solver.cpp:105] Iteration 5550, lr = 1e-08
I1223 02:06:02.825280 25375 solver.cpp:219] Iteration 5600 (0.920686 iter/s, 54.3073s/50 iters), loss = 2992.81
I1223 02:06:02.825315 25375 solver.cpp:238]     Train net output #0: loss = 848.946 (* 1 = 848.946 loss)
I1223 02:06:02.825322 25375 sgd_solver.cpp:105] Iteration 5600, lr = 1e-08
I1223 02:06:56.417183 25375 solver.cpp:219] Iteration 5650 (0.932994 iter/s, 53.5909s/50 iters), loss = 2984.33
I1223 02:06:56.417224 25375 solver.cpp:238]     Train net output #0: loss = 3077.79 (* 1 = 3077.79 loss)
I1223 02:06:56.417234 25375 sgd_solver.cpp:105] Iteration 5650, lr = 1e-08
I1223 02:07:50.239951 25375 solver.cpp:219] Iteration 5700 (0.928992 iter/s, 53.8218s/50 iters), loss = 2968.23
I1223 02:07:50.239984 25375 solver.cpp:238]     Train net output #0: loss = 2353.32 (* 1 = 2353.32 loss)
I1223 02:07:50.239992 25375 sgd_solver.cpp:105] Iteration 5700, lr = 1e-08
I1223 02:08:44.215533 25375 solver.cpp:219] Iteration 5750 (0.926362 iter/s, 53.9746s/50 iters), loss = 2964.07
I1223 02:08:44.215569 25375 solver.cpp:238]     Train net output #0: loss = 820.541 (* 1 = 820.541 loss)
I1223 02:08:44.215575 25375 sgd_solver.cpp:105] Iteration 5750, lr = 1e-08
I1223 02:09:38.612695 25375 solver.cpp:219] Iteration 5800 (0.919183 iter/s, 54.3961s/50 iters), loss = 2962.98
I1223 02:09:38.612733 25375 solver.cpp:238]     Train net output #0: loss = 2393.14 (* 1 = 2393.14 loss)
I1223 02:09:38.612740 25375 sgd_solver.cpp:105] Iteration 5800, lr = 1e-08
I1223 02:10:30.860821 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_5850.caffemodel
I1223 02:10:31.487818 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_5850.solverstate
I1223 02:10:31.580618 25375 solver.cpp:331] Iteration 5850, Testing net (#0)
I1223 02:11:44.295542 25375 solver.cpp:398]     Test net output #0: loss = 6777.8 (* 1 = 6777.8 loss)
I1223 02:11:45.095831 25375 solver.cpp:219] Iteration 5850 (0.395317 iter/s, 126.481s/50 iters), loss = 2950.37
I1223 02:11:45.095868 25375 solver.cpp:238]     Train net output #0: loss = 1970.34 (* 1 = 1970.34 loss)
I1223 02:11:45.095875 25375 sgd_solver.cpp:105] Iteration 5850, lr = 1e-08
I1223 02:12:37.190299 25375 solver.cpp:219] Iteration 5900 (0.959812 iter/s, 52.0935s/50 iters), loss = 2943.54
I1223 02:12:37.190335 25375 solver.cpp:238]     Train net output #0: loss = 780.802 (* 1 = 780.802 loss)
I1223 02:12:37.190342 25375 sgd_solver.cpp:105] Iteration 5900, lr = 1e-08
I1223 02:13:30.560750 25375 solver.cpp:219] Iteration 5950 (0.936865 iter/s, 53.3695s/50 iters), loss = 2926.95
I1223 02:13:30.560792 25375 solver.cpp:238]     Train net output #0: loss = 2533.05 (* 1 = 2533.05 loss)
I1223 02:13:30.560801 25375 sgd_solver.cpp:105] Iteration 5950, lr = 1e-08
I1223 02:14:24.413146 25375 solver.cpp:219] Iteration 6000 (0.928481 iter/s, 53.8514s/50 iters), loss = 2908.99
I1223 02:14:24.413178 25375 solver.cpp:238]     Train net output #0: loss = 1959.36 (* 1 = 1959.36 loss)
I1223 02:14:24.413185 25375 sgd_solver.cpp:105] Iteration 6000, lr = 1e-08
I1223 02:15:17.985806 25375 solver.cpp:219] Iteration 6050 (0.933329 iter/s, 53.5717s/50 iters), loss = 2917.27
I1223 02:15:17.985848 25375 solver.cpp:238]     Train net output #0: loss = 842.438 (* 1 = 842.438 loss)
I1223 02:15:17.985855 25375 sgd_solver.cpp:105] Iteration 6050, lr = 1e-08
I1223 02:16:11.443647 25375 solver.cpp:219] Iteration 6100 (0.935334 iter/s, 53.4568s/50 iters), loss = 2914.56
I1223 02:16:11.443684 25375 solver.cpp:238]     Train net output #0: loss = 2397.41 (* 1 = 2397.41 loss)
I1223 02:16:11.443692 25375 sgd_solver.cpp:105] Iteration 6100, lr = 1e-08
I1223 02:17:06.497936 25375 solver.cpp:219] Iteration 6150 (0.908212 iter/s, 55.0532s/50 iters), loss = 2923.34
I1223 02:17:06.497974 25375 solver.cpp:238]     Train net output #0: loss = 1903.1 (* 1 = 1903.1 loss)
I1223 02:17:06.497983 25375 sgd_solver.cpp:105] Iteration 6150, lr = 1e-08
I1223 02:18:01.314777 25375 solver.cpp:219] Iteration 6200 (0.912146 iter/s, 54.8158s/50 iters), loss = 2921.62
I1223 02:18:01.314815 25375 solver.cpp:238]     Train net output #0: loss = 869.419 (* 1 = 869.419 loss)
I1223 02:18:01.314821 25375 sgd_solver.cpp:105] Iteration 6200, lr = 1e-08
I1223 02:18:55.650631 25375 solver.cpp:219] Iteration 6250 (0.92022 iter/s, 54.3348s/50 iters), loss = 2913.8
I1223 02:18:55.650668 25375 solver.cpp:238]     Train net output #0: loss = 2608.05 (* 1 = 2608.05 loss)
I1223 02:18:55.650676 25375 sgd_solver.cpp:105] Iteration 6250, lr = 1e-08
I1223 02:19:50.755312 25375 solver.cpp:219] Iteration 6300 (0.907381 iter/s, 55.1036s/50 iters), loss = 2904.33
I1223 02:19:50.755349 25375 solver.cpp:238]     Train net output #0: loss = 2220.71 (* 1 = 2220.71 loss)
I1223 02:19:50.755355 25375 sgd_solver.cpp:105] Iteration 6300, lr = 1e-08
I1223 02:20:44.098676 25375 solver.cpp:219] Iteration 6350 (0.937342 iter/s, 53.3424s/50 iters), loss = 2893.46
I1223 02:20:44.098711 25375 solver.cpp:238]     Train net output #0: loss = 835.583 (* 1 = 835.583 loss)
I1223 02:20:44.098718 25375 sgd_solver.cpp:105] Iteration 6350, lr = 1e-08
I1223 02:21:37.463008 25375 solver.cpp:219] Iteration 6400 (0.936973 iter/s, 53.3633s/50 iters), loss = 2883.55
I1223 02:21:37.463033 25375 solver.cpp:238]     Train net output #0: loss = 2973.29 (* 1 = 2973.29 loss)
I1223 02:21:37.463054 25375 sgd_solver.cpp:105] Iteration 6400, lr = 1e-08
I1223 02:22:31.543514 25375 solver.cpp:219] Iteration 6450 (0.924565 iter/s, 54.0795s/50 iters), loss = 2887.66
I1223 02:22:31.543552 25375 solver.cpp:238]     Train net output #0: loss = 2158.36 (* 1 = 2158.36 loss)
I1223 02:22:31.543560 25375 sgd_solver.cpp:105] Iteration 6450, lr = 1e-08
I1223 02:23:24.374390 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_6500.caffemodel
I1223 02:23:24.915626 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_6500.solverstate
I1223 02:23:25.008384 25375 solver.cpp:331] Iteration 6500, Testing net (#0)
I1223 02:24:38.026429 25375 solver.cpp:398]     Test net output #0: loss = 6422.87 (* 1 = 6422.87 loss)
I1223 02:24:38.822124 25375 solver.cpp:219] Iteration 6500 (0.392846 iter/s, 127.276s/50 iters), loss = 2892.43
I1223 02:24:38.822162 25375 solver.cpp:238]     Train net output #0: loss = 817.131 (* 1 = 817.131 loss)
I1223 02:24:38.822170 25375 sgd_solver.cpp:105] Iteration 6500, lr = 1e-08
I1223 02:25:33.835631 25375 solver.cpp:219] Iteration 6550 (0.908884 iter/s, 55.0125s/50 iters), loss = 2885.24
I1223 02:25:33.835665 25375 solver.cpp:238]     Train net output #0: loss = 2514.92 (* 1 = 2514.92 loss)
I1223 02:25:33.835671 25375 sgd_solver.cpp:105] Iteration 6550, lr = 1e-08
I1223 02:26:28.167208 25375 solver.cpp:219] Iteration 6600 (0.920292 iter/s, 54.3306s/50 iters), loss = 2882.12
I1223 02:26:28.167249 25375 solver.cpp:238]     Train net output #0: loss = 1845.98 (* 1 = 1845.98 loss)
I1223 02:26:28.167258 25375 sgd_solver.cpp:105] Iteration 6600, lr = 1e-08
I1223 02:27:21.792295 25375 solver.cpp:219] Iteration 6650 (0.932417 iter/s, 53.6241s/50 iters), loss = 2883
I1223 02:27:21.792332 25375 solver.cpp:238]     Train net output #0: loss = 790.216 (* 1 = 790.216 loss)
I1223 02:27:21.792340 25375 sgd_solver.cpp:105] Iteration 6650, lr = 1e-08
I1223 02:28:14.737217 25375 solver.cpp:219] Iteration 6700 (0.944395 iter/s, 52.9439s/50 iters), loss = 2883.55
I1223 02:28:14.737262 25375 solver.cpp:238]     Train net output #0: loss = 2678.98 (* 1 = 2678.98 loss)
I1223 02:28:14.737270 25375 sgd_solver.cpp:105] Iteration 6700, lr = 1e-08
I1223 02:29:09.298255 25375 solver.cpp:219] Iteration 6750 (0.916422 iter/s, 54.56s/50 iters), loss = 2871.17
I1223 02:29:09.298295 25375 solver.cpp:238]     Train net output #0: loss = 2304.75 (* 1 = 2304.75 loss)
I1223 02:29:09.298302 25375 sgd_solver.cpp:105] Iteration 6750, lr = 1e-08
I1223 02:30:04.058305 25375 solver.cpp:219] Iteration 6800 (0.913092 iter/s, 54.759s/50 iters), loss = 2866.01
I1223 02:30:04.058344 25375 solver.cpp:238]     Train net output #0: loss = 778.923 (* 1 = 778.923 loss)
I1223 02:30:04.058352 25375 sgd_solver.cpp:105] Iteration 6800, lr = 1e-08
I1223 02:30:57.200335 25375 solver.cpp:219] Iteration 6850 (0.940893 iter/s, 53.141s/50 iters), loss = 2853.75
I1223 02:30:57.200371 25375 solver.cpp:238]     Train net output #0: loss = 2585.32 (* 1 = 2585.32 loss)
I1223 02:30:57.200376 25375 sgd_solver.cpp:105] Iteration 6850, lr = 1e-08
I1223 02:31:51.256618 25375 solver.cpp:219] Iteration 6900 (0.924979 iter/s, 54.0553s/50 iters), loss = 2850.26
I1223 02:31:51.256660 25375 solver.cpp:238]     Train net output #0: loss = 2153.92 (* 1 = 2153.92 loss)
I1223 02:31:51.256670 25375 sgd_solver.cpp:105] Iteration 6900, lr = 1e-08
I1223 02:32:45.485287 25375 solver.cpp:219] Iteration 6950 (0.922039 iter/s, 54.2276s/50 iters), loss = 2839.98
I1223 02:32:45.485330 25375 solver.cpp:238]     Train net output #0: loss = 807.446 (* 1 = 807.446 loss)
I1223 02:32:45.485339 25375 sgd_solver.cpp:105] Iteration 6950, lr = 1e-08
I1223 02:33:39.795269 25375 solver.cpp:219] Iteration 7000 (0.920659 iter/s, 54.3089s/50 iters), loss = 2837.88
I1223 02:33:39.795310 25375 solver.cpp:238]     Train net output #0: loss = 2755.94 (* 1 = 2755.94 loss)
I1223 02:33:39.795317 25375 sgd_solver.cpp:105] Iteration 7000, lr = 1e-08
I1223 02:34:34.112612 25375 solver.cpp:219] Iteration 7050 (0.920534 iter/s, 54.3163s/50 iters), loss = 2820.92
I1223 02:34:34.112644 25375 solver.cpp:238]     Train net output #0: loss = 2052.04 (* 1 = 2052.04 loss)
I1223 02:34:34.112650 25375 sgd_solver.cpp:105] Iteration 7050, lr = 1e-08
I1223 02:35:28.026016 25375 solver.cpp:219] Iteration 7100 (0.927431 iter/s, 53.9124s/50 iters), loss = 2819.73
I1223 02:35:28.026057 25375 solver.cpp:238]     Train net output #0: loss = 800.046 (* 1 = 800.046 loss)
I1223 02:35:28.026063 25375 sgd_solver.cpp:105] Iteration 7100, lr = 1e-08
I1223 02:36:21.661001 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_7150.caffemodel
I1223 02:36:22.293895 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_7150.solverstate
I1223 02:36:22.457134 25375 solver.cpp:331] Iteration 7150, Testing net (#0)
I1223 02:37:34.799332 25375 solver.cpp:398]     Test net output #0: loss = 6224.49 (* 1 = 6224.49 loss)
I1223 02:37:35.596356 25375 solver.cpp:219] Iteration 7150 (0.391948 iter/s, 127.568s/50 iters), loss = 2812.2
I1223 02:37:35.596397 25375 solver.cpp:238]     Train net output #0: loss = 2895.36 (* 1 = 2895.36 loss)
I1223 02:37:35.596405 25375 sgd_solver.cpp:105] Iteration 7150, lr = 1e-08
I1223 02:38:28.725780 25375 solver.cpp:219] Iteration 7200 (0.941115 iter/s, 53.1285s/50 iters), loss = 2803.84
I1223 02:38:28.725824 25375 solver.cpp:238]     Train net output #0: loss = 2070.43 (* 1 = 2070.43 loss)
I1223 02:38:28.725833 25375 sgd_solver.cpp:105] Iteration 7200, lr = 1e-08
I1223 02:39:23.695756 25375 solver.cpp:219] Iteration 7250 (0.909604 iter/s, 54.969s/50 iters), loss = 2796.26
I1223 02:39:23.695794 25375 solver.cpp:238]     Train net output #0: loss = 748 (* 1 = 748 loss)
I1223 02:39:23.695801 25375 sgd_solver.cpp:105] Iteration 7250, lr = 1e-08
I1223 02:40:17.941663 25375 solver.cpp:219] Iteration 7300 (0.921746 iter/s, 54.2449s/50 iters), loss = 2793.53
I1223 02:40:17.941699 25375 solver.cpp:238]     Train net output #0: loss = 2480.14 (* 1 = 2480.14 loss)
I1223 02:40:17.941706 25375 sgd_solver.cpp:105] Iteration 7300, lr = 1e-08
I1223 02:41:11.034893 25375 solver.cpp:219] Iteration 7350 (0.941757 iter/s, 53.0922s/50 iters), loss = 2787.31
I1223 02:41:11.034929 25375 solver.cpp:238]     Train net output #0: loss = 2027.15 (* 1 = 2027.15 loss)
I1223 02:41:11.034935 25375 sgd_solver.cpp:105] Iteration 7350, lr = 1e-08
I1223 02:42:05.249735 25375 solver.cpp:219] Iteration 7400 (0.922274 iter/s, 54.2138s/50 iters), loss = 2783.89
I1223 02:42:05.249766 25375 solver.cpp:238]     Train net output #0: loss = 798.854 (* 1 = 798.854 loss)
I1223 02:42:05.249773 25375 sgd_solver.cpp:105] Iteration 7400, lr = 1e-08
I1223 02:42:59.611727 25375 solver.cpp:219] Iteration 7450 (0.919777 iter/s, 54.361s/50 iters), loss = 2771.93
I1223 02:42:59.611764 25375 solver.cpp:238]     Train net output #0: loss = 2873.9 (* 1 = 2873.9 loss)
I1223 02:42:59.611770 25375 sgd_solver.cpp:105] Iteration 7450, lr = 1e-08
I1223 02:43:53.633795 25375 solver.cpp:219] Iteration 7500 (0.925565 iter/s, 54.021s/50 iters), loss = 2758.52
I1223 02:43:53.633831 25375 solver.cpp:238]     Train net output #0: loss = 2083.25 (* 1 = 2083.25 loss)
I1223 02:43:53.633836 25375 sgd_solver.cpp:105] Iteration 7500, lr = 1e-08
I1223 02:44:46.049854 25375 solver.cpp:219] Iteration 7550 (0.953924 iter/s, 52.4151s/50 iters), loss = 2756.91
I1223 02:44:46.049890 25375 solver.cpp:238]     Train net output #0: loss = 761.556 (* 1 = 761.556 loss)
I1223 02:44:46.049896 25375 sgd_solver.cpp:105] Iteration 7550, lr = 1e-08
I1223 02:45:40.650171 25375 solver.cpp:219] Iteration 7600 (0.915763 iter/s, 54.5993s/50 iters), loss = 2752.56
I1223 02:45:40.650207 25375 solver.cpp:238]     Train net output #0: loss = 2446.99 (* 1 = 2446.99 loss)
I1223 02:45:40.650213 25375 sgd_solver.cpp:105] Iteration 7600, lr = 1e-08
I1223 02:46:33.679472 25375 solver.cpp:219] Iteration 7650 (0.942893 iter/s, 53.0283s/50 iters), loss = 2747.13
I1223 02:46:33.679514 25375 solver.cpp:238]     Train net output #0: loss = 1847.18 (* 1 = 1847.18 loss)
I1223 02:46:33.679522 25375 sgd_solver.cpp:105] Iteration 7650, lr = 1e-08
I1223 02:47:28.056913 25375 solver.cpp:219] Iteration 7700 (0.919516 iter/s, 54.3764s/50 iters), loss = 2739.82
I1223 02:47:28.056951 25375 solver.cpp:238]     Train net output #0: loss = 866.814 (* 1 = 866.814 loss)
I1223 02:47:28.056957 25375 sgd_solver.cpp:105] Iteration 7700, lr = 1e-08
I1223 02:48:21.268265 25375 solver.cpp:219] Iteration 7750 (0.939667 iter/s, 53.2103s/50 iters), loss = 2734.89
I1223 02:48:21.268299 25375 solver.cpp:238]     Train net output #0: loss = 2728.27 (* 1 = 2728.27 loss)
I1223 02:48:21.268306 25375 sgd_solver.cpp:105] Iteration 7750, lr = 1e-08
I1223 02:49:14.838876 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_7800.caffemodel
I1223 02:49:15.367161 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_7800.solverstate
I1223 02:49:15.459666 25375 solver.cpp:331] Iteration 7800, Testing net (#0)
I1223 02:50:29.787426 25375 solver.cpp:398]     Test net output #0: loss = 6580.67 (* 1 = 6580.67 loss)
I1223 02:50:30.585757 25375 solver.cpp:219] Iteration 7800 (0.386652 iter/s, 129.315s/50 iters), loss = 2720.31
I1223 02:50:30.585795 25375 solver.cpp:238]     Train net output #0: loss = 1865.91 (* 1 = 1865.91 loss)
I1223 02:50:30.585803 25375 sgd_solver.cpp:105] Iteration 7800, lr = 1e-08
I1223 02:51:24.310189 25375 solver.cpp:219] Iteration 7850 (0.930692 iter/s, 53.7235s/50 iters), loss = 2728.03
I1223 02:51:24.310220 25375 solver.cpp:238]     Train net output #0: loss = 752.822 (* 1 = 752.822 loss)
I1223 02:51:24.310226 25375 sgd_solver.cpp:105] Iteration 7850, lr = 1e-08
I1223 02:52:17.903553 25375 solver.cpp:219] Iteration 7900 (0.932968 iter/s, 53.5924s/50 iters), loss = 2719.11
I1223 02:52:17.903589 25375 solver.cpp:238]     Train net output #0: loss = 2585.66 (* 1 = 2585.66 loss)
I1223 02:52:17.903596 25375 sgd_solver.cpp:105] Iteration 7900, lr = 1e-08
I1223 02:53:11.823242 25375 solver.cpp:219] Iteration 7950 (0.927322 iter/s, 53.9187s/50 iters), loss = 2728.55
I1223 02:53:11.823283 25375 solver.cpp:238]     Train net output #0: loss = 2028.22 (* 1 = 2028.22 loss)
I1223 02:53:11.823292 25375 sgd_solver.cpp:105] Iteration 7950, lr = 1e-08
I1223 02:54:07.163095 25375 solver.cpp:219] Iteration 8000 (0.903525 iter/s, 55.3388s/50 iters), loss = 2725.12
I1223 02:54:07.163141 25375 solver.cpp:238]     Train net output #0: loss = 714.615 (* 1 = 714.615 loss)
I1223 02:54:07.163149 25375 sgd_solver.cpp:105] Iteration 8000, lr = 1e-08
I1223 02:55:00.157459 25375 solver.cpp:219] Iteration 8050 (0.943514 iter/s, 52.9934s/50 iters), loss = 2732.47
I1223 02:55:00.157498 25375 solver.cpp:238]     Train net output #0: loss = 2289.82 (* 1 = 2289.82 loss)
I1223 02:55:00.157505 25375 sgd_solver.cpp:105] Iteration 8050, lr = 1e-08
I1223 02:55:55.741878 25375 solver.cpp:219] Iteration 8100 (0.89955 iter/s, 55.5834s/50 iters), loss = 2718.36
I1223 02:55:55.741919 25375 solver.cpp:238]     Train net output #0: loss = 1910.71 (* 1 = 1910.71 loss)
I1223 02:55:55.741925 25375 sgd_solver.cpp:105] Iteration 8100, lr = 1e-08
I1223 02:56:49.823640 25375 solver.cpp:219] Iteration 8150 (0.924543 iter/s, 54.0807s/50 iters), loss = 2713.91
I1223 02:56:49.823678 25375 solver.cpp:238]     Train net output #0: loss = 798.497 (* 1 = 798.497 loss)
I1223 02:56:49.823683 25375 sgd_solver.cpp:105] Iteration 8150, lr = 1e-08
I1223 02:57:42.593107 25375 solver.cpp:219] Iteration 8200 (0.947536 iter/s, 52.7685s/50 iters), loss = 2708.78
I1223 02:57:42.593148 25375 solver.cpp:238]     Train net output #0: loss = 2428.32 (* 1 = 2428.32 loss)
I1223 02:57:42.593156 25375 sgd_solver.cpp:105] Iteration 8200, lr = 1e-08
I1223 02:58:35.534342 25375 solver.cpp:219] Iteration 8250 (0.944461 iter/s, 52.9402s/50 iters), loss = 2698.62
I1223 02:58:35.534376 25375 solver.cpp:238]     Train net output #0: loss = 2214.74 (* 1 = 2214.74 loss)
I1223 02:58:35.534382 25375 sgd_solver.cpp:105] Iteration 8250, lr = 1e-08
I1223 02:59:29.690527 25375 solver.cpp:219] Iteration 8300 (0.923273 iter/s, 54.1552s/50 iters), loss = 2695.5
I1223 02:59:29.690568 25375 solver.cpp:238]     Train net output #0: loss = 761.577 (* 1 = 761.577 loss)
I1223 02:59:29.690575 25375 sgd_solver.cpp:105] Iteration 8300, lr = 1e-08
I1223 03:00:23.744933 25375 solver.cpp:219] Iteration 8350 (0.925012 iter/s, 54.0534s/50 iters), loss = 2701.7
I1223 03:00:23.744972 25375 solver.cpp:238]     Train net output #0: loss = 2704.41 (* 1 = 2704.41 loss)
I1223 03:00:23.744981 25375 sgd_solver.cpp:105] Iteration 8350, lr = 1e-08
I1223 03:01:17.893961 25375 solver.cpp:219] Iteration 8400 (0.923395 iter/s, 54.148s/50 iters), loss = 2705.41
I1223 03:01:17.893998 25375 solver.cpp:238]     Train net output #0: loss = 1913.07 (* 1 = 1913.07 loss)
I1223 03:01:17.894004 25375 sgd_solver.cpp:105] Iteration 8400, lr = 1e-08
I1223 03:02:10.503998 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_8450.caffemodel
I1223 03:02:11.090373 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_8450.solverstate
I1223 03:02:11.213344 25375 solver.cpp:331] Iteration 8450, Testing net (#0)
I1223 03:03:23.403848 25375 solver.cpp:398]     Test net output #0: loss = 6186.02 (* 1 = 6186.02 loss)
I1223 03:03:24.200441 25375 solver.cpp:219] Iteration 8450 (0.39587 iter/s, 126.304s/50 iters), loss = 2697.58
I1223 03:03:24.200474 25375 solver.cpp:238]     Train net output #0: loss = 789.366 (* 1 = 789.366 loss)
I1223 03:03:24.200479 25375 sgd_solver.cpp:105] Iteration 8450, lr = 1e-08
I1223 03:04:17.180366 25375 solver.cpp:219] Iteration 8500 (0.943771 iter/s, 52.979s/50 iters), loss = 2691.2
I1223 03:04:17.180397 25375 solver.cpp:238]     Train net output #0: loss = 2263.67 (* 1 = 2263.67 loss)
I1223 03:04:17.180418 25375 sgd_solver.cpp:105] Iteration 8500, lr = 1e-08
I1223 03:05:09.307157 25375 solver.cpp:219] Iteration 8550 (0.959217 iter/s, 52.1258s/50 iters), loss = 2687.12
I1223 03:05:09.307194 25375 solver.cpp:238]     Train net output #0: loss = 1827.11 (* 1 = 1827.11 loss)
I1223 03:05:09.307200 25375 sgd_solver.cpp:105] Iteration 8550, lr = 1e-08
I1223 03:06:02.498304 25375 solver.cpp:219] Iteration 8600 (0.940024 iter/s, 53.1902s/50 iters), loss = 2687.46
I1223 03:06:02.498340 25375 solver.cpp:238]     Train net output #0: loss = 768.504 (* 1 = 768.504 loss)
I1223 03:06:02.498347 25375 sgd_solver.cpp:105] Iteration 8600, lr = 1e-08
I1223 03:06:56.552575 25375 solver.cpp:219] Iteration 8650 (0.925014 iter/s, 54.0533s/50 iters), loss = 2684.44
I1223 03:06:56.552610 25375 solver.cpp:238]     Train net output #0: loss = 2384.99 (* 1 = 2384.99 loss)
I1223 03:06:56.552616 25375 sgd_solver.cpp:105] Iteration 8650, lr = 1e-08
I1223 03:07:50.522917 25375 solver.cpp:219] Iteration 8700 (0.926452 iter/s, 53.9693s/50 iters), loss = 2688.66
I1223 03:07:50.522969 25375 solver.cpp:238]     Train net output #0: loss = 1842.19 (* 1 = 1842.19 loss)
I1223 03:07:50.522979 25375 sgd_solver.cpp:105] Iteration 8700, lr = 1e-08
I1223 03:08:43.476774 25375 solver.cpp:219] Iteration 8750 (0.944236 iter/s, 52.9528s/50 iters), loss = 2685.06
I1223 03:08:43.476816 25375 solver.cpp:238]     Train net output #0: loss = 773.159 (* 1 = 773.159 loss)
I1223 03:08:43.476825 25375 sgd_solver.cpp:105] Iteration 8750, lr = 1e-08
I1223 03:09:37.653877 25375 solver.cpp:219] Iteration 8800 (0.922916 iter/s, 54.1761s/50 iters), loss = 2692.1
I1223 03:09:37.653913 25375 solver.cpp:238]     Train net output #0: loss = 2658.89 (* 1 = 2658.89 loss)
I1223 03:09:37.653919 25375 sgd_solver.cpp:105] Iteration 8800, lr = 1e-08
I1223 03:10:31.619700 25375 solver.cpp:219] Iteration 8850 (0.92653 iter/s, 53.9648s/50 iters), loss = 2686.94
I1223 03:10:31.619735 25375 solver.cpp:238]     Train net output #0: loss = 1752.84 (* 1 = 1752.84 loss)
I1223 03:10:31.619740 25375 sgd_solver.cpp:105] Iteration 8850, lr = 1e-08
I1223 03:11:25.133654 25375 solver.cpp:219] Iteration 8900 (0.934353 iter/s, 53.5129s/50 iters), loss = 2683.6
I1223 03:11:25.133694 25375 solver.cpp:238]     Train net output #0: loss = 700.049 (* 1 = 700.049 loss)
I1223 03:11:25.133702 25375 sgd_solver.cpp:105] Iteration 8900, lr = 1e-08
I1223 03:12:18.571352 25375 solver.cpp:219] Iteration 8950 (0.935687 iter/s, 53.4367s/50 iters), loss = 2672.85
I1223 03:12:18.571386 25375 solver.cpp:238]     Train net output #0: loss = 2698.7 (* 1 = 2698.7 loss)
I1223 03:12:18.571393 25375 sgd_solver.cpp:105] Iteration 8950, lr = 1e-08
I1223 03:13:12.883797 25375 solver.cpp:219] Iteration 9000 (0.920617 iter/s, 54.3114s/50 iters), loss = 2672.65
I1223 03:13:12.883834 25375 solver.cpp:238]     Train net output #0: loss = 2182.7 (* 1 = 2182.7 loss)
I1223 03:13:12.883841 25375 sgd_solver.cpp:105] Iteration 9000, lr = 1e-08
I1223 03:14:06.880336 25375 solver.cpp:219] Iteration 9050 (0.926003 iter/s, 53.9955s/50 iters), loss = 2659.49
I1223 03:14:06.880381 25375 solver.cpp:238]     Train net output #0: loss = 754.416 (* 1 = 754.416 loss)
I1223 03:14:06.880390 25375 sgd_solver.cpp:105] Iteration 9050, lr = 1e-08
I1223 03:14:58.694332 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_9100.caffemodel
I1223 03:14:59.223208 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_9100.solverstate
I1223 03:14:59.315716 25375 solver.cpp:331] Iteration 9100, Testing net (#0)
I1223 03:16:11.588567 25375 solver.cpp:398]     Test net output #0: loss = 6615.06 (* 1 = 6615.06 loss)
I1223 03:16:12.387795 25375 solver.cpp:219] Iteration 9100 (0.39839 iter/s, 125.505s/50 iters), loss = 2663.29
I1223 03:16:12.387833 25375 solver.cpp:238]     Train net output #0: loss = 2372.65 (* 1 = 2372.65 loss)
I1223 03:16:12.387842 25375 sgd_solver.cpp:105] Iteration 9100, lr = 1e-08
I1223 03:17:04.863317 25375 solver.cpp:219] Iteration 9150 (0.952842 iter/s, 52.4746s/50 iters), loss = 2653.21
I1223 03:17:04.863355 25375 solver.cpp:238]     Train net output #0: loss = 2058.74 (* 1 = 2058.74 loss)
I1223 03:17:04.863363 25375 sgd_solver.cpp:105] Iteration 9150, lr = 1e-08
I1223 03:17:59.626003 25375 solver.cpp:219] Iteration 9200 (0.913047 iter/s, 54.7617s/50 iters), loss = 2651.86
I1223 03:17:59.626039 25375 solver.cpp:238]     Train net output #0: loss = 724.284 (* 1 = 724.284 loss)
I1223 03:17:59.626045 25375 sgd_solver.cpp:105] Iteration 9200, lr = 1e-08
I1223 03:18:53.662395 25375 solver.cpp:219] Iteration 9250 (0.92532 iter/s, 54.0354s/50 iters), loss = 2657.23
I1223 03:18:53.662433 25375 solver.cpp:238]     Train net output #0: loss = 2745.32 (* 1 = 2745.32 loss)
I1223 03:18:53.662441 25375 sgd_solver.cpp:105] Iteration 9250, lr = 1e-08
I1223 03:19:47.323539 25375 solver.cpp:219] Iteration 9300 (0.93179 iter/s, 53.6601s/50 iters), loss = 2652.66
I1223 03:19:47.323571 25375 solver.cpp:238]     Train net output #0: loss = 2005.2 (* 1 = 2005.2 loss)
I1223 03:19:47.323577 25375 sgd_solver.cpp:105] Iteration 9300, lr = 1e-08
I1223 03:20:40.470628 25375 solver.cpp:219] Iteration 9350 (0.940803 iter/s, 53.1461s/50 iters), loss = 2649.83
I1223 03:20:40.470664 25375 solver.cpp:238]     Train net output #0: loss = 727.405 (* 1 = 727.405 loss)
I1223 03:20:40.470669 25375 sgd_solver.cpp:105] Iteration 9350, lr = 1e-08
I1223 03:21:34.569305 25375 solver.cpp:219] Iteration 9400 (0.924254 iter/s, 54.0977s/50 iters), loss = 2655.47
I1223 03:21:34.569342 25375 solver.cpp:238]     Train net output #0: loss = 2278.47 (* 1 = 2278.47 loss)
I1223 03:21:34.569350 25375 sgd_solver.cpp:105] Iteration 9400, lr = 1e-08
I1223 03:22:28.320274 25375 solver.cpp:219] Iteration 9450 (0.930233 iter/s, 53.75s/50 iters), loss = 2656.86
I1223 03:22:28.320308 25375 solver.cpp:238]     Train net output #0: loss = 2191.4 (* 1 = 2191.4 loss)
I1223 03:22:28.320314 25375 sgd_solver.cpp:105] Iteration 9450, lr = 1e-08
I1223 03:23:23.594259 25375 solver.cpp:219] Iteration 9500 (0.904602 iter/s, 55.2729s/50 iters), loss = 2660.11
I1223 03:23:23.594300 25375 solver.cpp:238]     Train net output #0: loss = 768.022 (* 1 = 768.022 loss)
I1223 03:23:23.594310 25375 sgd_solver.cpp:105] Iteration 9500, lr = 1e-08
I1223 03:24:16.857406 25375 solver.cpp:219] Iteration 9550 (0.938753 iter/s, 53.2621s/50 iters), loss = 2653.97
I1223 03:24:16.857452 25375 solver.cpp:238]     Train net output #0: loss = 2216.02 (* 1 = 2216.02 loss)
I1223 03:24:16.857460 25375 sgd_solver.cpp:105] Iteration 9550, lr = 1e-08
I1223 03:25:10.439606 25375 solver.cpp:219] Iteration 9600 (0.933163 iter/s, 53.5812s/50 iters), loss = 2648.12
I1223 03:25:10.439640 25375 solver.cpp:238]     Train net output #0: loss = 1932.59 (* 1 = 1932.59 loss)
I1223 03:25:10.439646 25375 sgd_solver.cpp:105] Iteration 9600, lr = 1e-08
I1223 03:26:05.107975 25375 solver.cpp:219] Iteration 9650 (0.914623 iter/s, 54.6673s/50 iters), loss = 2656.37
I1223 03:26:05.108011 25375 solver.cpp:238]     Train net output #0: loss = 769.019 (* 1 = 769.019 loss)
I1223 03:26:05.108017 25375 sgd_solver.cpp:105] Iteration 9650, lr = 1e-08
I1223 03:26:59.009199 25375 solver.cpp:219] Iteration 9700 (0.92764 iter/s, 53.9002s/50 iters), loss = 2651.96
I1223 03:26:59.009235 25375 solver.cpp:238]     Train net output #0: loss = 2204.5 (* 1 = 2204.5 loss)
I1223 03:26:59.009243 25375 sgd_solver.cpp:105] Iteration 9700, lr = 1e-08
I1223 03:27:51.755973 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_9750.caffemodel
I1223 03:27:52.289132 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_9750.solverstate
I1223 03:27:52.381685 25375 solver.cpp:331] Iteration 9750, Testing net (#0)
I1223 03:29:05.114718 25375 solver.cpp:398]     Test net output #0: loss = 6023.38 (* 1 = 6023.38 loss)
I1223 03:29:05.909729 25375 solver.cpp:219] Iteration 9750 (0.394017 iter/s, 126.898s/50 iters), loss = 2646.17
I1223 03:29:05.909768 25375 solver.cpp:238]     Train net output #0: loss = 1868.72 (* 1 = 1868.72 loss)
I1223 03:29:05.909775 25375 sgd_solver.cpp:105] Iteration 9750, lr = 1e-08
I1223 03:29:59.393975 25375 solver.cpp:219] Iteration 9800 (0.934871 iter/s, 53.4833s/50 iters), loss = 2645.02
I1223 03:29:59.394011 25375 solver.cpp:238]     Train net output #0: loss = 720.172 (* 1 = 720.172 loss)
I1223 03:29:59.394017 25375 sgd_solver.cpp:105] Iteration 9800, lr = 1e-08
I1223 03:30:52.578277 25375 solver.cpp:219] Iteration 9850 (0.940144 iter/s, 53.1833s/50 iters), loss = 2626.12
I1223 03:30:52.578313 25375 solver.cpp:238]     Train net output #0: loss = 2332.83 (* 1 = 2332.83 loss)
I1223 03:30:52.578320 25375 sgd_solver.cpp:105] Iteration 9850, lr = 1e-08
I1223 03:31:47.553617 25375 solver.cpp:219] Iteration 9900 (0.909516 iter/s, 54.9743s/50 iters), loss = 2633.93
I1223 03:31:47.553658 25375 solver.cpp:238]     Train net output #0: loss = 2013.1 (* 1 = 2013.1 loss)
I1223 03:31:47.553664 25375 sgd_solver.cpp:105] Iteration 9900, lr = 1e-08
I1223 03:32:43.420687 25375 solver.cpp:219] Iteration 9950 (0.894998 iter/s, 55.866s/50 iters), loss = 2632.85
I1223 03:32:43.420717 25375 solver.cpp:238]     Train net output #0: loss = 678.443 (* 1 = 678.443 loss)
I1223 03:32:43.420722 25375 sgd_solver.cpp:105] Iteration 9950, lr = 1e-08
I1223 03:33:39.226483 25375 solver.cpp:219] Iteration 10000 (0.895981 iter/s, 55.8048s/50 iters), loss = 2625.51
I1223 03:33:39.226521 25375 solver.cpp:238]     Train net output #0: loss = 2251.49 (* 1 = 2251.49 loss)
I1223 03:33:39.226528 25375 sgd_solver.cpp:105] Iteration 10000, lr = 1e-09
I1223 03:34:33.072374 25375 solver.cpp:219] Iteration 10050 (0.928593 iter/s, 53.8449s/50 iters), loss = 2626.6
I1223 03:34:33.072419 25375 solver.cpp:238]     Train net output #0: loss = 1716.15 (* 1 = 1716.15 loss)
I1223 03:34:33.072428 25375 sgd_solver.cpp:105] Iteration 10050, lr = 1e-09
I1223 03:35:27.047197 25375 solver.cpp:219] Iteration 10100 (0.926375 iter/s, 53.9738s/50 iters), loss = 2620.99
I1223 03:35:27.047228 25375 solver.cpp:238]     Train net output #0: loss = 741.683 (* 1 = 741.683 loss)
I1223 03:35:27.047233 25375 sgd_solver.cpp:105] Iteration 10100, lr = 1e-09
I1223 03:36:21.363672 25375 solver.cpp:219] Iteration 10150 (0.920548 iter/s, 54.3155s/50 iters), loss = 2628.25
I1223 03:36:21.363710 25375 solver.cpp:238]     Train net output #0: loss = 2248.48 (* 1 = 2248.48 loss)
I1223 03:36:21.363716 25375 sgd_solver.cpp:105] Iteration 10150, lr = 1e-09
I1223 03:37:15.515719 25375 solver.cpp:219] Iteration 10200 (0.923344 iter/s, 54.151s/50 iters), loss = 2625.58
I1223 03:37:15.515759 25375 solver.cpp:238]     Train net output #0: loss = 2178.19 (* 1 = 2178.19 loss)
I1223 03:37:15.515767 25375 sgd_solver.cpp:105] Iteration 10200, lr = 1e-09
I1223 03:38:10.519397 25375 solver.cpp:219] Iteration 10250 (0.909047 iter/s, 55.0026s/50 iters), loss = 2618.84
I1223 03:38:10.519431 25375 solver.cpp:238]     Train net output #0: loss = 852.802 (* 1 = 852.802 loss)
I1223 03:38:10.519438 25375 sgd_solver.cpp:105] Iteration 10250, lr = 1e-09
I1223 03:39:06.754559 25375 solver.cpp:219] Iteration 10300 (0.88914 iter/s, 56.2341s/50 iters), loss = 2612.04
I1223 03:39:06.754606 25375 solver.cpp:238]     Train net output #0: loss = 2227.2 (* 1 = 2227.2 loss)
I1223 03:39:06.754614 25375 sgd_solver.cpp:105] Iteration 10300, lr = 1e-09
I1223 03:40:01.084285 25375 solver.cpp:219] Iteration 10350 (0.920324 iter/s, 54.3287s/50 iters), loss = 2604.5
I1223 03:40:01.084323 25375 solver.cpp:238]     Train net output #0: loss = 2197 (* 1 = 2197 loss)
I1223 03:40:01.084331 25375 sgd_solver.cpp:105] Iteration 10350, lr = 1e-09
I1223 03:40:53.570282 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_10400.caffemodel
I1223 03:40:54.074801 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_10400.solverstate
I1223 03:40:54.158252 25375 solver.cpp:331] Iteration 10400, Testing net (#0)
I1223 03:42:05.207618 25375 solver.cpp:398]     Test net output #0: loss = 6505.49 (* 1 = 6505.49 loss)
I1223 03:42:06.005672 25375 solver.cpp:219] Iteration 10400 (0.400259 iter/s, 124.919s/50 iters), loss = 2594.79
I1223 03:42:06.005703 25375 solver.cpp:238]     Train net output #0: loss = 746.588 (* 1 = 746.588 loss)
I1223 03:42:06.005709 25375 sgd_solver.cpp:105] Iteration 10400, lr = 1e-09
I1223 03:42:59.533898 25375 solver.cpp:219] Iteration 10450 (0.934103 iter/s, 53.5273s/50 iters), loss = 2590.19
I1223 03:42:59.533937 25375 solver.cpp:238]     Train net output #0: loss = 2575.48 (* 1 = 2575.48 loss)
I1223 03:42:59.533943 25375 sgd_solver.cpp:105] Iteration 10450, lr = 1e-09
I1223 03:43:52.855778 25375 solver.cpp:219] Iteration 10500 (0.937719 iter/s, 53.3209s/50 iters), loss = 2586.55
I1223 03:43:52.855811 25375 solver.cpp:238]     Train net output #0: loss = 1779.02 (* 1 = 1779.02 loss)
I1223 03:43:52.855818 25375 sgd_solver.cpp:105] Iteration 10500, lr = 1e-09
I1223 03:44:46.694921 25375 solver.cpp:219] Iteration 10550 (0.92871 iter/s, 53.8381s/50 iters), loss = 2589.48
I1223 03:44:46.694958 25375 solver.cpp:238]     Train net output #0: loss = 712.473 (* 1 = 712.473 loss)
I1223 03:44:46.694965 25375 sgd_solver.cpp:105] Iteration 10550, lr = 1e-09
I1223 03:45:39.496378 25375 solver.cpp:219] Iteration 10600 (0.946961 iter/s, 52.8005s/50 iters), loss = 2588.87
I1223 03:45:39.496413 25375 solver.cpp:238]     Train net output #0: loss = 2250.65 (* 1 = 2250.65 loss)
I1223 03:45:39.496420 25375 sgd_solver.cpp:105] Iteration 10600, lr = 1e-09
I1223 03:46:34.149381 25375 solver.cpp:219] Iteration 10650 (0.91488 iter/s, 54.652s/50 iters), loss = 2574.02
I1223 03:46:34.149425 25375 solver.cpp:238]     Train net output #0: loss = 2150.03 (* 1 = 2150.03 loss)
I1223 03:46:34.149433 25375 sgd_solver.cpp:105] Iteration 10650, lr = 1e-09
I1223 03:47:27.666060 25375 solver.cpp:219] Iteration 10700 (0.934306 iter/s, 53.5157s/50 iters), loss = 2574.89
I1223 03:47:27.666105 25375 solver.cpp:238]     Train net output #0: loss = 737.901 (* 1 = 737.901 loss)
I1223 03:47:27.666112 25375 sgd_solver.cpp:105] Iteration 10700, lr = 1e-09
I1223 03:48:22.500686 25375 solver.cpp:219] Iteration 10750 (0.91185 iter/s, 54.8336s/50 iters), loss = 2584.22
I1223 03:48:22.500717 25375 solver.cpp:238]     Train net output #0: loss = 2705.96 (* 1 = 2705.96 loss)
I1223 03:48:22.500723 25375 sgd_solver.cpp:105] Iteration 10750, lr = 1e-09
I1223 03:49:14.942517 25375 solver.cpp:219] Iteration 10800 (0.953455 iter/s, 52.4408s/50 iters), loss = 2576.93
I1223 03:49:14.942550 25375 solver.cpp:238]     Train net output #0: loss = 2159.31 (* 1 = 2159.31 loss)
I1223 03:49:14.942558 25375 sgd_solver.cpp:105] Iteration 10800, lr = 1e-09
I1223 03:50:08.435233 25375 solver.cpp:219] Iteration 10850 (0.934724 iter/s, 53.4917s/50 iters), loss = 2588.49
I1223 03:50:08.435266 25375 solver.cpp:238]     Train net output #0: loss = 794.753 (* 1 = 794.753 loss)
I1223 03:50:08.435272 25375 sgd_solver.cpp:105] Iteration 10850, lr = 1e-09
I1223 03:51:01.196400 25375 solver.cpp:219] Iteration 10900 (0.947685 iter/s, 52.7602s/50 iters), loss = 2574.66
I1223 03:51:01.196435 25375 solver.cpp:238]     Train net output #0: loss = 2179.75 (* 1 = 2179.75 loss)
I1223 03:51:01.196441 25375 sgd_solver.cpp:105] Iteration 10900, lr = 1e-09
I1223 03:51:55.847519 25375 solver.cpp:219] Iteration 10950 (0.914912 iter/s, 54.6501s/50 iters), loss = 2579.96
I1223 03:51:55.847553 25375 solver.cpp:238]     Train net output #0: loss = 2212.83 (* 1 = 2212.83 loss)
I1223 03:51:55.847559 25375 sgd_solver.cpp:105] Iteration 10950, lr = 1e-09
I1223 03:52:50.157841 25375 solver.cpp:219] Iteration 11000 (0.920653 iter/s, 54.3093s/50 iters), loss = 2585.23
I1223 03:52:50.157878 25375 solver.cpp:238]     Train net output #0: loss = 734.044 (* 1 = 734.044 loss)
I1223 03:52:50.157886 25375 sgd_solver.cpp:105] Iteration 11000, lr = 1e-09
I1223 03:53:43.267014 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_11050.caffemodel
I1223 03:53:44.259361 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_11050.solverstate
I1223 03:53:44.352766 25375 solver.cpp:331] Iteration 11050, Testing net (#0)
I1223 03:54:57.007695 25375 solver.cpp:398]     Test net output #0: loss = 6476.08 (* 1 = 6476.08 loss)
I1223 03:54:57.807870 25375 solver.cpp:219] Iteration 11050 (0.391703 iter/s, 127.648s/50 iters), loss = 2586.31
I1223 03:54:57.807909 25375 solver.cpp:238]     Train net output #0: loss = 2317.67 (* 1 = 2317.67 loss)
I1223 03:54:57.807916 25375 sgd_solver.cpp:105] Iteration 11050, lr = 1e-09
I1223 03:55:50.423935 25375 solver.cpp:219] Iteration 11100 (0.950297 iter/s, 52.6151s/50 iters), loss = 2583.98
I1223 03:55:50.423975 25375 solver.cpp:238]     Train net output #0: loss = 1801.44 (* 1 = 1801.44 loss)
I1223 03:55:50.423982 25375 sgd_solver.cpp:105] Iteration 11100, lr = 1e-09
I1223 03:56:45.660002 25375 solver.cpp:219] Iteration 11150 (0.905222 iter/s, 55.2351s/50 iters), loss = 2578.39
I1223 03:56:45.660040 25375 solver.cpp:238]     Train net output #0: loss = 742.2 (* 1 = 742.2 loss)
I1223 03:56:45.660048 25375 sgd_solver.cpp:105] Iteration 11150, lr = 1e-09
I1223 03:57:39.955657 25375 solver.cpp:219] Iteration 11200 (0.920901 iter/s, 54.2946s/50 iters), loss = 2574
I1223 03:57:39.955698 25375 solver.cpp:238]     Train net output #0: loss = 2213.38 (* 1 = 2213.38 loss)
I1223 03:57:39.955704 25375 sgd_solver.cpp:105] Iteration 11200, lr = 1e-09
I1223 03:58:33.248450 25375 solver.cpp:219] Iteration 11250 (0.938231 iter/s, 53.2918s/50 iters), loss = 2570.95
I1223 03:58:33.248486 25375 solver.cpp:238]     Train net output #0: loss = 1838.73 (* 1 = 1838.73 loss)
I1223 03:58:33.248493 25375 sgd_solver.cpp:105] Iteration 11250, lr = 1e-09
I1223 03:59:28.318404 25375 solver.cpp:219] Iteration 11300 (0.907953 iter/s, 55.0689s/50 iters), loss = 2583.62
I1223 03:59:28.318444 25375 solver.cpp:238]     Train net output #0: loss = 729.277 (* 1 = 729.277 loss)
I1223 03:59:28.318452 25375 sgd_solver.cpp:105] Iteration 11300, lr = 1e-09
I1223 04:00:21.532423 25375 solver.cpp:219] Iteration 11350 (0.93962 iter/s, 53.213s/50 iters), loss = 2585.13
I1223 04:00:21.532451 25375 solver.cpp:238]     Train net output #0: loss = 2578.29 (* 1 = 2578.29 loss)
I1223 04:00:21.532456 25375 sgd_solver.cpp:105] Iteration 11350, lr = 1e-09
I1223 04:01:14.938427 25375 solver.cpp:219] Iteration 11400 (0.936242 iter/s, 53.405s/50 iters), loss = 2583.72
I1223 04:01:14.938465 25375 solver.cpp:238]     Train net output #0: loss = 1893.61 (* 1 = 1893.61 loss)
I1223 04:01:14.938472 25375 sgd_solver.cpp:105] Iteration 11400, lr = 1e-09
I1223 04:02:10.554512 25375 solver.cpp:219] Iteration 11450 (0.899037 iter/s, 55.615s/50 iters), loss = 2587.68
I1223 04:02:10.554549 25375 solver.cpp:238]     Train net output #0: loss = 838.981 (* 1 = 838.981 loss)
I1223 04:02:10.554556 25375 sgd_solver.cpp:105] Iteration 11450, lr = 1e-09
I1223 04:03:03.822734 25375 solver.cpp:219] Iteration 11500 (0.938664 iter/s, 53.2672s/50 iters), loss = 2585.54
I1223 04:03:03.822769 25375 solver.cpp:238]     Train net output #0: loss = 2337.83 (* 1 = 2337.83 loss)
I1223 04:03:03.822775 25375 sgd_solver.cpp:105] Iteration 11500, lr = 1e-09
I1223 04:03:57.785650 25375 solver.cpp:219] Iteration 11550 (0.92658 iter/s, 53.9619s/50 iters), loss = 2587.92
I1223 04:03:57.785691 25375 solver.cpp:238]     Train net output #0: loss = 2154.44 (* 1 = 2154.44 loss)
I1223 04:03:57.785698 25375 sgd_solver.cpp:105] Iteration 11550, lr = 1e-09
I1223 04:04:52.407090 25375 solver.cpp:219] Iteration 11600 (0.915409 iter/s, 54.6204s/50 iters), loss = 2583.96
I1223 04:04:52.407126 25375 solver.cpp:238]     Train net output #0: loss = 678.595 (* 1 = 678.595 loss)
I1223 04:04:52.407132 25375 sgd_solver.cpp:105] Iteration 11600, lr = 1e-09
I1223 04:05:46.024590 25375 solver.cpp:219] Iteration 11650 (0.932549 iter/s, 53.6165s/50 iters), loss = 2593.47
I1223 04:05:46.024627 25375 solver.cpp:238]     Train net output #0: loss = 2586.22 (* 1 = 2586.22 loss)
I1223 04:05:46.024633 25375 sgd_solver.cpp:105] Iteration 11650, lr = 1e-09
I1223 04:06:38.759667 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_11700.caffemodel
I1223 04:06:39.620219 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_11700.solverstate
I1223 04:06:39.716574 25375 solver.cpp:331] Iteration 11700, Testing net (#0)
I1223 04:07:50.879233 25375 solver.cpp:398]     Test net output #0: loss = 6590.22 (* 1 = 6590.22 loss)
I1223 04:07:51.674396 25375 solver.cpp:219] Iteration 11700 (0.397939 iter/s, 125.648s/50 iters), loss = 2586.67
I1223 04:07:51.674428 25375 solver.cpp:238]     Train net output #0: loss = 1788.69 (* 1 = 1788.69 loss)
I1223 04:07:51.674435 25375 sgd_solver.cpp:105] Iteration 11700, lr = 1e-09
I1223 04:08:44.993491 25375 solver.cpp:219] Iteration 11750 (0.937767 iter/s, 53.3182s/50 iters), loss = 2580.21
I1223 04:08:44.993533 25375 solver.cpp:238]     Train net output #0: loss = 740.982 (* 1 = 740.982 loss)
I1223 04:08:44.993541 25375 sgd_solver.cpp:105] Iteration 11750, lr = 1e-09
I1223 04:09:38.288218 25375 solver.cpp:219] Iteration 11800 (0.938196 iter/s, 53.2937s/50 iters), loss = 2575.86
I1223 04:09:38.288254 25375 solver.cpp:238]     Train net output #0: loss = 2558.85 (* 1 = 2558.85 loss)
I1223 04:09:38.288260 25375 sgd_solver.cpp:105] Iteration 11800, lr = 1e-09
I1223 04:10:30.715526 25375 solver.cpp:219] Iteration 11850 (0.953719 iter/s, 52.4263s/50 iters), loss = 2576.71
I1223 04:10:30.715565 25375 solver.cpp:238]     Train net output #0: loss = 1839.84 (* 1 = 1839.84 loss)
I1223 04:10:30.715575 25375 sgd_solver.cpp:105] Iteration 11850, lr = 1e-09
I1223 04:11:23.233304 25375 solver.cpp:219] Iteration 11900 (0.952076 iter/s, 52.5168s/50 iters), loss = 2585.27
I1223 04:11:23.233341 25375 solver.cpp:238]     Train net output #0: loss = 732.139 (* 1 = 732.139 loss)
I1223 04:11:23.233348 25375 sgd_solver.cpp:105] Iteration 11900, lr = 1e-09
I1223 04:12:17.503899 25375 solver.cpp:219] Iteration 11950 (0.921327 iter/s, 54.2696s/50 iters), loss = 2576.75
I1223 04:12:17.503940 25375 solver.cpp:238]     Train net output #0: loss = 2252.16 (* 1 = 2252.16 loss)
I1223 04:12:17.503949 25375 sgd_solver.cpp:105] Iteration 11950, lr = 1e-09
I1223 04:13:12.840615 25375 solver.cpp:219] Iteration 12000 (0.903576 iter/s, 55.3357s/50 iters), loss = 2568.81
I1223 04:13:12.840654 25375 solver.cpp:238]     Train net output #0: loss = 1865.29 (* 1 = 1865.29 loss)
I1223 04:13:12.840662 25375 sgd_solver.cpp:105] Iteration 12000, lr = 1e-09
I1223 04:14:07.058006 25375 solver.cpp:219] Iteration 12050 (0.922231 iter/s, 54.2164s/50 iters), loss = 2561
I1223 04:14:07.058046 25375 solver.cpp:238]     Train net output #0: loss = 799.584 (* 1 = 799.584 loss)
I1223 04:14:07.058053 25375 sgd_solver.cpp:105] Iteration 12050, lr = 1e-09
I1223 04:15:01.185091 25375 solver.cpp:219] Iteration 12100 (0.923769 iter/s, 54.1261s/50 iters), loss = 2562.17
I1223 04:15:01.185125 25375 solver.cpp:238]     Train net output #0: loss = 2244.19 (* 1 = 2244.19 loss)
I1223 04:15:01.185132 25375 sgd_solver.cpp:105] Iteration 12100, lr = 1e-09
I1223 04:15:54.992256 25375 solver.cpp:219] Iteration 12150 (0.929262 iter/s, 53.8062s/50 iters), loss = 2563.36
I1223 04:15:54.992297 25375 solver.cpp:238]     Train net output #0: loss = 1841.05 (* 1 = 1841.05 loss)
I1223 04:15:54.992306 25375 sgd_solver.cpp:105] Iteration 12150, lr = 1e-09
I1223 04:16:48.789084 25375 solver.cpp:219] Iteration 12200 (0.92944 iter/s, 53.7958s/50 iters), loss = 2569.01
I1223 04:16:48.789117 25375 solver.cpp:238]     Train net output #0: loss = 693.868 (* 1 = 693.868 loss)
I1223 04:16:48.789124 25375 sgd_solver.cpp:105] Iteration 12200, lr = 1e-09
I1223 04:17:41.505561 25375 solver.cpp:219] Iteration 12250 (0.948488 iter/s, 52.7155s/50 iters), loss = 2574.27
I1223 04:17:41.505604 25375 solver.cpp:238]     Train net output #0: loss = 2264.47 (* 1 = 2264.47 loss)
I1223 04:17:41.505614 25375 sgd_solver.cpp:105] Iteration 12250, lr = 1e-09
I1223 04:18:35.638198 25375 solver.cpp:219] Iteration 12300 (0.923675 iter/s, 54.1316s/50 iters), loss = 2560.47
I1223 04:18:35.638231 25375 solver.cpp:238]     Train net output #0: loss = 2094.69 (* 1 = 2094.69 loss)
I1223 04:18:35.638236 25375 sgd_solver.cpp:105] Iteration 12300, lr = 1e-09
I1223 04:19:28.518714 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_12350.caffemodel
I1223 04:19:29.124477 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_12350.solverstate
I1223 04:19:29.206881 25375 solver.cpp:331] Iteration 12350, Testing net (#0)
I1223 04:20:41.793771 25375 solver.cpp:398]     Test net output #0: loss = 6374.65 (* 1 = 6374.65 loss)
I1223 04:20:42.594554 25375 solver.cpp:219] Iteration 12350 (0.393843 iter/s, 126.954s/50 iters), loss = 2562.5
I1223 04:20:42.594601 25375 solver.cpp:238]     Train net output #0: loss = 745.532 (* 1 = 745.532 loss)
I1223 04:20:42.594609 25375 sgd_solver.cpp:105] Iteration 12350, lr = 1e-09
I1223 04:21:36.987968 25375 solver.cpp:219] Iteration 12400 (0.919245 iter/s, 54.3924s/50 iters), loss = 2562.55
I1223 04:21:36.988003 25375 solver.cpp:238]     Train net output #0: loss = 2255.67 (* 1 = 2255.67 loss)
I1223 04:21:36.988009 25375 sgd_solver.cpp:105] Iteration 12400, lr = 1e-09
I1223 04:22:31.018203 25375 solver.cpp:219] Iteration 12450 (0.925425 iter/s, 54.0293s/50 iters), loss = 2559.51
I1223 04:22:31.018240 25375 solver.cpp:238]     Train net output #0: loss = 1782.76 (* 1 = 1782.76 loss)
I1223 04:22:31.018247 25375 sgd_solver.cpp:105] Iteration 12450, lr = 1e-09
I1223 04:23:23.912075 25375 solver.cpp:219] Iteration 12500 (0.945307 iter/s, 52.8929s/50 iters), loss = 2559.1
I1223 04:23:23.912117 25375 solver.cpp:238]     Train net output #0: loss = 694.012 (* 1 = 694.012 loss)
I1223 04:23:23.912127 25375 sgd_solver.cpp:105] Iteration 12500, lr = 1e-09
I1223 04:24:17.762827 25375 solver.cpp:219] Iteration 12550 (0.92851 iter/s, 53.8497s/50 iters), loss = 2556.9
I1223 04:24:17.762866 25375 solver.cpp:238]     Train net output #0: loss = 2553.85 (* 1 = 2553.85 loss)
I1223 04:24:17.762873 25375 sgd_solver.cpp:105] Iteration 12550, lr = 1e-09
I1223 04:25:11.822329 25375 solver.cpp:219] Iteration 12600 (0.924924 iter/s, 54.0585s/50 iters), loss = 2565.01
I1223 04:25:11.822369 25375 solver.cpp:238]     Train net output #0: loss = 2133.84 (* 1 = 2133.84 loss)
I1223 04:25:11.822376 25375 sgd_solver.cpp:105] Iteration 12600, lr = 1e-09
I1223 04:26:06.514336 25375 solver.cpp:219] Iteration 12650 (0.914227 iter/s, 54.691s/50 iters), loss = 2557.83
I1223 04:26:06.514374 25375 solver.cpp:238]     Train net output #0: loss = 729.052 (* 1 = 729.052 loss)
I1223 04:26:06.514379 25375 sgd_solver.cpp:105] Iteration 12650, lr = 1e-09
I1223 04:27:00.115424 25375 solver.cpp:219] Iteration 12700 (0.932834 iter/s, 53.6001s/50 iters), loss = 2554.76
I1223 04:27:00.115459 25375 solver.cpp:238]     Train net output #0: loss = 2208.02 (* 1 = 2208.02 loss)
I1223 04:27:00.115465 25375 sgd_solver.cpp:105] Iteration 12700, lr = 1e-09
I1223 04:27:54.112604 25375 solver.cpp:219] Iteration 12750 (0.925992 iter/s, 53.9962s/50 iters), loss = 2553.42
I1223 04:27:54.112637 25375 solver.cpp:238]     Train net output #0: loss = 1995.16 (* 1 = 1995.16 loss)
I1223 04:27:54.112643 25375 sgd_solver.cpp:105] Iteration 12750, lr = 1e-09
I1223 04:28:48.385581 25375 solver.cpp:219] Iteration 12800 (0.921286 iter/s, 54.272s/50 iters), loss = 2552.64
I1223 04:28:48.385617 25375 solver.cpp:238]     Train net output #0: loss = 717.039 (* 1 = 717.039 loss)
I1223 04:28:48.385623 25375 sgd_solver.cpp:105] Iteration 12800, lr = 1e-09
I1223 04:29:42.084354 25375 solver.cpp:219] Iteration 12850 (0.931138 iter/s, 53.6978s/50 iters), loss = 2551.39
I1223 04:29:42.084390 25375 solver.cpp:238]     Train net output #0: loss = 2375.58 (* 1 = 2375.58 loss)
I1223 04:29:42.084398 25375 sgd_solver.cpp:105] Iteration 12850, lr = 1e-09
I1223 04:30:36.917016 25375 solver.cpp:219] Iteration 12900 (0.911882 iter/s, 54.8316s/50 iters), loss = 2542.31
I1223 04:30:36.917052 25375 solver.cpp:238]     Train net output #0: loss = 2015.68 (* 1 = 2015.68 loss)
I1223 04:30:36.917057 25375 sgd_solver.cpp:105] Iteration 12900, lr = 1e-09
I1223 04:31:30.904939 25375 solver.cpp:219] Iteration 12950 (0.92615 iter/s, 53.9869s/50 iters), loss = 2545.38
I1223 04:31:30.904979 25375 solver.cpp:238]     Train net output #0: loss = 739.194 (* 1 = 739.194 loss)
I1223 04:31:30.904988 25375 sgd_solver.cpp:105] Iteration 12950, lr = 1e-09
I1223 04:32:24.678406 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_13000.caffemodel
I1223 04:32:25.413451 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_13000.solverstate
I1223 04:32:25.496863 25375 solver.cpp:331] Iteration 13000, Testing net (#0)
I1223 04:33:37.151384 25375 solver.cpp:398]     Test net output #0: loss = 6536.78 (* 1 = 6536.78 loss)
I1223 04:33:37.942762 25375 solver.cpp:219] Iteration 13000 (0.393591 iter/s, 127.036s/50 iters), loss = 2547.2
I1223 04:33:37.942798 25375 solver.cpp:238]     Train net output #0: loss = 2505.82 (* 1 = 2505.82 loss)
I1223 04:33:37.942806 25375 sgd_solver.cpp:105] Iteration 13000, lr = 1e-09
I1223 04:34:31.764477 25375 solver.cpp:219] Iteration 13050 (0.929009 iter/s, 53.8208s/50 iters), loss = 2549.65
I1223 04:34:31.764511 25375 solver.cpp:238]     Train net output #0: loss = 1761.84 (* 1 = 1761.84 loss)
I1223 04:34:31.764518 25375 sgd_solver.cpp:105] Iteration 13050, lr = 1e-09
I1223 04:35:23.608248 25375 solver.cpp:219] Iteration 13100 (0.964454 iter/s, 51.8428s/50 iters), loss = 2545.8
I1223 04:35:23.608284 25375 solver.cpp:238]     Train net output #0: loss = 697.491 (* 1 = 697.491 loss)
I1223 04:35:23.608290 25375 sgd_solver.cpp:105] Iteration 13100, lr = 1e-09
I1223 04:36:18.163228 25375 solver.cpp:219] Iteration 13150 (0.916524 iter/s, 54.554s/50 iters), loss = 2546.26
I1223 04:36:18.163260 25375 solver.cpp:238]     Train net output #0: loss = 2558.4 (* 1 = 2558.4 loss)
I1223 04:36:18.163266 25375 sgd_solver.cpp:105] Iteration 13150, lr = 1e-09
I1223 04:37:12.009644 25375 solver.cpp:219] Iteration 13200 (0.928584 iter/s, 53.8454s/50 iters), loss = 2539.35
I1223 04:37:12.009682 25375 solver.cpp:238]     Train net output #0: loss = 1778.15 (* 1 = 1778.15 loss)
I1223 04:37:12.009690 25375 sgd_solver.cpp:105] Iteration 13200, lr = 1e-09
I1223 04:38:06.695353 25375 solver.cpp:219] Iteration 13250 (0.914333 iter/s, 54.6847s/50 iters), loss = 2537.51
I1223 04:38:06.695390 25375 solver.cpp:238]     Train net output #0: loss = 758.592 (* 1 = 758.592 loss)
I1223 04:38:06.695399 25375 sgd_solver.cpp:105] Iteration 13250, lr = 1e-09
I1223 04:39:01.128083 25375 solver.cpp:219] Iteration 13300 (0.918582 iter/s, 54.4317s/50 iters), loss = 2543.47
I1223 04:39:01.128120 25375 solver.cpp:238]     Train net output #0: loss = 2474.1 (* 1 = 2474.1 loss)
I1223 04:39:01.128129 25375 sgd_solver.cpp:105] Iteration 13300, lr = 1e-09
I1223 04:39:55.153031 25375 solver.cpp:219] Iteration 13350 (0.925516 iter/s, 54.0239s/50 iters), loss = 2538.95
I1223 04:39:55.153075 25375 solver.cpp:238]     Train net output #0: loss = 2056.96 (* 1 = 2056.96 loss)
I1223 04:39:55.153084 25375 sgd_solver.cpp:105] Iteration 13350, lr = 1e-09
I1223 04:40:48.816323 25375 solver.cpp:219] Iteration 13400 (0.931753 iter/s, 53.6623s/50 iters), loss = 2538.85
I1223 04:40:48.816357 25375 solver.cpp:238]     Train net output #0: loss = 724.324 (* 1 = 724.324 loss)
I1223 04:40:48.816364 25375 sgd_solver.cpp:105] Iteration 13400, lr = 1e-09
I1223 04:41:42.433468 25375 solver.cpp:219] Iteration 13450 (0.932555 iter/s, 53.6161s/50 iters), loss = 2536.9
I1223 04:41:42.433511 25375 solver.cpp:238]     Train net output #0: loss = 2323.29 (* 1 = 2323.29 loss)
I1223 04:41:42.433519 25375 sgd_solver.cpp:105] Iteration 13450, lr = 1e-09
I1223 04:42:37.457460 25375 solver.cpp:219] Iteration 13500 (0.908712 iter/s, 55.023s/50 iters), loss = 2532.26
I1223 04:42:37.457495 25375 solver.cpp:238]     Train net output #0: loss = 1973.02 (* 1 = 1973.02 loss)
I1223 04:42:37.457501 25375 sgd_solver.cpp:105] Iteration 13500, lr = 1e-09
I1223 04:43:30.755820 25375 solver.cpp:219] Iteration 13550 (0.938133 iter/s, 53.2974s/50 iters), loss = 2524.44
I1223 04:43:30.755858 25375 solver.cpp:238]     Train net output #0: loss = 736.02 (* 1 = 736.02 loss)
I1223 04:43:30.755865 25375 sgd_solver.cpp:105] Iteration 13550, lr = 1e-09
I1223 04:44:24.987583 25375 solver.cpp:219] Iteration 13600 (0.921986 iter/s, 54.2307s/50 iters), loss = 2518.7
I1223 04:44:24.987619 25375 solver.cpp:238]     Train net output #0: loss = 2282.71 (* 1 = 2282.71 loss)
I1223 04:44:24.987627 25375 sgd_solver.cpp:105] Iteration 13600, lr = 1e-09
I1223 04:45:16.633754 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_13650.caffemodel
I1223 04:45:17.236286 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_13650.solverstate
I1223 04:45:17.331632 25375 solver.cpp:331] Iteration 13650, Testing net (#0)
I1223 04:46:31.340236 25375 solver.cpp:398]     Test net output #0: loss = 5796.14 (* 1 = 5796.14 loss)
I1223 04:46:32.136831 25375 solver.cpp:219] Iteration 13650 (0.393246 iter/s, 127.147s/50 iters), loss = 2525.16
I1223 04:46:32.136871 25375 solver.cpp:238]     Train net output #0: loss = 2138.16 (* 1 = 2138.16 loss)
I1223 04:46:32.136879 25375 sgd_solver.cpp:105] Iteration 13650, lr = 1e-09
I1223 04:47:24.640076 25375 solver.cpp:219] Iteration 13700 (0.952339 iter/s, 52.5023s/50 iters), loss = 2535.89
I1223 04:47:24.640113 25375 solver.cpp:238]     Train net output #0: loss = 740.375 (* 1 = 740.375 loss)
I1223 04:47:24.640121 25375 sgd_solver.cpp:105] Iteration 13700, lr = 1e-09
I1223 04:48:17.960480 25375 solver.cpp:219] Iteration 13750 (0.937744 iter/s, 53.3194s/50 iters), loss = 2540.06
I1223 04:48:17.960522 25375 solver.cpp:238]     Train net output #0: loss = 2558.43 (* 1 = 2558.43 loss)
I1223 04:48:17.960530 25375 sgd_solver.cpp:105] Iteration 13750, lr = 1e-09
I1223 04:49:11.034775 25375 solver.cpp:219] Iteration 13800 (0.942093 iter/s, 53.0733s/50 iters), loss = 2544.18
I1223 04:49:11.034818 25375 solver.cpp:238]     Train net output #0: loss = 1834.94 (* 1 = 1834.94 loss)
I1223 04:49:11.034827 25375 sgd_solver.cpp:105] Iteration 13800, lr = 1e-09
I1223 04:50:05.215433 25375 solver.cpp:219] Iteration 13850 (0.922856 iter/s, 54.1796s/50 iters), loss = 2541.53
I1223 04:50:05.215469 25375 solver.cpp:238]     Train net output #0: loss = 684.461 (* 1 = 684.461 loss)
I1223 04:50:05.215476 25375 sgd_solver.cpp:105] Iteration 13850, lr = 1e-09
I1223 04:50:58.358521 25375 solver.cpp:219] Iteration 13900 (0.940874 iter/s, 53.1421s/50 iters), loss = 2551.5
I1223 04:50:58.358556 25375 solver.cpp:238]     Train net output #0: loss = 2502.62 (* 1 = 2502.62 loss)
I1223 04:50:58.358561 25375 sgd_solver.cpp:105] Iteration 13900, lr = 1e-09
I1223 04:51:52.415325 25375 solver.cpp:219] Iteration 13950 (0.92497 iter/s, 54.0558s/50 iters), loss = 2549.08
I1223 04:51:52.415365 25375 solver.cpp:238]     Train net output #0: loss = 1830.77 (* 1 = 1830.77 loss)
I1223 04:51:52.415371 25375 sgd_solver.cpp:105] Iteration 13950, lr = 1e-09
I1223 04:52:46.411608 25375 solver.cpp:219] Iteration 14000 (0.926007 iter/s, 53.9953s/50 iters), loss = 2542.2
I1223 04:52:46.411644 25375 solver.cpp:238]     Train net output #0: loss = 741.091 (* 1 = 741.091 loss)
I1223 04:52:46.411651 25375 sgd_solver.cpp:105] Iteration 14000, lr = 1e-09
I1223 04:53:40.845527 25375 solver.cpp:219] Iteration 14050 (0.918562 iter/s, 54.4329s/50 iters), loss = 2542.86
I1223 04:53:40.845567 25375 solver.cpp:238]     Train net output #0: loss = 2522.09 (* 1 = 2522.09 loss)
I1223 04:53:40.845576 25375 sgd_solver.cpp:105] Iteration 14050, lr = 1e-09
I1223 04:54:35.665436 25375 solver.cpp:219] Iteration 14100 (0.912095 iter/s, 54.8189s/50 iters), loss = 2539.76
I1223 04:54:35.665475 25375 solver.cpp:238]     Train net output #0: loss = 1777.95 (* 1 = 1777.95 loss)
I1223 04:54:35.665482 25375 sgd_solver.cpp:105] Iteration 14100, lr = 1e-09
I1223 04:55:29.708115 25375 solver.cpp:219] Iteration 14150 (0.925212 iter/s, 54.0417s/50 iters), loss = 2538.08
I1223 04:55:29.708153 25375 solver.cpp:238]     Train net output #0: loss = 742.699 (* 1 = 742.699 loss)
I1223 04:55:29.708158 25375 sgd_solver.cpp:105] Iteration 14150, lr = 1e-09
I1223 04:56:23.069020 25375 solver.cpp:219] Iteration 14200 (0.937033 iter/s, 53.3599s/50 iters), loss = 2544.05
I1223 04:56:23.069056 25375 solver.cpp:238]     Train net output #0: loss = 2283.77 (* 1 = 2283.77 loss)
I1223 04:56:23.069063 25375 sgd_solver.cpp:105] Iteration 14200, lr = 1e-09
I1223 04:57:16.461520 25375 solver.cpp:219] Iteration 14250 (0.936479 iter/s, 53.3915s/50 iters), loss = 2545.65
I1223 04:57:16.461563 25375 solver.cpp:238]     Train net output #0: loss = 1796.29 (* 1 = 1796.29 loss)
I1223 04:57:16.461573 25375 sgd_solver.cpp:105] Iteration 14250, lr = 1e-09
I1223 04:58:08.324142 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_14300.caffemodel
I1223 04:58:09.104398 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_14300.solverstate
I1223 04:58:09.190642 25375 solver.cpp:331] Iteration 14300, Testing net (#0)
I1223 04:59:19.953853 25375 solver.cpp:398]     Test net output #0: loss = 6373.42 (* 1 = 6373.42 loss)
I1223 04:59:20.750813 25375 solver.cpp:219] Iteration 14300 (0.402295 iter/s, 124.287s/50 iters), loss = 2544.63
I1223 04:59:20.750852 25375 solver.cpp:238]     Train net output #0: loss = 711.343 (* 1 = 711.343 loss)
I1223 04:59:20.750860 25375 sgd_solver.cpp:105] Iteration 14300, lr = 1e-09
I1223 05:00:15.248586 25375 solver.cpp:219] Iteration 14350 (0.917485 iter/s, 54.4968s/50 iters), loss = 2549.39
I1223 05:00:15.248626 25375 solver.cpp:238]     Train net output #0: loss = 2316.17 (* 1 = 2316.17 loss)
I1223 05:00:15.248633 25375 sgd_solver.cpp:105] Iteration 14350, lr = 1e-09
I1223 05:01:07.312160 25375 solver.cpp:219] Iteration 14400 (0.960382 iter/s, 52.0626s/50 iters), loss = 2549.57
I1223 05:01:07.312193 25375 solver.cpp:238]     Train net output #0: loss = 2061.81 (* 1 = 2061.81 loss)
I1223 05:01:07.312201 25375 sgd_solver.cpp:105] Iteration 14400, lr = 1e-09
I1223 05:02:01.255174 25375 solver.cpp:219] Iteration 14450 (0.926921 iter/s, 53.942s/50 iters), loss = 2556.82
I1223 05:02:01.255210 25375 solver.cpp:238]     Train net output #0: loss = 704.36 (* 1 = 704.36 loss)
I1223 05:02:01.255216 25375 sgd_solver.cpp:105] Iteration 14450, lr = 1e-09
I1223 05:02:54.879824 25375 solver.cpp:219] Iteration 14500 (0.932424 iter/s, 53.6236s/50 iters), loss = 2568.83
I1223 05:02:54.879859 25375 solver.cpp:238]     Train net output #0: loss = 2478.69 (* 1 = 2478.69 loss)
I1223 05:02:54.879866 25375 sgd_solver.cpp:105] Iteration 14500, lr = 1e-09
I1223 05:03:48.336485 25375 solver.cpp:219] Iteration 14550 (0.935355 iter/s, 53.4557s/50 iters), loss = 2569.79
I1223 05:03:48.336522 25375 solver.cpp:238]     Train net output #0: loss = 1912.96 (* 1 = 1912.96 loss)
I1223 05:03:48.336529 25375 sgd_solver.cpp:105] Iteration 14550, lr = 1e-09
I1223 05:04:42.028398 25375 solver.cpp:219] Iteration 14600 (0.931256 iter/s, 53.6909s/50 iters), loss = 2569.07
I1223 05:04:42.028440 25375 solver.cpp:238]     Train net output #0: loss = 735.753 (* 1 = 735.753 loss)
I1223 05:04:42.028450 25375 sgd_solver.cpp:105] Iteration 14600, lr = 1e-09
I1223 05:05:35.491822 25375 solver.cpp:219] Iteration 14650 (0.935237 iter/s, 53.4624s/50 iters), loss = 2555.7
I1223 05:05:35.491880 25375 solver.cpp:238]     Train net output #0: loss = 2263.13 (* 1 = 2263.13 loss)
I1223 05:05:35.491892 25375 sgd_solver.cpp:105] Iteration 14650, lr = 1e-09
I1223 05:06:30.047770 25375 solver.cpp:219] Iteration 14700 (0.916508 iter/s, 54.5549s/50 iters), loss = 2545.75
I1223 05:06:30.047807 25375 solver.cpp:238]     Train net output #0: loss = 2201.7 (* 1 = 2201.7 loss)
I1223 05:06:30.047814 25375 sgd_solver.cpp:105] Iteration 14700, lr = 1e-09
I1223 05:07:23.443470 25375 solver.cpp:219] Iteration 14750 (0.936423 iter/s, 53.3947s/50 iters), loss = 2541.15
I1223 05:07:23.443505 25375 solver.cpp:238]     Train net output #0: loss = 687.201 (* 1 = 687.201 loss)
I1223 05:07:23.443511 25375 sgd_solver.cpp:105] Iteration 14750, lr = 1e-09
I1223 05:08:18.046921 25375 solver.cpp:219] Iteration 14800 (0.91571 iter/s, 54.6024s/50 iters), loss = 2536.84
I1223 05:08:18.046963 25375 solver.cpp:238]     Train net output #0: loss = 2158.54 (* 1 = 2158.54 loss)
I1223 05:08:18.046972 25375 sgd_solver.cpp:105] Iteration 14800, lr = 1e-09
I1223 05:09:11.797991 25375 solver.cpp:219] Iteration 14850 (0.930232 iter/s, 53.75s/50 iters), loss = 2542.26
I1223 05:09:11.798030 25375 solver.cpp:238]     Train net output #0: loss = 1789.25 (* 1 = 1789.25 loss)
I1223 05:09:11.798039 25375 sgd_solver.cpp:105] Iteration 14850, lr = 1e-09
I1223 05:10:05.689266 25375 solver.cpp:219] Iteration 14900 (0.927812 iter/s, 53.8903s/50 iters), loss = 2533.18
I1223 05:10:05.689303 25375 solver.cpp:238]     Train net output #0: loss = 712.968 (* 1 = 712.968 loss)
I1223 05:10:05.689311 25375 sgd_solver.cpp:105] Iteration 14900, lr = 1e-09
I1223 05:10:58.937623 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_14950.caffemodel
I1223 05:10:59.721778 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_14950.solverstate
I1223 05:10:59.817031 25375 solver.cpp:331] Iteration 14950, Testing net (#0)
I1223 05:12:12.514832 25375 solver.cpp:398]     Test net output #0: loss = 6986.6 (* 1 = 6986.6 loss)
I1223 05:12:13.309731 25375 solver.cpp:219] Iteration 14950 (0.391794 iter/s, 127.618s/50 iters), loss = 2547.33
I1223 05:12:13.309768 25375 solver.cpp:238]     Train net output #0: loss = 2630.46 (* 1 = 2630.46 loss)
I1223 05:12:13.309774 25375 sgd_solver.cpp:105] Iteration 14950, lr = 1e-09
I1223 05:13:04.596303 25375 solver.cpp:219] Iteration 15000 (0.974931 iter/s, 51.2857s/50 iters), loss = 2549.03
I1223 05:13:04.596338 25375 solver.cpp:238]     Train net output #0: loss = 1661.95 (* 1 = 1661.95 loss)
I1223 05:13:04.596344 25375 sgd_solver.cpp:105] Iteration 15000, lr = 1e-09
I1223 05:13:58.521564 25375 solver.cpp:219] Iteration 15050 (0.927226 iter/s, 53.9243s/50 iters), loss = 2544.68
I1223 05:13:58.521602 25375 solver.cpp:238]     Train net output #0: loss = 700.947 (* 1 = 700.947 loss)
I1223 05:13:58.521608 25375 sgd_solver.cpp:105] Iteration 15050, lr = 1e-09
I1223 05:14:52.993613 25375 solver.cpp:219] Iteration 15100 (0.917919 iter/s, 54.471s/50 iters), loss = 2546.3
I1223 05:14:52.993652 25375 solver.cpp:238]     Train net output #0: loss = 2485.64 (* 1 = 2485.64 loss)
I1223 05:14:52.993659 25375 sgd_solver.cpp:105] Iteration 15100, lr = 1e-09
I1223 05:15:47.847239 25375 solver.cpp:219] Iteration 15150 (0.911534 iter/s, 54.8526s/50 iters), loss = 2551.94
I1223 05:15:47.847280 25375 solver.cpp:238]     Train net output #0: loss = 1840.06 (* 1 = 1840.06 loss)
I1223 05:15:47.847288 25375 sgd_solver.cpp:105] Iteration 15150, lr = 1e-09
I1223 05:16:42.728006 25375 solver.cpp:219] Iteration 15200 (0.911083 iter/s, 54.8797s/50 iters), loss = 2552.96
I1223 05:16:42.728040 25375 solver.cpp:238]     Train net output #0: loss = 716.09 (* 1 = 716.09 loss)
I1223 05:16:42.728047 25375 sgd_solver.cpp:105] Iteration 15200, lr = 1e-09
I1223 05:17:36.100090 25375 solver.cpp:219] Iteration 15250 (0.936837 iter/s, 53.3711s/50 iters), loss = 2547.82
I1223 05:17:36.100126 25375 solver.cpp:238]     Train net output #0: loss = 2529.89 (* 1 = 2529.89 loss)
I1223 05:17:36.100131 25375 sgd_solver.cpp:105] Iteration 15250, lr = 1e-09
I1223 05:18:30.131218 25375 solver.cpp:219] Iteration 15300 (0.92541 iter/s, 54.0301s/50 iters), loss = 2550.95
I1223 05:18:30.131254 25375 solver.cpp:238]     Train net output #0: loss = 2247.75 (* 1 = 2247.75 loss)
I1223 05:18:30.131261 25375 sgd_solver.cpp:105] Iteration 15300, lr = 1e-09
I1223 05:19:24.816547 25375 solver.cpp:219] Iteration 15350 (0.914339 iter/s, 54.6843s/50 iters), loss = 2547.47
I1223 05:19:24.816582 25375 solver.cpp:238]     Train net output #0: loss = 677.197 (* 1 = 677.197 loss)
I1223 05:19:24.816588 25375 sgd_solver.cpp:105] Iteration 15350, lr = 1e-09
I1223 05:20:18.275120 25375 solver.cpp:219] Iteration 15400 (0.935321 iter/s, 53.4576s/50 iters), loss = 2540.45
I1223 05:20:18.275156 25375 solver.cpp:238]     Train net output #0: loss = 2178.52 (* 1 = 2178.52 loss)
I1223 05:20:18.275163 25375 sgd_solver.cpp:105] Iteration 15400, lr = 1e-09
I1223 05:21:13.182718 25375 solver.cpp:219] Iteration 15450 (0.910638 iter/s, 54.9066s/50 iters), loss = 2534.98
I1223 05:21:13.182750 25375 solver.cpp:238]     Train net output #0: loss = 1712.58 (* 1 = 1712.58 loss)
I1223 05:21:13.182755 25375 sgd_solver.cpp:105] Iteration 15450, lr = 1e-09
I1223 05:22:06.862469 25375 solver.cpp:219] Iteration 15500 (0.931467 iter/s, 53.6787s/50 iters), loss = 2532.59
I1223 05:22:06.862506 25375 solver.cpp:238]     Train net output #0: loss = 770.281 (* 1 = 770.281 loss)
I1223 05:22:06.862514 25375 sgd_solver.cpp:105] Iteration 15500, lr = 1e-09
I1223 05:23:00.624169 25375 solver.cpp:219] Iteration 15550 (0.930048 iter/s, 53.7607s/50 iters), loss = 2524.41
I1223 05:23:00.624214 25375 solver.cpp:238]     Train net output #0: loss = 2694.22 (* 1 = 2694.22 loss)
I1223 05:23:00.624222 25375 sgd_solver.cpp:105] Iteration 15550, lr = 1e-09
I1223 05:23:53.324968 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_15600.caffemodel
I1223 05:23:53.988059 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_15600.solverstate
I1223 05:23:54.081379 25375 solver.cpp:331] Iteration 15600, Testing net (#0)
I1223 05:25:05.770200 25375 solver.cpp:398]     Test net output #0: loss = 5501.41 (* 1 = 5501.41 loss)
I1223 05:25:06.567405 25375 solver.cpp:219] Iteration 15600 (0.397011 iter/s, 125.941s/50 iters), loss = 2521.89
I1223 05:25:06.567454 25375 solver.cpp:238]     Train net output #0: loss = 1652.33 (* 1 = 1652.33 loss)
I1223 05:25:06.567469 25375 sgd_solver.cpp:105] Iteration 15600, lr = 1e-09
I1223 05:25:59.542979 25375 solver.cpp:219] Iteration 15650 (0.943848 iter/s, 52.9746s/50 iters), loss = 2526.19
I1223 05:25:59.543014 25375 solver.cpp:238]     Train net output #0: loss = 683.583 (* 1 = 683.583 loss)
I1223 05:25:59.543020 25375 sgd_solver.cpp:105] Iteration 15650, lr = 1e-09
I1223 05:26:53.754760 25375 solver.cpp:219] Iteration 15700 (0.922326 iter/s, 54.2108s/50 iters), loss = 2538.18
I1223 05:26:53.754797 25375 solver.cpp:238]     Train net output #0: loss = 2242.44 (* 1 = 2242.44 loss)
I1223 05:26:53.754804 25375 sgd_solver.cpp:105] Iteration 15700, lr = 1e-09
I1223 05:27:47.567420 25375 solver.cpp:219] Iteration 15750 (0.929167 iter/s, 53.8117s/50 iters), loss = 2538.15
I1223 05:27:47.567452 25375 solver.cpp:238]     Train net output #0: loss = 1764.72 (* 1 = 1764.72 loss)
I1223 05:27:47.567458 25375 sgd_solver.cpp:105] Iteration 15750, lr = 1e-09
I1223 05:28:44.108901 25375 solver.cpp:219] Iteration 15800 (0.884323 iter/s, 56.5404s/50 iters), loss = 2538.98
I1223 05:28:44.108934 25375 solver.cpp:238]     Train net output #0: loss = 696.606 (* 1 = 696.606 loss)
I1223 05:28:44.108943 25375 sgd_solver.cpp:105] Iteration 15800, lr = 1e-09
I1223 05:29:37.403697 25375 solver.cpp:219] Iteration 15850 (0.938195 iter/s, 53.2938s/50 iters), loss = 2529.56
I1223 05:29:37.403734 25375 solver.cpp:238]     Train net output #0: loss = 2257.09 (* 1 = 2257.09 loss)
I1223 05:29:37.403741 25375 sgd_solver.cpp:105] Iteration 15850, lr = 1e-09
I1223 05:30:32.228047 25375 solver.cpp:219] Iteration 15900 (0.91202 iter/s, 54.8233s/50 iters), loss = 2537.4
I1223 05:30:32.228076 25375 solver.cpp:238]     Train net output #0: loss = 2258.34 (* 1 = 2258.34 loss)
I1223 05:30:32.228082 25375 sgd_solver.cpp:105] Iteration 15900, lr = 1e-09
I1223 05:31:26.543579 25375 solver.cpp:219] Iteration 15950 (0.920564 iter/s, 54.3145s/50 iters), loss = 2532.42
I1223 05:31:26.543612 25375 solver.cpp:238]     Train net output #0: loss = 734.896 (* 1 = 734.896 loss)
I1223 05:31:26.543618 25375 sgd_solver.cpp:105] Iteration 15950, lr = 1e-09
I1223 05:32:20.565667 25375 solver.cpp:219] Iteration 16000 (0.925565 iter/s, 54.0211s/50 iters), loss = 2533.6
I1223 05:32:20.565699 25375 solver.cpp:238]     Train net output #0: loss = 2198.85 (* 1 = 2198.85 loss)
I1223 05:32:20.565706 25375 sgd_solver.cpp:105] Iteration 16000, lr = 1e-09
I1223 05:33:13.823667 25375 solver.cpp:219] Iteration 16050 (0.938844 iter/s, 53.257s/50 iters), loss = 2541.28
I1223 05:33:13.823700 25375 solver.cpp:238]     Train net output #0: loss = 1703.38 (* 1 = 1703.38 loss)
I1223 05:33:13.823706 25375 sgd_solver.cpp:105] Iteration 16050, lr = 1e-09
I1223 05:34:07.521481 25375 solver.cpp:219] Iteration 16100 (0.931154 iter/s, 53.6968s/50 iters), loss = 2545.32
I1223 05:34:07.521519 25375 solver.cpp:238]     Train net output #0: loss = 760.679 (* 1 = 760.679 loss)
I1223 05:34:07.521525 25375 sgd_solver.cpp:105] Iteration 16100, lr = 1e-09
I1223 05:35:02.067471 25375 solver.cpp:219] Iteration 16150 (0.916675 iter/s, 54.545s/50 iters), loss = 2538.12
I1223 05:35:02.067510 25375 solver.cpp:238]     Train net output #0: loss = 2151.81 (* 1 = 2151.81 loss)
I1223 05:35:02.067517 25375 sgd_solver.cpp:105] Iteration 16150, lr = 1e-09
I1223 05:35:56.471253 25375 solver.cpp:219] Iteration 16200 (0.919071 iter/s, 54.4028s/50 iters), loss = 2531.69
I1223 05:35:56.471290 25375 solver.cpp:238]     Train net output #0: loss = 1671.65 (* 1 = 1671.65 loss)
I1223 05:35:56.471298 25375 sgd_solver.cpp:105] Iteration 16200, lr = 1e-09
I1223 05:36:47.632165 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_16250.caffemodel
I1223 05:36:48.274602 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_16250.solverstate
I1223 05:36:48.368013 25375 solver.cpp:331] Iteration 16250, Testing net (#0)
I1223 05:38:00.514519 25375 solver.cpp:398]     Test net output #0: loss = 5982.66 (* 1 = 5982.66 loss)
I1223 05:38:01.310322 25375 solver.cpp:219] Iteration 16250 (0.400523 iter/s, 124.837s/50 iters), loss = 2544.05
I1223 05:38:01.310359 25375 solver.cpp:238]     Train net output #0: loss = 733.587 (* 1 = 733.587 loss)
I1223 05:38:01.310365 25375 sgd_solver.cpp:105] Iteration 16250, lr = 1e-09
I1223 05:38:55.662247 25375 solver.cpp:219] Iteration 16300 (0.919947 iter/s, 54.351s/50 iters), loss = 2543.43
I1223 05:38:55.662289 25375 solver.cpp:238]     Train net output #0: loss = 2489.39 (* 1 = 2489.39 loss)
I1223 05:38:55.662297 25375 sgd_solver.cpp:105] Iteration 16300, lr = 1e-09
I1223 05:39:48.640223 25375 solver.cpp:219] Iteration 16350 (0.943806 iter/s, 52.977s/50 iters), loss = 2535.42
I1223 05:39:48.640264 25375 solver.cpp:238]     Train net output #0: loss = 2130.06 (* 1 = 2130.06 loss)
I1223 05:39:48.640271 25375 sgd_solver.cpp:105] Iteration 16350, lr = 1e-09
I1223 05:40:42.549259 25375 solver.cpp:219] Iteration 16400 (0.927505 iter/s, 53.908s/50 iters), loss = 2541.79
I1223 05:40:42.549295 25375 solver.cpp:238]     Train net output #0: loss = 695.195 (* 1 = 695.195 loss)
I1223 05:40:42.549302 25375 sgd_solver.cpp:105] Iteration 16400, lr = 1e-09
I1223 05:41:36.430414 25375 solver.cpp:219] Iteration 16450 (0.927985 iter/s, 53.8802s/50 iters), loss = 2545.2
I1223 05:41:36.430454 25375 solver.cpp:238]     Train net output #0: loss = 2215.95 (* 1 = 2215.95 loss)
I1223 05:41:36.430460 25375 sgd_solver.cpp:105] Iteration 16450, lr = 1e-09
I1223 05:42:30.835059 25375 solver.cpp:219] Iteration 16500 (0.919056 iter/s, 54.4036s/50 iters), loss = 2546.88
I1223 05:42:30.835104 25375 solver.cpp:238]     Train net output #0: loss = 1773.77 (* 1 = 1773.77 loss)
I1223 05:42:30.835114 25375 sgd_solver.cpp:105] Iteration 16500, lr = 1e-09
I1223 05:43:24.345451 25375 solver.cpp:219] Iteration 16550 (0.934415 iter/s, 53.5094s/50 iters), loss = 2555.59
I1223 05:43:24.345479 25375 solver.cpp:238]     Train net output #0: loss = 703.812 (* 1 = 703.812 loss)
I1223 05:43:24.345485 25375 sgd_solver.cpp:105] Iteration 16550, lr = 1e-09
I1223 05:44:18.324257 25375 solver.cpp:219] Iteration 16600 (0.926307 iter/s, 53.9778s/50 iters), loss = 2559.91
I1223 05:44:18.324301 25375 solver.cpp:238]     Train net output #0: loss = 2326.22 (* 1 = 2326.22 loss)
I1223 05:44:18.324309 25375 sgd_solver.cpp:105] Iteration 16600, lr = 1e-09
I1223 05:45:14.333840 25375 solver.cpp:219] Iteration 16650 (0.892721 iter/s, 56.0085s/50 iters), loss = 2556.46
I1223 05:45:14.333874 25375 solver.cpp:238]     Train net output #0: loss = 1687.87 (* 1 = 1687.87 loss)
I1223 05:45:14.333880 25375 sgd_solver.cpp:105] Iteration 16650, lr = 1e-09
I1223 05:46:09.129184 25375 solver.cpp:219] Iteration 16700 (0.912503 iter/s, 54.7943s/50 iters), loss = 2543.36
I1223 05:46:09.129217 25375 solver.cpp:238]     Train net output #0: loss = 756.873 (* 1 = 756.873 loss)
I1223 05:46:09.129223 25375 sgd_solver.cpp:105] Iteration 16700, lr = 1e-09
I1223 05:47:03.330679 25375 solver.cpp:219] Iteration 16750 (0.922501 iter/s, 54.2005s/50 iters), loss = 2544.62
I1223 05:47:03.330719 25375 solver.cpp:238]     Train net output #0: loss = 2405.77 (* 1 = 2405.77 loss)
I1223 05:47:03.330727 25375 sgd_solver.cpp:105] Iteration 16750, lr = 1e-09
I1223 05:47:57.309792 25375 solver.cpp:219] Iteration 16800 (0.926302 iter/s, 53.9781s/50 iters), loss = 2545.42
I1223 05:47:57.309824 25375 solver.cpp:238]     Train net output #0: loss = 2086.95 (* 1 = 2086.95 loss)
I1223 05:47:57.309831 25375 sgd_solver.cpp:105] Iteration 16800, lr = 1e-09
I1223 05:48:50.855374 25375 solver.cpp:219] Iteration 16850 (0.933801 iter/s, 53.5446s/50 iters), loss = 2553.01
I1223 05:48:50.855415 25375 solver.cpp:238]     Train net output #0: loss = 764.429 (* 1 = 764.429 loss)
I1223 05:48:50.855424 25375 sgd_solver.cpp:105] Iteration 16850, lr = 1e-09
I1223 05:49:43.480597 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_16900.caffemodel
I1223 05:49:44.107331 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_16900.solverstate
I1223 05:49:44.190893 25375 solver.cpp:331] Iteration 16900, Testing net (#0)
I1223 05:50:57.043529 25375 solver.cpp:398]     Test net output #0: loss = 5943.91 (* 1 = 5943.91 loss)
I1223 05:50:57.840131 25375 solver.cpp:219] Iteration 16900 (0.393755 iter/s, 126.982s/50 iters), loss = 2550.43
I1223 05:50:57.840167 25375 solver.cpp:238]     Train net output #0: loss = 2176.93 (* 1 = 2176.93 loss)
I1223 05:50:57.840174 25375 sgd_solver.cpp:105] Iteration 16900, lr = 1e-09
I1223 05:51:49.787677 25375 solver.cpp:219] Iteration 16950 (0.962526 iter/s, 51.9466s/50 iters), loss = 2547.41
I1223 05:51:49.787710 25375 solver.cpp:238]     Train net output #0: loss = 2011.82 (* 1 = 2011.82 loss)
I1223 05:51:49.787716 25375 sgd_solver.cpp:105] Iteration 16950, lr = 1e-09
I1223 05:52:43.225807 25375 solver.cpp:219] Iteration 17000 (0.935678 iter/s, 53.4372s/50 iters), loss = 2555.03
I1223 05:52:43.225842 25375 solver.cpp:238]     Train net output #0: loss = 692.076 (* 1 = 692.076 loss)
I1223 05:52:43.225849 25375 sgd_solver.cpp:105] Iteration 17000, lr = 1e-09
I1223 05:53:36.615607 25375 solver.cpp:219] Iteration 17050 (0.936526 iter/s, 53.3888s/50 iters), loss = 2554.76
I1223 05:53:36.615643 25375 solver.cpp:238]     Train net output #0: loss = 2329.55 (* 1 = 2329.55 loss)
I1223 05:53:36.615650 25375 sgd_solver.cpp:105] Iteration 17050, lr = 1e-09
I1223 05:54:29.271694 25375 solver.cpp:219] Iteration 17100 (0.949576 iter/s, 52.6551s/50 iters), loss = 2550.96
I1223 05:54:29.271729 25375 solver.cpp:238]     Train net output #0: loss = 1714.03 (* 1 = 1714.03 loss)
I1223 05:54:29.271735 25375 sgd_solver.cpp:105] Iteration 17100, lr = 1e-09
I1223 05:55:24.541107 25375 solver.cpp:219] Iteration 17150 (0.904676 iter/s, 55.2684s/50 iters), loss = 2557.61
I1223 05:55:24.541147 25375 solver.cpp:238]     Train net output #0: loss = 730.535 (* 1 = 730.535 loss)
I1223 05:55:24.541154 25375 sgd_solver.cpp:105] Iteration 17150, lr = 1e-09
I1223 05:56:18.401157 25375 solver.cpp:219] Iteration 17200 (0.928349 iter/s, 53.859s/50 iters), loss = 2566.38
I1223 05:56:18.401195 25375 solver.cpp:238]     Train net output #0: loss = 2204.43 (* 1 = 2204.43 loss)
I1223 05:56:18.401201 25375 sgd_solver.cpp:105] Iteration 17200, lr = 1e-09
I1223 05:57:12.929308 25375 solver.cpp:219] Iteration 17250 (0.916975 iter/s, 54.5271s/50 iters), loss = 2553.65
I1223 05:57:12.929350 25375 solver.cpp:238]     Train net output #0: loss = 1791.48 (* 1 = 1791.48 loss)
I1223 05:57:12.929358 25375 sgd_solver.cpp:105] Iteration 17250, lr = 1e-09
I1223 05:58:07.084903 25375 solver.cpp:219] Iteration 17300 (0.923283 iter/s, 54.1546s/50 iters), loss = 2553.97
I1223 05:58:07.084939 25375 solver.cpp:238]     Train net output #0: loss = 722.316 (* 1 = 722.316 loss)
I1223 05:58:07.084945 25375 sgd_solver.cpp:105] Iteration 17300, lr = 1e-09
I1223 05:59:01.946774 25375 solver.cpp:219] Iteration 17350 (0.911397 iter/s, 54.8608s/50 iters), loss = 2556.27
I1223 05:59:01.946807 25375 solver.cpp:238]     Train net output #0: loss = 2454.16 (* 1 = 2454.16 loss)
I1223 05:59:01.946815 25375 sgd_solver.cpp:105] Iteration 17350, lr = 1e-09
I1223 05:59:55.199600 25375 solver.cpp:219] Iteration 17400 (0.938935 iter/s, 53.2518s/50 iters), loss = 2554.62
I1223 05:59:55.199635 25375 solver.cpp:238]     Train net output #0: loss = 1792.91 (* 1 = 1792.91 loss)
I1223 05:59:55.199640 25375 sgd_solver.cpp:105] Iteration 17400, lr = 1e-09
I1223 06:00:48.576617 25375 solver.cpp:219] Iteration 17450 (0.93675 iter/s, 53.376s/50 iters), loss = 2552.33
I1223 06:00:48.576655 25375 solver.cpp:238]     Train net output #0: loss = 835.066 (* 1 = 835.066 loss)
I1223 06:00:48.576661 25375 sgd_solver.cpp:105] Iteration 17450, lr = 1e-09
I1223 06:01:43.645480 25375 solver.cpp:219] Iteration 17500 (0.907971 iter/s, 55.0678s/50 iters), loss = 2545.46
I1223 06:01:43.645515 25375 solver.cpp:238]     Train net output #0: loss = 2469.54 (* 1 = 2469.54 loss)
I1223 06:01:43.645522 25375 sgd_solver.cpp:105] Iteration 17500, lr = 1e-09
I1223 06:02:35.673298 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_17550.caffemodel
I1223 06:02:36.309013 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_17550.solverstate
I1223 06:02:36.402765 25375 solver.cpp:331] Iteration 17550, Testing net (#0)
I1223 06:03:49.000519 25375 solver.cpp:398]     Test net output #0: loss = 6564.85 (* 1 = 6564.85 loss)
I1223 06:03:49.796618 25375 solver.cpp:219] Iteration 17550 (0.396357 iter/s, 126.149s/50 iters), loss = 2549.97
I1223 06:03:49.796658 25375 solver.cpp:238]     Train net output #0: loss = 2117.8 (* 1 = 2117.8 loss)
I1223 06:03:49.796664 25375 sgd_solver.cpp:105] Iteration 17550, lr = 1e-09
I1223 06:04:44.099664 25375 solver.cpp:219] Iteration 17600 (0.920775 iter/s, 54.3021s/50 iters), loss = 2560.76
I1223 06:04:44.099700 25375 solver.cpp:238]     Train net output #0: loss = 742.68 (* 1 = 742.68 loss)
I1223 06:04:44.099709 25375 sgd_solver.cpp:105] Iteration 17600, lr = 1e-09
I1223 06:05:37.182623 25375 solver.cpp:219] Iteration 17650 (0.941939 iter/s, 53.082s/50 iters), loss = 2559.93
I1223 06:05:37.182662 25375 solver.cpp:238]     Train net output #0: loss = 2261.25 (* 1 = 2261.25 loss)
I1223 06:05:37.182668 25375 sgd_solver.cpp:105] Iteration 17650, lr = 1e-09
I1223 06:06:30.878440 25375 solver.cpp:219] Iteration 17700 (0.931188 iter/s, 53.6948s/50 iters), loss = 2568.75
I1223 06:06:30.878473 25375 solver.cpp:238]     Train net output #0: loss = 1943.59 (* 1 = 1943.59 loss)
I1223 06:06:30.878480 25375 sgd_solver.cpp:105] Iteration 17700, lr = 1e-09
I1223 06:07:23.138830 25375 solver.cpp:219] Iteration 17750 (0.956765 iter/s, 52.2594s/50 iters), loss = 2578.99
I1223 06:07:23.138872 25375 solver.cpp:238]     Train net output #0: loss = 731.53 (* 1 = 731.53 loss)
I1223 06:07:23.138880 25375 sgd_solver.cpp:105] Iteration 17750, lr = 1e-09
I1223 06:08:16.810904 25375 solver.cpp:219] Iteration 17800 (0.931601 iter/s, 53.6711s/50 iters), loss = 2583.75
I1223 06:08:16.810941 25375 solver.cpp:238]     Train net output #0: loss = 2337.65 (* 1 = 2337.65 loss)
I1223 06:08:16.810947 25375 sgd_solver.cpp:105] Iteration 17800, lr = 1e-09
I1223 06:09:11.423411 25375 solver.cpp:219] Iteration 17850 (0.915558 iter/s, 54.6115s/50 iters), loss = 2586.11
I1223 06:09:11.423450 25375 solver.cpp:238]     Train net output #0: loss = 1777.89 (* 1 = 1777.89 loss)
I1223 06:09:11.423457 25375 sgd_solver.cpp:105] Iteration 17850, lr = 1e-09
I1223 06:10:04.514155 25375 solver.cpp:219] Iteration 17900 (0.941801 iter/s, 53.0897s/50 iters), loss = 2590.25
I1223 06:10:04.514195 25375 solver.cpp:238]     Train net output #0: loss = 703.064 (* 1 = 703.064 loss)
I1223 06:10:04.514204 25375 sgd_solver.cpp:105] Iteration 17900, lr = 1e-09
I1223 06:10:59.408967 25375 solver.cpp:219] Iteration 17950 (0.91085 iter/s, 54.8938s/50 iters), loss = 2582.63
I1223 06:10:59.409005 25375 solver.cpp:238]     Train net output #0: loss = 2646.96 (* 1 = 2646.96 loss)
I1223 06:10:59.409013 25375 sgd_solver.cpp:105] Iteration 17950, lr = 1e-09
I1223 06:11:53.514199 25375 solver.cpp:219] Iteration 18000 (0.924142 iter/s, 54.1042s/50 iters), loss = 2587.41
I1223 06:11:53.514243 25375 solver.cpp:238]     Train net output #0: loss = 1854.53 (* 1 = 1854.53 loss)
I1223 06:11:53.514253 25375 sgd_solver.cpp:105] Iteration 18000, lr = 1e-09
I1223 06:12:47.000313 25375 solver.cpp:219] Iteration 18050 (0.93484 iter/s, 53.4851s/50 iters), loss = 2591.05
I1223 06:12:47.000349 25375 solver.cpp:238]     Train net output #0: loss = 701.317 (* 1 = 701.317 loss)
I1223 06:12:47.000355 25375 sgd_solver.cpp:105] Iteration 18050, lr = 1e-09
I1223 06:13:41.314946 25375 solver.cpp:219] Iteration 18100 (0.92058 iter/s, 54.3136s/50 iters), loss = 2591.28
I1223 06:13:41.314996 25375 solver.cpp:238]     Train net output #0: loss = 2328.5 (* 1 = 2328.5 loss)
I1223 06:13:41.315003 25375 sgd_solver.cpp:105] Iteration 18100, lr = 1e-09
I1223 06:14:35.656090 25375 solver.cpp:219] Iteration 18150 (0.920131 iter/s, 54.3401s/50 iters), loss = 2590.6
I1223 06:14:35.656126 25375 solver.cpp:238]     Train net output #0: loss = 1796.4 (* 1 = 1796.4 loss)
I1223 06:14:35.656131 25375 sgd_solver.cpp:105] Iteration 18150, lr = 1e-09
I1223 06:15:27.928484 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_18200.caffemodel
I1223 06:15:28.734774 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_18200.solverstate
I1223 06:15:28.843828 25375 solver.cpp:331] Iteration 18200, Testing net (#0)
I1223 06:16:41.656272 25375 solver.cpp:398]     Test net output #0: loss = 5800.94 (* 1 = 5800.94 loss)
I1223 06:16:42.452383 25375 solver.cpp:219] Iteration 18200 (0.39434 iter/s, 126.794s/50 iters), loss = 2583.5
I1223 06:16:42.452414 25375 solver.cpp:238]     Train net output #0: loss = 704.63 (* 1 = 704.63 loss)
I1223 06:16:42.452420 25375 sgd_solver.cpp:105] Iteration 18200, lr = 1e-09
I1223 06:17:34.746316 25375 solver.cpp:219] Iteration 18250 (0.956151 iter/s, 52.293s/50 iters), loss = 2589.63
I1223 06:17:34.746354 25375 solver.cpp:238]     Train net output #0: loss = 2568.28 (* 1 = 2568.28 loss)
I1223 06:17:34.746361 25375 sgd_solver.cpp:105] Iteration 18250, lr = 1e-09
I1223 06:18:27.537415 25375 solver.cpp:219] Iteration 18300 (0.947147 iter/s, 52.7901s/50 iters), loss = 2590.03
I1223 06:18:27.537451 25375 solver.cpp:238]     Train net output #0: loss = 1842.13 (* 1 = 1842.13 loss)
I1223 06:18:27.537457 25375 sgd_solver.cpp:105] Iteration 18300, lr = 1e-09
I1223 06:19:21.287636 25375 solver.cpp:219] Iteration 18350 (0.930246 iter/s, 53.7492s/50 iters), loss = 2592.73
I1223 06:19:21.287668 25375 solver.cpp:238]     Train net output #0: loss = 714.152 (* 1 = 714.152 loss)
I1223 06:19:21.287674 25375 sgd_solver.cpp:105] Iteration 18350, lr = 1e-09
I1223 06:20:15.508399 25375 solver.cpp:219] Iteration 18400 (0.922173 iter/s, 54.2198s/50 iters), loss = 2596.12
I1223 06:20:15.508430 25375 solver.cpp:238]     Train net output #0: loss = 2346.48 (* 1 = 2346.48 loss)
I1223 06:20:15.508435 25375 sgd_solver.cpp:105] Iteration 18400, lr = 1e-09
I1223 06:21:11.461335 25375 solver.cpp:219] Iteration 18450 (0.893625 iter/s, 55.9519s/50 iters), loss = 2584.36
I1223 06:21:11.461367 25375 solver.cpp:238]     Train net output #0: loss = 1695.82 (* 1 = 1695.82 loss)
I1223 06:21:11.461374 25375 sgd_solver.cpp:105] Iteration 18450, lr = 1e-09
I1223 06:22:05.190887 25375 solver.cpp:219] Iteration 18500 (0.930604 iter/s, 53.7286s/50 iters), loss = 2583.3
I1223 06:22:05.190923 25375 solver.cpp:238]     Train net output #0: loss = 720.524 (* 1 = 720.524 loss)
I1223 06:22:05.190930 25375 sgd_solver.cpp:105] Iteration 18500, lr = 1e-09
I1223 06:23:00.899941 25375 solver.cpp:219] Iteration 18550 (0.897537 iter/s, 55.708s/50 iters), loss = 2576.39
I1223 06:23:00.899976 25375 solver.cpp:238]     Train net output #0: loss = 2284.44 (* 1 = 2284.44 loss)
I1223 06:23:00.899981 25375 sgd_solver.cpp:105] Iteration 18550, lr = 1e-09
I1223 06:23:54.985759 25375 solver.cpp:219] Iteration 18600 (0.924474 iter/s, 54.0848s/50 iters), loss = 2562.21
I1223 06:23:54.985801 25375 solver.cpp:238]     Train net output #0: loss = 1706.18 (* 1 = 1706.18 loss)
I1223 06:23:54.985811 25375 sgd_solver.cpp:105] Iteration 18600, lr = 1e-09
I1223 06:24:48.996371 25375 solver.cpp:219] Iteration 18650 (0.925761 iter/s, 54.0096s/50 iters), loss = 2571.71
I1223 06:24:48.996408 25375 solver.cpp:238]     Train net output #0: loss = 750.696 (* 1 = 750.696 loss)
I1223 06:24:48.996414 25375 sgd_solver.cpp:105] Iteration 18650, lr = 1e-09
I1223 06:25:41.530786 25375 solver.cpp:219] Iteration 18700 (0.951775 iter/s, 52.5334s/50 iters), loss = 2560.11
I1223 06:25:41.530820 25375 solver.cpp:238]     Train net output #0: loss = 2453.68 (* 1 = 2453.68 loss)
I1223 06:25:41.530827 25375 sgd_solver.cpp:105] Iteration 18700, lr = 1e-09
I1223 06:26:35.173197 25375 solver.cpp:219] Iteration 18750 (0.932116 iter/s, 53.6414s/50 iters), loss = 2553.59
I1223 06:26:35.173238 25375 solver.cpp:238]     Train net output #0: loss = 1844.99 (* 1 = 1844.99 loss)
I1223 06:26:35.173244 25375 sgd_solver.cpp:105] Iteration 18750, lr = 1e-09
I1223 06:27:28.942792 25375 solver.cpp:219] Iteration 18800 (0.929911 iter/s, 53.7686s/50 iters), loss = 2556.94
I1223 06:27:28.942829 25375 solver.cpp:238]     Train net output #0: loss = 690.475 (* 1 = 690.475 loss)
I1223 06:27:28.942836 25375 sgd_solver.cpp:105] Iteration 18800, lr = 1e-09
I1223 06:28:20.466259 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_18850.caffemodel
I1223 06:28:21.088362 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_18850.solverstate
I1223 06:28:21.195454 25375 solver.cpp:331] Iteration 18850, Testing net (#0)
I1223 06:29:33.861873 25375 solver.cpp:398]     Test net output #0: loss = 6503.77 (* 1 = 6503.77 loss)
I1223 06:29:34.656438 25375 solver.cpp:219] Iteration 18850 (0.397736 iter/s, 125.711s/50 iters), loss = 2545.96
I1223 06:29:34.656473 25375 solver.cpp:238]     Train net output #0: loss = 2278.09 (* 1 = 2278.09 loss)
I1223 06:29:34.656481 25375 sgd_solver.cpp:105] Iteration 18850, lr = 1e-09
I1223 06:30:27.029791 25375 solver.cpp:219] Iteration 18900 (0.954701 iter/s, 52.3724s/50 iters), loss = 2539.26
I1223 06:30:27.029824 25375 solver.cpp:238]     Train net output #0: loss = 1900.17 (* 1 = 1900.17 loss)
I1223 06:30:27.029830 25375 sgd_solver.cpp:105] Iteration 18900, lr = 1e-09
I1223 06:31:20.570312 25375 solver.cpp:219] Iteration 18950 (0.933889 iter/s, 53.5395s/50 iters), loss = 2552.82
I1223 06:31:20.570353 25375 solver.cpp:238]     Train net output #0: loss = 752.942 (* 1 = 752.942 loss)
I1223 06:31:20.570360 25375 sgd_solver.cpp:105] Iteration 18950, lr = 1e-09
I1223 06:32:14.641508 25375 solver.cpp:219] Iteration 19000 (0.924724 iter/s, 54.0702s/50 iters), loss = 2540.72
I1223 06:32:14.641542 25375 solver.cpp:238]     Train net output #0: loss = 2302.56 (* 1 = 2302.56 loss)
I1223 06:32:14.641548 25375 sgd_solver.cpp:105] Iteration 19000, lr = 1e-09
I1223 06:33:08.552867 25375 solver.cpp:219] Iteration 19050 (0.927466 iter/s, 53.9104s/50 iters), loss = 2533.44
I1223 06:33:08.552911 25375 solver.cpp:238]     Train net output #0: loss = 1679.02 (* 1 = 1679.02 loss)
I1223 06:33:08.552918 25375 sgd_solver.cpp:105] Iteration 19050, lr = 1e-09
I1223 06:34:01.690865 25375 solver.cpp:219] Iteration 19100 (0.940964 iter/s, 53.137s/50 iters), loss = 2534.86
I1223 06:34:01.690909 25375 solver.cpp:238]     Train net output #0: loss = 687.012 (* 1 = 687.012 loss)
I1223 06:34:01.690917 25375 sgd_solver.cpp:105] Iteration 19100, lr = 1e-09
I1223 06:34:55.820757 25375 solver.cpp:219] Iteration 19150 (0.923721 iter/s, 54.1289s/50 iters), loss = 2534.97
I1223 06:34:55.820802 25375 solver.cpp:238]     Train net output #0: loss = 2210 (* 1 = 2210 loss)
I1223 06:34:55.820811 25375 sgd_solver.cpp:105] Iteration 19150, lr = 1e-09
I1223 06:35:49.786443 25375 solver.cpp:219] Iteration 19200 (0.926532 iter/s, 53.9647s/50 iters), loss = 2535
I1223 06:35:49.786480 25375 solver.cpp:238]     Train net output #0: loss = 1695.44 (* 1 = 1695.44 loss)
I1223 06:35:49.786487 25375 sgd_solver.cpp:105] Iteration 19200, lr = 1e-09
I1223 06:36:43.874461 25375 solver.cpp:219] Iteration 19250 (0.924437 iter/s, 54.087s/50 iters), loss = 2523.1
I1223 06:36:43.874500 25375 solver.cpp:238]     Train net output #0: loss = 725.841 (* 1 = 725.841 loss)
I1223 06:36:43.874506 25375 sgd_solver.cpp:105] Iteration 19250, lr = 1e-09
I1223 06:37:36.804574 25375 solver.cpp:219] Iteration 19300 (0.94466 iter/s, 52.9291s/50 iters), loss = 2517.46
I1223 06:37:36.804611 25375 solver.cpp:238]     Train net output #0: loss = 2437.45 (* 1 = 2437.45 loss)
I1223 06:37:36.804618 25375 sgd_solver.cpp:105] Iteration 19300, lr = 1e-09
I1223 06:38:30.993783 25375 solver.cpp:219] Iteration 19350 (0.92271 iter/s, 54.1882s/50 iters), loss = 2511.26
I1223 06:38:30.993826 25375 solver.cpp:238]     Train net output #0: loss = 1840.28 (* 1 = 1840.28 loss)
I1223 06:38:30.993836 25375 sgd_solver.cpp:105] Iteration 19350, lr = 1e-09
I1223 06:39:25.969738 25375 solver.cpp:219] Iteration 19400 (0.909506 iter/s, 54.9749s/50 iters), loss = 2506.14
I1223 06:39:25.969781 25375 solver.cpp:238]     Train net output #0: loss = 719.281 (* 1 = 719.281 loss)
I1223 06:39:25.969792 25375 sgd_solver.cpp:105] Iteration 19400, lr = 1e-09
I1223 06:40:20.531945 25375 solver.cpp:219] Iteration 19450 (0.916403 iter/s, 54.5612s/50 iters), loss = 2509.41
I1223 06:40:20.531982 25375 solver.cpp:238]     Train net output #0: loss = 2252.02 (* 1 = 2252.02 loss)
I1223 06:40:20.531989 25375 sgd_solver.cpp:105] Iteration 19450, lr = 1e-09
I1223 06:41:13.071364 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_19500.caffemodel
I1223 06:41:13.597631 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_19500.solverstate
I1223 06:41:13.690814 25375 solver.cpp:331] Iteration 19500, Testing net (#0)
I1223 06:42:25.523584 25375 solver.cpp:398]     Test net output #0: loss = 6388.27 (* 1 = 6388.27 loss)
I1223 06:42:26.322674 25375 solver.cpp:219] Iteration 19500 (0.397493 iter/s, 125.788s/50 iters), loss = 2506.15
I1223 06:42:26.322708 25375 solver.cpp:238]     Train net output #0: loss = 1986.87 (* 1 = 1986.87 loss)
I1223 06:42:26.322715 25375 sgd_solver.cpp:105] Iteration 19500, lr = 1e-09
I1223 06:43:18.999433 25375 solver.cpp:219] Iteration 19550 (0.949202 iter/s, 52.6758s/50 iters), loss = 2512.99
I1223 06:43:18.999470 25375 solver.cpp:238]     Train net output #0: loss = 739.236 (* 1 = 739.236 loss)
I1223 06:43:18.999477 25375 sgd_solver.cpp:105] Iteration 19550, lr = 1e-09
I1223 06:44:12.210867 25375 solver.cpp:219] Iteration 19600 (0.939665 iter/s, 53.2105s/50 iters), loss = 2518.66
I1223 06:44:12.210901 25375 solver.cpp:238]     Train net output #0: loss = 2245.72 (* 1 = 2245.72 loss)
I1223 06:44:12.210907 25375 sgd_solver.cpp:105] Iteration 19600, lr = 1e-09
I1223 06:45:05.493649 25375 solver.cpp:219] Iteration 19650 (0.938407 iter/s, 53.2818s/50 iters), loss = 2512.45
I1223 06:45:05.493687 25375 solver.cpp:238]     Train net output #0: loss = 1785.73 (* 1 = 1785.73 loss)
I1223 06:45:05.493696 25375 sgd_solver.cpp:105] Iteration 19650, lr = 1e-09
I1223 06:45:58.800571 25375 solver.cpp:219] Iteration 19700 (0.937982 iter/s, 53.3059s/50 iters), loss = 2518.7
I1223 06:45:58.800609 25375 solver.cpp:238]     Train net output #0: loss = 756.591 (* 1 = 756.591 loss)
I1223 06:45:58.800616 25375 sgd_solver.cpp:105] Iteration 19700, lr = 1e-09
I1223 06:46:52.548372 25375 solver.cpp:219] Iteration 19750 (0.930288 iter/s, 53.7468s/50 iters), loss = 2504.63
I1223 06:46:52.548405 25375 solver.cpp:238]     Train net output #0: loss = 2429.17 (* 1 = 2429.17 loss)
I1223 06:46:52.548411 25375 sgd_solver.cpp:105] Iteration 19750, lr = 1e-09
I1223 06:47:46.757345 25375 solver.cpp:219] Iteration 19800 (0.922374 iter/s, 54.208s/50 iters), loss = 2492.95
I1223 06:47:46.757385 25375 solver.cpp:238]     Train net output #0: loss = 1704.61 (* 1 = 1704.61 loss)
I1223 06:47:46.757392 25375 sgd_solver.cpp:105] Iteration 19800, lr = 1e-09
I1223 06:48:40.969741 25375 solver.cpp:219] Iteration 19850 (0.922316 iter/s, 54.2114s/50 iters), loss = 2507.52
I1223 06:48:40.969779 25375 solver.cpp:238]     Train net output #0: loss = 707.582 (* 1 = 707.582 loss)
I1223 06:48:40.969785 25375 sgd_solver.cpp:105] Iteration 19850, lr = 1e-09
I1223 06:49:34.111099 25375 solver.cpp:219] Iteration 19900 (0.940904 iter/s, 53.1404s/50 iters), loss = 2512.47
I1223 06:49:34.111131 25375 solver.cpp:238]     Train net output #0: loss = 2447.99 (* 1 = 2447.99 loss)
I1223 06:49:34.111137 25375 sgd_solver.cpp:105] Iteration 19900, lr = 1e-09
I1223 06:50:27.336174 25375 solver.cpp:219] Iteration 19950 (0.939424 iter/s, 53.2241s/50 iters), loss = 2493.47
I1223 06:50:27.336208 25375 solver.cpp:238]     Train net output #0: loss = 1907.69 (* 1 = 1907.69 loss)
I1223 06:50:27.336215 25375 sgd_solver.cpp:105] Iteration 19950, lr = 1e-09
I1223 06:51:21.598340 25375 solver.cpp:219] Iteration 20000 (0.92147 iter/s, 54.2611s/50 iters), loss = 2509.79
I1223 06:51:21.598372 25375 solver.cpp:238]     Train net output #0: loss = 672.727 (* 1 = 672.727 loss)
I1223 06:51:21.598379 25375 sgd_solver.cpp:105] Iteration 20000, lr = 1e-10
I1223 06:52:15.710995 25375 solver.cpp:219] Iteration 20050 (0.924016 iter/s, 54.1116s/50 iters), loss = 2512.13
I1223 06:52:15.711030 25375 solver.cpp:238]     Train net output #0: loss = 2240.25 (* 1 = 2240.25 loss)
I1223 06:52:15.711036 25375 sgd_solver.cpp:105] Iteration 20050, lr = 1e-10
I1223 06:53:10.287060 25375 solver.cpp:219] Iteration 20100 (0.91617 iter/s, 54.575s/50 iters), loss = 2509.93
I1223 06:53:10.287101 25375 solver.cpp:238]     Train net output #0: loss = 1935.82 (* 1 = 1935.82 loss)
I1223 06:53:10.287109 25375 sgd_solver.cpp:105] Iteration 20100, lr = 1e-10
I1223 06:54:02.790956 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_20150.caffemodel
I1223 06:54:03.298828 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_20150.solverstate
I1223 06:54:03.381789 25375 solver.cpp:331] Iteration 20150, Testing net (#0)
I1223 06:55:16.164414 25375 solver.cpp:398]     Test net output #0: loss = 6619.43 (* 1 = 6619.43 loss)
I1223 06:55:16.958796 25375 solver.cpp:219] Iteration 20150 (0.394728 iter/s, 126.669s/50 iters), loss = 2508.17
I1223 06:55:16.958833 25375 solver.cpp:238]     Train net output #0: loss = 709.265 (* 1 = 709.265 loss)
I1223 06:55:16.958839 25375 sgd_solver.cpp:105] Iteration 20150, lr = 1e-10
I1223 06:56:11.707690 25375 solver.cpp:219] Iteration 20200 (0.913277 iter/s, 54.7479s/50 iters), loss = 2509.11
I1223 06:56:11.707727 25375 solver.cpp:238]     Train net output #0: loss = 2189.35 (* 1 = 2189.35 loss)
I1223 06:56:11.707733 25375 sgd_solver.cpp:105] Iteration 20200, lr = 1e-10
I1223 06:57:04.953510 25375 solver.cpp:219] Iteration 20250 (0.939058 iter/s, 53.2449s/50 iters), loss = 2521.69
I1223 06:57:04.953549 25375 solver.cpp:238]     Train net output #0: loss = 1667.66 (* 1 = 1667.66 loss)
I1223 06:57:04.953557 25375 sgd_solver.cpp:105] Iteration 20250, lr = 1e-10
I1223 06:57:58.094184 25375 solver.cpp:219] Iteration 20300 (0.940916 iter/s, 53.1397s/50 iters), loss = 2528.27
I1223 06:57:58.094220 25375 solver.cpp:238]     Train net output #0: loss = 723.316 (* 1 = 723.316 loss)
I1223 06:57:58.094228 25375 sgd_solver.cpp:105] Iteration 20300, lr = 1e-10
I1223 06:58:52.034615 25375 solver.cpp:219] Iteration 20350 (0.926966 iter/s, 53.9394s/50 iters), loss = 2530.42
I1223 06:58:52.034652 25375 solver.cpp:238]     Train net output #0: loss = 2208.56 (* 1 = 2208.56 loss)
I1223 06:58:52.034659 25375 sgd_solver.cpp:105] Iteration 20350, lr = 1e-10
I1223 06:59:45.614382 25375 solver.cpp:219] Iteration 20400 (0.933206 iter/s, 53.5788s/50 iters), loss = 2526.89
I1223 06:59:45.614425 25375 solver.cpp:238]     Train net output #0: loss = 1823.72 (* 1 = 1823.72 loss)
I1223 06:59:45.614434 25375 sgd_solver.cpp:105] Iteration 20400, lr = 1e-10
I1223 07:00:40.330624 25375 solver.cpp:219] Iteration 20450 (0.913823 iter/s, 54.7152s/50 iters), loss = 2536.49
I1223 07:00:40.330662 25375 solver.cpp:238]     Train net output #0: loss = 796.044 (* 1 = 796.044 loss)
I1223 07:00:40.330670 25375 sgd_solver.cpp:105] Iteration 20450, lr = 1e-10
I1223 07:01:34.222113 25375 solver.cpp:219] Iteration 20500 (0.927808 iter/s, 53.8905s/50 iters), loss = 2539.91
I1223 07:01:34.222156 25375 solver.cpp:238]     Train net output #0: loss = 2171.85 (* 1 = 2171.85 loss)
I1223 07:01:34.222163 25375 sgd_solver.cpp:105] Iteration 20500, lr = 1e-10
I1223 07:02:27.613087 25375 solver.cpp:219] Iteration 20550 (0.936505 iter/s, 53.39s/50 iters), loss = 2534.55
I1223 07:02:27.613123 25375 solver.cpp:238]     Train net output #0: loss = 1788.31 (* 1 = 1788.31 loss)
I1223 07:02:27.613129 25375 sgd_solver.cpp:105] Iteration 20550, lr = 1e-10
I1223 07:03:22.482755 25375 solver.cpp:219] Iteration 20600 (0.911267 iter/s, 54.8686s/50 iters), loss = 2524.1
I1223 07:03:22.482796 25375 solver.cpp:238]     Train net output #0: loss = 714.617 (* 1 = 714.617 loss)
I1223 07:03:22.482805 25375 sgd_solver.cpp:105] Iteration 20600, lr = 1e-10
I1223 07:04:14.908608 25375 solver.cpp:219] Iteration 20650 (0.953746 iter/s, 52.4249s/50 iters), loss = 2527.14
I1223 07:04:14.908641 25375 solver.cpp:238]     Train net output #0: loss = 2552.2 (* 1 = 2552.2 loss)
I1223 07:04:14.908648 25375 sgd_solver.cpp:105] Iteration 20650, lr = 1e-10
I1223 07:05:08.236811 25375 solver.cpp:219] Iteration 20700 (0.937608 iter/s, 53.3272s/50 iters), loss = 2532.95
I1223 07:05:08.236847 25375 solver.cpp:238]     Train net output #0: loss = 2107.51 (* 1 = 2107.51 loss)
I1223 07:05:08.236852 25375 sgd_solver.cpp:105] Iteration 20700, lr = 1e-10
I1223 07:06:01.439731 25375 solver.cpp:219] Iteration 20750 (0.939816 iter/s, 53.2019s/50 iters), loss = 2543.92
I1223 07:06:01.439766 25375 solver.cpp:238]     Train net output #0: loss = 709.095 (* 1 = 709.095 loss)
I1223 07:06:01.439774 25375 sgd_solver.cpp:105] Iteration 20750, lr = 1e-10
I1223 07:06:54.360347 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_20800.caffemodel
I1223 07:06:54.900842 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_20800.solverstate
I1223 07:06:54.994293 25375 solver.cpp:331] Iteration 20800, Testing net (#0)
I1223 07:08:07.159059 25375 solver.cpp:398]     Test net output #0: loss = 6441.75 (* 1 = 6441.75 loss)
I1223 07:08:07.955005 25375 solver.cpp:219] Iteration 20800 (0.395216 iter/s, 126.513s/50 iters), loss = 2553.03
I1223 07:08:07.955036 25375 solver.cpp:238]     Train net output #0: loss = 2515.19 (* 1 = 2515.19 loss)
I1223 07:08:07.955044 25375 sgd_solver.cpp:105] Iteration 20800, lr = 1e-10
I1223 07:09:00.339318 25375 solver.cpp:219] Iteration 20850 (0.954501 iter/s, 52.3834s/50 iters), loss = 2534.78
I1223 07:09:00.339354 25375 solver.cpp:238]     Train net output #0: loss = 1662.26 (* 1 = 1662.26 loss)
I1223 07:09:00.339360 25375 sgd_solver.cpp:105] Iteration 20850, lr = 1e-10
I1223 07:09:53.014034 25375 solver.cpp:219] Iteration 20900 (0.949239 iter/s, 52.6738s/50 iters), loss = 2533.01
I1223 07:09:53.014081 25375 solver.cpp:238]     Train net output #0: loss = 768.05 (* 1 = 768.05 loss)
I1223 07:09:53.014088 25375 sgd_solver.cpp:105] Iteration 20900, lr = 1e-10
I1223 07:10:47.142904 25375 solver.cpp:219] Iteration 20950 (0.923739 iter/s, 54.1279s/50 iters), loss = 2553.79
I1223 07:10:47.142938 25375 solver.cpp:238]     Train net output #0: loss = 2523.03 (* 1 = 2523.03 loss)
I1223 07:10:47.142946 25375 sgd_solver.cpp:105] Iteration 20950, lr = 1e-10
I1223 07:11:41.105516 25375 solver.cpp:219] Iteration 21000 (0.926585 iter/s, 53.9616s/50 iters), loss = 2542.14
I1223 07:11:41.105554 25375 solver.cpp:238]     Train net output #0: loss = 2053.01 (* 1 = 2053.01 loss)
I1223 07:11:41.105561 25375 sgd_solver.cpp:105] Iteration 21000, lr = 1e-10
I1223 07:12:35.023157 25375 solver.cpp:219] Iteration 21050 (0.927358 iter/s, 53.9166s/50 iters), loss = 2547.29
I1223 07:12:35.023192 25375 solver.cpp:238]     Train net output #0: loss = 701.953 (* 1 = 701.953 loss)
I1223 07:12:35.023198 25375 sgd_solver.cpp:105] Iteration 21050, lr = 1e-10
I1223 07:13:28.675246 25375 solver.cpp:219] Iteration 21100 (0.931948 iter/s, 53.6511s/50 iters), loss = 2548.2
I1223 07:13:28.675284 25375 solver.cpp:238]     Train net output #0: loss = 2221.82 (* 1 = 2221.82 loss)
I1223 07:13:28.675292 25375 sgd_solver.cpp:105] Iteration 21100, lr = 1e-10
I1223 07:14:21.734386 25375 solver.cpp:219] Iteration 21150 (0.942362 iter/s, 53.0581s/50 iters), loss = 2543.22
I1223 07:14:21.734431 25375 solver.cpp:238]     Train net output #0: loss = 1885.13 (* 1 = 1885.13 loss)
I1223 07:14:21.734441 25375 sgd_solver.cpp:105] Iteration 21150, lr = 1e-10
I1223 07:15:15.506806 25375 solver.cpp:219] Iteration 21200 (0.929862 iter/s, 53.7714s/50 iters), loss = 2542.45
I1223 07:15:15.506842 25375 solver.cpp:238]     Train net output #0: loss = 682.71 (* 1 = 682.71 loss)
I1223 07:15:15.506850 25375 sgd_solver.cpp:105] Iteration 21200, lr = 1e-10
I1223 07:16:09.698809 25375 solver.cpp:219] Iteration 21250 (0.922663 iter/s, 54.191s/50 iters), loss = 2543.48
I1223 07:16:09.698842 25375 solver.cpp:238]     Train net output #0: loss = 2441.51 (* 1 = 2441.51 loss)
I1223 07:16:09.698848 25375 sgd_solver.cpp:105] Iteration 21250, lr = 1e-10
I1223 07:17:04.796708 25375 solver.cpp:219] Iteration 21300 (0.907493 iter/s, 55.0969s/50 iters), loss = 2538.58
I1223 07:17:04.796743 25375 solver.cpp:238]     Train net output #0: loss = 2021.14 (* 1 = 2021.14 loss)
I1223 07:17:04.796749 25375 sgd_solver.cpp:105] Iteration 21300, lr = 1e-10
I1223 07:17:58.733819 25375 solver.cpp:219] Iteration 21350 (0.927023 iter/s, 53.9361s/50 iters), loss = 2545.08
I1223 07:17:58.733856 25375 solver.cpp:238]     Train net output #0: loss = 706.352 (* 1 = 706.352 loss)
I1223 07:17:58.733863 25375 sgd_solver.cpp:105] Iteration 21350, lr = 1e-10
I1223 07:18:54.141389 25375 solver.cpp:219] Iteration 21400 (0.902421 iter/s, 55.4065s/50 iters), loss = 2549.31
I1223 07:18:54.141429 25375 solver.cpp:238]     Train net output #0: loss = 2171.72 (* 1 = 2171.72 loss)
I1223 07:18:54.141439 25375 sgd_solver.cpp:105] Iteration 21400, lr = 1e-10
I1223 07:19:46.471907 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_21450.caffemodel
I1223 07:19:47.109280 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_21450.solverstate
I1223 07:19:47.204550 25375 solver.cpp:331] Iteration 21450, Testing net (#0)
I1223 07:20:59.246575 25375 solver.cpp:398]     Test net output #0: loss = 6605.65 (* 1 = 6605.65 loss)
I1223 07:21:00.038192 25375 solver.cpp:219] Iteration 21450 (0.397158 iter/s, 125.895s/50 iters), loss = 2541
I1223 07:21:00.038228 25375 solver.cpp:238]     Train net output #0: loss = 2124.19 (* 1 = 2124.19 loss)
I1223 07:21:00.038233 25375 sgd_solver.cpp:105] Iteration 21450, lr = 1e-10
I1223 07:21:51.991561 25375 solver.cpp:219] Iteration 21500 (0.962418 iter/s, 51.9524s/50 iters), loss = 2540.32
I1223 07:21:51.991605 25375 solver.cpp:238]     Train net output #0: loss = 781.468 (* 1 = 781.468 loss)
I1223 07:21:51.991611 25375 sgd_solver.cpp:105] Iteration 21500, lr = 1e-10
I1223 07:22:44.090275 25375 solver.cpp:219] Iteration 21550 (0.959734 iter/s, 52.0978s/50 iters), loss = 2540.7
I1223 07:22:44.090313 25375 solver.cpp:238]     Train net output #0: loss = 2467.57 (* 1 = 2467.57 loss)
I1223 07:22:44.090322 25375 sgd_solver.cpp:105] Iteration 21550, lr = 1e-10
I1223 07:23:37.602921 25375 solver.cpp:219] Iteration 21600 (0.934376 iter/s, 53.5117s/50 iters), loss = 2546.52
I1223 07:23:37.602960 25375 solver.cpp:238]     Train net output #0: loss = 1847.81 (* 1 = 1847.81 loss)
I1223 07:23:37.602968 25375 sgd_solver.cpp:105] Iteration 21600, lr = 1e-10
I1223 07:24:31.256520 25375 solver.cpp:219] Iteration 21650 (0.931921 iter/s, 53.6526s/50 iters), loss = 2538.2
I1223 07:24:31.256563 25375 solver.cpp:238]     Train net output #0: loss = 689.399 (* 1 = 689.399 loss)
I1223 07:24:31.256574 25375 sgd_solver.cpp:105] Iteration 21650, lr = 1e-10
I1223 07:25:26.817761 25375 solver.cpp:219] Iteration 21700 (0.899925 iter/s, 55.5602s/50 iters), loss = 2531.2
I1223 07:25:26.817795 25375 solver.cpp:238]     Train net output #0: loss = 2156.61 (* 1 = 2156.61 loss)
I1223 07:25:26.817800 25375 sgd_solver.cpp:105] Iteration 21700, lr = 1e-10
I1223 07:26:19.910290 25375 solver.cpp:219] Iteration 21750 (0.94177 iter/s, 53.0915s/50 iters), loss = 2523.68
I1223 07:26:19.910326 25375 solver.cpp:238]     Train net output #0: loss = 1910.72 (* 1 = 1910.72 loss)
I1223 07:26:19.910332 25375 sgd_solver.cpp:105] Iteration 21750, lr = 1e-10
I1223 07:27:14.570191 25375 solver.cpp:219] Iteration 21800 (0.914764 iter/s, 54.6589s/50 iters), loss = 2527.4
I1223 07:27:14.570226 25375 solver.cpp:238]     Train net output #0: loss = 736.237 (* 1 = 736.237 loss)
I1223 07:27:14.570232 25375 sgd_solver.cpp:105] Iteration 21800, lr = 1e-10
I1223 07:28:08.508173 25375 solver.cpp:219] Iteration 21850 (0.927008 iter/s, 53.937s/50 iters), loss = 2531.11
I1223 07:28:08.508214 25375 solver.cpp:238]     Train net output #0: loss = 2310.94 (* 1 = 2310.94 loss)
I1223 07:28:08.508221 25375 sgd_solver.cpp:105] Iteration 21850, lr = 1e-10
I1223 07:29:02.663300 25375 solver.cpp:219] Iteration 21900 (0.923291 iter/s, 54.1541s/50 iters), loss = 2532.34
I1223 07:29:02.663336 25375 solver.cpp:238]     Train net output #0: loss = 2271.33 (* 1 = 2271.33 loss)
I1223 07:29:02.663341 25375 sgd_solver.cpp:105] Iteration 21900, lr = 1e-10
I1223 07:29:56.404130 25375 solver.cpp:219] Iteration 21950 (0.930409 iter/s, 53.7398s/50 iters), loss = 2522.09
I1223 07:29:56.404168 25375 solver.cpp:238]     Train net output #0: loss = 710.98 (* 1 = 710.98 loss)
I1223 07:29:56.404175 25375 sgd_solver.cpp:105] Iteration 21950, lr = 1e-10
I1223 07:30:50.554401 25375 solver.cpp:219] Iteration 22000 (0.923374 iter/s, 54.1493s/50 iters), loss = 2518.39
I1223 07:30:50.554436 25375 solver.cpp:238]     Train net output #0: loss = 2190.96 (* 1 = 2190.96 loss)
I1223 07:30:50.554442 25375 sgd_solver.cpp:105] Iteration 22000, lr = 1e-10
I1223 07:31:45.323791 25375 solver.cpp:219] Iteration 22050 (0.912936 iter/s, 54.7684s/50 iters), loss = 2507.5
I1223 07:31:45.323833 25375 solver.cpp:238]     Train net output #0: loss = 1776.48 (* 1 = 1776.48 loss)
I1223 07:31:45.323842 25375 sgd_solver.cpp:105] Iteration 22050, lr = 1e-10
I1223 07:32:38.321660 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_22100.caffemodel
I1223 07:32:39.054656 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_22100.solverstate
I1223 07:32:39.161443 25375 solver.cpp:331] Iteration 22100, Testing net (#0)
I1223 07:33:51.198225 25375 solver.cpp:398]     Test net output #0: loss = 6111.67 (* 1 = 6111.67 loss)
I1223 07:33:51.994062 25375 solver.cpp:219] Iteration 22100 (0.394733 iter/s, 126.668s/50 iters), loss = 2500.84
I1223 07:33:51.994099 25375 solver.cpp:238]     Train net output #0: loss = 676.48 (* 1 = 676.48 loss)
I1223 07:33:51.994107 25375 sgd_solver.cpp:105] Iteration 22100, lr = 1e-10
I1223 07:34:44.716351 25375 solver.cpp:219] Iteration 22150 (0.948382 iter/s, 52.7214s/50 iters), loss = 2504.44
I1223 07:34:44.716388 25375 solver.cpp:238]     Train net output #0: loss = 2305.71 (* 1 = 2305.71 loss)
I1223 07:34:44.716394 25375 sgd_solver.cpp:105] Iteration 22150, lr = 1e-10
I1223 07:35:36.697659 25375 solver.cpp:219] Iteration 22200 (0.961902 iter/s, 51.9804s/50 iters), loss = 2501.35
I1223 07:35:36.697692 25375 solver.cpp:238]     Train net output #0: loss = 1741.48 (* 1 = 1741.48 loss)
I1223 07:35:36.697698 25375 sgd_solver.cpp:105] Iteration 22200, lr = 1e-10
I1223 07:36:30.879909 25375 solver.cpp:219] Iteration 22250 (0.922828 iter/s, 54.1813s/50 iters), loss = 2502.41
I1223 07:36:30.879948 25375 solver.cpp:238]     Train net output #0: loss = 782.074 (* 1 = 782.074 loss)
I1223 07:36:30.879957 25375 sgd_solver.cpp:105] Iteration 22250, lr = 1e-10
I1223 07:37:24.655038 25375 solver.cpp:219] Iteration 22300 (0.929815 iter/s, 53.7741s/50 iters), loss = 2500.99
I1223 07:37:24.655079 25375 solver.cpp:238]     Train net output #0: loss = 2128.87 (* 1 = 2128.87 loss)
I1223 07:37:24.655087 25375 sgd_solver.cpp:105] Iteration 22300, lr = 1e-10
I1223 07:38:17.606899 25375 solver.cpp:219] Iteration 22350 (0.944272 iter/s, 52.9509s/50 iters), loss = 2500.93
I1223 07:38:17.606942 25375 solver.cpp:238]     Train net output #0: loss = 1913.66 (* 1 = 1913.66 loss)
I1223 07:38:17.606950 25375 sgd_solver.cpp:105] Iteration 22350, lr = 1e-10
I1223 07:39:11.174057 25375 solver.cpp:219] Iteration 22400 (0.933425 iter/s, 53.5661s/50 iters), loss = 2511.23
I1223 07:39:11.174091 25375 solver.cpp:238]     Train net output #0: loss = 744.268 (* 1 = 744.268 loss)
I1223 07:39:11.174098 25375 sgd_solver.cpp:105] Iteration 22400, lr = 1e-10
I1223 07:40:05.818156 25375 solver.cpp:219] Iteration 22450 (0.915029 iter/s, 54.6431s/50 iters), loss = 2510.87
I1223 07:40:05.818194 25375 solver.cpp:238]     Train net output #0: loss = 2333.05 (* 1 = 2333.05 loss)
I1223 07:40:05.818202 25375 sgd_solver.cpp:105] Iteration 22450, lr = 1e-10
I1223 07:41:00.085711 25375 solver.cpp:219] Iteration 22500 (0.921378 iter/s, 54.2665s/50 iters), loss = 2513.26
I1223 07:41:00.085749 25375 solver.cpp:238]     Train net output #0: loss = 2268.7 (* 1 = 2268.7 loss)
I1223 07:41:00.085757 25375 sgd_solver.cpp:105] Iteration 22500, lr = 1e-10
I1223 07:41:53.073199 25375 solver.cpp:219] Iteration 22550 (0.943637 iter/s, 52.9865s/50 iters), loss = 2513.71
I1223 07:41:53.073241 25375 solver.cpp:238]     Train net output #0: loss = 706.177 (* 1 = 706.177 loss)
I1223 07:41:53.073248 25375 sgd_solver.cpp:105] Iteration 22550, lr = 1e-10
I1223 07:42:47.466585 25375 solver.cpp:219] Iteration 22600 (0.919247 iter/s, 54.3924s/50 iters), loss = 2516.32
I1223 07:42:47.466622 25375 solver.cpp:238]     Train net output #0: loss = 2254.6 (* 1 = 2254.6 loss)
I1223 07:42:47.466629 25375 sgd_solver.cpp:105] Iteration 22600, lr = 1e-10
I1223 07:43:42.900580 25375 solver.cpp:219] Iteration 22650 (0.90199 iter/s, 55.433s/50 iters), loss = 2528.47
I1223 07:43:42.900614 25375 solver.cpp:238]     Train net output #0: loss = 1667.81 (* 1 = 1667.81 loss)
I1223 07:43:42.900621 25375 sgd_solver.cpp:105] Iteration 22650, lr = 1e-10
I1223 07:44:36.685488 25375 solver.cpp:219] Iteration 22700 (0.929646 iter/s, 53.7839s/50 iters), loss = 2534.56
I1223 07:44:36.685525 25375 solver.cpp:238]     Train net output #0: loss = 710.582 (* 1 = 710.582 loss)
I1223 07:44:36.685533 25375 sgd_solver.cpp:105] Iteration 22700, lr = 1e-10
I1223 07:45:30.254256 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_22750.caffemodel
I1223 07:45:31.126616 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_22750.solverstate
I1223 07:45:31.220038 25375 solver.cpp:331] Iteration 22750, Testing net (#0)
I1223 07:46:42.994019 25375 solver.cpp:398]     Test net output #0: loss = 6790.22 (* 1 = 6790.22 loss)
I1223 07:46:43.791409 25375 solver.cpp:219] Iteration 22750 (0.39338 iter/s, 127.104s/50 iters), loss = 2537.98
I1223 07:46:43.791447 25375 solver.cpp:238]     Train net output #0: loss = 2269.53 (* 1 = 2269.53 loss)
I1223 07:46:43.791455 25375 sgd_solver.cpp:105] Iteration 22750, lr = 1e-10
I1223 07:47:37.129695 25375 solver.cpp:219] Iteration 22800 (0.937429 iter/s, 53.3374s/50 iters), loss = 2529.76
I1223 07:47:37.129729 25375 solver.cpp:238]     Train net output #0: loss = 1659.57 (* 1 = 1659.57 loss)
I1223 07:47:37.129735 25375 sgd_solver.cpp:105] Iteration 22800, lr = 1e-10
I1223 07:48:30.893627 25375 solver.cpp:219] Iteration 22850 (0.930008 iter/s, 53.763s/50 iters), loss = 2536.2
I1223 07:48:30.893661 25375 solver.cpp:238]     Train net output #0: loss = 753.504 (* 1 = 753.504 loss)
I1223 07:48:30.893667 25375 sgd_solver.cpp:105] Iteration 22850, lr = 1e-10
I1223 07:49:23.245793 25375 solver.cpp:219] Iteration 22900 (0.955088 iter/s, 52.3512s/50 iters), loss = 2534.48
I1223 07:49:23.245831 25375 solver.cpp:238]     Train net output #0: loss = 2452.31 (* 1 = 2452.31 loss)
I1223 07:49:23.245836 25375 sgd_solver.cpp:105] Iteration 22900, lr = 1e-10
I1223 07:50:16.778092 25375 solver.cpp:219] Iteration 22950 (0.934033 iter/s, 53.5313s/50 iters), loss = 2530.8
I1223 07:50:16.778127 25375 solver.cpp:238]     Train net output #0: loss = 1776.6 (* 1 = 1776.6 loss)
I1223 07:50:16.778134 25375 sgd_solver.cpp:105] Iteration 22950, lr = 1e-10
I1223 07:51:10.676695 25375 solver.cpp:219] Iteration 23000 (0.927685 iter/s, 53.8976s/50 iters), loss = 2534.29
I1223 07:51:10.676731 25375 solver.cpp:238]     Train net output #0: loss = 694.682 (* 1 = 694.682 loss)
I1223 07:51:10.676739 25375 sgd_solver.cpp:105] Iteration 23000, lr = 1e-10
I1223 07:52:04.403100 25375 solver.cpp:219] Iteration 23050 (0.930659 iter/s, 53.7254s/50 iters), loss = 2537.39
I1223 07:52:04.403132 25375 solver.cpp:238]     Train net output #0: loss = 2336.99 (* 1 = 2336.99 loss)
I1223 07:52:04.403139 25375 sgd_solver.cpp:105] Iteration 23050, lr = 1e-10
I1223 07:52:58.240746 25375 solver.cpp:219] Iteration 23100 (0.928736 iter/s, 53.8366s/50 iters), loss = 2550.67
I1223 07:52:58.240787 25375 solver.cpp:238]     Train net output #0: loss = 2283.23 (* 1 = 2283.23 loss)
I1223 07:52:58.240793 25375 sgd_solver.cpp:105] Iteration 23100, lr = 1e-10
I1223 07:53:50.954691 25375 solver.cpp:219] Iteration 23150 (0.948533 iter/s, 52.713s/50 iters), loss = 2557.57
I1223 07:53:50.954725 25375 solver.cpp:238]     Train net output #0: loss = 732.427 (* 1 = 732.427 loss)
I1223 07:53:50.954730 25375 sgd_solver.cpp:105] Iteration 23150, lr = 1e-10
I1223 07:54:45.806994 25375 solver.cpp:219] Iteration 23200 (0.911556 iter/s, 54.8513s/50 iters), loss = 2560.08
I1223 07:54:45.807034 25375 solver.cpp:238]     Train net output #0: loss = 2241.18 (* 1 = 2241.18 loss)
I1223 07:54:45.807041 25375 sgd_solver.cpp:105] Iteration 23200, lr = 1e-10
I1223 07:55:39.861871 25375 solver.cpp:219] Iteration 23250 (0.925003 iter/s, 54.0539s/50 iters), loss = 2562.66
I1223 07:55:39.861908 25375 solver.cpp:238]     Train net output #0: loss = 2021.56 (* 1 = 2021.56 loss)
I1223 07:55:39.861915 25375 sgd_solver.cpp:105] Iteration 23250, lr = 1e-10
I1223 07:56:33.091233 25375 solver.cpp:219] Iteration 23300 (0.939349 iter/s, 53.2284s/50 iters), loss = 2567.98
I1223 07:56:33.091269 25375 solver.cpp:238]     Train net output #0: loss = 684.73 (* 1 = 684.73 loss)
I1223 07:56:33.091275 25375 sgd_solver.cpp:105] Iteration 23300, lr = 1e-10
I1223 07:57:27.266896 25375 solver.cpp:219] Iteration 23350 (0.922941 iter/s, 54.1746s/50 iters), loss = 2569.79
I1223 07:57:27.266927 25375 solver.cpp:238]     Train net output #0: loss = 2219.57 (* 1 = 2219.57 loss)
I1223 07:57:27.266933 25375 sgd_solver.cpp:105] Iteration 23350, lr = 1e-10
I1223 07:58:19.894677 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_23400.caffemodel
I1223 07:58:20.702497 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_23400.solverstate
I1223 07:58:20.799036 25375 solver.cpp:331] Iteration 23400, Testing net (#0)
I1223 07:59:32.515977 25375 solver.cpp:398]     Test net output #0: loss = 6584.73 (* 1 = 6584.73 loss)
I1223 07:59:33.309166 25375 solver.cpp:219] Iteration 23400 (0.396699 iter/s, 126.04s/50 iters), loss = 2555.22
I1223 07:59:33.309200 25375 solver.cpp:238]     Train net output #0: loss = 1748.56 (* 1 = 1748.56 loss)
I1223 07:59:33.309206 25375 sgd_solver.cpp:105] Iteration 23400, lr = 1e-10
I1223 08:00:26.464864 25375 solver.cpp:219] Iteration 23450 (0.94065 iter/s, 53.1548s/50 iters), loss = 2574.62
I1223 08:00:26.464901 25375 solver.cpp:238]     Train net output #0: loss = 678.395 (* 1 = 678.395 loss)
I1223 08:00:26.464910 25375 sgd_solver.cpp:105] Iteration 23450, lr = 1e-10
I1223 08:01:19.418056 25375 solver.cpp:219] Iteration 23500 (0.944247 iter/s, 52.9522s/50 iters), loss = 2576.64
I1223 08:01:19.418094 25375 solver.cpp:238]     Train net output #0: loss = 2153.83 (* 1 = 2153.83 loss)
I1223 08:01:19.418102 25375 sgd_solver.cpp:105] Iteration 23500, lr = 1e-10
I1223 08:02:13.666128 25375 solver.cpp:219] Iteration 23550 (0.921709 iter/s, 54.2471s/50 iters), loss = 2575.08
I1223 08:02:13.666162 25375 solver.cpp:238]     Train net output #0: loss = 2170.68 (* 1 = 2170.68 loss)
I1223 08:02:13.666168 25375 sgd_solver.cpp:105] Iteration 23550, lr = 1e-10
I1223 08:03:05.542466 25375 solver.cpp:219] Iteration 23600 (0.963848 iter/s, 51.8754s/50 iters), loss = 2568.15
I1223 08:03:05.542500 25375 solver.cpp:238]     Train net output #0: loss = 725.31 (* 1 = 725.31 loss)
I1223 08:03:05.542506 25375 sgd_solver.cpp:105] Iteration 23600, lr = 1e-10
I1223 08:03:59.005455 25375 solver.cpp:219] Iteration 23650 (0.935244 iter/s, 53.462s/50 iters), loss = 2570.12
I1223 08:03:59.005491 25375 solver.cpp:238]     Train net output #0: loss = 2144.86 (* 1 = 2144.86 loss)
I1223 08:03:59.005497 25375 sgd_solver.cpp:105] Iteration 23650, lr = 1e-10
I1223 08:04:53.095887 25375 solver.cpp:219] Iteration 23700 (0.924395 iter/s, 54.0894s/50 iters), loss = 2563.54
I1223 08:04:53.095921 25375 solver.cpp:238]     Train net output #0: loss = 2235.21 (* 1 = 2235.21 loss)
I1223 08:04:53.095928 25375 sgd_solver.cpp:105] Iteration 23700, lr = 1e-10
I1223 08:05:45.608837 25375 solver.cpp:219] Iteration 23750 (0.952164 iter/s, 52.512s/50 iters), loss = 2565.43
I1223 08:05:45.608875 25375 solver.cpp:238]     Train net output #0: loss = 719.559 (* 1 = 719.559 loss)
I1223 08:05:45.608881 25375 sgd_solver.cpp:105] Iteration 23750, lr = 1e-10
I1223 08:06:40.520894 25375 solver.cpp:219] Iteration 23800 (0.910564 iter/s, 54.911s/50 iters), loss = 2571.05
I1223 08:06:40.520939 25375 solver.cpp:238]     Train net output #0: loss = 2204.67 (* 1 = 2204.67 loss)
I1223 08:06:40.520947 25375 sgd_solver.cpp:105] Iteration 23800, lr = 1e-10
I1223 08:07:35.375082 25375 solver.cpp:219] Iteration 23850 (0.911525 iter/s, 54.8532s/50 iters), loss = 2564.17
I1223 08:07:35.375124 25375 solver.cpp:238]     Train net output #0: loss = 2056.09 (* 1 = 2056.09 loss)
I1223 08:07:35.375133 25375 sgd_solver.cpp:105] Iteration 23850, lr = 1e-10
I1223 08:08:29.520890 25375 solver.cpp:219] Iteration 23900 (0.92345 iter/s, 54.1448s/50 iters), loss = 2561.89
I1223 08:08:29.520921 25375 solver.cpp:238]     Train net output #0: loss = 718.313 (* 1 = 718.313 loss)
I1223 08:08:29.520927 25375 sgd_solver.cpp:105] Iteration 23900, lr = 1e-10
I1223 08:09:24.257582 25375 solver.cpp:219] Iteration 23950 (0.913481 iter/s, 54.7357s/50 iters), loss = 2567.76
I1223 08:09:24.257621 25375 solver.cpp:238]     Train net output #0: loss = 2215.6 (* 1 = 2215.6 loss)
I1223 08:09:24.257627 25375 sgd_solver.cpp:105] Iteration 23950, lr = 1e-10
I1223 08:10:17.346899 25375 solver.cpp:219] Iteration 24000 (0.941827 iter/s, 53.0883s/50 iters), loss = 2559.26
I1223 08:10:17.346931 25375 solver.cpp:238]     Train net output #0: loss = 1834.86 (* 1 = 1834.86 loss)
I1223 08:10:17.346940 25375 sgd_solver.cpp:105] Iteration 24000, lr = 1e-10
I1223 08:11:09.716758 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_24050.caffemodel
I1223 08:11:10.508774 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_24050.solverstate
I1223 08:11:10.673403 25375 solver.cpp:331] Iteration 24050, Testing net (#0)
I1223 08:12:24.751730 25375 solver.cpp:398]     Test net output #0: loss = 6117.94 (* 1 = 6117.94 loss)
I1223 08:12:25.545784 25375 solver.cpp:219] Iteration 24050 (0.390026 iter/s, 128.197s/50 iters), loss = 2560.9
I1223 08:12:25.545825 25375 solver.cpp:238]     Train net output #0: loss = 701.925 (* 1 = 701.925 loss)
I1223 08:12:25.545832 25375 sgd_solver.cpp:105] Iteration 24050, lr = 1e-10
I1223 08:13:17.210098 25375 solver.cpp:219] Iteration 24100 (0.967803 iter/s, 51.6634s/50 iters), loss = 2561.56
I1223 08:13:17.210134 25375 solver.cpp:238]     Train net output #0: loss = 2234.45 (* 1 = 2234.45 loss)
I1223 08:13:17.210141 25375 sgd_solver.cpp:105] Iteration 24100, lr = 1e-10
I1223 08:14:09.739425 25375 solver.cpp:219] Iteration 24150 (0.951867 iter/s, 52.5284s/50 iters), loss = 2554.31
I1223 08:14:09.739462 25375 solver.cpp:238]     Train net output #0: loss = 1773.45 (* 1 = 1773.45 loss)
I1223 08:14:09.739470 25375 sgd_solver.cpp:105] Iteration 24150, lr = 1e-10
I1223 08:15:04.772956 25375 solver.cpp:219] Iteration 24200 (0.908554 iter/s, 55.0325s/50 iters), loss = 2558.3
I1223 08:15:04.773000 25375 solver.cpp:238]     Train net output #0: loss = 709.308 (* 1 = 709.308 loss)
I1223 08:15:04.773008 25375 sgd_solver.cpp:105] Iteration 24200, lr = 1e-10
I1223 08:15:59.750927 25375 solver.cpp:219] Iteration 24250 (0.909472 iter/s, 54.9769s/50 iters), loss = 2551.35
I1223 08:15:59.750967 25375 solver.cpp:238]     Train net output #0: loss = 2440.97 (* 1 = 2440.97 loss)
I1223 08:15:59.750972 25375 sgd_solver.cpp:105] Iteration 24250, lr = 1e-10
I1223 08:16:53.150960 25375 solver.cpp:219] Iteration 24300 (0.936346 iter/s, 53.399s/50 iters), loss = 2542.38
I1223 08:16:53.150992 25375 solver.cpp:238]     Train net output #0: loss = 1714.21 (* 1 = 1714.21 loss)
I1223 08:16:53.150998 25375 sgd_solver.cpp:105] Iteration 24300, lr = 1e-10
I1223 08:17:46.808327 25375 solver.cpp:219] Iteration 24350 (0.931856 iter/s, 53.6564s/50 iters), loss = 2531.97
I1223 08:17:46.808370 25375 solver.cpp:238]     Train net output #0: loss = 716.376 (* 1 = 716.376 loss)
I1223 08:17:46.808379 25375 sgd_solver.cpp:105] Iteration 24350, lr = 1e-10
I1223 08:18:41.453359 25375 solver.cpp:219] Iteration 24400 (0.915013 iter/s, 54.644s/50 iters), loss = 2532.74
I1223 08:18:41.453390 25375 solver.cpp:238]     Train net output #0: loss = 2173.96 (* 1 = 2173.96 loss)
I1223 08:18:41.453397 25375 sgd_solver.cpp:105] Iteration 24400, lr = 1e-10
I1223 08:19:35.378742 25375 solver.cpp:219] Iteration 24450 (0.927224 iter/s, 53.9244s/50 iters), loss = 2519.04
I1223 08:19:35.378792 25375 solver.cpp:238]     Train net output #0: loss = 1688.14 (* 1 = 1688.14 loss)
I1223 08:19:35.378803 25375 sgd_solver.cpp:105] Iteration 24450, lr = 1e-10
I1223 08:20:27.376786 25375 solver.cpp:219] Iteration 24500 (0.961593 iter/s, 51.9971s/50 iters), loss = 2522.36
I1223 08:20:27.376816 25375 solver.cpp:238]     Train net output #0: loss = 720.092 (* 1 = 720.092 loss)
I1223 08:20:27.376821 25375 sgd_solver.cpp:105] Iteration 24500, lr = 1e-10
I1223 08:21:22.417547 25375 solver.cpp:219] Iteration 24550 (0.908435 iter/s, 55.0397s/50 iters), loss = 2531.84
I1223 08:21:22.417577 25375 solver.cpp:238]     Train net output #0: loss = 2149.64 (* 1 = 2149.64 loss)
I1223 08:21:22.417582 25375 sgd_solver.cpp:105] Iteration 24550, lr = 1e-10
I1223 08:22:16.058152 25375 solver.cpp:219] Iteration 24600 (0.932147 iter/s, 53.6396s/50 iters), loss = 2526.05
I1223 08:22:16.058197 25375 solver.cpp:238]     Train net output #0: loss = 1917.65 (* 1 = 1917.65 loss)
I1223 08:22:16.058205 25375 sgd_solver.cpp:105] Iteration 24600, lr = 1e-10
I1223 08:23:11.956101 25375 solver.cpp:219] Iteration 24650 (0.894504 iter/s, 55.8969s/50 iters), loss = 2529.87
I1223 08:23:11.956135 25375 solver.cpp:238]     Train net output #0: loss = 691.894 (* 1 = 691.894 loss)
I1223 08:23:11.956140 25375 sgd_solver.cpp:105] Iteration 24650, lr = 1e-10
I1223 08:24:05.507390 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_24700.caffemodel
I1223 08:24:06.329416 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_24700.solverstate
I1223 08:24:06.414994 25375 solver.cpp:331] Iteration 24700, Testing net (#0)
I1223 08:25:17.336424 25375 solver.cpp:398]     Test net output #0: loss = 6843.81 (* 1 = 6843.81 loss)
I1223 08:25:18.131142 25375 solver.cpp:219] Iteration 24700 (0.396282 iter/s, 126.173s/50 iters), loss = 2524.75
I1223 08:25:18.131180 25375 solver.cpp:238]     Train net output #0: loss = 2316.1 (* 1 = 2316.1 loss)
I1223 08:25:18.131186 25375 sgd_solver.cpp:105] Iteration 24700, lr = 1e-10
I1223 08:26:11.593102 25375 solver.cpp:219] Iteration 24750 (0.935261 iter/s, 53.461s/50 iters), loss = 2530.74
I1223 08:26:11.593139 25375 solver.cpp:238]     Train net output #0: loss = 1820.94 (* 1 = 1820.94 loss)
I1223 08:26:11.593147 25375 sgd_solver.cpp:105] Iteration 24750, lr = 1e-10
I1223 08:27:05.017901 25375 solver.cpp:219] Iteration 24800 (0.935912 iter/s, 53.4238s/50 iters), loss = 2524.03
I1223 08:27:05.017936 25375 solver.cpp:238]     Train net output #0: loss = 710.83 (* 1 = 710.83 loss)
I1223 08:27:05.017942 25375 sgd_solver.cpp:105] Iteration 24800, lr = 1e-10
I1223 08:27:57.736589 25375 solver.cpp:219] Iteration 24850 (0.948448 iter/s, 52.7177s/50 iters), loss = 2532.58
I1223 08:27:57.736635 25375 solver.cpp:238]     Train net output #0: loss = 2254.55 (* 1 = 2254.55 loss)
I1223 08:27:57.736644 25375 sgd_solver.cpp:105] Iteration 24850, lr = 1e-10
I1223 08:28:51.025216 25375 solver.cpp:219] Iteration 24900 (0.938304 iter/s, 53.2876s/50 iters), loss = 2538.05
I1223 08:28:51.025251 25375 solver.cpp:238]     Train net output #0: loss = 2189.56 (* 1 = 2189.56 loss)
I1223 08:28:51.025259 25375 sgd_solver.cpp:105] Iteration 24900, lr = 1e-10
I1223 08:29:46.427778 25375 solver.cpp:219] Iteration 24950 (0.902502 iter/s, 55.4015s/50 iters), loss = 2530.91
I1223 08:29:46.427810 25375 solver.cpp:238]     Train net output #0: loss = 702.213 (* 1 = 702.213 loss)
I1223 08:29:46.427817 25375 sgd_solver.cpp:105] Iteration 24950, lr = 1e-10
I1223 08:30:40.991704 25375 solver.cpp:219] Iteration 25000 (0.916373 iter/s, 54.5629s/50 iters), loss = 2545.97
I1223 08:30:40.991745 25375 solver.cpp:238]     Train net output #0: loss = 2260.77 (* 1 = 2260.77 loss)
I1223 08:30:40.991753 25375 sgd_solver.cpp:105] Iteration 25000, lr = 1e-10
I1223 08:31:35.230386 25375 solver.cpp:219] Iteration 25050 (0.921869 iter/s, 54.2377s/50 iters), loss = 2544.31
I1223 08:31:35.230423 25375 solver.cpp:238]     Train net output #0: loss = 1916.85 (* 1 = 1916.85 loss)
I1223 08:31:35.230432 25375 sgd_solver.cpp:105] Iteration 25050, lr = 1e-10
I1223 08:32:28.129724 25375 solver.cpp:219] Iteration 25100 (0.945209 iter/s, 52.8983s/50 iters), loss = 2540.11
I1223 08:32:28.129760 25375 solver.cpp:238]     Train net output #0: loss = 775.078 (* 1 = 775.078 loss)
I1223 08:32:28.129766 25375 sgd_solver.cpp:105] Iteration 25100, lr = 1e-10
I1223 08:33:22.619568 25375 solver.cpp:219] Iteration 25150 (0.917619 iter/s, 54.4888s/50 iters), loss = 2535.21
I1223 08:33:22.619597 25375 solver.cpp:238]     Train net output #0: loss = 2241.91 (* 1 = 2241.91 loss)
I1223 08:33:22.619602 25375 sgd_solver.cpp:105] Iteration 25150, lr = 1e-10
I1223 08:34:16.110199 25375 solver.cpp:219] Iteration 25200 (0.934761 iter/s, 53.4896s/50 iters), loss = 2531.66
I1223 08:34:16.110236 25375 solver.cpp:238]     Train net output #0: loss = 1638.1 (* 1 = 1638.1 loss)
I1223 08:34:16.110244 25375 sgd_solver.cpp:105] Iteration 25200, lr = 1e-10
I1223 08:35:09.933199 25375 solver.cpp:219] Iteration 25250 (0.928988 iter/s, 53.822s/50 iters), loss = 2537.11
I1223 08:35:09.933230 25375 solver.cpp:238]     Train net output #0: loss = 743.818 (* 1 = 743.818 loss)
I1223 08:35:09.933236 25375 sgd_solver.cpp:105] Iteration 25250, lr = 1e-10
I1223 08:36:03.570315 25375 solver.cpp:219] Iteration 25300 (0.932208 iter/s, 53.6361s/50 iters), loss = 2535.82
I1223 08:36:03.570356 25375 solver.cpp:238]     Train net output #0: loss = 2153.07 (* 1 = 2153.07 loss)
I1223 08:36:03.570364 25375 sgd_solver.cpp:105] Iteration 25300, lr = 1e-10
I1223 08:36:56.103724 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_25350.caffemodel
I1223 08:36:56.702888 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_25350.solverstate
I1223 08:36:56.787744 25375 solver.cpp:331] Iteration 25350, Testing net (#0)
I1223 08:38:09.514899 25375 solver.cpp:398]     Test net output #0: loss = 6104.09 (* 1 = 6104.09 loss)
I1223 08:38:10.310298 25375 solver.cpp:219] Iteration 25350 (0.394516 iter/s, 126.738s/50 iters), loss = 2538.12
I1223 08:38:10.310340 25375 solver.cpp:238]     Train net output #0: loss = 1766.14 (* 1 = 1766.14 loss)
I1223 08:38:10.310348 25375 sgd_solver.cpp:105] Iteration 25350, lr = 1e-10
I1223 08:39:03.583410 25375 solver.cpp:219] Iteration 25400 (0.938577 iter/s, 53.2721s/50 iters), loss = 2546.96
I1223 08:39:03.583447 25375 solver.cpp:238]     Train net output #0: loss = 713.847 (* 1 = 713.847 loss)
I1223 08:39:03.583454 25375 sgd_solver.cpp:105] Iteration 25400, lr = 1e-10
I1223 08:39:57.017860 25375 solver.cpp:219] Iteration 25450 (0.935743 iter/s, 53.4335s/50 iters), loss = 2546.64
I1223 08:39:57.017901 25375 solver.cpp:238]     Train net output #0: loss = 2261.69 (* 1 = 2261.69 loss)
I1223 08:39:57.017910 25375 sgd_solver.cpp:105] Iteration 25450, lr = 1e-10
I1223 08:40:50.459498 25375 solver.cpp:219] Iteration 25500 (0.935617 iter/s, 53.4407s/50 iters), loss = 2544.07
I1223 08:40:50.459533 25375 solver.cpp:238]     Train net output #0: loss = 1931.18 (* 1 = 1931.18 loss)
I1223 08:40:50.459539 25375 sgd_solver.cpp:105] Iteration 25500, lr = 1e-10
I1223 08:41:43.518697 25375 solver.cpp:219] Iteration 25550 (0.942361 iter/s, 53.0582s/50 iters), loss = 2534.14
I1223 08:41:43.518731 25375 solver.cpp:238]     Train net output #0: loss = 731.571 (* 1 = 731.571 loss)
I1223 08:41:43.518738 25375 sgd_solver.cpp:105] Iteration 25550, lr = 1e-10
I1223 08:42:37.005035 25375 solver.cpp:219] Iteration 25600 (0.934835 iter/s, 53.4854s/50 iters), loss = 2542.85
I1223 08:42:37.005070 25375 solver.cpp:238]     Train net output #0: loss = 2205.27 (* 1 = 2205.27 loss)
I1223 08:42:37.005077 25375 sgd_solver.cpp:105] Iteration 25600, lr = 1e-10
I1223 08:43:31.298998 25375 solver.cpp:219] Iteration 25650 (0.92093 iter/s, 54.293s/50 iters), loss = 2530.97
I1223 08:43:31.299028 25375 solver.cpp:238]     Train net output #0: loss = 2045.55 (* 1 = 2045.55 loss)
I1223 08:43:31.299034 25375 sgd_solver.cpp:105] Iteration 25650, lr = 1e-10
I1223 08:44:23.798686 25375 solver.cpp:219] Iteration 25700 (0.952404 iter/s, 52.4987s/50 iters), loss = 2539.14
I1223 08:44:23.798743 25375 solver.cpp:238]     Train net output #0: loss = 721.034 (* 1 = 721.034 loss)
I1223 08:44:23.798754 25375 sgd_solver.cpp:105] Iteration 25700, lr = 1e-10
I1223 08:45:18.912403 25375 solver.cpp:219] Iteration 25750 (0.907232 iter/s, 55.1127s/50 iters), loss = 2531.65
I1223 08:45:18.912444 25375 solver.cpp:238]     Train net output #0: loss = 2523.9 (* 1 = 2523.9 loss)
I1223 08:45:18.912451 25375 sgd_solver.cpp:105] Iteration 25750, lr = 1e-10
I1223 08:46:12.552042 25375 solver.cpp:219] Iteration 25800 (0.932164 iter/s, 53.6386s/50 iters), loss = 2521.96
I1223 08:46:12.552083 25375 solver.cpp:238]     Train net output #0: loss = 1802.63 (* 1 = 1802.63 loss)
I1223 08:46:12.552090 25375 sgd_solver.cpp:105] Iteration 25800, lr = 1e-10
I1223 08:47:05.290911 25375 solver.cpp:219] Iteration 25850 (0.948085 iter/s, 52.7379s/50 iters), loss = 2512.54
I1223 08:47:05.290948 25375 solver.cpp:238]     Train net output #0: loss = 744.347 (* 1 = 744.347 loss)
I1223 08:47:05.290954 25375 sgd_solver.cpp:105] Iteration 25850, lr = 1e-10
I1223 08:47:59.750455 25375 solver.cpp:219] Iteration 25900 (0.91813 iter/s, 54.4585s/50 iters), loss = 2505.72
I1223 08:47:59.750493 25375 solver.cpp:238]     Train net output #0: loss = 2440.53 (* 1 = 2440.53 loss)
I1223 08:47:59.750499 25375 sgd_solver.cpp:105] Iteration 25900, lr = 1e-10
I1223 08:48:53.903646 25375 solver.cpp:219] Iteration 25950 (0.923324 iter/s, 54.1522s/50 iters), loss = 2509.65
I1223 08:48:53.903686 25375 solver.cpp:238]     Train net output #0: loss = 1702.24 (* 1 = 1702.24 loss)
I1223 08:48:53.903693 25375 sgd_solver.cpp:105] Iteration 25950, lr = 1e-10
I1223 08:49:45.689566 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_26000.caffemodel
I1223 08:49:46.419710 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_26000.solverstate
I1223 08:49:46.504215 25375 solver.cpp:331] Iteration 26000, Testing net (#0)
I1223 08:50:58.765466 25375 solver.cpp:398]     Test net output #0: loss = 6542.31 (* 1 = 6542.31 loss)
I1223 08:50:59.559195 25375 solver.cpp:219] Iteration 26000 (0.39792 iter/s, 125.653s/50 iters), loss = 2505.94
I1223 08:50:59.559232 25375 solver.cpp:238]     Train net output #0: loss = 693.162 (* 1 = 693.162 loss)
I1223 08:50:59.559240 25375 sgd_solver.cpp:105] Iteration 26000, lr = 1e-10
I1223 08:51:51.541355 25375 solver.cpp:219] Iteration 26050 (0.961885 iter/s, 51.9812s/50 iters), loss = 2501.66
I1223 08:51:51.541388 25375 solver.cpp:238]     Train net output #0: loss = 2568.77 (* 1 = 2568.77 loss)
I1223 08:51:51.541394 25375 sgd_solver.cpp:105] Iteration 26050, lr = 1e-10
I1223 08:52:46.398205 25375 solver.cpp:219] Iteration 26100 (0.91148 iter/s, 54.8559s/50 iters), loss = 2502.25
I1223 08:52:46.398239 25375 solver.cpp:238]     Train net output #0: loss = 1954.28 (* 1 = 1954.28 loss)
I1223 08:52:46.398246 25375 sgd_solver.cpp:105] Iteration 26100, lr = 1e-10
I1223 08:53:41.132972 25375 solver.cpp:219] Iteration 26150 (0.913513 iter/s, 54.7338s/50 iters), loss = 2505.7
I1223 08:53:41.133011 25375 solver.cpp:238]     Train net output #0: loss = 670.154 (* 1 = 670.154 loss)
I1223 08:53:41.133018 25375 sgd_solver.cpp:105] Iteration 26150, lr = 1e-10
I1223 08:54:34.424690 25375 solver.cpp:219] Iteration 26200 (0.938249 iter/s, 53.2907s/50 iters), loss = 2503.34
I1223 08:54:34.424726 25375 solver.cpp:238]     Train net output #0: loss = 2507.67 (* 1 = 2507.67 loss)
I1223 08:54:34.424733 25375 sgd_solver.cpp:105] Iteration 26200, lr = 1e-10
I1223 08:55:29.126433 25375 solver.cpp:219] Iteration 26250 (0.914065 iter/s, 54.7007s/50 iters), loss = 2501.62
I1223 08:55:29.126466 25375 solver.cpp:238]     Train net output #0: loss = 1765.28 (* 1 = 1765.28 loss)
I1223 08:55:29.126471 25375 sgd_solver.cpp:105] Iteration 26250, lr = 1e-10
I1223 08:56:23.730902 25375 solver.cpp:219] Iteration 26300 (0.915693 iter/s, 54.6035s/50 iters), loss = 2503.58
I1223 08:56:23.730945 25375 solver.cpp:238]     Train net output #0: loss = 687.51 (* 1 = 687.51 loss)
I1223 08:56:23.730954 25375 sgd_solver.cpp:105] Iteration 26300, lr = 1e-10
I1223 08:57:18.255394 25375 solver.cpp:219] Iteration 26350 (0.917036 iter/s, 54.5235s/50 iters), loss = 2506.88
I1223 08:57:18.255431 25375 solver.cpp:238]     Train net output #0: loss = 2230.83 (* 1 = 2230.83 loss)
I1223 08:57:18.255439 25375 sgd_solver.cpp:105] Iteration 26350, lr = 1e-10
I1223 08:58:11.645700 25375 solver.cpp:219] Iteration 26400 (0.936517 iter/s, 53.3893s/50 iters), loss = 2500.75
I1223 08:58:11.645738 25375 solver.cpp:238]     Train net output #0: loss = 2048.4 (* 1 = 2048.4 loss)
I1223 08:58:11.645745 25375 sgd_solver.cpp:105] Iteration 26400, lr = 1e-10
I1223 08:59:05.087543 25375 solver.cpp:219] Iteration 26450 (0.935614 iter/s, 53.4408s/50 iters), loss = 2501.46
I1223 08:59:05.087579 25375 solver.cpp:238]     Train net output #0: loss = 688.621 (* 1 = 688.621 loss)
I1223 08:59:05.087586 25375 sgd_solver.cpp:105] Iteration 26450, lr = 1e-10
I1223 08:59:58.803203 25375 solver.cpp:219] Iteration 26500 (0.930845 iter/s, 53.7147s/50 iters), loss = 2498.35
I1223 08:59:58.803236 25375 solver.cpp:238]     Train net output #0: loss = 2345.7 (* 1 = 2345.7 loss)
I1223 08:59:58.803242 25375 sgd_solver.cpp:105] Iteration 26500, lr = 1e-10
I1223 09:00:52.513895 25375 solver.cpp:219] Iteration 26550 (0.930931 iter/s, 53.7097s/50 iters), loss = 2506.33
I1223 09:00:52.513923 25375 solver.cpp:238]     Train net output #0: loss = 1788.06 (* 1 = 1788.06 loss)
I1223 09:00:52.513929 25375 sgd_solver.cpp:105] Iteration 26550, lr = 1e-10
I1223 09:01:46.567893 25375 solver.cpp:219] Iteration 26600 (0.925018 iter/s, 54.053s/50 iters), loss = 2506.67
I1223 09:01:46.567925 25375 solver.cpp:238]     Train net output #0: loss = 680.486 (* 1 = 680.486 loss)
I1223 09:01:46.567931 25375 sgd_solver.cpp:105] Iteration 26600, lr = 1e-10
I1223 09:02:38.692862 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_26650.caffemodel
I1223 09:02:39.298187 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_26650.solverstate
I1223 09:02:39.392792 25375 solver.cpp:331] Iteration 26650, Testing net (#0)
I1223 09:03:51.275737 25375 solver.cpp:398]     Test net output #0: loss = 5991.14 (* 1 = 5991.14 loss)
I1223 09:03:52.071772 25375 solver.cpp:219] Iteration 26650 (0.398401 iter/s, 125.502s/50 iters), loss = 2507.61
I1223 09:03:52.071807 25375 solver.cpp:238]     Train net output #0: loss = 2238.62 (* 1 = 2238.62 loss)
I1223 09:03:52.071815 25375 sgd_solver.cpp:105] Iteration 26650, lr = 1e-10
I1223 09:04:46.400992 25375 solver.cpp:219] Iteration 26700 (0.920331 iter/s, 54.3283s/50 iters), loss = 2503.04
I1223 09:04:46.401026 25375 solver.cpp:238]     Train net output #0: loss = 1741.74 (* 1 = 1741.74 loss)
I1223 09:04:46.401031 25375 sgd_solver.cpp:105] Iteration 26700, lr = 1e-10
I1223 09:05:38.720196 25375 solver.cpp:219] Iteration 26750 (0.955689 iter/s, 52.3183s/50 iters), loss = 2504.57
I1223 09:05:38.720227 25375 solver.cpp:238]     Train net output #0: loss = 672.81 (* 1 = 672.81 loss)
I1223 09:05:38.720232 25375 sgd_solver.cpp:105] Iteration 26750, lr = 1e-10
I1223 09:06:32.618046 25375 solver.cpp:219] Iteration 26800 (0.927698 iter/s, 53.8969s/50 iters), loss = 2516.54
I1223 09:06:32.618074 25375 solver.cpp:238]     Train net output #0: loss = 2180.68 (* 1 = 2180.68 loss)
I1223 09:06:32.618080 25375 sgd_solver.cpp:105] Iteration 26800, lr = 1e-10
I1223 09:07:26.626408 25375 solver.cpp:219] Iteration 26850 (0.9258 iter/s, 54.0074s/50 iters), loss = 2518.43
I1223 09:07:26.626444 25375 solver.cpp:238]     Train net output #0: loss = 1691.33 (* 1 = 1691.33 loss)
I1223 09:07:26.626451 25375 sgd_solver.cpp:105] Iteration 26850, lr = 1e-10
I1223 09:08:19.849608 25375 solver.cpp:219] Iteration 26900 (0.939457 iter/s, 53.2222s/50 iters), loss = 2521.08
I1223 09:08:19.849643 25375 solver.cpp:238]     Train net output #0: loss = 705.605 (* 1 = 705.605 loss)
I1223 09:08:19.849650 25375 sgd_solver.cpp:105] Iteration 26900, lr = 1e-10
I1223 09:09:14.236670 25375 solver.cpp:219] Iteration 26950 (0.919353 iter/s, 54.3861s/50 iters), loss = 2526.01
I1223 09:09:14.236704 25375 solver.cpp:238]     Train net output #0: loss = 2550.1 (* 1 = 2550.1 loss)
I1223 09:09:14.236711 25375 sgd_solver.cpp:105] Iteration 26950, lr = 1e-10
I1223 09:10:06.331604 25375 solver.cpp:219] Iteration 27000 (0.959804 iter/s, 52.094s/50 iters), loss = 2517.68
I1223 09:10:06.331647 25375 solver.cpp:238]     Train net output #0: loss = 2073.1 (* 1 = 2073.1 loss)
I1223 09:10:06.331657 25375 sgd_solver.cpp:105] Iteration 27000, lr = 1e-10
I1223 09:11:01.533249 25375 solver.cpp:219] Iteration 27050 (0.905787 iter/s, 55.2006s/50 iters), loss = 2518.8
I1223 09:11:01.533285 25375 solver.cpp:238]     Train net output #0: loss = 773.172 (* 1 = 773.172 loss)
I1223 09:11:01.533293 25375 sgd_solver.cpp:105] Iteration 27050, lr = 1e-10
I1223 09:11:54.607203 25375 solver.cpp:219] Iteration 27100 (0.942099 iter/s, 53.073s/50 iters), loss = 2514.37
I1223 09:11:54.607239 25375 solver.cpp:238]     Train net output #0: loss = 2366.35 (* 1 = 2366.35 loss)
I1223 09:11:54.607246 25375 sgd_solver.cpp:105] Iteration 27100, lr = 1e-10
I1223 09:12:48.953043 25375 solver.cpp:219] Iteration 27150 (0.920051 iter/s, 54.3448s/50 iters), loss = 2505.42
I1223 09:12:48.953083 25375 solver.cpp:238]     Train net output #0: loss = 1991.87 (* 1 = 1991.87 loss)
I1223 09:12:48.953091 25375 sgd_solver.cpp:105] Iteration 27150, lr = 1e-10
I1223 09:13:41.382915 25375 solver.cpp:219] Iteration 27200 (0.953673 iter/s, 52.4289s/50 iters), loss = 2501.06
I1223 09:13:41.382951 25375 solver.cpp:238]     Train net output #0: loss = 724.831 (* 1 = 724.831 loss)
I1223 09:13:41.382958 25375 sgd_solver.cpp:105] Iteration 27200, lr = 1e-10
I1223 09:14:34.596884 25375 solver.cpp:219] Iteration 27250 (0.939621 iter/s, 53.213s/50 iters), loss = 2502.43
I1223 09:14:34.596921 25375 solver.cpp:238]     Train net output #0: loss = 2532.3 (* 1 = 2532.3 loss)
I1223 09:14:34.596928 25375 sgd_solver.cpp:105] Iteration 27250, lr = 1e-10
I1223 09:15:29.087508 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_27300.caffemodel
I1223 09:15:29.787703 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_27300.solverstate
I1223 09:15:29.874517 25375 solver.cpp:331] Iteration 27300, Testing net (#0)
I1223 09:16:40.664865 25375 solver.cpp:398]     Test net output #0: loss = 6810.49 (* 1 = 6810.49 loss)
I1223 09:16:41.461849 25375 solver.cpp:219] Iteration 27300 (0.394127 iter/s, 126.863s/50 iters), loss = 2503.74
I1223 09:16:41.461884 25375 solver.cpp:238]     Train net output #0: loss = 1736.46 (* 1 = 1736.46 loss)
I1223 09:16:41.461889 25375 sgd_solver.cpp:105] Iteration 27300, lr = 1e-10
I1223 09:17:34.332661 25375 solver.cpp:219] Iteration 27350 (0.945718 iter/s, 52.8699s/50 iters), loss = 2512.29
I1223 09:17:34.332700 25375 solver.cpp:238]     Train net output #0: loss = 735.142 (* 1 = 735.142 loss)
I1223 09:17:34.332705 25375 sgd_solver.cpp:105] Iteration 27350, lr = 1e-10
I1223 09:18:26.943305 25375 solver.cpp:219] Iteration 27400 (0.950395 iter/s, 52.6097s/50 iters), loss = 2516.18
I1223 09:18:26.943344 25375 solver.cpp:238]     Train net output #0: loss = 2243.21 (* 1 = 2243.21 loss)
I1223 09:18:26.943352 25375 sgd_solver.cpp:105] Iteration 27400, lr = 1e-10
I1223 09:19:20.556669 25375 solver.cpp:219] Iteration 27450 (0.93262 iter/s, 53.6124s/50 iters), loss = 2520.71
I1223 09:19:20.556704 25375 solver.cpp:238]     Train net output #0: loss = 1769.17 (* 1 = 1769.17 loss)
I1223 09:19:20.556710 25375 sgd_solver.cpp:105] Iteration 27450, lr = 1e-10
I1223 09:20:14.314952 25375 solver.cpp:219] Iteration 27500 (0.930106 iter/s, 53.7573s/50 iters), loss = 2524.98
I1223 09:20:14.314990 25375 solver.cpp:238]     Train net output #0: loss = 788.455 (* 1 = 788.455 loss)
I1223 09:20:14.314997 25375 sgd_solver.cpp:105] Iteration 27500, lr = 1e-10
I1223 09:21:08.761868 25375 solver.cpp:219] Iteration 27550 (0.918343 iter/s, 54.4459s/50 iters), loss = 2512.67
I1223 09:21:08.761905 25375 solver.cpp:238]     Train net output #0: loss = 2588.86 (* 1 = 2588.86 loss)
I1223 09:21:08.761911 25375 sgd_solver.cpp:105] Iteration 27550, lr = 1e-10
I1223 09:22:02.190662 25375 solver.cpp:219] Iteration 27600 (0.935842 iter/s, 53.4278s/50 iters), loss = 2514.13
I1223 09:22:02.190692 25375 solver.cpp:238]     Train net output #0: loss = 1831.67 (* 1 = 1831.67 loss)
I1223 09:22:02.190698 25375 sgd_solver.cpp:105] Iteration 27600, lr = 1e-10
I1223 09:22:54.935885 25375 solver.cpp:219] Iteration 27650 (0.947971 iter/s, 52.7443s/50 iters), loss = 2524.32
I1223 09:22:54.935916 25375 solver.cpp:238]     Train net output #0: loss = 738.306 (* 1 = 738.306 loss)
I1223 09:22:54.935922 25375 sgd_solver.cpp:105] Iteration 27650, lr = 1e-10
I1223 09:23:48.801357 25375 solver.cpp:219] Iteration 27700 (0.928256 iter/s, 53.8645s/50 iters), loss = 2524.85
I1223 09:23:48.801393 25375 solver.cpp:238]     Train net output #0: loss = 2152.37 (* 1 = 2152.37 loss)
I1223 09:23:48.801400 25375 sgd_solver.cpp:105] Iteration 27700, lr = 1e-10
I1223 09:24:42.922777 25375 solver.cpp:219] Iteration 27750 (0.923866 iter/s, 54.1204s/50 iters), loss = 2525.14
I1223 09:24:42.922817 25375 solver.cpp:238]     Train net output #0: loss = 1794.65 (* 1 = 1794.65 loss)
I1223 09:24:42.922824 25375 sgd_solver.cpp:105] Iteration 27750, lr = 1e-10
I1223 09:25:36.977475 25375 solver.cpp:219] Iteration 27800 (0.925006 iter/s, 54.0537s/50 iters), loss = 2519.29
I1223 09:25:36.977516 25375 solver.cpp:238]     Train net output #0: loss = 701.082 (* 1 = 701.082 loss)
I1223 09:25:36.977524 25375 sgd_solver.cpp:105] Iteration 27800, lr = 1e-10
I1223 09:26:30.095425 25375 solver.cpp:219] Iteration 27850 (0.941319 iter/s, 53.117s/50 iters), loss = 2525.43
I1223 09:26:30.095463 25375 solver.cpp:238]     Train net output #0: loss = 2484.49 (* 1 = 2484.49 loss)
I1223 09:26:30.095470 25375 sgd_solver.cpp:105] Iteration 27850, lr = 1e-10
I1223 09:27:25.158685 25375 solver.cpp:219] Iteration 27900 (0.908064 iter/s, 55.0622s/50 iters), loss = 2528.14
I1223 09:27:25.158728 25375 solver.cpp:238]     Train net output #0: loss = 2300.6 (* 1 = 2300.6 loss)
I1223 09:27:25.158736 25375 sgd_solver.cpp:105] Iteration 27900, lr = 1e-10
I1223 09:28:16.897634 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_27950.caffemodel
I1223 09:28:17.491221 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_27950.solverstate
I1223 09:28:17.586076 25375 solver.cpp:331] Iteration 27950, Testing net (#0)
I1223 09:29:29.480224 25375 solver.cpp:398]     Test net output #0: loss = 6332.21 (* 1 = 6332.21 loss)
I1223 09:29:30.276104 25375 solver.cpp:219] Iteration 27950 (0.399632 iter/s, 125.115s/50 iters), loss = 2531.05
I1223 09:29:30.276139 25375 solver.cpp:238]     Train net output #0: loss = 728.674 (* 1 = 728.674 loss)
I1223 09:29:30.276145 25375 sgd_solver.cpp:105] Iteration 27950, lr = 1e-10
I1223 09:30:22.205341 25375 solver.cpp:219] Iteration 28000 (0.962865 iter/s, 51.9283s/50 iters), loss = 2528.07
I1223 09:30:22.205376 25375 solver.cpp:238]     Train net output #0: loss = 2152.31 (* 1 = 2152.31 loss)
I1223 09:30:22.205384 25375 sgd_solver.cpp:105] Iteration 28000, lr = 1e-10
I1223 09:31:16.374910 25375 solver.cpp:219] Iteration 28050 (0.923044 iter/s, 54.1686s/50 iters), loss = 2540.75
I1223 09:31:16.374943 25375 solver.cpp:238]     Train net output #0: loss = 1687.25 (* 1 = 1687.25 loss)
I1223 09:31:16.374948 25375 sgd_solver.cpp:105] Iteration 28050, lr = 1e-10
I1223 09:32:09.286293 25375 solver.cpp:219] Iteration 28100 (0.944993 iter/s, 52.9104s/50 iters), loss = 2548.56
I1223 09:32:09.286334 25375 solver.cpp:238]     Train net output #0: loss = 689.75 (* 1 = 689.75 loss)
I1223 09:32:09.286342 25375 sgd_solver.cpp:105] Iteration 28100, lr = 1e-10
I1223 09:33:03.990916 25375 solver.cpp:219] Iteration 28150 (0.914016 iter/s, 54.7036s/50 iters), loss = 2557.18
I1223 09:33:03.990954 25375 solver.cpp:238]     Train net output #0: loss = 2388.64 (* 1 = 2388.64 loss)
I1223 09:33:03.990960 25375 sgd_solver.cpp:105] Iteration 28150, lr = 1e-10
I1223 09:33:58.079094 25375 solver.cpp:219] Iteration 28200 (0.924434 iter/s, 54.0872s/50 iters), loss = 2557.64
I1223 09:33:58.079131 25375 solver.cpp:238]     Train net output #0: loss = 1971.84 (* 1 = 1971.84 loss)
I1223 09:33:58.079138 25375 sgd_solver.cpp:105] Iteration 28200, lr = 1e-10
I1223 09:34:52.889706 25375 solver.cpp:219] Iteration 28250 (0.912249 iter/s, 54.8096s/50 iters), loss = 2552.67
I1223 09:34:52.889755 25375 solver.cpp:238]     Train net output #0: loss = 763.534 (* 1 = 763.534 loss)
I1223 09:34:52.889761 25375 sgd_solver.cpp:105] Iteration 28250, lr = 1e-10
I1223 09:35:45.625046 25375 solver.cpp:219] Iteration 28300 (0.948148 iter/s, 52.7344s/50 iters), loss = 2546.22
I1223 09:35:45.625079 25375 solver.cpp:238]     Train net output #0: loss = 2222.67 (* 1 = 2222.67 loss)
I1223 09:35:45.625087 25375 sgd_solver.cpp:105] Iteration 28300, lr = 1e-10
I1223 09:36:39.872544 25375 solver.cpp:219] Iteration 28350 (0.921719 iter/s, 54.2465s/50 iters), loss = 2537.12
I1223 09:36:39.872577 25375 solver.cpp:238]     Train net output #0: loss = 1741.49 (* 1 = 1741.49 loss)
I1223 09:36:39.872584 25375 sgd_solver.cpp:105] Iteration 28350, lr = 1e-10
I1223 09:37:34.402753 25375 solver.cpp:219] Iteration 28400 (0.91694 iter/s, 54.5292s/50 iters), loss = 2536.41
I1223 09:37:34.402787 25375 solver.cpp:238]     Train net output #0: loss = 732.515 (* 1 = 732.515 loss)
I1223 09:37:34.402794 25375 sgd_solver.cpp:105] Iteration 28400, lr = 1e-10
I1223 09:38:27.216563 25375 solver.cpp:219] Iteration 28450 (0.94674 iter/s, 52.8128s/50 iters), loss = 2538.71
I1223 09:38:27.216603 25375 solver.cpp:238]     Train net output #0: loss = 2484.2 (* 1 = 2484.2 loss)
I1223 09:38:27.216609 25375 sgd_solver.cpp:105] Iteration 28450, lr = 1e-10
I1223 09:39:21.664650 25375 solver.cpp:219] Iteration 28500 (0.918323 iter/s, 54.4471s/50 iters), loss = 2536.13
I1223 09:39:21.664691 25375 solver.cpp:238]     Train net output #0: loss = 2262.62 (* 1 = 2262.62 loss)
I1223 09:39:21.664700 25375 sgd_solver.cpp:105] Iteration 28500, lr = 1e-10
I1223 09:40:14.966715 25375 solver.cpp:219] Iteration 28550 (0.938067 iter/s, 53.3011s/50 iters), loss = 2545.42
I1223 09:40:14.966747 25375 solver.cpp:238]     Train net output #0: loss = 704.571 (* 1 = 704.571 loss)
I1223 09:40:14.966754 25375 sgd_solver.cpp:105] Iteration 28550, lr = 1e-10
I1223 09:41:07.118191 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_28600.caffemodel
I1223 09:41:07.828006 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_28600.solverstate
I1223 09:41:07.921500 25375 solver.cpp:331] Iteration 28600, Testing net (#0)
I1223 09:42:19.211829 25375 solver.cpp:398]     Test net output #0: loss = 6816.27 (* 1 = 6816.27 loss)
I1223 09:42:20.009024 25375 solver.cpp:219] Iteration 28600 (0.399872 iter/s, 125.04s/50 iters), loss = 2546.37
I1223 09:42:20.009054 25375 solver.cpp:238]     Train net output #0: loss = 2207.83 (* 1 = 2207.83 loss)
I1223 09:42:20.009061 25375 sgd_solver.cpp:105] Iteration 28600, lr = 1e-10
I1223 09:43:13.900712 25375 solver.cpp:219] Iteration 28650 (0.927803 iter/s, 53.8908s/50 iters), loss = 2539.31
I1223 09:43:13.900750 25375 solver.cpp:238]     Train net output #0: loss = 1953.96 (* 1 = 1953.96 loss)
I1223 09:43:13.900758 25375 sgd_solver.cpp:105] Iteration 28650, lr = 1e-10
I1223 09:44:06.192291 25375 solver.cpp:219] Iteration 28700 (0.956194 iter/s, 52.2906s/50 iters), loss = 2536.88
I1223 09:44:06.192334 25375 solver.cpp:238]     Train net output #0: loss = 710.801 (* 1 = 710.801 loss)
I1223 09:44:06.192342 25375 sgd_solver.cpp:105] Iteration 28700, lr = 1e-10
I1223 09:45:00.430991 25375 solver.cpp:219] Iteration 28750 (0.921868 iter/s, 54.2377s/50 iters), loss = 2540.4
I1223 09:45:00.431025 25375 solver.cpp:238]     Train net output #0: loss = 2147.23 (* 1 = 2147.23 loss)
I1223 09:45:00.431031 25375 sgd_solver.cpp:105] Iteration 28750, lr = 1e-10
I1223 09:45:54.275076 25375 solver.cpp:219] Iteration 28800 (0.928624 iter/s, 53.8431s/50 iters), loss = 2544.55
I1223 09:45:54.275120 25375 solver.cpp:238]     Train net output #0: loss = 1995.05 (* 1 = 1995.05 loss)
I1223 09:45:54.275130 25375 sgd_solver.cpp:105] Iteration 28800, lr = 1e-10
I1223 09:46:48.883496 25375 solver.cpp:219] Iteration 28850 (0.915664 iter/s, 54.6052s/50 iters), loss = 2545.89
I1223 09:46:48.883530 25375 solver.cpp:238]     Train net output #0: loss = 690.056 (* 1 = 690.056 loss)
I1223 09:46:48.883536 25375 sgd_solver.cpp:105] Iteration 28850, lr = 1e-10
I1223 09:47:42.361320 25375 solver.cpp:219] Iteration 28900 (0.93499 iter/s, 53.4765s/50 iters), loss = 2544.25
I1223 09:47:42.361357 25375 solver.cpp:238]     Train net output #0: loss = 2458.66 (* 1 = 2458.66 loss)
I1223 09:47:42.361363 25375 sgd_solver.cpp:105] Iteration 28900, lr = 1e-10
I1223 09:48:34.923302 25375 solver.cpp:219] Iteration 28950 (0.951276 iter/s, 52.561s/50 iters), loss = 2537.43
I1223 09:48:34.923344 25375 solver.cpp:238]     Train net output #0: loss = 1785.5 (* 1 = 1785.5 loss)
I1223 09:48:34.923352 25375 sgd_solver.cpp:105] Iteration 28950, lr = 1e-10
I1223 09:49:29.190721 25375 solver.cpp:219] Iteration 29000 (0.92138 iter/s, 54.2664s/50 iters), loss = 2548.42
I1223 09:49:29.190757 25375 solver.cpp:238]     Train net output #0: loss = 741.188 (* 1 = 741.188 loss)
I1223 09:49:29.190765 25375 sgd_solver.cpp:105] Iteration 29000, lr = 1e-10
I1223 09:50:21.625624 25375 solver.cpp:219] Iteration 29050 (0.953581 iter/s, 52.4339s/50 iters), loss = 2547.67
I1223 09:50:21.625659 25375 solver.cpp:238]     Train net output #0: loss = 2429.53 (* 1 = 2429.53 loss)
I1223 09:50:21.625665 25375 sgd_solver.cpp:105] Iteration 29050, lr = 1e-10
I1223 09:51:16.067942 25375 solver.cpp:219] Iteration 29100 (0.91842 iter/s, 54.4413s/50 iters), loss = 2543.79
I1223 09:51:16.067981 25375 solver.cpp:238]     Train net output #0: loss = 2294.28 (* 1 = 2294.28 loss)
I1223 09:51:16.067987 25375 sgd_solver.cpp:105] Iteration 29100, lr = 1e-10
I1223 09:52:10.366921 25375 solver.cpp:219] Iteration 29150 (0.920845 iter/s, 54.298s/50 iters), loss = 2543.99
I1223 09:52:10.366961 25375 solver.cpp:238]     Train net output #0: loss = 725.825 (* 1 = 725.825 loss)
I1223 09:52:10.366969 25375 sgd_solver.cpp:105] Iteration 29150, lr = 1e-10
I1223 09:53:03.962501 25375 solver.cpp:219] Iteration 29200 (0.93293 iter/s, 53.5946s/50 iters), loss = 2550.27
I1223 09:53:03.962543 25375 solver.cpp:238]     Train net output #0: loss = 2170.65 (* 1 = 2170.65 loss)
I1223 09:53:03.962551 25375 sgd_solver.cpp:105] Iteration 29200, lr = 1e-10
I1223 09:53:55.621029 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_29250.caffemodel
I1223 09:53:56.171411 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_29250.solverstate
I1223 09:53:56.264413 25375 solver.cpp:331] Iteration 29250, Testing net (#0)
I1223 09:55:09.275732 25375 solver.cpp:398]     Test net output #0: loss = 5911.41 (* 1 = 5911.41 loss)
I1223 09:55:10.074015 25375 solver.cpp:219] Iteration 29250 (0.396482 iter/s, 126.109s/50 iters), loss = 2544.43
I1223 09:55:10.074053 25375 solver.cpp:238]     Train net output #0: loss = 1746.67 (* 1 = 1746.67 loss)
I1223 09:55:10.074059 25375 sgd_solver.cpp:105] Iteration 29250, lr = 1e-10
I1223 09:56:02.200440 25375 solver.cpp:219] Iteration 29300 (0.959223 iter/s, 52.1255s/50 iters), loss = 2553.15
I1223 09:56:02.200475 25375 solver.cpp:238]     Train net output #0: loss = 693.869 (* 1 = 693.869 loss)
I1223 09:56:02.200481 25375 sgd_solver.cpp:105] Iteration 29300, lr = 1e-10
I1223 09:56:56.261605 25375 solver.cpp:219] Iteration 29350 (0.924895 iter/s, 54.0602s/50 iters), loss = 2547.69
I1223 09:56:56.261638 25375 solver.cpp:238]     Train net output #0: loss = 2322.87 (* 1 = 2322.87 loss)
I1223 09:56:56.261644 25375 sgd_solver.cpp:105] Iteration 29350, lr = 1e-10
I1223 09:57:49.114619 25375 solver.cpp:219] Iteration 29400 (0.946037 iter/s, 52.852s/50 iters), loss = 2548.46
I1223 09:57:49.114656 25375 solver.cpp:238]     Train net output #0: loss = 1744.87 (* 1 = 1744.87 loss)
I1223 09:57:49.114662 25375 sgd_solver.cpp:105] Iteration 29400, lr = 1e-10
I1223 09:58:44.830278 25375 solver.cpp:219] Iteration 29450 (0.89743 iter/s, 55.7146s/50 iters), loss = 2542.32
I1223 09:58:44.830314 25375 solver.cpp:238]     Train net output #0: loss = 756.984 (* 1 = 756.984 loss)
I1223 09:58:44.830322 25375 sgd_solver.cpp:105] Iteration 29450, lr = 1e-10
I1223 09:59:38.131223 25375 solver.cpp:219] Iteration 29500 (0.938087 iter/s, 53.3s/50 iters), loss = 2544.19
I1223 09:59:38.131263 25375 solver.cpp:238]     Train net output #0: loss = 2470.67 (* 1 = 2470.67 loss)
I1223 09:59:38.131271 25375 sgd_solver.cpp:105] Iteration 29500, lr = 1e-10
I1223 10:00:31.566121 25375 solver.cpp:219] Iteration 29550 (0.935735 iter/s, 53.4339s/50 iters), loss = 2541.24
I1223 10:00:31.566160 25375 solver.cpp:238]     Train net output #0: loss = 1989.88 (* 1 = 1989.88 loss)
I1223 10:00:31.566167 25375 sgd_solver.cpp:105] Iteration 29550, lr = 1e-10
I1223 10:01:26.451730 25375 solver.cpp:219] Iteration 29600 (0.911003 iter/s, 54.8846s/50 iters), loss = 2538.37
I1223 10:01:26.451768 25375 solver.cpp:238]     Train net output #0: loss = 748.526 (* 1 = 748.526 loss)
I1223 10:01:26.451776 25375 sgd_solver.cpp:105] Iteration 29600, lr = 1e-10
I1223 10:02:21.899583 25375 solver.cpp:219] Iteration 29650 (0.901765 iter/s, 55.4468s/50 iters), loss = 2537.64
I1223 10:02:21.899618 25375 solver.cpp:238]     Train net output #0: loss = 2219.99 (* 1 = 2219.99 loss)
I1223 10:02:21.899624 25375 sgd_solver.cpp:105] Iteration 29650, lr = 1e-10
I1223 10:03:15.098754 25375 solver.cpp:219] Iteration 29700 (0.939882 iter/s, 53.1982s/50 iters), loss = 2532.52
I1223 10:03:15.098790 25375 solver.cpp:238]     Train net output #0: loss = 1842.35 (* 1 = 1842.35 loss)
I1223 10:03:15.098796 25375 sgd_solver.cpp:105] Iteration 29700, lr = 1e-10
I1223 10:04:08.657835 25375 solver.cpp:219] Iteration 29750 (0.933566 iter/s, 53.5581s/50 iters), loss = 2527.76
I1223 10:04:08.657871 25375 solver.cpp:238]     Train net output #0: loss = 731.78 (* 1 = 731.78 loss)
I1223 10:04:08.657878 25375 sgd_solver.cpp:105] Iteration 29750, lr = 1e-10
I1223 10:05:01.512310 25375 solver.cpp:219] Iteration 29800 (0.946011 iter/s, 52.8535s/50 iters), loss = 2525.67
I1223 10:05:01.512354 25375 solver.cpp:238]     Train net output #0: loss = 2527.67 (* 1 = 2527.67 loss)
I1223 10:05:01.512362 25375 sgd_solver.cpp:105] Iteration 29800, lr = 1e-10
I1223 10:05:55.299484 25375 solver.cpp:219] Iteration 29850 (0.929607 iter/s, 53.7862s/50 iters), loss = 2516.38
I1223 10:05:55.299517 25375 solver.cpp:238]     Train net output #0: loss = 1682.41 (* 1 = 1682.41 loss)
I1223 10:05:55.299525 25375 sgd_solver.cpp:105] Iteration 29850, lr = 1e-10
I1223 10:06:48.600450 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_29900.caffemodel
I1223 10:06:49.124338 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_29900.solverstate
I1223 10:06:49.216881 25375 solver.cpp:331] Iteration 29900, Testing net (#0)
I1223 10:08:01.079813 25375 solver.cpp:398]     Test net output #0: loss = 6769.85 (* 1 = 6769.85 loss)
I1223 10:08:01.876507 25375 solver.cpp:219] Iteration 29900 (0.395023 iter/s, 126.575s/50 iters), loss = 2517.98
I1223 10:08:01.876544 25375 solver.cpp:238]     Train net output #0: loss = 694.819 (* 1 = 694.819 loss)
I1223 10:08:01.876551 25375 sgd_solver.cpp:105] Iteration 29900, lr = 1e-10
I1223 10:08:55.310771 25375 solver.cpp:219] Iteration 29950 (0.935745 iter/s, 53.4333s/50 iters), loss = 2519.58
I1223 10:08:55.310809 25375 solver.cpp:238]     Train net output #0: loss = 2354.79 (* 1 = 2354.79 loss)
I1223 10:08:55.310817 25375 sgd_solver.cpp:105] Iteration 29950, lr = 1e-10
I1223 10:09:47.281008 25375 solver.cpp:448] Snapshotting to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_30000.caffemodel
I1223 10:09:47.783797 25375 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/may/Documents/caffe-masters/caffe-convlstm-master/examples/convLstm/model20/c20_iter_30000.solverstate
I1223 10:09:48.597702 25375 solver.cpp:311] Iteration 30000, loss = 2515.9
I1223 10:09:48.597725 25375 solver.cpp:316] Optimization Done.
I1223 10:09:48.597728 25375 caffe.cpp:259] Optimization Done.
